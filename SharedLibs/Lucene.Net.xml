<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Lucene.Net</name>
    </assembly>
    <members>
        <member name="T:Lucene.Net.Util.Cache.SimpleMapCache">
            <summary> Simple cache implementation that uses a HashMap to store (key, value) pairs.
            This cache is not synchronized, use {@link Cache#SynchronizedCache(Cache)}
            if needed.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.Cache.Cache">
            <summary> Base class for cache implementations.</summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.SynchronizedCache(Lucene.Net.Util.Cache.Cache)">
            <summary> Returns a thread-safe cache backed by the specified cache. 
            In order to guarantee thread-safety, all access to the backed cache must
            be accomplished through the returned cache.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.GetSynchronizedCache">
            <summary> Called by {@link #SynchronizedCache(Cache)}. This method
            returns a {@link SynchronizedCache} instance that wraps
            this instance by default and can be overridden to return
            e. g. subclasses of {@link SynchronizedCache} or this
            in case this cache is already synchronized.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.Put(System.Object,System.Object)">
            <summary> Puts a (key, value)-pair into the cache. </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.Get(System.Object)">
            <summary> Returns the value for the given key. </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.ContainsKey(System.Object)">
            <summary> Returns whether the given key is in this cache. </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.Cache.Close">
            <summary> Closes the cache.</summary>
        </member>
        <member name="T:Lucene.Net.Util.Cache.Cache.SynchronizedCache_Renamed_Class">
            <summary> Simple Cache wrapper that synchronizes all
            calls that access the cache. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.Cache.SimpleMapCache.KeySet">
            <summary> Returns a Set containing all keys in this cache.</summary>
        </member>
        <member name="F:Lucene.Net.Util.Cache.SimpleLRUCache.capacity">
            <summary>
            The maximum number of items to cache.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.Cache.SimpleLRUCache.list">
            <summary>
            The list to efficiently maintain the LRU state.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.Cache.SimpleLRUCache.lookup">
            <summary>
            The dictionary to hash into any location in the list.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.Cache.SimpleLRUCache.openNode">
            <summary>
            The node instance to use/re-use when adding an item to the cache.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.Cache.SimpleLRUCache.ListValueEntry">
            <summary>
            Container to hold the key and value to aid in removal from 
            the <see cref="F:Lucene.Net.Util.Cache.SimpleLRUCache.lookup"/> dictionary when an item is removed from cache.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.ArrayUtil">
            <summary> Methods for manipulating arrays.</summary>
        </member>
        <member name="M:Lucene.Net.Util.ArrayUtil.ParseInt(System.Char[])">
            <summary> Parses the string argument as if it was an int value and returns the
            result. Throws NumberFormatException if the string does not represent an
            int quantity.
            
            </summary>
            <param name="chars">a string representation of an int quantity.
            </param>
            <returns> int the value represented by the argument
            </returns>
            <throws>  NumberFormatException if the argument could not be parsed as an int quantity. </throws>
        </member>
        <member name="M:Lucene.Net.Util.ArrayUtil.ParseInt(System.Char[],System.Int32,System.Int32)">
            <summary> Parses a char array into an int.</summary>
            <param name="chars">the character array
            </param>
            <param name="offset">The offset into the array
            </param>
            <param name="len">The length
            </param>
            <returns> the int
            </returns>
            <throws>  NumberFormatException if it can't parse </throws>
        </member>
        <member name="M:Lucene.Net.Util.ArrayUtil.ParseInt(System.Char[],System.Int32,System.Int32,System.Int32)">
            <summary> Parses the string argument as if it was an int value and returns the
            result. Throws NumberFormatException if the string does not represent an
            int quantity. The second argument specifies the radix to use when parsing
            the value.
            
            </summary>
            <param name="chars">a string representation of an int quantity.
            </param>
            <param name="radix">the base to use for conversion.
            </param>
            <returns> int the value represented by the argument
            </returns>
            <throws>  NumberFormatException if the argument could not be parsed as an int quantity. </throws>
        </member>
        <member name="M:Lucene.Net.Util.ArrayUtil.HashCode(System.Char[],System.Int32,System.Int32)">
            <summary> Returns hash of chars in range start (inclusive) to
            end (inclusive)
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ArrayUtil.HashCode(System.Byte[],System.Int32,System.Int32)">
            <summary> Returns hash of chars in range start (inclusive) to
            end (inclusive)
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.TopScoreDocCollector">
            <summary> A {@link Collector} implementation that collects the top-scoring hits,
            returning them as a {@link TopDocs}. This is used by {@link IndexSearcher} to
            implement {@link TopDocs}-based search. Hits are sorted by score descending
            and then (when the scores are tied) docID ascending. When you create an
            instance of this collector you should know in advance whether documents are
            going to be collected in doc Id order or not.
            
            <p/><b>NOTE</b>: The values {@link Float#NaN} and
            {Float#NEGATIVE_INFINITY} are not valid scores.  This
            collector will not properly collect hits with such
            scores.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.TopDocsCollector">
            <summary> A base class for all collectors that return a {@link TopDocs} output. This
            collector allows easy extension by providing a single constructor which
            accepts a {@link PriorityQueue} as well as protected members for that
            priority queue and a counter of the number of total hits.<br/>
            Extending classes can override {@link #TopDocs(int, int)} and
            {@link #GetTotalHits()} in order to provide their own implementation.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Collector">
            <summary> <p/>Expert: Collectors are primarily meant to be used to
            gather raw results from a search, and implement sorting
            or custom result filtering, collation, etc. <p/>
            
            <p/>As of 2.9, this class replaces the deprecated
            HitCollector, and offers an API for efficient collection
            of hits across sequential {@link IndexReader}s. {@link
            IndexSearcher} advances the collector through each of the
            sub readers, in an arbitrary order. This results in a
            higher performance means of collection.<p/>
            
            <p/>Lucene's core collectors are derived from Collector.
            Likely your application can use one of these classes, or
            subclass {@link TopDocsCollector}, instead of
            implementing Collector directly:
            
            <ul>
            
            <li>{@link TopDocsCollector} is an abstract base class
            that assumes you will retrieve the top N docs,
            according to some criteria, after collection is
            done.  </li>
            
            <li>{@link TopScoreDocCollector} is a concrete subclass
            {@link TopDocsCollector} and sorts according to score +
            docID.  This is used internally by the {@link
            IndexSearcher} search methods that do not take an
            explicit {@link Sort}. It is likely the most frequently
            used collector.</li>
            
            <li>{@link TopFieldCollector} subclasses {@link
            TopDocsCollector} and sorts according to a specified
            {@link Sort} object (sort by field).  This is used
            internally by the {@link IndexSearcher} search methods
            that take an explicit {@link Sort}.</li>
            
            <li>{@link TimeLimitingCollector}, which wraps any other
            Collector and aborts the search if it's taken too much
            time, will subclass Collector in 3.0 (presently it
            subclasses the deprecated HitCollector).</li>
            
            <li>{@link PositiveScoresOnlyCollector} wraps any other
            Collector and prevents collection of hits whose score
            is &lt;= 0.0</li>
            
            </ul>
            
            <p/>Collector decouples the score from the collected doc:
            the score computation is skipped entirely if it's not
            needed.  Collectors that do need the score should
            implement the {@link #setScorer} method, to hold onto the
            passed {@link Scorer} instance, and call {@link
            Scorer#Score()} within the collect method to compute the
            current hit's score.  If your collector may request the
            score for a single hit multiple times, you should use
            {@link ScoreCachingWrappingScorer}. <p/>
            
            <p/><b>NOTE:</b> The doc that is passed to the collect
            method is relative to the current reader. If your
            collector needs to resolve this to the docID space of the
            Multi*Reader, you must re-base it by recording the
            docBase from the most recent setNextReader call.  Here's
            a simple example showing how to collect docIDs into a
            BitSet:<p/>
            
            <pre>
            Searcher searcher = new IndexSearcher(indexReader);
            final BitSet bits = new BitSet(indexReader.maxDoc());
            searcher.search(query, new Collector() {
            private int docBase;
            
            <em>// ignore scorer</em>
            public void setScorer(Scorer scorer) {
            }
            
            <em>// accept docs out of order (for a BitSet it doesn't matter)</em>
            public boolean acceptsDocsOutOfOrder() {
            return true;
            }
            
            public void collect(int doc) {
            bits.set(doc + docBase);
            }
            
            public void setNextReader(IndexReader reader, int docBase) {
            this.docBase = docBase;
            }
            });
            </pre>
            
            <p/>Not all collectors will need to rebase the docID.  For
            example, a collector that simply counts the total number
            of hits would skip it.<p/>
            
            <p/><b>NOTE:</b> Prior to 2.9, Lucene silently filtered
            out hits with score &lt;= 0.  As of 2.9, the core Collectors
            no longer do that.  It's very unusual to have such hits
            (a negative query boost, or function query returning
            negative custom scores, could cause it to happen).  If
            you need that behavior, use {@link
            PositiveScoresOnlyCollector}.<p/>
            
            <p/><b>NOTE:</b> This API is experimental and might change
            in incompatible ways in the next release.<p/>
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.Collector.SetScorer(Lucene.Net.Search.Scorer)">
            <summary> Called before successive calls to {@link #Collect(int)}. Implementations
            that need the score of the current document (passed-in to
            {@link #Collect(int)}), should save the passed-in Scorer and call
            scorer.score() when needed.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Collector.Collect(System.Int32)">
            <summary> Called once for every document matching a query, with the unbased document
            number.
            
            <p/>
            Note: This is called in an inner search loop. For good search performance,
            implementations of this method should not call {@link Searcher#Doc(int)} or
            {@link Lucene.Net.Index.IndexReader#Document(int)} on every hit.
            Doing so can slow searches by an order of magnitude or more.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Collector.SetNextReader(Lucene.Net.Index.IndexReader,System.Int32)">
            <summary> Called before collecting from each IndexReader. All doc ids in
            {@link #Collect(int)} will correspond to reader.
            
            Add docBase to the current IndexReaders internal document id to re-base ids
            in {@link #Collect(int)}.
            
            </summary>
            <param name="reader">next IndexReader
            </param>
            <param name="docBase">
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Collector.AcceptsDocsOutOfOrder">
            <summary>
             * Return <code>true</code> if this collector does not
             * require the matching docIDs to be delivered in int sort
             * order (smallest to largest) to {@link #collect}.
             *
             * <p/> Most Lucene Query implementations will visit
             * matching docIDs in order.  However, some queries
             * (currently limited to certain cases of {@link
             * BooleanQuery}) can achieve faster searching if the
             * <code>Collector</code> allows them to deliver the
             * docIDs out of order.
             *
             * <p/> Many collectors don't mind getting docIDs out of
             * order, so it's important to return <code>true</code>
             * here.
             *
            </summary>
            <returns></returns>
        </member>
        <member name="F:Lucene.Net.Search.TopDocsCollector.pq">
            <summary> The priority queue which holds the top documents. Note that different
            implementations of PriorityQueue give different meaning to 'top documents'.
            HitQueue for example aggregates the top scoring documents, while other PQ
            implementations may hold documents sorted by other criteria.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopDocsCollector.totalHits">
            <summary>The total number of documents that the collector encountered. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.PopulateResults(Lucene.Net.Search.ScoreDoc[],System.Int32)">
            <summary> Populates the results array with the ScoreDoc instaces. This can be
            overridden in case a different ScoreDoc type should be returned.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.NewTopDocs(Lucene.Net.Search.ScoreDoc[],System.Int32)">
            <summary> Returns a {@link TopDocs} instance containing the given results. If
            <code>results</code> is null it means there are no results to return,
            either because there were 0 calls to collect() or because the arguments to
            topDocs were invalid.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.GetTotalHits">
            <summary>The total number of documents that matched this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.TopDocs">
            <summary>Returns the top docs that were collected by this collector. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.TopDocs(System.Int32)">
            <summary> Returns the documents in the rage [start .. pq.size()) that were collected
            by this collector. Note that if start >= pq.size(), an empty TopDocs is
            returned.<br/>
            This method is convenient to call if the application allways asks for the
            last results, starting from the last 'page'.<br/>
            <b>NOTE:</b> you cannot call this method more than once for each search
            execution. If you need to call it more than once, passing each time a
            different <code>start</code>, you should call {@link #TopDocs()} and work
            with the returned {@link TopDocs} object, which will contain all the
            results this search execution collected.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocsCollector.TopDocs(System.Int32,System.Int32)">
            <summary> Returns the documents in the rage [start .. start+howMany) that were
            collected by this collector. Note that if start >= pq.size(), an empty
            TopDocs is returned, and if pq.size() - start &lt; howMany, then only the
            available documents in [start .. pq.size()) are returned.<br/>
            This method is useful to call in case pagination of search results is
            allowed by the search application, as well as it attempts to optimize the
            memory used by allocating only as much as requested by howMany.<br/>
            <b>NOTE:</b> you cannot call this method more than once for each search
            execution. If you need to call it more than once, passing each time a
            different range, you should call {@link #TopDocs()} and work with the
            returned {@link TopDocs} object, which will contain all the results this
            search execution collected.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopScoreDocCollector.create(System.Int32,System.Boolean)">
            <summary> Creates a new {@link TopScoreDocCollector} given the number of hits to
            collect and whether documents are scored in order by the input
            {@link Scorer} to {@link #SetScorer(Scorer)}.
            
            <p/><b>NOTE</b>: The instances returned by this method
            pre-allocate a full array of length
            <code>numHits</code>, and fill the array with sentinel
            objects.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanScorer">
            <summary> Public for extension only.</summary>
        </member>
        <member name="T:Lucene.Net.Search.Scorer">
            <summary> Expert: Common scoring functionality for different types of queries.
            
            <p/>
            A <code>Scorer</code> iterates over documents matching a
            query in increasing order of doc Id.
            <p/>
            <p/>
            Document scores are computed using a given <code>Similarity</code>
            implementation.
            <p/>
            
            <p/><b>NOTE</b>: The values Float.Nan,
            Float.NEGATIVE_INFINITY and Float.POSITIVE_INFINITY are
            not valid scores.  Certain collectors (eg {@link
            TopScoreDocCollector}) will not properly collect hits
            with these scores.
            
            </summary>
            <seealso cref="!:BooleanQuery.setAllowDocsOutOfOrder">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.DocIdSetIterator">
            <summary> This abstract class defines methods to iterate over a set of non-decreasing
            doc ids. Note that this class assumes it iterates on doc Ids, and therefore
            {@link #NO_MORE_DOCS} is set to {@value #NO_MORE_DOCS} in order to be used as
            a sentinel object. Implementations of this class are expected to consider
            {@link Integer#MAX_VALUE} as an invalid value.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.DocIdSetIterator.NO_MORE_DOCS">
            <summary> When returned by {@link #NextDoc()}, {@link #Advance(int)} and
            {@link #Doc()} it means there are no more docs in the iterator.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.Doc">
            <summary> Unsupported anymore. Call {@link #DocID()} instead. This method throws
            {@link UnsupportedOperationException} if called.
            
            </summary>
            <deprecated> use {@link #DocID()} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.DocID">
            <summary> Returns the following:
            <ul>
            <li>-1 or {@link #NO_MORE_DOCS} if {@link #NextDoc()} or
            {@link #Advance(int)} were not called yet.</li>
            <li>{@link #NO_MORE_DOCS} if the iterator has exhausted.</li>
            <li>Otherwise it should return the doc ID it is currently on.</li>
            </ul>
            <p/>
            <b>NOTE:</b> in 3.0, this method will become abstract.
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.Next">
            <summary> Unsupported anymore. Call {@link #NextDoc()} instead. This method throws
            {@link UnsupportedOperationException} if called.
            
            </summary>
            <deprecated> use {@link #NextDoc()} instead. This will be removed in 3.0
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.SkipTo(System.Int32)">
            <summary> Unsupported anymore. Call {@link #Advance(int)} instead. This method throws
            {@link UnsupportedOperationException} if called.
            
            </summary>
            <deprecated> use {@link #Advance(int)} instead. This will be removed in 3.0
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.NextDoc">
            <summary> Advances to the next document in the set and returns the doc it is
            currently on, or {@link #NO_MORE_DOCS} if there are no more docs in the
            set.<br/>
            
            <b>NOTE:</b> in 3.0 this method will become abstract, following the removal
            of {@link #Next()}. For backward compatibility it is implemented as:
            
            <pre>
            public int nextDoc() throws IOException {
            return next() ? doc() : NO_MORE_DOCS;
            }
            </pre>
            
            <b>NOTE:</b> after the iterator has exhausted you should not call this
            method, as it may result in unpredicted behavior.
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSetIterator.Advance(System.Int32)">
            <summary> Advances to the first beyond the current whose document number is greater
            than or equal to <i>target</i>. Returns the current document number or
            {@link #NO_MORE_DOCS} if there are no more docs in the set.
            <p/>
            Behaves as if written:
            
            <pre>
            int advance(int target) {
            int doc;
            while ((doc = nextDoc()) &lt; target) {
            }
            return doc;
            }
            </pre>
            
            Some implementations are considerably more efficient than that.
            <p/>
            <b>NOTE:</b> certain implemenations may return a different value (each
            time) if called several times in a row with the same target.
            <p/>
            <b>NOTE:</b> this method may be called with {@value #NO_MORE_DOCS} for
            efficiency by some Scorers. If your implementation cannot efficiently
            determine that it should exhaust, it is recommended that you check for that
            value in each call to this method.
            <p/>
            <b>NOTE:</b> after the iterator has exhausted you should not call this
            method, as it may result in unpredicted behavior.
            <p/>
            <b>NOTE:</b> in 3.0 this method will become abstract, following the removal
            of {@link #SkipTo(int)}.
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.#ctor(Lucene.Net.Search.Similarity)">
            <summary>Constructs a Scorer.</summary>
            <param name="similarity">The <code>Similarity</code> implementation used by this scorer.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.GetSimilarity">
            <summary>Returns the Similarity implementation used by this scorer. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Score(Lucene.Net.Search.HitCollector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
            <deprecated> use {@link #Score(Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Score(Lucene.Net.Search.Collector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="collector">The collector to which all matching documents are passed.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Score(Lucene.Net.Search.HitCollector,System.Int32)">
            <summary>Expert: Collects matching documents in a range.  Hook for optimization.
            Note that {@link #Next()} must be called once before this method is called
            for the first time.
            </summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            </param>
            <param name="max">Do not score documents past this.
            </param>
            <returns> true if more matching documents may remain.
            </returns>
            <deprecated> use {@link #Score(Collector, int, int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Score(Lucene.Net.Search.Collector,System.Int32,System.Int32)">
            <summary> Expert: Collects matching documents in a range. Hook for optimization.
            Note, <code>firstDocID</code> is added to ensure that {@link #NextDoc()}
            was called before this method.
            
            </summary>
            <param name="collector">The collector to which all matching documents are passed.
            </param>
            <param name="max">Do not score documents past this.
            </param>
            <param name="firstDocID">
            The first document ID (ensures {@link #NextDoc()} is called before
            this method.
            </param>
            <returns> true if more matching documents may remain.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Score">
            <summary>Returns the score of the current document matching the query.
            Initially invalid, until {@link #Next()} or {@link #SkipTo(int)}
            is called the first time, or when called from within
            {@link Collector#collect}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Scorer.Explain(System.Int32)">
            <summary>Returns an explanation of the score for a document.
            <br/>When this method is used, the {@link #Next()}, {@link #SkipTo(int)} and
            {@link #Score(HitCollector)} methods should not be used.
            </summary>
            <param name="doc">The document number for the explanation.
            
            </param>
            <deprecated> Please use {@link IndexSearcher#explain}
            or {@link Weight#explain} instead.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.Spans.SpanScorer.firstTime">
            <deprecated> not needed anymore 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.Spans.Spans">
            <summary>Expert: an enumeration of span matches.  Used to implement span searching.
            Each span represents a range of term positions within a document.  Matches
            are enumerated in order, by increasing document number, within that by
            increasing start position and finally by increasing end position. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.Next">
            <summary>Move to the next match, returning true iff any such exists. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.SkipTo(System.Int32)">
            <summary>Skips to the first match beyond the current, whose document number is
            greater than or equal to <i>target</i>. <p/>Returns true iff there is such
            a match.  <p/>Behaves as if written: <pre>
            boolean skipTo(int target) {
            do {
            if (!next())
            return false;
            } while (target > doc());
            return true;
            }
            </pre>
            Most implementations are considerably more efficient than that.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.Doc">
            <summary>Returns the document number of the current match.  Initially invalid. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.Start">
            <summary>Returns the start position of the current match.  Initially invalid. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.End">
            <summary>Returns the end position of the current match.  Initially invalid. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.GetPayload">
            <summary> Returns the payload data for the current span.
            This is invalid until {@link #Next()} is called for
            the first time.
            This method must not be called more than once after each call
            of {@link #Next()}. However, most payloads are loaded lazily,
            so if the payload data for the current position is not needed,
            this method may not be called at all for performance reasons. An ordered
            SpanQuery does not lazy load, so if you have payloads in your index and
            you do not want ordered SpanNearQuerys to collect payloads, you can
            disable collection with a constructor option.<br/>
            
            Note that the return type is a collection, thus the ordering should not be relied upon.
            <br/>
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Payloads</b> feature is experimental.
            The APIs introduced here might change in the future and will not be
            supported anymore in such a case.</font><p/>
            
            </summary>
            <returns> a List of byte arrays containing the data of this payload, otherwise null if isPayloadAvailable is false
            </returns>
            <throws>  java.io.IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Spans.Spans.IsPayloadAvailable">
            <summary> Checks if a payload can be loaded at this position.
            <p/>
            Payloads can only be loaded once per call to
            {@link #Next()}.
            
            </summary>
            <returns> true if there is a payload available at this position that can be loaded
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanNotQuery">
            <summary>Removes matches which overlap with another SpanQuery. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanQuery">
            <summary>Base class for span-based queries. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Query">
            <summary>The abstract base class for queries.
            <p/>Instantiable subclasses are:
            <ul>
            <li> {@link TermQuery} </li>
            <li> {@link MultiTermQuery} </li>
            <li> {@link BooleanQuery} </li>
            <li> {@link WildcardQuery} </li>
            <li> {@link PhraseQuery} </li>
            <li> {@link PrefixQuery} </li>
            <li> {@link MultiPhraseQuery} </li>
            <li> {@link FuzzyQuery} </li>
            <li> {@link TermRangeQuery} </li>
            <li> {@link NumericRangeQuery} </li>
            <li> {@link Lucene.Net.Search.Spans.SpanQuery} </li>
            </ul>
            <p/>A parser for queries is contained in:
            <ul>
            <li>{@link Lucene.Net.QueryParsers.QueryParser QueryParser} </li>
            </ul>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.SetBoost(System.Single)">
            <summary>Sets the boost for this query clause to <code>b</code>.  Documents
            matching this clause will (in addition to the normal weightings) have
            their score multiplied by <code>b</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.GetBoost">
            <summary>Gets the boost for this clause.  Documents matching
            this clause will (in addition to the normal weightings) have their score
            multiplied by <code>b</code>.   The boost is 1.0 by default.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.ToString(System.String)">
            <summary>Prints a query to a string, with <code>field</code> assumed to be the 
            default field and omitted.
            <p/>The representation used is one that is supposed to be readable
            by {@link Lucene.Net.QueryParsers.QueryParser QueryParser}. However,
            there are the following limitations:
            <ul>
            <li>If the query was created by the parser, the printed
            representation may not be exactly what was parsed. For example,
            characters that need to be escaped will be represented without
            the required backslash.</li>
            <li>Some of the more complicated queries (e.g. span queries)
            don't have a representation that can be parsed by QueryParser.</li>
            </ul>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.ToString">
            <summary>Prints a query to a string. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.CreateWeight(Lucene.Net.Search.Searcher)">
            <summary> Expert: Constructs an appropriate Weight implementation for this query.
            
            <p/>
            Only implemented by primitive queries, which re-write to themselves.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.Weight(Lucene.Net.Search.Searcher)">
            <summary> Expert: Constructs and initializes a Weight for a top-level query.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.Rewrite(Lucene.Net.Index.IndexReader)">
            <summary>Expert: called to re-write queries into primitive queries. For example,
            a PrefixQuery will be rewritten into a BooleanQuery that consists
            of TermQuerys.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.Combine(Lucene.Net.Search.Query[])">
            <summary>Expert: called when re-writing queries under MultiSearcher.
            
            Create a single query suitable for use by all subsearchers (in 1-1
            correspondence with queries). This is an optimization of the OR of
            all queries. We handle the common optimization cases of equal
            queries and overlapping clauses of boolean OR queries (as generated
            by MultiTermQuery.rewrite()).
            Be careful overriding this method as queries[0] determines which
            method will be called and is not necessarily of the same type as
            the other queries.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.ExtractTerms(System.Collections.Hashtable)">
            <summary> Expert: adds all terms occuring in this query to the terms set. Only
            works if this query is in its {@link #rewrite rewritten} form.
            
            </summary>
            <throws>  UnsupportedOperationException if this query is not yet rewritten </throws>
        </member>
        <member name="M:Lucene.Net.Search.Query.MergeBooleanQueries(Lucene.Net.Search.BooleanQuery[])">
            <summary>Expert: merges the clauses of a set of BooleanQuery's into a single
            BooleanQuery.
            
            <p/>A utility for use by {@link #Combine(Query[])} implementations.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.GetSimilarity(Lucene.Net.Search.Searcher)">
            <summary>Expert: Returns the Similarity implementation to be used for this query.
            Subclasses may override this method to specify their own Similarity
            implementation, perhaps one that delegates through that of the Searcher.
            By default the Searcher's Similarity implementation is returned.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Query.Clone">
            <summary>Returns a clone of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanQuery.GetSpans(Lucene.Net.Index.IndexReader)">
            <summary>Expert: Returns the matches for this query in an index.  Used internally
            to search for spans. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanQuery.GetField">
            <summary>Returns the name of the field matched by this query.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:Query.ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNotQuery.#ctor(Lucene.Net.Search.Spans.SpanQuery,Lucene.Net.Search.Spans.SpanQuery)">
            <summary>Construct a SpanNotQuery matching spans from <code>include</code> which
            have no overlap with spans from <code>exclude</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNotQuery.GetInclude">
            <summary>Return the SpanQuery whose matches are filtered. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNotQuery.GetExclude">
            <summary>Return the SpanQuery whose matches must not overlap those returned. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNotQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNotQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="T:Lucene.Net.Search.PrefixFilter">
            <summary> A Filter that restricts search results to values that have a matching prefix in a given
            field.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.MultiTermQueryWrapperFilter">
            <summary> A wrapper for {@link MultiTermQuery}, that exposes its
            functionality as a {@link Filter}.
            <p/>
            <code>MultiTermQueryWrapperFilter</code> is not designed to
            be used by itself. Normally you subclass it to provide a Filter
            counterpart for a {@link MultiTermQuery} subclass.
            <p/>
            For example, {@link TermRangeFilter} and {@link PrefixFilter} extend
            <code>MultiTermQueryWrapperFilter</code>.
            This class also provides the functionality behind
            {@link MultiTermQuery#CONSTANT_SCORE_FILTER_REWRITE};
            this is why it is not abstract.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Filter">
            <summary>Abstract base class for restricting which documents may be returned during searching.
            <p/>
            <b>Note:</b> In Lucene 3.0 {@link #Bits(IndexReader)} will be removed
            and {@link #GetDocIdSet(IndexReader)} will be defined as abstract.
            All implementing classes must therefore implement {@link #GetDocIdSet(IndexReader)}
            in order to work with Lucene 3.0.
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Lucene.Net.Search.Filter.Bits(Lucene.Net.Index.IndexReader)" -->
        <member name="M:Lucene.Net.Search.Filter.GetDocIdSet(Lucene.Net.Index.IndexReader)">
            <summary>
              Creates a {@link DocIdSet} enumerating the documents that should be
              permitted in search results. <b>NOTE:</b> null can be
              returned if no documents are accepted by this Filter.
              <p/>
              Note: This method will be called once per segment in
              the index during searching.  The returned {@link DocIdSet}
              must refer to document IDs for that segment, not for
              the top-level reader.
               
              @param reader a {@link IndexReader} instance opened on the index currently
                       searched on. Note, it is likely that the provided reader does not
                       represent the whole underlying index i.e. if the index has more than
                       one segment the given reader only represents a single segment.
                        
            </summary>
             <returns> a DocIdSet that provides the documents which should be permitted or
             prohibited in search results. <b>NOTE:</b> null can be returned if
             no documents will be accepted by this Filter.
             </returns>
             <seealso cref="T:Lucene.Net.Util.DocIdBitSet">
             </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQueryWrapperFilter.#ctor(Lucene.Net.Search.MultiTermQuery)">
            <summary> Wrap a {@link MultiTermQuery} as a Filter.</summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQueryWrapperFilter.GetTotalNumberOfTerms">
            <summary> Expert: Return the number of unique terms visited during execution of the filter.
            If there are many of them, you may consider using another filter type
            or optimize your total term count in index.
            <p/>This method is not thread safe, be sure to only call it when no filter is running!
            If you re-use the same filter instance for another
            search, be sure to first reset the term counter
            with {@link #clearTotalNumberOfTerms}.
            </summary>
            <seealso cref="!:clearTotalNumberOfTerms">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQueryWrapperFilter.ClearTotalNumberOfTerms">
            <summary> Expert: Resets the counting of unique terms.
            Do this before executing the filter.
            </summary>
            <seealso cref="!:getTotalNumberOfTerms">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQueryWrapperFilter.Bits(Lucene.Net.Index.IndexReader)">
            <summary> Returns a BitSet with true for documents which should be
            permitted in search results, and false for those that should
            not.
            </summary>
            <deprecated> Use {@link #GetDocIdSet(IndexReader)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQueryWrapperFilter.GetDocIdSet(Lucene.Net.Index.IndexReader)">
            <summary> Returns a DocIdSet with documents that should be
            permitted in search results.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PrefixFilter.ToString">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="T:Lucene.Net.Util.PriorityQueue">
            <summary>A PriorityQueue maintains a partial ordering of its elements such that the
            least element can always be found in constant time.  Put()'s and pop()'s
            require log(size) time.
            
            <p/><b>NOTE</b>: This class pre-allocates a full array of
            length <code>maxSize+1</code>, in {@link #initialize}.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.LessThan(System.Object,System.Object)">
            <summary>Determines the ordering of objects in this priority queue.  Subclasses
            must define this one method. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.GetSentinelObject">
            <summary> This method can be overridden by extending classes to return a sentinel
            object which will be used by {@link #Initialize(int)} to fill the queue, so
            that the code which uses that queue can always assume it's full and only
            change the top without attempting to insert any new object.<br/>
            
            Those sentinel values should always compare worse than any non-sentinel
            value (i.e., {@link #LessThan(Object, Object)} should always favor the
            non-sentinel values).<br/>
            
            By default, this method returns false, which means the queue will not be
            filled with sentinel values. Otherwise, the value returned will be used to
            pre-populate the queue. Adds sentinel values to the queue.<br/>
            
            If this method is extended to return a non-null value, then the following
            usage pattern is recommended:
            
            <pre>
            // extends getSentinelObject() to return a non-null value.
            PriorityQueue pq = new MyQueue(numHits);
            // save the 'top' element, which is guaranteed to not be null.
            MyObject pqTop = (MyObject) pq.top();
            &lt;...&gt;
            // now in order to add a new element, which is 'better' than top (after 
            // you've verified it is better), it is as simple as:
            pqTop.change().
            pqTop = pq.updateTop();
            </pre>
            
            <b>NOTE:</b> if this method returns a non-null value, it will be called by
            {@link #Initialize(int)} {@link #Size()} times, relying on a new object to
            be returned and will not check if it's null again. Therefore you should
            ensure any call to this method creates a new instance and behaves
            consistently, e.g., it cannot return null if it previously returned
            non-null.
            
            </summary>
            <returns> the sentinel object to use to pre-populate the queue, or null if
            sentinel objects are not supported.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Initialize(System.Int32)">
            <summary>Subclass constructors must call this. </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Put(System.Object)">
            <summary> Adds an Object to a PriorityQueue in log(size) time. If one tries to add
            more objects than maxSize from initialize a RuntimeException
            (ArrayIndexOutOfBound) is thrown.
            
            </summary>
            <deprecated> use {@link #Add(Object)} which returns the new top object,
            saving an additional call to {@link #Top()}.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Add(System.Object)">
            <summary> Adds an Object to a PriorityQueue in log(size) time. If one tries to add
            more objects than maxSize from initialize an
            {@link ArrayIndexOutOfBoundsException} is thrown.
            
            </summary>
            <returns> the new 'top' element in the queue.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Insert(System.Object)">
            <summary> Adds element to the PriorityQueue in log(size) time if either the
            PriorityQueue is not full, or not lessThan(element, top()).
            
            </summary>
            <param name="element">
            </param>
            <returns> true if element is added, false otherwise.
            </returns>
            <deprecated> use {@link #InsertWithOverflow(Object)} instead, which
            encourages objects reuse.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.InsertWithOverflow(System.Object)">
            <summary> insertWithOverflow() is the same as insert() except its
            return value: it returns the object (if any) that was
            dropped off the heap because it was full. This can be
            the given parameter (in case it is smaller than the
            full heap's minimum, and couldn't be added), or another
            object that was previously the smallest value in the
            heap and now has been replaced by a larger one, or null
            if the queue wasn't yet full with maxSize elements.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Top">
            <summary>Returns the least element of the PriorityQueue in constant time. </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Pop">
            <summary>Removes and returns the least element of the PriorityQueue in log(size)
            time. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.AdjustTop">
            <summary> Should be called when the Object at top changes values. Still log(n) worst
            case, but it's at least twice as fast to
            
            <pre>
            pq.top().change();
            pq.adjustTop();
            </pre>
            
            instead of
            
            <pre>
            o = pq.pop();
            o.change();
            pq.push(o);
            </pre>
            
            </summary>
            <deprecated> use {@link #UpdateTop()} which returns the new top element and
            saves an additional call to {@link #Top()}.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.UpdateTop">
            <summary> Should be called when the Object at top changes values. Still log(n) worst
            case, but it's at least twice as fast to
            
            <pre>
            pq.top().change();
            pq.updateTop();
            </pre>
            
            instead of
            
            <pre>
            o = pq.pop();
            o.change();
            pq.push(o);
            </pre>
            
            </summary>
            <returns> the new 'top' element.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Size">
            <summary>Returns the number of elements currently stored in the PriorityQueue. </summary>
        </member>
        <member name="M:Lucene.Net.Util.PriorityQueue.Clear">
            <summary>Removes all entries from the PriorityQueue. </summary>
        </member>
        <member name="M:Lucene.Net.Search.HitQueue.#ctor(System.Int32,System.Boolean)">
            <summary> Creates a new instance with <code>size</code> elements. If
            <code>prePopulate</code> is set to true, the queue will pre-populate itself
            with sentinel objects and set its {@link #Size()} to <code>size</code>. In
            that case, you should not rely on {@link #Size()} to get the number of
            actual elements that were added to the queue, but keep track yourself.<br/>
            <b>NOTE:</b> in case <code>prePopulate</code> is true, you should pop
            elements from the queue using the following code example:
            
            <pre>
            PriorityQueue pq = new HitQueue(10, true); // pre-populate.
            ScoreDoc top = pq.top();
            
            // Add/Update one element.
            top.score = 1.0f;
            top.doc = 0;
            top = (ScoreDoc) pq.updateTop();
            int totalHits = 1;
            
            // Now pop only the elements that were *truly* inserted.
            // First, pop all the sentinel elements (there are pq.size() - totalHits).
            for (int i = pq.size() - totalHits; i &gt; 0; i--) pq.pop();
            
            // Now pop the truly added elements.
            ScoreDoc[] results = new ScoreDoc[totalHits];
            for (int i = totalHits - 1; i &gt;= 0; i--) {
            results[i] = (ScoreDoc) pq.pop();
            }
            </pre>
            
            <p/><b>NOTE</b>: This class pre-allocate a full array of
            length <code>size</code>.
            
            </summary>
            <param name="size">the requested size of this queue.
            </param>
            <param name="prePopulate">specifies whether to pre-populate the queue with sentinel values.
            </param>
            <seealso cref="M:Lucene.Net.Search.HitQueue.GetSentinelObject">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.FuzzyTermEnum">
            <summary>Subclass of FilteredTermEnum for enumerating all terms that are similiar
            to the specified filter term.
            
            <p/>Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FilteredTermEnum">
            <summary>Abstract class for enumerating a subset of all terms. 
            <p/>Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.  
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermEnum">
            <summary>Abstract class for enumerating terms.
            <p/>Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermEnum.Next">
            <summary>Increments the enumeration to the next element.  True if one exists.</summary>
        </member>
        <member name="M:Lucene.Net.Index.TermEnum.Term">
            <summary>Returns the current Term in the enumeration.</summary>
        </member>
        <member name="M:Lucene.Net.Index.TermEnum.DocFreq">
            <summary>Returns the docFreq of the current Term in the enumeration.</summary>
        </member>
        <member name="M:Lucene.Net.Index.TermEnum.Close">
            <summary>Closes the enumeration to further activity, freeing resources. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermEnum.SkipTo(Lucene.Net.Index.Term)">
            <summary>Skips terms to the first beyond the current whose value is
            greater or equal to <i>target</i>. <p/>Returns true iff there is such
            an entry.  <p/>Behaves as if written: <pre>
            public boolean skipTo(Term target) {
            do {
            if (!next())
            return false;
            } while (target > term());
            return true;
            }
            </pre>
            Some implementations *could* be considerably more efficient than a linear scan.
            Check the implementation to be sure.
            </summary>
            <deprecated> This method is not performant and will be removed in Lucene 3.0.
            Use {@link IndexReader#Terms(Term)} to create a new TermEnum positioned at a
            given term.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.FilteredTermEnum.currentTerm">
            <summary>the current term </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilteredTermEnum.actualEnum">
            <summary>the delegate enum - to set this member use {@link #setEnum} </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.TermCompare(Lucene.Net.Index.Term)">
            <summary>Equality compare on the term </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.Difference">
            <summary>Equality measure on the term </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.EndEnum">
            <summary>Indicates the end of the enumeration has been reached </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.SetEnum(Lucene.Net.Index.TermEnum)">
            <summary> use this method to set the actual TermEnum (e.g. in ctor),
            it will be automatically positioned on the first matching term.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.DocFreq">
            <summary> Returns the docFreq of the current Term in the enumeration.
            Returns -1 if no Term matches or all terms have been enumerated.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.Next">
            <summary>Increments the enumeration to the next element.  True if one exists. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.Term">
            <summary>Returns the current Term in the enumeration.
            Returns null if no Term matches or all terms have been enumerated. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredTermEnum.Close">
            <summary>Closes the enumeration to further activity, freeing resources.  </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term)">
            <summary> Creates a FuzzyTermEnum with an empty prefix and a minSimilarity of 0.5f.
            <p/>
            After calling the constructor the enumeration is already pointing to the first 
            valid term if such a term exists. 
            
            </summary>
            <param name="reader">
            </param>
            <param name="term">
            </param>
            <throws>  IOException </throws>
            <seealso cref="M:Lucene.Net.Search.FuzzyTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term,System.Single,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term,System.Single)">
            <summary> Creates a FuzzyTermEnum with an empty prefix.
            <p/>
            After calling the constructor the enumeration is already pointing to the first 
            valid term if such a term exists. 
            
            </summary>
            <param name="reader">
            </param>
            <param name="term">
            </param>
            <param name="minSimilarity">
            </param>
            <throws>  IOException </throws>
            <seealso cref="M:Lucene.Net.Search.FuzzyTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term,System.Single,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term,System.Single,System.Int32)">
            <summary> Constructor for enumeration of all terms from specified <code>reader</code> which share a prefix of
            length <code>prefixLength</code> with <code>term</code> and which have a fuzzy similarity &gt;
            <code>minSimilarity</code>.
            <p/>
            After calling the constructor the enumeration is already pointing to the first 
            valid term if such a term exists. 
            
            </summary>
            <param name="reader">Delivers terms.
            </param>
            <param name="term">Pattern term.
            </param>
            <param name="minSimilarity">Minimum required similarity for terms from the reader. Default value is 0.5f.
            </param>
            <param name="prefixLength">Length of required common prefix. Default value is 0.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.TermCompare(Lucene.Net.Index.Term)">
            <summary> The termCompare method in FuzzyTermEnum uses Levenshtein distance to 
            calculate the distance between the given term and the comparing term. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.Min(System.Int32,System.Int32,System.Int32)">
            <summary> Finds and returns the smallest of three integers </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.Similarity(System.String)">
            <summary> <p/>Similarity returns a number that is 1.0f or less (including negative numbers)
            based on how similar the Term is compared to a target term.  It returns
            exactly 0.0f when
            <pre>
            editDistance &lt; maximumEditDistance</pre>
            Otherwise it returns:
            <pre>
            1 - (editDistance / length)</pre>
            where length is the length of the shortest term (text or target) including a
            prefix that are identical and editDistance is the Levenshtein distance for
            the two words.<p/>
            
            <p/>Embedded within this algorithm is a fail-fast Levenshtein distance
            algorithm.  The fail-fast algorithm differs from the standard Levenshtein
            distance algorithm in that it is aborted if it is discovered that the
            mimimum distance between the words is greater than some threshold.
            
            <p/>To calculate the maximum distance threshold we use the following formula:
            <pre>
            (1 - minimumSimilarity) * length</pre>
            where length is the shortest term including any prefix that is not part of the
            similarity comparision.  This formula was derived by solving for what maximum value
            of distance returns false for the following statements:
            <pre>
            similarity = 1 - ((float)distance / (float) (prefixLength + Math.min(textlen, targetlen)));
            return (similarity > minimumSimilarity);</pre>
            where distance is the Levenshtein distance for the two words.
            <p/>
            <p/>Levenshtein distance (also known as edit distance) is a measure of similiarity
            between two strings where the distance is measured as the number of character
            deletions, insertions or substitutions required to transform one string to
            the other string.
            </summary>
            <param name="target">the target word or phrase
            </param>
            <returns> the similarity,  0.0 or less indicates that it matches less than the required
            threshold and 1.0 indicates that the text and target are identical
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.GrowDistanceArray(System.Int32)">
            <summary> Grow the second dimension of the array, so that we can calculate the
            Levenshtein difference.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyTermEnum.GetMaxDistance(System.Int32)">
            <summary> The max Distance is the maximum Levenshtein distance for the text
            compared to some other value that results in score that is
            better than the minimum similarity.
            </summary>
            <param name="m">the length of the "other value"
            </param>
            <returns> the maximum levenshtein distance that we care about
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.Function.FloatFieldSource">
            <summary> Expert: obtains float field values from the 
            {@link Lucene.Net.Search.FieldCache FieldCache}
            using <code>getFloats()</code> and makes those values 
            available as other numeric types, casting as needed.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.Function.FieldCacheSource"> for requirements"
            on the field.
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.Function.FieldCacheSource">
            <summary> Expert: A base class for ValueSource implementations that retrieve values for
            a single field from the {@link Lucene.Net.Search.FieldCache FieldCache}.
            <p/>
            Fields used herein nust be indexed (doesn't matter if these fields are stored or not).
            <p/> 
            It is assumed that each such indexed field is untokenized, or at least has a single token in a document.
            For documents with multiple tokens of the same field, behavior is undefined (It is likely that current 
            code would use the value of one of these tokens, but this is not guaranteed).
            <p/>
            Document with no tokens in this field are assigned the <code>Zero</code> value.    
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.ValueSource">
            <summary> Expert: source of values for basic function queries.
            <p/>At its default/simplest form, values - one per doc - are used as the score of that doc.
            <p/>Values are instantiated as 
            {@link Lucene.Net.Search.Function.DocValues DocValues} for a particular reader.
            <p/>ValueSource implementations differ in RAM requirements: it would always be a factor
            of the number of documents, but for each document the number of bytes can be 1, 2, 4, or 8. 
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSource.GetValues(Lucene.Net.Index.IndexReader)">
            <summary> Return the DocValues used by the function query.</summary>
            <param name="reader">the IndexReader used to read these values.
            If any caching is involved, that caching would also be IndexReader based.  
            </param>
            <throws>  IOException for any error. </throws>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSource.Description">
            <summary> description of field, used in explain() </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSource.Equals(System.Object)">
            <summary> Needed for possible caching of query results - used by {@link ValueSourceQuery#equals(Object)}.</summary>
            <seealso cref="!:Object.equals(Object)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSource.GetHashCode">
            <summary> Needed for possible caching of query results - used by {@link ValueSourceQuery#hashCode()}.</summary>
            <seealso cref="!:Object.hashCode()">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.FieldCacheSource.#ctor(System.String)">
            <summary> Create a cached field source for the input field.  </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.FieldCacheSource.GetCachedFieldValues(Lucene.Net.Search.FieldCache,System.String,Lucene.Net.Index.IndexReader)">
            <summary> Return cached DocValues for input field and reader.</summary>
            <param name="cache">FieldCache so that values of a field are loaded once per reader (RAM allowing)
            </param>
            <param name="field">Field for which values are required.
            </param>
            <seealso cref="T:Lucene.Net.Search.Function.ValueSource">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.FieldCacheSource.CachedFieldSourceEquals(Lucene.Net.Search.Function.FieldCacheSource)">
            <summary> Check if equals to another {@link FieldCacheSource}, already knowing that cache and field are equal.  </summary>
            <seealso cref="!:Object.equals(java.lang.Object)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.FieldCacheSource.CachedFieldSourceHashCode">
            <summary> Return a hash code of a {@link FieldCacheSource}, without the hash-codes of the field 
            and the cache (those are taken care of elsewhere).  
            </summary>
            <seealso cref="!:Object.hashCode()">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.FloatFieldSource.#ctor(System.String)">
            <summary> Create a cached float field source with default string-to-float parser. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.FloatFieldSource.#ctor(System.String,Lucene.Net.Search.FloatParser)">
            <summary> Create a cached float field source with a specific string-to-float parser. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.DocValues">
            <summary> Expert: represents field values as different types.
            Normally created via a 
            {@link Lucene.Net.Search.Function.ValueSource ValueSuorce} 
            for a particular field and reader.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.FloatVal(System.Int32)">
            <summary> Return doc value as a float. 
            <p/>Mandatory: every DocValues implementation must implement at least this method. 
            </summary>
            <param name="doc">document whose float value is requested. 
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.IntVal(System.Int32)">
            <summary> Return doc value as an int. 
            <p/>Optional: DocValues implementation can (but don't have to) override this method. 
            </summary>
            <param name="doc">document whose int value is requested.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.LongVal(System.Int32)">
            <summary> Return doc value as a long. 
            <p/>Optional: DocValues implementation can (but don't have to) override this method. 
            </summary>
            <param name="doc">document whose long value is requested.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.DoubleVal(System.Int32)">
            <summary> Return doc value as a double. 
            <p/>Optional: DocValues implementation can (but don't have to) override this method. 
            </summary>
            <param name="doc">document whose double value is requested.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.StrVal(System.Int32)">
            <summary> Return doc value as a string. 
            <p/>Optional: DocValues implementation can (but don't have to) override this method. 
            </summary>
            <param name="doc">document whose string value is requested.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.ToString(System.Int32)">
            <summary> Return a string representation of a doc value, as reuired for Explanations.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.Explain(System.Int32)">
            <summary> Explain the scoring value for the input doc.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.GetInnerArray">
            <summary> Expert: for test purposes only, return the inner array of values, or null if not applicable.
            <p/>
            Allows tests to verify that loaded values are:
            <ol>
            <li>indeed cached/reused.</li>
            <li>stored in the expected size/type (byte/short/int/float).</li>
            </ol>
            Note: implementations of DocValues must override this method for 
            these test elements to be tested, Otherwise the test would not fail, just 
            print a warning.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.GetMinValue">
            <summary> Returns the minimum of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value.
            <p/>
            This operation is optional
            <p/>
            
            </summary>
            <returns> the minimum of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.GetMaxValue">
            <summary> Returns the maximum of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value.
            <p/>
            This operation is optional
            <p/>
            
            </summary>
            <returns> the maximum of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Function.DocValues.GetAverageValue">
            <summary> Returns the average of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value. *
            <p/>
            This operation is optional
            <p/>
            
            </summary>
            <returns> the average of all values or <code>Float.NaN</code> if this
            DocValues instance does not contain any value
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.TermPositions">
            <summary> TermPositions provides an interface for enumerating the &lt;document,
            frequency, &lt;position&gt;* &gt; tuples for a term.  <p/> The document and
            frequency are the same as for a TermDocs.  The positions portion lists the ordinal
            positions of each occurrence of a term in a document.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.TermPositions">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Index.TermDocs">
            <summary>TermDocs provides an interface for enumerating &lt;document, frequency&gt;
            pairs for a term.  <p/> The document portion names each document containing
            the term.  Documents are indicated by number.  The frequency portion gives
            the number of times the term occurred in each document.  <p/> The pairs are
            ordered by document number.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.TermDocs">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Seek(Lucene.Net.Index.Term)">
            <summary>Sets this to the data for a term.
            The enumeration is reset to the start of the data for this term.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Seek(Lucene.Net.Index.TermEnum)">
            <summary>Sets this to the data for the current term in a {@link TermEnum}.
            This may be optimized in some implementations.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Doc">
            <summary>Returns the current document number.  <p/> This is invalid until {@link
            #Next()} is called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Freq">
            <summary>Returns the frequency of the term within the current document.  <p/> This
            is invalid until {@link #Next()} is called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Next">
            <summary>Moves to the next pair in the enumeration.  <p/> Returns true iff there is
            such a next pair in the enumeration. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Read(System.Int32[],System.Int32[])">
            <summary>Attempts to read multiple entries from the enumeration, up to length of
            <i>docs</i>.  Document numbers are stored in <i>docs</i>, and term
            frequencies are stored in <i>freqs</i>.  The <i>freqs</i> array must be as
            long as the <i>docs</i> array.
            
            <p/>Returns the number of entries read.  Zero is only returned when the
            stream has been exhausted.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.SkipTo(System.Int32)">
            <summary>Skips entries to the first beyond the current whose document number is
            greater than or equal to <i>target</i>. <p/>Returns true iff there is such
            an entry.  <p/>Behaves as if written: <pre>
            boolean skipTo(int target) {
            do {
            if (!next())
            return false;
            } while (target > doc());
            return true;
            }
            </pre>
            Some implementations are considerably more efficient than that.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermDocs.Close">
            <summary>Frees associated resources. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermPositions.NextPosition">
            <summary>Returns next position in the current document.  It is an error to call
            this more than {@link #Freq()} times
            without calling {@link #Next()}<p/> This is
            invalid until {@link #Next()} is called for
            the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermPositions.GetPayloadLength">
            <summary> Returns the length of the payload at the current term position.
            This is invalid until {@link #NextPosition()} is called for
            the first time.<br/>
            </summary>
            <returns> length of the current payload in number of bytes
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermPositions.GetPayload(System.Byte[],System.Int32)">
            <summary> Returns the payload data at the current term position.
            This is invalid until {@link #NextPosition()} is called for
            the first time.
            This method must not be called more than once after each call
            of {@link #NextPosition()}. However, payloads are loaded lazily,
            so if the payload data for the current position is not needed,
            this method may not be called at all for performance reasons.<br/>
            
            </summary>
            <param name="data">the array into which the data of this payload is to be
            stored, if it is big enough; otherwise, a new byte[] array
            is allocated for this purpose. 
            </param>
            <param name="offset">the offset in the array into which the data of this payload
            is to be stored.
            </param>
            <returns> a byte[] array containing the data of this payload
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.TermPositions.IsPayloadAvailable">
            <summary> Checks if a payload can be loaded at this position.
            <p/>
            Payloads can only be loaded once per call to 
            {@link #NextPosition()}.
            
            </summary>
            <returns> true if there is a payload available at this position that can be loaded
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.TermInfo">
            <summary>A TermInfo is the record of information stored for a term.</summary>
        </member>
        <member name="F:Lucene.Net.Index.TermInfo.docFreq">
            <summary>The number of documents which contain the term. </summary>
        </member>
        <member name="T:Lucene.Net.Index.Term">
            <summary>A Term represents a word from text.  This is the unit of search.  It is
            composed of two elements, the text of the word, as a string, and the name of
            the field that the text occured in, an interned string.
            Note that terms may represent more than words from text fields, but also
            things like dates, email addresses, urls, etc.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Term.#ctor(System.String,System.String)">
            <summary>Constructs a Term with the given field and text.
            <p/>Note that a null field or null text value results in undefined
            behavior for most Lucene APIs that accept a Term parameter. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Term.#ctor(System.String)">
            <summary>Constructs a Term with the given field and empty text.
            This serves two purposes: 1) reuse of a Term with the same field.
            2) pattern for a query.
            
            </summary>
            <param name="fld">
            </param>
        </member>
        <member name="M:Lucene.Net.Index.Term.Field">
            <summary>Returns the field of this term, an interned string.   The field indicates
            the part of a document which this term came from. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Term.Text">
            <summary>Returns the text of this term.  In the case of words, this is simply the
            text of the word.  In the case of dates and other types, this is an
            encoding of the object as a string.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Term.CreateTerm(System.String)">
            <summary> Optimized construction of new Terms by reusing same field as this Term
            - avoids field.intern() overhead 
            </summary>
            <param name="text">The text of the new term (field is implicitly same as this Term instance)
            </param>
            <returns> A new Term
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.Term.CompareTo(Lucene.Net.Index.Term)">
            <summary>Compares two terms, returning a negative integer if this
            term belongs before the argument, zero if this term is equal to the
            argument, and a positive integer if this term belongs after the argument.
            The ordering of terms is first by field, then by text.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Term.Set(System.String,System.String)">
            <summary>Resets the field and text of a Term. </summary>
        </member>
        <member name="T:Lucene.Net.Index.ParallelReader">
            <summary>An IndexReader which reads multiple, parallel indexes.  Each index added
            must have the same number of documents, but typically each contains
            different fields.  Each document contains the union of the fields of all
            documents with the same document number.  When searching, matches for a
            query term are from the first index added that has the field.
            
            <p/>This is useful, e.g., with collections that have large fields which
            change rarely and small fields that change more frequently.  The smaller
            fields may be re-indexed in a new index and both indexes may be searched
            together.
            
            <p/><strong>Warning:</strong> It is up to you to make sure all indexes
            are created and modified the same way. For example, if you add
            documents to one index, you need to add the same documents in the
            same order to the other indexes. <em>Failure to do so will result in
            undefined behavior</em>.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexReader">
            <summary>IndexReader is an abstract class, providing an interface for accessing an
            index.  Search of an index is done entirely through this abstract interface,
            so that any subclass which implements it is searchable.
            <p/> Concrete subclasses of IndexReader are usually constructed with a call to
            one of the static <code>open()</code> methods, e.g. {@link
            #Open(String, boolean)}.
            <p/> For efficiency, in this API documents are often referred to via
            <i>document numbers</i>, non-negative integers which each name a unique
            document in the index.  These document numbers are ephemeral--they may change
            as documents are added to and deleted from an index.  Clients should thus not
            rely on a given document having the same number between sessions.
            <p/> An IndexReader can be opened on a directory for which an IndexWriter is
            opened already, but it cannot be used to delete documents from the index then.
            <p/>
            <b>NOTE</b>: for backwards API compatibility, several methods are not listed 
            as abstract, but have no useful implementations in this base class and 
            instead always throw UnsupportedOperationException.  Subclasses are 
            strongly encouraged to override these methods, but in many cases may not 
            need to.
            <p/>
            <p/>
            <b>NOTE</b>: as of 2.4, it's possible to open a read-only
            IndexReader using one of the static open methods that
            accepts the boolean readOnly parameter.  Such a reader has
            better concurrency as it's not necessary to synchronize on
            the isDeleted method.  Currently the default for readOnly
            is false, meaning if not specified you will get a
            read/write IndexReader.  But in 3.0 this default will
            change to true, meaning you must explicitly specify false
            if you want to make changes with the resulting IndexReader.
            <p/>
            <a name="thread-safety"></a><p/><b>NOTE</b>: {@link
            <code>IndexReader</code>} instances are completely thread
            safe, meaning multiple threads can call any of its methods,
            concurrently.  If your application requires external
            synchronization, you should <b>not</b> synchronize on the
            <code>IndexReader</code> instance; use your own
            (non-Lucene) objects instead.
            </summary>
            <version>  $Id: IndexReader.java 826049 2009-10-16 19:28:55Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetRefCount">
            <summary>Expert: returns the current refCount for this reader </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IncRef">
            <summary> Expert: increments the refCount of this IndexReader
            instance.  RefCounts are used to determine when a
            reader can be closed safely, i.e. as soon as there are
            no more references.  Be sure to always call a
            corresponding {@link #decRef}, in a finally clause;
            otherwise the reader may never be closed.  Note that
            {@link #close} simply calls decRef(), which means that
            the IndexReader will not really be closed until {@link
            #decRef} has been called for all outstanding
            references.
            
            </summary>
            <seealso cref="!:decRef">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DecRef">
            <summary> Expert: decreases the refCount of this IndexReader
            instance.  If the refCount drops to 0, then pending
            changes (if any) are committed to the index and this
            reader is closed.
            
            </summary>
            <throws>  IOException in case an IOException occurs in commit() or doClose() </throws>
            <summary> 
            </summary>
            <seealso cref="!:incRef">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.directory">
            <deprecated> will be deleted when IndexReader(Directory) is deleted
            </deprecated>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Directory">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.#ctor(Lucene.Net.Store.Directory)">
            <summary> Legacy Constructor for backwards compatibility.
            
            <p/>
            This Constructor should not be used, it exists for backwards 
            compatibility only to support legacy subclasses that did not "own" 
            a specific directory, but needed to specify something to be returned 
            by the directory() method.  Future subclasses should delegate to the 
            no arg constructor and implement the directory() method as appropriate.
            
            </summary>
            <param name="directory">Directory to be returned by the directory() method
            </param>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Directory">
            </seealso>
            <deprecated> - use IndexReader()
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.EnsureOpen">
            <throws>  AlreadyClosedException if this IndexReader is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(System.String)">
            <summary>Returns a read/write IndexReader reading the index in an FSDirectory in the named
            path.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #Open(Directory, boolean)} instead. 
            This method will be removed in the 3.0 release.
            
            </deprecated>
            <param name="path">the path to the index directory 
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(System.String,System.Boolean)">
            <summary>Returns an IndexReader reading the index in an
            FSDirectory in the named path.  You should pass
            readOnly=true, since it gives much better concurrent
            performance, unless you intend to do write operations
            (delete documents or change norms) with the reader.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <param name="path">the path to the index directory
            </param>
            <param name="readOnly">true if this should be a readOnly
            reader
            </param>
            <deprecated> Use {@link #Open(Directory, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(System.IO.FileInfo)">
            <summary>Returns a read/write IndexReader reading the index in an FSDirectory in the named
            path.
            </summary>
            <param name="path">the path to the index directory
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #Open(Directory, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(System.IO.FileInfo,System.Boolean)">
            <summary>Returns an IndexReader reading the index in an
            FSDirectory in the named path.  You should pass
            readOnly=true, since it gives much better concurrent
            performance, unless you intend to do write operations
            (delete documents or change norms) with the reader.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <param name="path">the path to the index directory
            </param>
            <param name="readOnly">true if this should be a readOnly
            reader
            </param>
            <deprecated> Use {@link #Open(Directory, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Store.Directory)">
            <summary>Returns a read/write IndexReader reading the index in
            the given Directory.
            </summary>
            <param name="directory">the index directory
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #Open(Directory, boolean)} instead
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Store.Directory,System.Boolean)">
            <summary>Returns an IndexReader reading the index in the given
            Directory.  You should pass readOnly=true, since it
            gives much better concurrent performance, unless you
            intend to do write operations (delete documents or
            change norms) with the reader.
            </summary>
            <param name="directory">the index directory
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Index.IndexCommit)">
            <summary>Expert: returns a read/write IndexReader reading the index in the given
            {@link IndexCommit}.
            </summary>
            <param name="commit">the commit point to open
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <deprecated> Use {@link #Open(IndexCommit, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Index.IndexCommit,System.Boolean)">
            <summary>Expert: returns an IndexReader reading the index in the given
            {@link IndexCommit}.  You should pass readOnly=true, since it
            gives much better concurrent performance, unless you
            intend to do write operations (delete documents or
            change norms) with the reader.
            </summary>
            <param name="commit">the commit point to open
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Store.Directory,Lucene.Net.Index.IndexDeletionPolicy)">
            <summary>Expert: returns a read/write IndexReader reading the index in the given
            Directory, with a custom {@link IndexDeletionPolicy}.
            </summary>
            <param name="directory">the index directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <deprecated> Use {@link #Open(Directory, IndexDeletionPolicy, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Store.Directory,Lucene.Net.Index.IndexDeletionPolicy,System.Boolean)">
            <summary>Expert: returns an IndexReader reading the index in
            the given Directory, with a custom {@link
            IndexDeletionPolicy}.  You should pass readOnly=true,
            since it gives much better concurrent performance,
            unless you intend to do write operations (delete
            documents or change norms) with the reader.
            </summary>
            <param name="directory">the index directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Store.Directory,Lucene.Net.Index.IndexDeletionPolicy,System.Boolean,System.Int32)">
            <summary>Expert: returns an IndexReader reading the index in
            the given Directory, with a custom {@link
            IndexDeletionPolicy}.  You should pass readOnly=true,
            since it gives much better concurrent performance,
            unless you intend to do write operations (delete
            documents or change norms) with the reader.
            </summary>
            <param name="directory">the index directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <param name="termInfosIndexDivisor">Subsamples which indexed
            terms are loaded into RAM. This has the same effect as {@link
            IndexWriter#setTermIndexInterval} except that setting
            must be done at indexing time while this setting can be
            set per reader.  When set to N, then one in every
            N*termIndexInterval terms in the index is loaded into
            memory.  By setting this to a value > 1 you can reduce
            memory usage, at the expense of higher latency when
            loading a TermInfo.  The default value is 1.  Set this
            to -1 to skip loading the terms index entirely.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Index.IndexCommit,Lucene.Net.Index.IndexDeletionPolicy)">
            <summary>Expert: returns a read/write IndexReader reading the index in the given
            Directory, using a specific commit and with a custom
            {@link IndexDeletionPolicy}.
            </summary>
            <param name="commit">the specific {@link IndexCommit} to open;
            see {@link IndexReader#listCommits} to list all commits
            in a directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <deprecated> Use {@link #Open(IndexCommit, IndexDeletionPolicy, boolean)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Index.IndexCommit,Lucene.Net.Index.IndexDeletionPolicy,System.Boolean)">
            <summary>Expert: returns an IndexReader reading the index in
            the given Directory, using a specific commit and with
            a custom {@link IndexDeletionPolicy}.  You should pass
            readOnly=true, since it gives much better concurrent
            performance, unless you intend to do write operations
            (delete documents or change norms) with the reader.
            </summary>
            <param name="commit">the specific {@link IndexCommit} to open;
            see {@link IndexReader#listCommits} to list all commits
            in a directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Open(Lucene.Net.Index.IndexCommit,Lucene.Net.Index.IndexDeletionPolicy,System.Boolean,System.Int32)">
            <summary>Expert: returns an IndexReader reading the index in
            the given Directory, using a specific commit and with
            a custom {@link IndexDeletionPolicy}.  You should pass
            readOnly=true, since it gives much better concurrent
            performance, unless you intend to do write operations
            (delete documents or change norms) with the reader.
            </summary>
            <param name="commit">the specific {@link IndexCommit} to open;
            see {@link IndexReader#listCommits} to list all commits
            in a directory
            </param>
            <param name="deletionPolicy">a custom deletion policy (only used
            if you use this reader to perform deletes or to set
            norms); see {@link IndexWriter} for details.
            </param>
            <param name="readOnly">true if no changes (deletions, norms) will be made with this IndexReader
            </param>
            <param name="termInfosIndexDivisor">Subsambles which indexed
            terms are loaded into RAM. This has the same effect as {@link
            IndexWriter#setTermIndexInterval} except that setting
            must be done at indexing time while this setting can be
            set per reader.  When set to N, then one in every
            N*termIndexInterval terms in the index is loaded into
            memory.  By setting this to a value > 1 you can reduce
            memory usage, at the expense of higher latency when
            loading a TermInfo.  The default value is 1.  Set this
            to -1 to skip loading the terms index entirely.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Reopen">
            <summary> Refreshes an IndexReader if the index has changed since this instance 
            was (re)opened. 
            <p/>
            Opening an IndexReader is an expensive operation. This method can be used
            to refresh an existing IndexReader to reduce these costs. This method 
            tries to only load segments that have changed or were created after the 
            IndexReader was (re)opened.
            <p/>
            If the index has not changed since this instance was (re)opened, then this
            call is a NOOP and returns this instance. Otherwise, a new instance is 
            returned. The old instance is <b>not</b> closed and remains usable.<br/>
            <p/>   
            If the reader is reopened, even though they share
            resources internally, it's safe to make changes
            (deletions, norms) with the new reader.  All shared
            mutable state obeys "copy on write" semantics to ensure
            the changes are not seen by other readers.
            <p/>
            You can determine whether a reader was actually reopened by comparing the
            old instance with the instance returned by this method: 
            <pre>
            IndexReader reader = ... 
            ...
            IndexReader newReader = r.reopen();
            if (newReader != reader) {
            ...     // reader was reopened
            reader.close(); 
            }
            reader = newReader;
            ...
            </pre>
            
            Be sure to synchronize that code so that other threads,
            if present, can never use reader after it has been
            closed and before it's switched to newReader.
            
            <p/><b>NOTE</b>: If this reader is a near real-time
            reader (obtained from {@link IndexWriter#GetReader()},
            reopen() will simply call writer.getReader() again for
            you, though this may change in the future.
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Reopen(System.Boolean)">
            <summary>Just like {@link #Reopen()}, except you can change the
            readOnly of the original reader.  If the index is
            unchanged but readOnly is different then a new reader
            will be returned. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Reopen(Lucene.Net.Index.IndexCommit)">
            <summary>Expert: reopen this reader on a specific commit point.
            This always returns a readOnly reader.  If the
            specified commit point matches what this reader is
            already on, and this reader is already readOnly, then
            this same instance is returned; if it is not already
            readOnly, a readOnly clone is returned. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Clone">
            <summary> Efficiently clones the IndexReader (sharing most
            internal state).
            <p/>
            On cloning a reader with pending changes (deletions,
            norms), the original reader transfers its write lock to
            the cloned reader.  This means only the cloned reader
            may make further changes to the index, and commit the
            changes to the index on close, but the old reader still
            reflects all changes made up until it was cloned.
            <p/>
            Like {@link #Reopen()}, it's safe to make changes to
            either the original or the cloned reader: all shared
            mutable state obeys "copy on write" semantics to ensure
            the changes are not seen by other readers.
            <p/>
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Clone(System.Boolean)">
            <summary> Clones the IndexReader and optionally changes readOnly.  A readOnly 
            reader cannot open a writeable reader.  
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Directory">
            <summary> Returns the directory associated with this index.  The Default 
            implementation returns the directory specified by subclasses when 
            delegating to the IndexReader(Directory) constructor, or throws an 
            UnsupportedOperationException if one was not specified.
            </summary>
            <throws>  UnsupportedOperationException if no directory </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.LastModified(System.String)">
            <summary> Returns the time the index in the named directory was last modified.
            Do not use this to check whether the reader is still up-to-date, use
            {@link #IsCurrent()} instead. 
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #LastModified(Directory)} instead.
            This method will be removed in the 3.0 release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.LastModified(System.IO.FileInfo)">
            <summary> Returns the time the index in the named directory was last modified. 
            Do not use this to check whether the reader is still up-to-date, use
            {@link #IsCurrent()} instead. 
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #LastModified(Directory)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.LastModified(Lucene.Net.Store.Directory)">
            <summary> Returns the time the index in the named directory was last modified. 
            Do not use this to check whether the reader is still up-to-date, use
            {@link #IsCurrent()} instead. 
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetCurrentVersion(System.String)">
            <summary> Reads version number from segments files. The version number is
            initialized with a timestamp and then increased by one for each change of
            the index.
            
            </summary>
            <param name="directory">where the index resides.
            </param>
            <returns> version number.
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #GetCurrentVersion(Directory)} instead.
            This method will be removed in the 3.0 release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetCurrentVersion(System.IO.FileInfo)">
            <summary> Reads version number from segments files. The version number is
            initialized with a timestamp and then increased by one for each change of
            the index.
            
            </summary>
            <param name="directory">where the index resides.
            </param>
            <returns> version number.
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #GetCurrentVersion(Directory)} instead.
            This method will be removed in the 3.0 release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetCurrentVersion(Lucene.Net.Store.Directory)">
            <summary> Reads version number from segments files. The version number is
            initialized with a timestamp and then increased by one for each change of
            the index.
            
            </summary>
            <param name="directory">where the index resides.
            </param>
            <returns> version number.
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetCommitUserData(Lucene.Net.Store.Directory)">
            <summary> Reads commitUserData, previously passed to {@link
            IndexWriter#Commit(Map)}, from current index
            segments file.  This will return null if {@link
            IndexWriter#Commit(Map)} has never been called for
            this index.
            
            </summary>
            <param name="directory">where the index resides.
            </param>
            <returns> commit userData.
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <summary> 
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.GetCommitUserData">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetVersion">
            <summary> Version number when this IndexReader was opened. Not implemented in the
            IndexReader base class.
            
            <p/>
            If this reader is based on a Directory (ie, was created by calling
            {@link #Open}, or {@link #Reopen} on a reader based on a Directory), then
            this method returns the version recorded in the commit that the reader
            opened. This version is advanced every time {@link IndexWriter#Commit} is
            called.
            <p/>
            
            <p/>
            If instead this reader is a near real-time reader (ie, obtained by a call
            to {@link IndexWriter#GetReader}, or by calling {@link #Reopen} on a near
            real-time reader), then this method returns the version of the last
            commit done by the writer. Note that even as further changes are made
            with the writer, the version will not changed until a commit is
            completed. Thus, you should not rely on this method to determine when a
            near real-time reader should be opened. Use {@link #IsCurrent} instead.
            <p/>
            
            </summary>
            <throws>  UnsupportedOperationException </throws>
            <summary>             unless overridden in subclass
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetCommitUserData">
            <summary> Retrieve the String userData optionally passed to
            IndexWriter#commit.  This will return null if {@link
            IndexWriter#Commit(Map)} has never been called for
            this index.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.GetCommitUserData(Lucene.Net.Store.Directory)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.SetTermInfosIndexDivisor(System.Int32)">
            <summary><p/>For IndexReader implementations that use
            TermInfosReader to read terms, this sets the
            indexDivisor to subsample the number of indexed terms
            loaded into memory.  This has the same effect as {@link
            IndexWriter#setTermIndexInterval} except that setting
            must be done at indexing time while this setting can be
            set per reader.  When set to N, then one in every
            N*termIndexInterval terms in the index is loaded into
            memory.  By setting this to a value > 1 you can reduce
            memory usage, at the expense of higher latency when
            loading a TermInfo.  The default value is 1.<p/>
            
            <b>NOTE:</b> you must call this before the term
            index is loaded.  If the index is already loaded, 
            an IllegalStateException is thrown.
            </summary>
            <throws>  IllegalStateException if the term index has already been loaded into memory </throws>
            <deprecated> Please use {@link IndexReader#Open(Directory, IndexDeletionPolicy, boolean, int)} to specify the required TermInfos index divisor instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetTermInfosIndexDivisor">
            <summary><p/>For IndexReader implementations that use
            TermInfosReader to read terms, this returns the
            current indexDivisor as specified when the reader was
            opened.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IsCurrent">
            <summary> Check whether any new changes have occurred to the index since this
            reader was opened.
            
            <p/>
            If this reader is based on a Directory (ie, was created by calling
            {@link #open}, or {@link #reopen} on a reader based on a Directory), then
            this method checks if any further commits (see {@link IndexWriter#commit}
            have occurred in that directory).
            <p/>
            
            <p/>
            If instead this reader is a near real-time reader (ie, obtained by a call
            to {@link IndexWriter#getReader}, or by calling {@link #reopen} on a near
            real-time reader), then this method checks if either a new commmit has
            occurred, or any new uncommitted changes have taken place via the writer.
            Note that even if the writer has only performed merging, this method will
            still return false.
            <p/>
            
            <p/>
            In any event, if this returns false, you should call {@link #reopen} to
            get a new reader that sees the changes.
            <p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <throws>  UnsupportedOperationException unless overridden in subclass </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IsOptimized">
            <summary> Checks is the index is optimized (if it has a single segment and 
            no deletions).  Not implemented in the IndexReader base class.
            </summary>
            <returns> <code>true</code> if the index is optimized; <code>false</code> otherwise
            </returns>
            <throws>  UnsupportedOperationException unless overridden in subclass </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetTermFreqVectors(System.Int32)">
            <summary> Return an array of term frequency vectors for the specified document.
            The array contains a vector for each vectorized field in the document.
            Each vector contains terms and frequencies for all terms in a given vectorized field.
            If no such fields existed, the method returns null. The term vectors that are
            returned may either be of type {@link TermFreqVector}
            or of type {@link TermPositionVector} if
            positions or offsets have been stored.
            
            </summary>
            <param name="docNumber">document for which term frequency vectors are returned
            </param>
            <returns> array of term frequency vectors. May be null if no term vectors have been
            stored for the specified document.
            </returns>
            <throws>  IOException if index cannot be accessed </throws>
            <seealso cref="T:Lucene.Net.Documents.Field.TermVector">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetTermFreqVector(System.Int32,System.String)">
            <summary> Return a term frequency vector for the specified document and field. The
            returned vector contains terms and frequencies for the terms in
            the specified field of this document, if the field had the storeTermVector
            flag set. If termvectors had been stored with positions or offsets, a 
            {@link TermPositionVector} is returned.
            
            </summary>
            <param name="docNumber">document for which the term frequency vector is returned
            </param>
            <param name="field">field for which the term frequency vector is returned.
            </param>
            <returns> term frequency vector May be null if field does not exist in the specified
            document or term vector was not stored.
            </returns>
            <throws>  IOException if index cannot be accessed </throws>
            <seealso cref="T:Lucene.Net.Documents.Field.TermVector">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetTermFreqVector(System.Int32,System.String,Lucene.Net.Index.TermVectorMapper)">
            <summary> Load the Term Vector into a user-defined data structure instead of relying on the parallel arrays of
            the {@link TermFreqVector}.
            </summary>
            <param name="docNumber">The number of the document to load the vector for
            </param>
            <param name="field">The name of the field to load
            </param>
            <param name="mapper">The {@link TermVectorMapper} to process the vector.  Must not be null
            </param>
            <throws>  IOException if term vectors cannot be accessed or if they do not exist on the field and doc. specified. </throws>
            <summary> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetTermFreqVector(System.Int32,Lucene.Net.Index.TermVectorMapper)">
            <summary> Map all the term vectors for all fields in a Document</summary>
            <param name="docNumber">The number of the document to load the vector for
            </param>
            <param name="mapper">The {@link TermVectorMapper} to process the vector.  Must not be null
            </param>
            <throws>  IOException if term vectors cannot be accessed or if they do not exist on the field and doc. specified. </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IndexExists(System.String)">
            <summary> Returns <code>true</code> if an index exists at the specified directory.
            If the directory does not exist or if there is no index in it.
            <code>false</code> is returned.
            </summary>
            <param name="directory">the directory to check for an index
            </param>
            <returns> <code>true</code> if an index exists; <code>false</code> otherwise
            </returns>
            <deprecated> Use {@link #IndexExists(Directory)} instead
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IndexExists(System.IO.FileInfo)">
            <summary> Returns <code>true</code> if an index exists at the specified directory.
            If the directory does not exist or if there is no index in it.
            </summary>
            <param name="directory">the directory to check for an index
            </param>
            <returns> <code>true</code> if an index exists; <code>false</code> otherwise
            </returns>
            <deprecated> Use {@link #IndexExists(Directory)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IndexExists(Lucene.Net.Store.Directory)">
            <summary> Returns <code>true</code> if an index exists at the specified directory.
            If the directory does not exist or if there is no index in it.
            </summary>
            <param name="directory">the directory to check for an index
            </param>
            <returns> <code>true</code> if an index exists; <code>false</code> otherwise
            </returns>
            <throws>  IOException if there is a problem with accessing the index </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.NumDocs">
            <summary>Returns the number of documents in this index. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.MaxDoc">
            <summary>Returns one greater than the largest possible document number.
            This may be used to, e.g., determine how big to allocate an array which
            will have an element for every document number in an index.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.NumDeletedDocs">
            <summary>Returns the number of deleted documents. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Document(System.Int32)">
            <summary> Returns the stored fields of the <code>n</code><sup>th</sup>
            <code>Document</code> in this index.
            <p/>
            <b>NOTE:</b> for performance reasons, this method does not check if the
            requested document is deleted, and therefore asking for a deleted document
            may yield unspecified results. Usually this is not required, however you
            can call {@link #IsDeleted(int)} with the requested document ID to verify
            the document is not deleted.
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Document(System.Int32,Lucene.Net.Documents.FieldSelector)">
            <summary> Get the {@link Lucene.Net.Documents.Document} at the <code>n</code>
            <sup>th</sup> position. The {@link FieldSelector} may be used to determine
            what {@link Lucene.Net.Documents.Field}s to load and how they should
            be loaded. <b>NOTE:</b> If this Reader (more specifically, the underlying
            <code>FieldsReader</code>) is closed before the lazy
            {@link Lucene.Net.Documents.Field} is loaded an exception may be
            thrown. If you want the value of a lazy
            {@link Lucene.Net.Documents.Field} to be available after closing you
            must explicitly load it or fetch the Document again with a new loader.
            <p/>
            <b>NOTE:</b> for performance reasons, this method does not check if the
            requested document is deleted, and therefore asking for a deleted document
            may yield unspecified results. Usually this is not required, however you
            can call {@link #IsDeleted(int)} with the requested document ID to verify
            the document is not deleted.
            
            </summary>
            <param name="n">Get the document at the <code>n</code><sup>th</sup> position
            </param>
            <param name="fieldSelector">The {@link FieldSelector} to use to determine what
            Fields should be loaded on the Document. May be null, in which case
            all Fields will be loaded.
            </param>
            <returns> The stored fields of the
            {@link Lucene.Net.Documents.Document} at the nth position
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <seealso cref="T:Lucene.Net.Documents.Fieldable">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.FieldSelector">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.SetBasedFieldSelector">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.LoadFirstFieldSelector">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IsDeleted(System.Int32)">
            <summary>Returns true if document <i>n</i> has been deleted </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.HasDeletions">
            <summary>Returns true if any documents have been deleted </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.HasNorms(System.String)">
            <summary>Returns true if there are norms stored for this field. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Norms(System.String)">
            <summary>Returns the byte-encoded normalization factor for the named field of
            every document.  This is used by the search code to score documents.
            
            </summary>
            <seealso cref="!:Lucene.Net.Documents.Field.SetBoost(float)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Norms(System.String,System.Byte[],System.Int32)">
            <summary>Reads the byte-encoded normalization factor for the named field of every
            document.  This is used by the search code to score documents.
            
            </summary>
            <seealso cref="!:Lucene.Net.Documents.Field.SetBoost(float)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.SetNorm(System.Int32,System.String,System.Byte)">
            <summary>Expert: Resets the normalization factor for the named field of the named
            document.  The norm represents the product of the field's {@link
            Lucene.Net.Documents.Fieldable#SetBoost(float) boost} and its {@link Similarity#LengthNorm(String,
            int) length normalization}.  Thus, to preserve the length normalization
            values when resetting this, one should base the new value upon the old.
            
            <b>NOTE:</b> If this field does not store norms, then
            this method call will silently do nothing.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Norms(System.String)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.DecodeNorm(System.Byte)">
            </seealso>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoSetNorm(System.Int32,System.String,System.Byte)">
            <summary>Implements setNorm in subclass.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.SetNorm(System.Int32,System.String,System.Single)">
            <summary>Expert: Resets the normalization factor for the named field of the named
            document.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Norms(System.String)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.DecodeNorm(System.Byte)">
            
            </seealso>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Terms">
            <summary>Returns an enumeration of all the terms in the index. The
            enumeration is ordered by Term.compareTo(). Each term is greater
            than all that precede it in the enumeration. Note that after
            calling terms(), {@link TermEnum#Next()} must be called
            on the resulting enumeration before calling other methods such as
            {@link TermEnum#Term()}.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Terms(Lucene.Net.Index.Term)">
            <summary>Returns an enumeration of all terms starting at a given term. If
            the given term does not exist, the enumeration is positioned at the
            first term greater than the supplied term. The enumeration is
            ordered by Term.compareTo(). Each term is greater than all that
            precede it in the enumeration.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DocFreq(Lucene.Net.Index.Term)">
            <summary>Returns the number of documents containing the term <code>t</code>.</summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.TermDocs(Lucene.Net.Index.Term)">
            <summary>Returns an enumeration of all the documents which contain
            <code>term</code>. For each document, the document number, the frequency of
            the term in that document is also provided, for use in
            search scoring.  If term is null, then all non-deleted
            docs are returned with freq=1.
            Thus, this method implements the mapping:
            <p/><ul>
            Term &#160;&#160; =&gt; &#160;&#160; &lt;docNum, freq&gt;<sup>*</sup>
            </ul>
            <p/>The enumeration is ordered by document number.  Each document number
            is greater than all that precede it in the enumeration.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.TermDocs">
            <summary>Returns an unpositioned {@link TermDocs} enumerator.</summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.TermPositions(Lucene.Net.Index.Term)">
            <summary>Returns an enumeration of all the documents which contain
            <code>term</code>.  For each document, in addition to the document number
            and frequency of the term in that document, a list of all of the ordinal
            positions of the term in the document is available.  Thus, this method
            implements the mapping:
            
            <p/><ul>
            Term &#160;&#160; =&gt; &#160;&#160; &lt;docNum, freq,
            &lt;pos<sub>1</sub>, pos<sub>2</sub>, ...
            pos<sub>freq-1</sub>&gt;
            &gt;<sup>*</sup>
            </ul>
            <p/> This positional information facilitates phrase and proximity searching.
            <p/>The enumeration is ordered by document number.  Each document number is
            greater than all that precede it in the enumeration.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.TermPositions">
            <summary>Returns an unpositioned {@link TermPositions} enumerator.</summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DeleteDocument(System.Int32)">
            <summary>Deletes the document numbered <code>docNum</code>.  Once a document is
            deleted it will not appear in TermDocs or TermPostitions enumerations.
            Attempts to read its field with the {@link #document}
            method will result in an error.  The presence of this document may still be
            reflected in the {@link #docFreq} statistic, though
            this will be corrected eventually as the index is further modified.
            
            </summary>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary> since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoDelete(System.Int32)">
            <summary>Implements deletion of the document numbered <code>docNum</code>.
            Applications should call {@link #DeleteDocument(int)} or {@link #DeleteDocuments(Term)}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DeleteDocuments(Lucene.Net.Index.Term)">
            <summary>Deletes all documents that have a given <code>term</code> indexed.
            This is useful if one uses a document field to hold a unique ID string for
            the document.  Then to delete such a document, one merely constructs a
            term with the appropriate field and the unique ID string as its text and
            passes it to this method.
            See {@link #DeleteDocument(int)} for information about when this deletion will 
            become effective.
            
            </summary>
            <returns> the number of documents deleted
            </returns>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.UndeleteAll">
            <summary>Undeletes all documents currently marked as deleted in this index.
            
            </summary>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoUndeleteAll">
            <summary>Implements actual undeleteAll() in subclass. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.AcquireWriteLock">
            <summary>Does nothing by default. Subclasses that require a write lock for
            index modifications must implement this method. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Flush">
            <summary> </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Flush(System.Collections.Generic.IDictionary{System.String,System.String})">
            <param name="commitUserData">Opaque Map (String -> String)
            that's recorded into the segments file in the index,
            and retrievable by {@link
            IndexReader#getCommitUserData}.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Commit">
            <summary> Commit changes resulting from delete, undeleteAll, or
            setNorm operations
            
            If an exception is hit, then either no changes or all
            changes will have been committed to the index
            (transactional semantics).
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Commit(System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Commit changes resulting from delete, undeleteAll, or
            setNorm operations
            
            If an exception is hit, then either no changes or all
            changes will have been committed to the index
            (transactional semantics).
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoCommit">
            <summary>Implements commit.</summary>
            <deprecated> Please implement {@link #DoCommit(Map)
            instead}. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoCommit(System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary>Implements commit.  NOTE: subclasses should override
            this.  In 3.0 this will become an abstract method. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Close">
            <summary> Closes files associated with this index.
            Also saves any new deletions to disk.
            No other methods should be called after this has been called.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.DoClose">
            <summary>Implements close. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetFieldNames(Lucene.Net.Index.IndexReader.FieldOption)">
            <summary> Get a list of unique field names that exist in this index and have the specified
            field option information.
            </summary>
            <param name="fldOption">specifies which field option should be available for the returned fields
            </param>
            <returns> Collection of Strings indicating the names of the fields.
            </returns>
            <seealso cref="T:Lucene.Net.Index.IndexReader.FieldOption">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IsLocked(Lucene.Net.Store.Directory)">
            <summary> Returns <code>true</code> iff the index in the named directory is
            currently locked.
            </summary>
            <param name="directory">the directory to check for a lock
            </param>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Please use {@link IndexWriter#IsLocked(Directory)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.IsLocked(System.String)">
            <summary> Returns <code>true</code> iff the index in the named directory is
            currently locked.
            </summary>
            <param name="directory">the directory to check for a lock
            </param>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #IsLocked(Directory)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Unlock(Lucene.Net.Store.Directory)">
            <summary> Forcibly unlocks the index in the named directory.
            <p/>
            Caution: this should only be used by failure recovery code,
            when it is known that no other process nor thread is in fact
            currently accessing this index.
            </summary>
            <deprecated> Please use {@link IndexWriter#Unlock(Directory)} instead.
            This method will be removed in the 3.0 release.
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetIndexCommit">
            <summary> Expert: return the IndexCommit that this reader has
            opened.  This method is only implemented by those
            readers that correspond to a Directory with its own
            segments_N file.
            
            <p/><b>WARNING</b>: this API is new and experimental and
            may suddenly change.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.Main(System.String[])">
            <summary> Prints the filename and size of each file within a given compound file.
            Add the -extract flag to extract files to the current working directory.
            In order to make the extracted version of the index work, you have to copy
            the segments file from the compound index into the directory where the extracted files are stored.
            </summary>
            <param name="args">Usage: Lucene.Net.Index.IndexReader [-extract] &lt;cfsfile&gt;
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.ListCommits(Lucene.Net.Store.Directory)">
            <summary>Returns all commit points that exist in the Directory.
            Normally, because the default is {@link
            KeepOnlyLastCommitDeletionPolicy}, there would be only
            one commit point.  But if you're using a custom {@link
            IndexDeletionPolicy} then there could be many commits.
            Once you have a given commit, you can open a reader on
            it by calling {@link IndexReader#Open(IndexCommit)}
            There must be at least one commit in
            the Directory, else this method throws {@link
            java.io.IOException}.  Note that if a commit is in
            progress while this method is running, that commit
            may or may not be returned array.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetSequentialSubReaders">
            <summary>Expert: returns the sequential sub readers that this
            reader is logically composed of.  For example,
            IndexSearcher uses this API to drive searching by one
            sub reader at a time.  If this reader is not composed
            of sequential child readers, it should return null.
            If this method returns an empty array, that means this
            reader is a null reader (for example a MultiReader
            that has no sub readers).
            <p/>
            NOTE: You should not try using sub-readers returned by
            this method to make any changes (setNorm, deleteDocument,
            etc.). While this might succeed for one composite reader
            (like MultiReader), it will most likely lead to index
            corruption for other readers (like DirectoryReader obtained
            through {@link #open}. Use the parent reader directly. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetFieldCacheKey">
            <summary>Expert    </summary>
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetDeletesCacheKey">
            Expert.  Warning: this returns null if the reader has
            no deletions 
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetUniqueTermCount">
            <summary>Returns the number of unique terms (across all fields)
            in this reader.
            
            This method returns long, even though internally
            Lucene cannot handle more than 2^31 unique terms, for
            a possible future when this limitation is removed.
            
            </summary>
            <throws>  UnsupportedOperationException if this count </throws>
            <summary>  cannot be easily determined (eg Multi*Readers).
            Instead, you should call {@link
            #getSequentialSubReaders} and ask each sub reader for
            its unique term count. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.GetDisableFakeNorms">
            <summary>Expert: Return the state of the flag that disables fakes norms in favor of representing the absence of field norms with null.</summary>
            <returns> true if fake norms are disabled
            </returns>
            <deprecated> This currently defaults to false (to remain
            back-compatible), but in 3.0 it will be hardwired to
            true, meaning the norms() methods will return null for
            fields that had disabled norms.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexReader.SetDisableFakeNorms(System.Boolean)">
            <summary>Expert: Set the state of the flag that disables fakes norms in favor of representing the absence of field norms with null.</summary>
            <param name="disableFakeNorms">true to disable fake norms, false to preserve the legacy behavior
            </param>
            <deprecated> This currently defaults to false (to remain
            back-compatible), but in 3.0 it will be hardwired to
            true, meaning the norms() methods will return null for
            fields that had disabled norms.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Index.SegmentInfos.FindSegmentsFile">
            <summary> Utility class for executing code that needs to do
            something with the current segments file.  This is
            necessary with lock-less commits because from the time
            you locate the current segments file name, until you
            actually open it, read its contents, or check modified
            time, etc., it could have been deleted due to a writer
            commit finishing.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.SegmentInfos">
            <summary> A collection of segmentInfo objects with methods for operating on
            those segments in relation to the file system.
            
            <p/><b>NOTE:</b> This API is new and still experimental
            (subject to change suddenly in the next release)<p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT">
            <summary>The file format version, a negative number. </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_LOCKLESS">
            <summary>This format adds details used for lockless commits.  It differs
            slightly from the previous format in that file names
            are never re-used (write once).  Instead, each file is
            written to the next generation.  For example,
            segments_1, segments_2, etc.  This allows us to not use
            a commit lock.  See <a
            href="http://lucene.apache.org/java/docs/fileformats.html">file
            formats</a> for details.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_SINGLE_NORM_FILE">
            <summary>This format adds a "hasSingleNormFile" flag into each segment info.
            See <a href="http://issues.apache.org/jira/browse/LUCENE-756">LUCENE-756</a>
            for details.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_SHARED_DOC_STORE">
            <summary>This format allows multiple segments to share a single
            vectors and stored fields file. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_CHECKSUM">
            <summary>This format adds a checksum at the end of the file to
            ensure all bytes were successfully written. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_DEL_COUNT">
            <summary>This format adds the deletion count for each segment.
            This way IndexWriter can efficiently report numDocs(). 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_HAS_PROX">
            <summary>This format adds the boolean hasProx to record if any
            fields in the segment store prox information (ie, have
            omitTermFreqAndPositions==false) 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_USER_DATA">
            <summary>This format adds optional commit userData (String) storage. </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.FORMAT_DIAGNOSTICS">
            <summary>This format adds optional per-segment String
            dianostics storage, and switches userData to Map 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.version">
            <summary> counts how often the index has been changed by adding or deleting docs.
            starting with the current time in milliseconds forces to create unique version numbers.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentInfos.infoStream">
            <summary> If non-null, information about loading segments_N files</summary>
            <seealso cref="!:setInfoStream">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetCurrentSegmentGeneration(System.String[])">
            <summary> Get the generation (N) of the current segments_N file
            from a list of files.
            
            </summary>
            <param name="files">-- array of file names to check
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetCurrentSegmentGeneration(Lucene.Net.Store.Directory)">
            <summary> Get the generation (N) of the current segments_N file
            in the directory.
            
            </summary>
            <param name="directory">-- directory to search for the latest segments_N file
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetCurrentSegmentFileName(System.String[])">
            <summary> Get the filename of the current segments_N file
            from a list of files.
            
            </summary>
            <param name="files">-- array of file names to check
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetCurrentSegmentFileName(Lucene.Net.Store.Directory)">
            <summary> Get the filename of the current segments_N file
            in the directory.
            
            </summary>
            <param name="directory">-- directory to search for the latest segments_N file
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetCurrentSegmentFileName">
            <summary> Get the segments_N filename in use by this segment infos.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GenerationFromSegmentsFileName(System.String)">
            <summary> Parse the generation off the segments file name and
            return it.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetNextSegmentFileName">
            <summary> Get the next segments_N filename that will be written.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Read(Lucene.Net.Store.Directory,System.String)">
            <summary> Read a particular segmentFileName.  Note that this may
            throw an IOException if a commit is in process.
            
            </summary>
            <param name="directory">-- directory containing the segments file
            </param>
            <param name="segmentFileName">-- segment file to load
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Read(Lucene.Net.Store.Directory)">
            <summary> This version of read uses the retry logic (for lock-less
            commits) to find the right segments file to load.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Clone">
            <summary> Returns a copy of this instance, also copying each
            SegmentInfo.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetVersion">
            <summary> version number when this SegmentInfos was generated.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.ReadCurrentVersion(Lucene.Net.Store.Directory)">
            <summary> Current version number from segments file.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.ReadCurrentUserData(Lucene.Net.Store.Directory)">
            <summary> Returns userData from latest segments file</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.SetInfoStream(System.IO.StreamWriter)">
            <summary>If non-null, information about retries when loading
            the segments file will be printed to this.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.SetDefaultGenFileRetryCount(System.Int32)">
            <summary> Advanced: set how many times to try loading the
            segments.gen file contents to determine current segment
            generation.  This file is only referenced when the
            primary method (listing the directory) fails.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetDefaultGenFileRetryCount">
            <seealso cref="!:setDefaultGenFileRetryCount">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.SetDefaultGenFileRetryPauseMsec(System.Int32)">
            <summary> Advanced: set how many milliseconds to pause in between
            attempts to load the segments.gen file.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetDefaultGenFileRetryPauseMsec">
            <seealso cref="!:setDefaultGenFileRetryPauseMsec">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.SetDefaultGenLookaheadCount(System.Int32)">
            <summary> Advanced: set how many times to try incrementing the
            gen when loading the segments file.  This only runs if
            the primary (listing directory) and secondary (opening
            segments.gen file) methods fail to find the segments
            file.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetDefaultGenLookahedCount">
            <seealso cref="!:setDefaultGenLookaheadCount">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetInfoStream">
            <seealso cref="!:setInfoStream">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Range(System.Int32,System.Int32)">
            <summary> Returns a new SegmentInfos containg the SegmentInfo
            instances in the specified range first (inclusive) to
            last (exclusive), so total number of segments returned
            is last-first.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.PrepareCommit(Lucene.Net.Store.Directory)">
            <summary>Call this to start a commit.  This writes the new
            segments file, but writes an invalid checksum at the
            end, so that it is not visible to readers.  Once this
            is called you must call {@link #finishCommit} to complete
            the commit or {@link #rollbackCommit} to abort it. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Files(Lucene.Net.Store.Directory,System.Boolean)">
            <summary>Returns all file names referenced by SegmentInfo
            instances matching the provided Directory (ie files
            associated with any "external" segments are skipped).
            The returned collection is recomputed on each
            invocation.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Commit(Lucene.Net.Store.Directory)">
            <summary>Writes &amp; syncs to the Directory dir, taking care to
            remove the segments file on exception 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Replace(Lucene.Net.Index.SegmentInfos)">
            <summary>Replaces all segments in this instance, but keeps
            generation, version, counter so that future commits
            remain write once.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.Equals(System.Object)">
            <summary>
            Simple brute force implementation.
            If size is equal, compare items one by one.
            </summary>
            <param name="obj">SegmentInfos object to check equality for</param>
            <returns>true if lists are equal, false otherwise</returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.GetHashCode">
            <summary>
            Calculate hash code of SegmentInfos
            </summary>
            <returns>hash code as in java version of ArrayList</returns>
        </member>
        <member name="T:Lucene.Net.Index.SegmentInfos.FindSegmentsFile">
            <summary> Utility class for executing code that needs to do
            something with the current segments file.  This is
            necessary with lock-less commits because from the time
            you locate the current segments file name, until you
            actually open it, read its contents, or check modified
            time, etc., it could have been deleted due to a writer
            commit finishing.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfos.FindSegmentsFile.DoBody(System.String)">
            <summary> Subclass must implement this.  The assumption is an
            IOException will be thrown if something goes wrong
            during the processing that could have been caused by
            a writer committing.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexReader.FieldOption">
            <summary> Constants describing field properties, for example used for
            {@link IndexReader#GetFieldNames(FieldOption)}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.ALL">
            <summary>All fields </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.INDEXED">
            <summary>All indexed fields </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.STORES_PAYLOADS">
            <summary>All fields that store payloads </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.OMIT_TERM_FREQ_AND_POSITIONS">
            <summary>All fields that omit tf </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.OMIT_TF">
            <deprecated> Renamed to {@link #OMIT_TERM_FREQ_AND_POSITIONS} 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.UNINDEXED">
            <summary>All fields which are not indexed </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.INDEXED_WITH_TERMVECTOR">
            <summary>All fields which are indexed with termvectors enabled </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.INDEXED_NO_TERMVECTOR">
            <summary>All fields which are indexed but don't have termvectors enabled </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.TERMVECTOR">
            <summary>All fields with termvectors enabled. Please note that only standard termvector fields are returned </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.TERMVECTOR_WITH_POSITION">
            <summary>All fields with termvectors with position values enabled </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.TERMVECTOR_WITH_OFFSET">
            <summary>All fields with termvectors with offset values enabled </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexReader.FieldOption.TERMVECTOR_WITH_POSITION_OFFSET">
            <summary>All fields with termvectors with offset values and position values enabled </summary>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.#ctor">
            <summary>Construct a ParallelReader. 
            <p/>Note that all subreaders are closed if this ParallelReader is closed.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.#ctor(System.Boolean)">
            <summary>Construct a ParallelReader. </summary>
            <param name="closeSubReaders">indicates whether the subreaders should be closed
            when this ParallelReader is closed
            </param>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.Add(Lucene.Net.Index.IndexReader)">
            <summary>Add an IndexReader.</summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.Add(Lucene.Net.Index.IndexReader,System.Boolean)">
            <summary>Add an IndexReader whose stored fields will not be returned.  This can
            accellerate search when stored fields are only needed from a subset of
            the IndexReaders.
            
            </summary>
            <throws>  IllegalArgumentException if not all indexes contain the same number </throws>
            <summary>     of documents
            </summary>
            <throws>  IllegalArgumentException if not all indexes have the same value </throws>
            <summary>     of {@link IndexReader#MaxDoc()}
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.Reopen">
            <summary> Tries to reopen the subreaders.
            <br/>
            If one or more subreaders could be re-opened (i. e. subReader.reopen() 
            returned a new instance != subReader), then a new ParallelReader instance 
            is returned, otherwise this instance is returned.
            <p/>
            A re-opened instance might share one or more subreaders with the old 
            instance. Index modification operations result in undefined behavior
            when performed before the old instance is closed.
            (see {@link IndexReader#Reopen()}).
            <p/>
            If subreaders are shared, then the reference count of those
            readers is increased to ensure that the subreaders remain open
            until the last referring reader is closed.
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error  </throws>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.IsCurrent">
            <summary> Checks recursively if all subreaders are up to date. </summary>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.IsOptimized">
            <summary> Checks recursively if all subindexes are optimized </summary>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.GetVersion">
            <summary>Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.ParallelReader.DoCommit">
            <deprecated> 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Index.MergeDocIDRemapper">
            <summary>Remaps docIDs after a merge has completed, where the
            merged segments had at least one deletion.  This is used
            to renumber the buffered deletes in IndexWriter when a
            merge of segments with deletions commits. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileDeleter.VERBOSE_REF_COUNTS">
            <summary>Change to true to see details of reference counts when
            infoStream != null 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Index.IndexDeletionPolicy,Lucene.Net.Index.SegmentInfos,System.IO.StreamWriter,Lucene.Net.Index.DocumentsWriter,System.Collections.Generic.Dictionary{System.String,System.String})">
            <summary> Initialize the deleter: find all previous commits in
            the Directory, incref the files they reference, call
            the policy to let it delete commits.  This will remove
            any files not referenced by any of the commits.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.DeleteCommits">
            <summary> Remove the CommitPoints in the commitsToDelete List by
            DecRef'ing all files from each SegmentInfos.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.Refresh(System.String)">
            <summary> Writer calls this when it has hit an error and had to
            roll back, to tell us that there may now be
            unreferenced files in the filesystem.  So we re-list
            the filesystem and delete such files.  If segmentName
            is non-null, we will only delete files corresponding to
            that segment.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.Checkpoint(Lucene.Net.Index.SegmentInfos,System.Boolean)">
            <summary> For definition of "check point" see IndexWriter comments:
            "Clarification: Check Points (and commits)".
            
            Writer calls this when it has made a "consistent
            change" to the index, meaning new files are written to
            the index and the in-memory SegmentInfos have been
            modified to point to those files.
            
            This may or may not be a commit (segments_N may or may
            not have been written).
            
            We simply incref the files referenced by the new
            SegmentInfos and decref the files we had previously
            seen (if any).
            
            If this is a commit, we also call the policy to give it
            a chance to remove other commits.  If any commits are
            removed, we decref their files as well.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.DeleteNewFiles(System.Collections.Generic.ICollection{System.String})">
            <summary>Deletes the specified files, but only if they are new
            (have not yet been incref'd). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexFileDeleter.RefCount">
            <summary> Tracks the reference count for a single index file:</summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexFileDeleter.CommitPoint">
            <summary> Holds details for each commit point.  This class is
            also passed to the deletion policy.  Note: this class
            has a natural ordering that is inconsistent with
            equals.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexCommit">
            <summary> <p/>Expert: represents a single commit into an index as seen by the
            {@link IndexDeletionPolicy} or {@link IndexReader}.<p/>
            
            <p/> Changes to the content of an index are made visible
            only after the writer who made that change commits by
            writing a new segments file
            (<code>segments_N</code>). This point in time, when the
            action of writing of a new segments file to the directory
            is completed, is an index commit.<p/>
            
            <p/>Each index commit point has a unique segments file
            associated with it. The segments file associated with a
            later index commit point would have a larger N.<p/>
            
            <p/><b>WARNING</b>: This API is a new and experimental and
            may suddenly change. <p/>
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexCommitPoint">
            <deprecated> Please subclass IndexCommit class instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommitPoint.GetSegmentsFileName">
            <summary> Get the segments file (<code>segments_N</code>) associated 
            with this commit point.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommitPoint.GetFileNames">
            <summary> Returns all index files referenced by this commit point.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommitPoint.Delete">
            <summary> Delete this commit point.
            <p/>
            Upon calling this, the writer is notified that this commit 
            point should be deleted. 
            <p/>
            Decision that a commit-point should be deleted is taken by the {@link IndexDeletionPolicy} in effect
            and therefore this should only be called by its {@link IndexDeletionPolicy#onInit onInit()} or 
            {@link IndexDeletionPolicy#onCommit onCommit()} methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetSegmentsFileName">
            <summary> Get the segments file (<code>segments_N</code>) associated 
            with this commit point.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetFileNames">
            <summary> Returns all index files referenced by this commit point.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetDirectory">
            <summary> Returns the {@link Directory} for the index.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.Delete">
            <summary> Delete this commit point.  This only applies when using
            the commit point in the context of IndexWriter's
            IndexDeletionPolicy.
            <p/>
            Upon calling this, the writer is notified that this commit 
            point should be deleted. 
            <p/>
            Decision that a commit-point should be deleted is taken by the {@link IndexDeletionPolicy} in effect
            and therefore this should only be called by its {@link IndexDeletionPolicy#onInit onInit()} or 
            {@link IndexDeletionPolicy#onCommit onCommit()} methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.IsOptimized">
            <summary> Returns true if this commit is an optimized index.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.Equals(System.Object)">
            <summary> Two IndexCommits are equal if both their Directory and versions are equal.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetVersion">
            <summary>Returns the version for this IndexCommit.  This is the
            same value that {@link IndexReader#getVersion} would
            return if it were opened on this commit. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetGeneration">
            <summary>Returns the generation (the _N in segments_N) for this
            IndexCommit 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetTimestamp">
            <summary>Convenience method that returns the last modified time
            of the segments_N file corresponding to this index
            commit, equivalent to
            getDirectory().fileModified(getSegmentsFileName()). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexCommit.GetUserData">
            <summary>Returns userData, previously passed to {@link
            IndexWriter#Commit(Map)} for this commit.  Map is
            String -> String. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileDeleter.CommitPoint.Delete">
            <summary> Called only be the deletion policy, to remove this
            commit point from the index.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumerPerField.ProcessFields(Lucene.Net.Documents.Fieldable[],System.Int32)">
            <summary>Processes all occurrences of a single field </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocFieldConsumers">
            <summary>This is just a "splitter" class: it lets you wrap two
            DocFieldConsumer instances as a single consumer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumer.Flush(System.Collections.IDictionary,Lucene.Net.Index.SegmentWriteState)">
            <summary>Called when DocumentsWriter decides to create a new
            segment 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumer.CloseDocStore(Lucene.Net.Index.SegmentWriteState)">
            <summary>Called when DocumentsWriter decides to close the doc
            stores 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumer.Abort">
            <summary>Called when an aborting exception is hit </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumer.AddThread(Lucene.Net.Index.DocFieldProcessorPerThread)">
            <summary>Add a new thread </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldConsumer.FreeRAM">
            <summary>Called when DocumentsWriter is using too much RAM.
            The consumer should free RAM, if possible, returning
            true if any RAM was in fact freed. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriter.DocWriter">
            <summary>Consumer returns this on each doc.  This holds any
            state that must be flushed synchronized "in docID
            order".  We gather these and flush them in order. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriter">
            <summary> This class accepts multiple added documents and directly
            writes a single segment file.  It does this more
            efficiently than creating a single segment per document
            (with DocumentWriter) and doing standard merges on those
            segments.
            
            Each added document is passed to the {@link DocConsumer},
            which in turn processes the document and interacts with
            other consumers in the indexing chain.  Certain
            consumers, like {@link StoredFieldsWriter} and {@link
            TermVectorsTermsWriter}, digest a document and
            immediately write bytes to the "doc store" files (ie,
            they do not consume RAM per document, except while they
            are processing the document).
            
            Other consumers, eg {@link FreqProxTermsWriter} and
            {@link NormsWriter}, buffer bytes in RAM and flush only
            when a new segment is produced.
            Once we have used our allowed RAM buffer, or the number
            of added docs is large enough (in the case we are
            flushing by doc count instead of RAM usage), we create a
            real segment and flush it to the Directory.
            
            Threads:
            
            Multiple threads are allowed into addDocument at once.
            There is an initial synchronized call to getThreadState
            which allocates a ThreadState for this thread.  The same
            thread will get the same ThreadState over time (thread
            affinity) so that if there are consistent patterns (for
            example each thread is indexing a different content
            source) then we make better use of RAM.  Then
            processDocument is called on that ThreadState without
            synchronization (most of the "heavy lifting" is in this
            call).  Finally the synchronized "finishDocument" is
            called to flush changes to the directory.
            
            When flush is called by IndexWriter, or, we flush
            internally when autoCommit=false, we forcefully idle all
            threads and flush only once they are all idle.  This
            means you can call flush with a given thread even while
            other threads are actively adding/deleting documents.
            
            
            Exceptions:
            
            Because this class directly updates in-memory posting
            lists, and flushes stored fields and term vectors
            directly to files in the directory, there are certain
            limited times when an exception can corrupt this state.
            For example, a disk full while flushing stored fields
            leaves this file in a corrupt state.  Or, an OOM
            exception while appending to the in-memory posting lists
            can corrupt that posting list.  We call such exceptions
            "aborting exceptions".  In these cases we must call
            abort() to discard all docs added since the last flush.
            
            All other exceptions ("non-aborting exceptions") can
            still partially update the index structures.  These
            updates are consistent, but, they represent only a part
            of the document seen up until the exception was hit.
            When this happens, we immediately mark the document as
            deleted so that the document is always atomically ("all
            or none") added to the index.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.NewPerDocBuffer">
            Create and return a new DocWriterBuffer.
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.HasProx">
            <summary>Returns true if any of the fields in the current
            buffered docs have omitTermFreqAndPositions==false 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.SetInfoStream(System.IO.StreamWriter)">
            <summary>If non-null, various details of indexing are printed
            here. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.SetRAMBufferSizeMB(System.Double)">
            <summary>Set how much RAM we can use before flushing. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.SetMaxBufferedDocs(System.Int32)">
            <summary>Set max buffered docs, which means we will flush by
            doc count instead of by RAM usage. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.GetSegment">
            <summary>Get current segment name we are writing. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.GetNumDocsInRAM">
            <summary>Returns how many docs are currently buffered in RAM. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.GetDocStoreSegment">
            <summary>Returns the current doc store segment we are writing
            to.  This will be the same as segment when autoCommit
            * is true. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.GetDocStoreOffset">
            <summary>Returns the doc offset into the shared doc store for
            the current buffered docs. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.CloseDocStore">
            <summary>Closes the current open doc stores an returns the doc
            store segment name.  This returns null if there are *
            no buffered documents. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.Abort">
            <summary>Called if we hit an exception at a bad time (when
            updating the index files) and must discard all
            currently buffered docs.  This resets our state,
            discarding any docs added since last flush. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.DoAfterFlush">
            <summary>Reset after a flush </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.Flush(System.Boolean)">
            <summary>Flush all pending docs to a new segment </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.CreateCompoundFile(System.String)">
            <summary>Build compound file for the segment we just flushed </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.SetFlushPending">
            <summary>Set flushPending if it is not already set and returns
            whether it was set. This is used by IndexWriter to
            trigger a single flush even when multiple threads are
            trying to do so. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.GetThreadState(Lucene.Net.Documents.Document,Lucene.Net.Index.Term)">
            <summary>Returns a free (idle) ThreadState that may be used for
            indexing this one document.  This call also pauses if a
            flush is pending.  If delTerm is non-null then we
            buffer this deleted term after the thread state has
            been acquired. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.AddDocument(Lucene.Net.Documents.Document,Lucene.Net.Analysis.Analyzer)">
            <summary>Returns true if the caller (IndexWriter) should now
            flush. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.RemapDeletes(Lucene.Net.Index.SegmentInfos,System.Int32[][],System.Int32[],Lucene.Net.Index.MergePolicy.OneMerge,System.Int32)">
            <summary>Called whenever a merge has completed and the merged segments had deletions </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.FinishDocument(Lucene.Net.Index.DocumentsWriterThreadState,Lucene.Net.Index.DocumentsWriter.DocWriter)">
            <summary>Does the synchronized work to finish/flush the
            inverted document. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriter.IndexingChain">
            <summary> The IndexingChain must define the {@link #GetChain(DocumentsWriter)} method
            which returns the DocConsumer that the DocumentsWriter calls to process the
            documents. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriter.DocWriter">
            <summary>Consumer returns this on each doc.  This holds any
            state that must be flushed synchronized "in docID
            order".  We gather these and flush them in order. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriter.PerDocBuffer">
            RAMFile buffer for DocWriters.
        </member>
        <member name="M:Lucene.Net.Store.RAMFile.NewBuffer(System.Int32)">
            <summary> Expert: allocate a new buffer. 
            Subclasses can allocate differently. 
            </summary>
            <param name="size">size of allocated buffer.
            </param>
            <returns> allocated buffer.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.PerDocBuffer.NewBuffer(System.Int32)">
            Allocate bytes used from shared pool.
        </member>
        <member name="M:Lucene.Net.Index.DocumentsWriter.PerDocBuffer.Recycle">
            Recycle the bytes used.
        </member>
        <member name="T:Lucene.Net.Index.DirectoryOwningReader">
            <summary> This class keeps track of closing the underlying directory. It is used to wrap
            DirectoryReaders, that are created using a String/File parameter
            in IndexReader.open() with FSDirectory.getDirectory().
            </summary>
            <deprecated> This helper class is removed with all String/File
            IndexReader.open() methods in Lucene 3.0
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Index.FilterIndexReader">
            <summary>A <code>FilterIndexReader</code> contains another IndexReader, which it
            uses as its basic source of data, possibly transforming the data along the
            way or providing additional functionality. The class
            <code>FilterIndexReader</code> itself simply implements all abstract methods
            of <code>IndexReader</code> with versions that pass all requests to the
            contained index reader. Subclasses of <code>FilterIndexReader</code> may
            further override some of these methods and may also provide additional
            methods and fields.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FilterIndexReader.#ctor(Lucene.Net.Index.IndexReader)">
            <summary> <p/>Construct a FilterIndexReader based on the specified base reader.
            Directory locking for delete, undeleteAll, and setNorm operations is
            left to the base reader.<p/>
            <p/>Note that base reader is closed if this FilterIndexReader is closed.<p/>
            </summary>
            <param name="in">specified base reader.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FilterIndexReader.DoCommit">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.FilterIndexReader.GetFieldCacheKey">
             <summary>
             If the subclass of FilteredIndexReader modifies the
             contents of the FieldCache, you must override this
             method to provide a different key */
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FilterIndexReader.GetDeletesCacheKey">
            <summary>
            If the subclass of FilteredIndexReader modifies the
            deleted docs, you must override this method to provide
            a different key */
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FilterIndexReader.FilterTermDocs">
            <summary>Base class for filtering {@link TermDocs} implementations. </summary>
        </member>
        <member name="T:Lucene.Net.Index.FilterIndexReader.FilterTermPositions">
            <summary>Base class for filtering {@link TermPositions} implementations. </summary>
        </member>
        <member name="T:Lucene.Net.Index.FilterIndexReader.FilterTermEnum">
            <summary>Base class for filtering {@link TermEnum} implementations. </summary>
        </member>
        <member name="F:Lucene.Net.Index.DirectoryOwningReader.ref_Renamed">
            <summary> This member contains the ref counter, that is passed to each instance after cloning/reopening,
            and is global to all DirectoryOwningReader derived from the original one.
            This reuses the class {@link SegmentReader.Ref}
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.DateTools">
            <summary> Provides support for converting dates to strings and vice-versa.
            The strings are structured so that lexicographic sorting orders 
            them by date, which makes them suitable for use as field values 
            and search terms.
            
            <p/>This class also helps you to limit the resolution of your dates. Do not
            save dates with a finer resolution than you really need, as then
            RangeQuery and PrefixQuery will require more memory and become slower.
            
            <p/>Compared to {@link DateField} the strings generated by the methods
            in this class take slightly more space, unless your selected resolution
            is set to <code>Resolution.DAY</code> or lower.
            
            <p/>
            Another approach is {@link NumericUtils}, which provides
            a sortable binary representation (prefix encoded) of numeric values, which
            date/time are.
            For indexing a {@link Date} or {@link Calendar}, just get the unix timestamp as
            <code>long</code> using {@link Date#getTime} or {@link Calendar#getTimeInMillis} and
            index this as a numeric value with {@link NumericField}
            and use {@link NumericRangeQuery} to query it.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.DateToString(System.DateTime,Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Converts a Date to a string suitable for indexing.
            
            </summary>
            <param name="date">the date to be converted
            </param>
            <param name="resolution">the desired resolution, see
            {@link #Round(Date, DateTools.Resolution)}
            </param>
            <returns> a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
            depending on <code>resolution</code>; using GMT as timezone 
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.TimeToString(System.Int64,Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Converts a millisecond time to a string suitable for indexing.
            
            </summary>
            <param name="time">the date expressed as milliseconds since January 1, 1970, 00:00:00 GMT
            </param>
            <param name="resolution">the desired resolution, see
            {@link #Round(long, DateTools.Resolution)}
            </param>
            <returns> a string in format <code>yyyyMMddHHmmssSSS</code> or shorter,
            depending on <code>resolution</code>; using GMT as timezone
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.StringToTime(System.String)">
            <summary> Converts a string produced by <code>timeToString</code> or
            <code>DateToString</code> back to a time, represented as the
            number of milliseconds since January 1, 1970, 00:00:00 GMT.
            
            </summary>
            <param name="dateString">the date string to be converted
            </param>
            <returns> the number of milliseconds since January 1, 1970, 00:00:00 GMT
            </returns>
            <throws>  ParseException if <code>dateString</code> is not in the  </throws>
            <summary>  expected format 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.StringToDate(System.String)">
            <summary> Converts a string produced by <code>timeToString</code> or
            <code>DateToString</code> back to a time, represented as a
            Date object.
            
            </summary>
            <param name="dateString">the date string to be converted
            </param>
            <returns> the parsed time as a Date object 
            </returns>
            <throws>  ParseException if <code>dateString</code> is not in the  </throws>
            <summary>  expected format 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.Round(System.DateTime,Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Limit a date's resolution. For example, the date <code>2004-09-21 13:50:11</code>
            will be changed to <code>2004-09-01 00:00:00</code> when using
            <code>Resolution.MONTH</code>. 
            
            </summary>
            <param name="resolution">The desired resolution of the date to be returned
            </param>
            <returns> the date with all values more precise than <code>resolution</code>
            set to 0 or 1
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.DateTools.Round(System.Int64,Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Limit a date's resolution. For example, the date <code>1095767411000</code>
            (which represents 2004-09-21 13:50:11) will be changed to 
            <code>1093989600000</code> (2004-09-01 00:00:00) when using
            <code>Resolution.MONTH</code>.
            
            </summary>
            <param name="time">The time in milliseconds (not ticks).</param>
            <param name="resolution">The desired resolution of the date to be returned
            </param>
            <returns> the date with all values more precise than <code>resolution</code>
            set to 0 or 1, expressed as milliseconds since January 1, 1970, 00:00:00 GMT
            </returns>
        </member>
        <member name="T:Lucene.Net.Documents.DateTools.Resolution">
            <summary>Specifies the time granularity. </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.TypeAttributeImpl">
            <summary> A Token's lexical type. The Default value is "word". </summary>
        </member>
        <member name="T:Lucene.Net.Util.AttributeImpl">
            <summary> Base class for Attributes that can be added to a 
            {@link Lucene.Net.Util.AttributeSource}.
            <p/>
            Attributes are used to add data in a dynamic, yet type-safe way to a source
            of usually streamed objects, e. g. a {@link Lucene.Net.Analysis.TokenStream}.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.Attribute">
            <summary> Base interface for attributes.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.Clear">
            <summary> Clears the values in this AttributeImpl and resets it to its 
            default value. If this implementation implements more than one Attribute interface
            it clears all.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.ToString">
            <summary> The default implementation of this method accesses all declared
            fields of this object and prints the values in the following syntax:
            
            <pre>
            public String toString() {
            return "start=" + startOffset + ",end=" + endOffset;
            }
            </pre>
            
            This method may be overridden by subclasses.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.GetHashCode">
            <summary> Subclasses must implement this method and should compute
            a hashCode similar to this:
            <pre>
            public int hashCode() {
            int code = startOffset;
            code = code * 31 + endOffset;
            return code;
            }
            </pre> 
            
            see also {@link #equals(Object)}
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.Equals(System.Object)">
            <summary> All values used for computation of {@link #hashCode()} 
            should be checked here for equality.
            
            see also {@link Object#equals(Object)}
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.CopyTo(Lucene.Net.Util.AttributeImpl)">
            <summary> Copies the values from this Attribute into the passed-in
            target attribute. The target implementation must support all the
            Attributes this implementation supports.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeImpl.Clone">
            <summary> Shallow clone. Subclasses must override this if they 
            need to clone any members deeply,
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.TypeAttribute">
            <summary> A Token's lexical type. The Default value is "word". </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TypeAttribute.Type">
            <summary>Returns this Token's lexical type.  Defaults to "word". </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TypeAttribute.SetType(System.String)">
            <summary>Set the lexical type.</summary>
            <seealso cref="M:Lucene.Net.Analysis.Tokenattributes.TypeAttribute.Type">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TypeAttributeImpl.Type">
            <summary>Returns this Token's lexical type.  Defaults to "word". </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TypeAttributeImpl.SetType(System.String)">
            <summary>Set the lexical type.</summary>
            <seealso cref="M:Lucene.Net.Analysis.Tokenattributes.TypeAttributeImpl.Type">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Analysis.StopFilter">
            <summary> Removes stop words from a token stream.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TokenFilter">
            <summary> A TokenFilter is a TokenStream whose input is another TokenStream.
            <p/>
            This is an abstract class; subclasses must override {@link #IncrementToken()}.
            
            </summary>
            <seealso cref="T:Lucene.Net.Analysis.TokenStream">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Analysis.TokenStream">
            <summary> A <code>TokenStream</code> enumerates the sequence of tokens, either from
            {@link Field}s of a {@link Document} or from query text.
            <p/>
            This is an abstract class. Concrete subclasses are:
            <ul>
            <li>{@link Tokenizer}, a <code>TokenStream</code> whose input is a Reader; and</li>
            <li>{@link TokenFilter}, a <code>TokenStream</code> whose input is another
            <code>TokenStream</code>.</li>
            </ul>
            A new <code>TokenStream</code> API has been introduced with Lucene 2.9. This API
            has moved from being {@link Token} based to {@link Attribute} based. While
            {@link Token} still exists in 2.9 as a convenience class, the preferred way
            to store the information of a {@link Token} is to use {@link AttributeImpl}s.
            <p/>
            <code>TokenStream</code> now extends {@link AttributeSource}, which provides
            access to all of the token {@link Attribute}s for the <code>TokenStream</code>.
            Note that only one instance per {@link AttributeImpl} is created and reused
            for every token. This approach reduces object creation and allows local
            caching of references to the {@link AttributeImpl}s. See
            {@link #IncrementToken()} for further details.
            <p/>
            <b>The workflow of the new <code>TokenStream</code> API is as follows:</b>
            <ol>
            <li>Instantiation of <code>TokenStream</code>/{@link TokenFilter}s which add/get
            attributes to/from the {@link AttributeSource}.</li>
            <li>The consumer calls {@link TokenStream#Reset()}.</li>
            <li>The consumer retrieves attributes from the stream and stores local
            references to all attributes it wants to access</li>
            <li>The consumer calls {@link #IncrementToken()} until it returns false and
            consumes the attributes after each call.</li>
            <li>The consumer calls {@link #End()} so that any end-of-stream operations
            can be performed.</li>
            <li>The consumer calls {@link #Close()} to release any resource when finished
            using the <code>TokenStream</code></li>
            </ol>
            To make sure that filters and consumers know which attributes are available,
            the attributes must be added during instantiation. Filters and consumers are
            not required to check for availability of attributes in
            {@link #IncrementToken()}.
            <p/>
            You can find some example code for the new API in the analysis package level
            Javadoc.
            <p/>
            Sometimes it is desirable to capture a current state of a <code>TokenStream</code>
            , e. g. for buffering purposes (see {@link CachingTokenFilter},
            {@link TeeSinkTokenFilter}). For this usecase
            {@link AttributeSource#CaptureState} and {@link AttributeSource#RestoreState}
            can be used.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.AttributeSource">
            <summary> An AttributeSource contains a list of different {@link AttributeImpl}s,
            and methods to add and get them. There can only be a single instance
            of an attribute in the same AttributeSource instance. This is ensured
            by passing in the actual type of the Attribute (Class&lt;Attribute&gt;) to 
            the {@link #AddAttribute(Class)}, which then checks if an instance of
            that type is already present. If yes, it returns the instance, otherwise
            it creates a new instance and returns it.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.#ctor">
            <summary> An AttributeSource using the default attribute factory {@link AttributeSource.AttributeFactory#DEFAULT_ATTRIBUTE_FACTORY}.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.#ctor(Lucene.Net.Util.AttributeSource)">
            <summary> An AttributeSource that uses the same attributes as the supplied one.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory)">
            <summary> An AttributeSource using the supplied {@link AttributeFactory} for creating new {@link Attribute} instances.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.GetAttributeFactory">
            <summary> returns the used AttributeFactory.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.GetAttributeClassesIterator">
             <summary>Returns a new iterator that iterates the attribute classes
             in the same order they were added in.
             Signature for Java 1.5: <code>public Iterator&lt;Class&lt;? extends Attribute&gt;&gt; getAttributeClassesIterator()</code>
            
             Note that this return value is different from Java in that it enumerates over the values
             and not the keys
             </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.GetAttributeImplsIterator">
            <summary>Returns a new iterator that iterates all unique Attribute implementations.
            This iterator may contain less entries that {@link #getAttributeClassesIterator},
            if one instance implements more than one Attribute interface.
            Signature for Java 1.5: <code>public Iterator&lt;AttributeImpl&gt; getAttributeImplsIterator()</code>
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.AttributeSource.knownImplClasses">
            <summary>a cache that stores all interfaces for known implementation classes for performance (slow reflection) </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.AddAttributeImpl(Lucene.Net.Util.AttributeImpl)">
            <summary>Adds a custom AttributeImpl instance with one or more Attribute interfaces. </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.AddAttribute(System.Type)">
            <summary> The caller must pass in a Class&lt;? extends Attribute&gt; value.
            This method first checks if an instance of that class is 
            already in this AttributeSource and returns it. Otherwise a
            new instance is created, added to this AttributeSource and returned. 
            Signature for Java 1.5: <code>public &lt;T extends Attribute&gt; T addAttribute(Class&lt;T&gt;)</code>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.HasAttributes">
            <summary>Returns true, iff this AttributeSource has any attributes </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.HasAttribute(System.Type)">
            <summary> The caller must pass in a Class&lt;? extends Attribute&gt; value. 
            Returns true, iff this AttributeSource contains the passed-in Attribute.
            Signature for Java 1.5: <code>public boolean hasAttribute(Class&lt;? extends Attribute&gt;)</code>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.GetAttribute(System.Type)">
            <summary> The caller must pass in a Class&lt;? extends Attribute&gt; value. 
            Returns the instance of the passed in Attribute contained in this AttributeSource
            Signature for Java 1.5: <code>public &lt;T extends Attribute&gt; T getAttribute(Class&lt;T&gt;)</code>
            
            </summary>
            <throws>  IllegalArgumentException if this AttributeSource does not contain the </throws>
            <summary>         Attribute. It is recommended to always use {@link #addAttribute} even in consumers
            of TokenStreams, because you cannot know if a specific TokenStream really uses
            a specific Attribute. {@link #addAttribute} will automatically make the attribute
            available. If you want to only use the attribute, if it is available (to optimize
            consuming), use {@link #hasAttribute}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.ClearAttributes">
            <summary> Resets all Attributes in this AttributeSource by calling
            {@link AttributeImpl#Clear()} on each Attribute implementation.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.CaptureState">
            <summary> Captures the state of all Attributes. The return value can be passed to
            {@link #restoreState} to restore the state of this or another AttributeSource.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.RestoreState(Lucene.Net.Util.AttributeSource.State)">
            <summary> Restores this state by copying the values of all attribute implementations
            that this state contains into the attributes implementations of the targetStream.
            The targetStream must contain a corresponding instance for each argument
            contained in this state (e.g. it is not possible to restore the state of
            an AttributeSource containing a TermAttribute into a AttributeSource using
            a Token instance as implementation).
            
            Note that this method does not affect attributes of the targetStream
            that are not contained in this state. In other words, if for example
            the targetStream contains an OffsetAttribute, but this state doesn't, then
            the value of the OffsetAttribute remains unchanged. It might be desirable to
            reset its value to the default, in which case the caller should first
            call {@link TokenStream#ClearAttributes()} on the targetStream.   
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.CloneAttributes">
            <summary> Performs a clone of all {@link AttributeImpl} instances returned in a new
            AttributeSource instance. This method can be used to e.g. create another TokenStream
            with exactly the same attributes (using {@link #AttributeSource(AttributeSource)})
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.AttributeSource.AttributeFactory">
            <summary> An AttributeFactory creates instances of {@link AttributeImpl}s.</summary>
        </member>
        <member name="M:Lucene.Net.Util.AttributeSource.AttributeFactory.CreateAttributeInstance(System.Type)">
            <summary> returns an {@link AttributeImpl} for the supplied {@link Attribute} interface class.
            <p/>Signature for Java 1.5: <code>public AttributeImpl createAttributeInstance(Class%lt;? extends Attribute&gt; attClass)</code>
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.AttributeSource.AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY">
            <summary> This is the default factory that creates {@link AttributeImpl}s using the
            class name of the supplied {@link Attribute} interface class by appending <code>Impl</code> to it.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.AttributeSource.State">
            <summary> This class holds the state of an AttributeSource.</summary>
            <seealso cref="!:captureState">
            </seealso>
            <seealso cref="!:restoreState">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenStream.DEFAULT_TOKEN_WRAPPER_ATTRIBUTE_FACTORY">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenStream.tokenWrapper">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenStream.onlyUseNewAPI">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenStream.supportedMethods">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenStream.knownMethodSupport">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.GetSupportedMethods(System.Type)">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.#ctor">
            <summary> A TokenStream using the default attribute factory.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.#ctor(Lucene.Net.Util.AttributeSource)">
            <summary> A TokenStream that uses the same attributes as the supplied one.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory)">
            <summary> A TokenStream using the supplied AttributeFactory for creating new {@link Attribute} instances.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.InitTokenWrapper(Lucene.Net.Util.AttributeSource)">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.Check">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.SetOnlyUseNewAPI(System.Boolean)">
            <summary> For extra performance you can globally enable the new
            {@link #IncrementToken} API using {@link Attribute}s. There will be a
            small, but in most cases negligible performance increase by enabling this,
            but it only works if <b>all</b> <code>TokenStream</code>s use the new API and
            implement {@link #IncrementToken}. This setting can only be enabled
            globally.
            <p/>
            This setting only affects <code>TokenStream</code>s instantiated after this
            call. All <code>TokenStream</code>s already created use the other setting.
            <p/>
            All core {@link Analyzer}s are compatible with this setting, if you have
            your own <code>TokenStream</code>s that are also compatible, you should enable
            this.
            <p/>
            When enabled, tokenization may throw {@link UnsupportedOperationException}
            s, if the whole tokenizer chain is not compatible eg one of the
            <code>TokenStream</code>s does not implement the new <code>TokenStream</code> API.
            <p/>
            The default is <code>false</code>, so there is the fallback to the old API
            available.
            
            </summary>
            <deprecated> This setting will no longer be needed in Lucene 3.0 as the old
            API will be removed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.GetOnlyUseNewAPI">
            <summary> Returns if only the new API is used.
            
            </summary>
            <seealso cref="!:setOnlyUseNewAPI">
            </seealso>
            <deprecated> This setting will no longer be needed in Lucene 3.0 as
            the old API will be removed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.IncrementToken">
            <summary> Consumers (i.e., {@link IndexWriter}) use this method to advance the stream to
            the next token. Implementing classes must implement this method and update
            the appropriate {@link AttributeImpl}s with the attributes of the next
            token.
            
            The producer must make no assumptions about the attributes after the
            method has been returned: the caller may arbitrarily change it. If the
            producer needs to preserve the state for subsequent calls, it can use
            {@link #captureState} to create a copy of the current attribute state.
            
            This method is called for every token of a document, so an efficient
            implementation is crucial for good performance. To avoid calls to
            {@link #AddAttribute(Class)} and {@link #GetAttribute(Class)} or downcasts,
            references to all {@link AttributeImpl}s that this stream uses should be
            retrieved during instantiation.
            
            To ensure that filters and consumers know which attributes are available,
            the attributes must be added during instantiation. Filters and consumers
            are not required to check for availability of attributes in
            {@link #IncrementToken()}.
            
            </summary>
            <returns> false for end of stream; true otherwise
            
            Note that this method will be defined abstract in Lucene
            3.0.
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.End">
            <summary> This method is called by the consumer after the last token has been
            consumed, after {@link #IncrementToken()} returned <code>false</code>
            (using the new <code>TokenStream</code> API). Streams implementing the old API
            should upgrade to use this feature.
            <p/>
            This method can be used to perform any end-of-stream operations, such as
            setting the final offset of a stream. The final offset of a stream might
            differ from the offset of the last token eg in case one or more whitespaces
            followed after the last token, but a {@link WhitespaceTokenizer} was used.
            
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.Next(Lucene.Net.Analysis.Token)">
            <summary> Returns the next token in the stream, or null at EOS. When possible, the
            input Token should be used as the returned Token (this gives fastest
            tokenization performance), but this is not required and a new Token may be
            returned. Callers may re-use a single Token instance for successive calls
            to this method.
            
            This implicitly defines a "contract" between consumers (callers of this
            method) and producers (implementations of this method that are the source
            for tokens):
            <ul>
            <li>A consumer must fully consume the previously returned {@link Token}
            before calling this method again.</li>
            <li>A producer must call {@link Token#Clear()} before setting the fields in
            it and returning it</li>
            </ul>
            Also, the producer must make no assumptions about a {@link Token} after it
            has been returned: the caller may arbitrarily change it. If the producer
            needs to hold onto the {@link Token} for subsequent calls, it must clone()
            it before storing it. Note that a {@link TokenFilter} is considered a
            consumer.
            
            </summary>
            <param name="reusableToken">a {@link Token} that may or may not be used to return;
            this parameter should never be null (the callee is not required to
            check for null before using it, but it is a good idea to assert that
            it is not null.)
            </param>
            <returns> next {@link Token} in the stream or null if end-of-stream was hit
            </returns>
            <deprecated> The new {@link #IncrementToken()} and {@link AttributeSource}
            APIs should be used instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.Next">
            <summary> Returns the next {@link Token} in the stream, or null at EOS.
            
            </summary>
            <deprecated> The returned Token is a "full private copy" (not re-used across
            calls to {@link #Next()}) but will be slower than calling
            {@link #Next(Token)} or using the new {@link #IncrementToken()}
            method with the new {@link AttributeSource} API.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.Reset">
            <summary> Resets this stream to the beginning. This is an optional operation, so
            subclasses may or may not implement this method. {@link #Reset()} is not needed for
            the standard indexing process. However, if the tokens of a
            <code>TokenStream</code> are intended to be consumed more than once, it is
            necessary to implement {@link #Reset()}. Note that if your TokenStream
            caches tokens and feeds them back again after a reset, it is imperative
            that you clone the tokens when you store them away (on the first pass) as
            well as when you return them (on future passes after {@link #Reset()}).
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenStream.Close">
            <summary>Releases resources associated with this stream. </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TokenStream.MethodSupport">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Analysis.TokenStream.TokenWrapperAttributeFactory">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.TokenFilter.input">
            <summary>The source of tokens for this filter. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenFilter.#ctor(Lucene.Net.Analysis.TokenStream)">
            <summary>Construct a token stream filtering the given input. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenFilter.End">
            <summary>Performs end-of-stream operations, if any, and calls then <code>end()</code> on the
            input TokenStream.<p/> 
            <b>NOTE:</b> Be sure to call <code>super.end()</code> first when overriding this method.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenFilter.Close">
            <summary>Close the input TokenStream. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TokenFilter.Reset">
            <summary>Reset the filter as well as the input TokenStream. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.String[])">
            <summary> Construct a token stream filtering the given input.</summary>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, String[])} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(System.Boolean,Lucene.Net.Analysis.TokenStream,System.String[])">
            <summary> Construct a token stream filtering the given input.</summary>
            <param name="enablePositionIncrements">true if token positions should record the removed stop words
            </param>
            <param name="input">input TokenStream
            </param>
            <param name="stopWords">array of stop words
            </param>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, Set)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.String[],System.Boolean)">
            <summary> Constructs a filter which removes words from the input
            TokenStream that are named in the array of words.
            </summary>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, String[], boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(System.Boolean,Lucene.Net.Analysis.TokenStream,System.String[],System.Boolean)">
            <summary> Constructs a filter which removes words from the input
            TokenStream that are named in the array of words.
            </summary>
            <param name="enablePositionIncrements">true if token positions should record the removed stop words
            </param>
            <param name="in">input TokenStream
            </param>
            <param name="stopWords">array of stop words
            </param>
            <param name="ignoreCase">true if case is ignored
            </param>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, Set, boolean)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable,System.Boolean)">
            <summary> Construct a token stream filtering the given input.
            If <code>stopWords</code> is an instance of {@link CharArraySet} (true if
            <code>makeStopSet()</code> was used to construct the set) it will be directly used
            and <code>ignoreCase</code> will be ignored since <code>CharArraySet</code>
            directly controls case sensitivity.
            <p/>
            If <code>stopWords</code> is not an instance of {@link CharArraySet},
            a new CharArraySet will be constructed and <code>ignoreCase</code> will be
            used to specify the case sensitivity of that set.
            
            </summary>
            <param name="input">
            </param>
            <param name="stopWords">The set of Stop Words.
            </param>
            <param name="ignoreCase">-Ignore case when stopping.
            </param>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, Set, boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(System.Boolean,Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable,System.Boolean)">
            <summary> Construct a token stream filtering the given input.
            If <code>stopWords</code> is an instance of {@link CharArraySet} (true if
            <code>makeStopSet()</code> was used to construct the set) it will be directly used
            and <code>ignoreCase</code> will be ignored since <code>CharArraySet</code>
            directly controls case sensitivity.
            <p/>
            If <code>stopWords</code> is not an instance of {@link CharArraySet},
            a new CharArraySet will be constructed and <code>ignoreCase</code> will be
            used to specify the case sensitivity of that set.
            
            </summary>
            <param name="enablePositionIncrements">true if token positions should record the removed stop words
            </param>
            <param name="input">Input TokenStream
            </param>
            <param name="stopWords">The set of Stop Words.
            </param>
            <param name="ignoreCase">-Ignore case when stopping.
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable)">
            <summary> Constructs a filter which removes words from the input
            TokenStream that are named in the Set.
            
            </summary>
            <seealso cref="!:MakeStopSet(java.lang.String[])">
            </seealso>
            <deprecated> Use {@link #StopFilter(boolean, TokenStream, Set)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.#ctor(System.Boolean,Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable)">
            <summary> Constructs a filter which removes words from the input
            TokenStream that are named in the Set.
            
            </summary>
            <param name="enablePositionIncrements">true if token positions should record the removed stop words
            </param>
            <param name="in">Input stream
            </param>
            <param name="stopWords">The set of Stop Words.
            </param>
            <seealso cref="!:MakeStopSet(java.lang.String[])">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.MakeStopSet(System.String[])">
            <summary> Builds a Set from an array of stop words,
            appropriate for passing into the StopFilter constructor.
            This permits this stopWords construction to be cached once when
            an Analyzer is constructed.
            
            </summary>
            <seealso cref="!:MakeStopSet(java.lang.String[], boolean)"> passing false to ignoreCase
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.MakeStopSet(System.Collections.IList)">
            <summary> Builds a Set from an array of stop words,
            appropriate for passing into the StopFilter constructor.
            This permits this stopWords construction to be cached once when
            an Analyzer is constructed.
            
            </summary>
            <seealso cref="!:MakeStopSet(java.lang.String[], boolean)"> passing false to ignoreCase
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.MakeStopSet(System.String[],System.Boolean)">
            <summary> </summary>
            <param name="stopWords">An array of stopwords
            </param>
            <param name="ignoreCase">If true, all words are lower cased first.  
            </param>
            <returns> a Set containing the words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.MakeStopSet(System.Collections.IList,System.Boolean)">
            <summary> </summary>
            <param name="stopWords">A List of Strings representing the stopwords
            </param>
            <param name="ignoreCase">if true, all words are lower cased first
            </param>
            <returns> A Set containing the words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.IncrementToken">
            <summary> Returns the next input Token whose term() is not a stop word.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.GetEnablePositionIncrementsDefault">
            <seealso cref="M:Lucene.Net.Analysis.StopFilter.SetEnablePositionIncrementsDefault(System.Boolean)">
            </seealso>
            <deprecated> Please specify this when you create the StopFilter
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.GetEnablePositionIncrementsVersionDefault(Lucene.Net.Util.Version)">
            <summary> Returns version-dependent default for enablePositionIncrements. Analyzers
            that embed StopFilter use this method when creating the StopFilter. Prior
            to 2.9, this returns {@link #getEnablePositionIncrementsDefault}. On 2.9
            or later, it returns true.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.SetEnablePositionIncrementsDefault(System.Boolean)">
            <summary> Set the default position increments behavior of every StopFilter created
            from now on.
            <p/>
            Note: behavior of a single StopFilter instance can be modified with
            {@link #SetEnablePositionIncrements(boolean)}. This static method allows
            control over behavior of classes using StopFilters internally, for
            example {@link Lucene.Net.Analysis.Standard.StandardAnalyzer
            StandardAnalyzer} if used with the no-arg ctor.
            <p/>
            Default : false.
            
            </summary>
            <seealso cref="!:setEnablePositionIncrements(bool)">
            </seealso>
            <deprecated> Please specify this when you create the StopFilter
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.GetEnablePositionIncrements">
            <seealso cref="M:Lucene.Net.Analysis.StopFilter.SetEnablePositionIncrements(System.Boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.StopFilter.SetEnablePositionIncrements(System.Boolean)">
            <summary> If <code>true</code>, this StopFilter will preserve
            positions of the incoming tokens (ie, accumulate and
            set position increments of the removed stop tokens).
            Generally, <code>true</code> is best as it does not
            lose information (positions of the original tokens)
            during indexing.
            
            <p/> When set, when a token is stopped
            (omitted), the position increment of the following
            token is incremented.
            
            <p/> <b>NOTE</b>: be sure to also
            set {@link QueryParser#setEnablePositionIncrements} if
            you use QueryParser to create queries.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Standard.StandardTokenizerImpl">
            <summary> This class is a scanner generated by 
            <a href="http://www.jflex.de/">JFlex</a> 1.4.1
            on 9/4/08 6:49 PM from the specification file
            <tt>/tango/mike/src/lucene.standarddigit/src/java/org/apache/lucene/analysis/standard/StandardTokenizerImpl.jflex</tt>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.YYEOF">
            <summary>This character denotes the end of file </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_BUFFERSIZE">
            <summary>initial size of the lookahead buffer </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.YYINITIAL">
            <summary>lexical states </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_CMAP_PACKED">
            <summary> Translates characters to character classes</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_CMAP">
            <summary> Translates characters to character classes</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_ACTION">
            <summary> Translates DFA states to action switch labels.</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_ROWMAP">
            <summary> Translates a state to a row index in the transition table</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_TRANS">
            <summary> The transition table of the DFA</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZZ_ATTRIBUTE">
            <summary> ZZ_ATTRIBUTE[aState] contains the attributes of state <code>aState</code></summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzReader">
            <summary>the input device </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzState">
            <summary>the current state of the DFA </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzLexicalState">
            <summary>the current lexical state </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzBuffer">
            <summary>this buffer contains the current text to be matched and is
            the source of the yytext() string 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzMarkedPos">
            <summary>the textposition at the last accepting state </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzPushbackPos">
            <summary>the textposition at the last state to be included in yytext </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzCurrentPos">
            <summary>the current text position in the buffer </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzStartRead">
            <summary>startRead marks the beginning of the yytext() string in the buffer </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzEndRead">
            <summary>endRead marks the last character in the buffer, that has been read
            from input 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.yyline">
            <summary>number of newlines encountered up to the start of the matched text </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.yychar">
            <summary>the number of characters up to the start of the matched text </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.yycolumn">
            <summary> the number of characters from the last newline up to the start of the 
            matched text
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzAtBOL">
            <summary> zzAtBOL == true &lt;=&gt; the scanner is currently at the beginning of a line</summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.zzAtEOF">
            <summary>zzAtEOF == true &lt;=&gt; the scanner is at the EOF </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ACRONYM_DEP">
            <deprecated> this solves a bug where HOSTs that end with '.' are identified
            as ACRONYMs. It is deprecated and will be removed in the next
            release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Reset(System.IO.TextReader)">
            Resets the Tokenizer to a new Reader.
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.GetText(Lucene.Net.Analysis.Token)">
            <summary> Fills Lucene token with the current token text.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.GetText(Lucene.Net.Analysis.Tokenattributes.TermAttribute)">
            <summary> Fills TermAttribute with the current token text.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.#ctor(System.IO.TextReader)">
            <summary> Creates a new scanner
            There is also a java.io.InputStream version of this constructor.
            
            </summary>
            <param name="in"> the java.io.Reader to read input from.
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.#ctor(System.IO.Stream)">
            <summary> Creates a new scanner.
            There is also java.io.Reader version of this constructor.
            
            </summary>
            <param name="in"> the java.io.Inputstream to read input from.
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZzUnpackCMap(System.String)">
            <summary> Unpacks the compressed character translation table.
            
            </summary>
            <param name="packed">  the packed character translation table
            </param>
            <returns>         the unpacked character translation table
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZzRefill">
            <summary> Refills the input buffer.
            
            </summary>
            <returns>      <code>false</code>, iff there was new input.
            
            </returns>
            <exception cref="!:java.io.IOException"> if any I/O-Error occurs
            </exception>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yyclose">
            <summary> Closes the input stream.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yyreset(System.IO.TextReader)">
            <summary> Resets the scanner to read from a new input stream.
            Does not close the old reader.
            
            All internal variables are reset, the old input stream 
            <b>cannot</b> be reused (internal buffer is discarded and lost).
            Lexical state is set to <tt>ZZ_INITIAL</tt>.
            
            </summary>
            <param name="reader">  the new input stream 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yystate">
            <summary> Returns the current lexical state.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yybegin(System.Int32)">
            <summary> Enters a new lexical state
            
            </summary>
            <param name="newState">the new lexical state
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yytext">
            <summary> Returns the text matched by the current regular expression.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yycharat(System.Int32)">
            <summary> Returns the character at position <tt>pos</tt> from the 
            matched text. 
            
            It is equivalent to yytext().charAt(pos), but faster
            
            </summary>
            <param name="pos">the position of the character to fetch. 
            A value from 0 to yylength()-1.
            
            </param>
            <returns> the character at position pos
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yylength">
            <summary> Returns the length of the matched text region.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.ZzScanError(System.Int32)">
            <summary> Reports an error that occured while scanning.
            
            In a wellformed scanner (no or only correct usage of 
            yypushback(int) and a match-all fallback rule) this method 
            will only be called with things that "Can't Possibly Happen".
            If this method is called, something is seriously wrong
            (e.g. a JFlex bug producing a faulty scanner etc.).
            
            Usual syntax/scanner level error handling should be done
            in error fallback rules.
            
            </summary>
            <param name="errorCode"> the code of the errormessage to display
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.Yypushback(System.Int32)">
            <summary> Pushes the specified amount of characters back into the input stream.
            
            They will be read again by then next call of the scanning method
            
            </summary>
            <param name="number"> the number of characters to be read again.
            This number must not be greater than yylength()!
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizerImpl.GetNextToken">
            <summary> Resumes scanning until the next regular expression is matched,
            the end of input is encountered or an I/O-Error occurs.
            
            </summary>
            <returns>      the next token
            </returns>
            <exception cref="!:java.io.IOException"> if any I/O-Error occurs
            </exception>
        </member>
        <member name="T:Lucene.Net.Analysis.Standard.StandardAnalyzer">
            <summary> Filters {@link StandardTokenizer} with {@link StandardFilter},
            {@link LowerCaseFilter} and {@link StopFilter}, using a list of English stop
            words.
            
            <a name="version"/>
            <p/>
            You must specify the required {@link Version} compatibility when creating
            StandardAnalyzer:
            <ul>
            <li>As of 2.9, StopFilter preserves position increments</li>
            <li>As of 2.4, Tokens incorrectly identified as acronyms are corrected (see
            <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a></li>
            </ul>
            
            </summary>
            <version>  $Id: StandardAnalyzer.java 829134 2009-10-23 17:18:53Z mikemccand $
            </version>
        </member>
        <member name="T:Lucene.Net.Analysis.Analyzer">
            <summary>An Analyzer builds TokenStreams, which analyze text.  It thus represents a
            policy for extracting index terms from text.
            <p/>
            Typical implementations first build a Tokenizer, which breaks the stream of
            characters from the Reader into raw Tokens.  One or more TokenFilters may
            then be applied to the output of the Tokenizer.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>Creates a TokenStream which tokenizes all the text in the provided
            Reader.  Must be able to handle null field name for
            backward compatibility.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.ReusableTokenStream(System.String,System.IO.TextReader)">
            <summary>Creates a TokenStream that is allowed to be re-used
            from the previous time that the same thread called
            this method.  Callers that do not need to use more
            than one TokenStream at the same time from this
            analyzer should use this method for better
            performance.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.GetPreviousTokenStream">
            <summary>Used by Analyzers that implement reusableTokenStream
            to retrieve previously saved TokenStreams for re-use
            by the same thread. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.SetPreviousTokenStream(System.Object)">
            <summary>Used by Analyzers that implement reusableTokenStream
            to save a TokenStream for later re-use by the same
            thread. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.SetOverridesTokenStreamMethod(System.Type)">
            <deprecated> This is only present to preserve
            back-compat of classes that subclass a core analyzer
            and override tokenStream but not reusableTokenStream 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.GetPositionIncrementGap(System.String)">
            <summary> Invoked before indexing a Fieldable instance if
            terms have already been added to that field.  This allows custom
            analyzers to place an automatic position increment gap between
            Fieldable instances using the same field name.  The default value
            position increment gap is 0.  With a 0 position increment gap and
            the typical default token position increment of 1, all terms in a field,
            including across Fieldable instances, are in successive positions, allowing
            exact PhraseQuery matches, for instance, across Fieldable instance boundaries.
            
            </summary>
            <param name="fieldName">Fieldable name being indexed.
            </param>
            <returns> position increment gap, added to the next token emitted from {@link #TokenStream(String,Reader)}
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.GetOffsetGap(Lucene.Net.Documents.Fieldable)">
            <summary> Just like {@link #getPositionIncrementGap}, except for
            Token offsets instead.  By default this returns 1 for
            tokenized fields and, as if the fields were joined
            with an extra space character, and 0 for un-tokenized
            fields.  This method is only called if the field
            produced at least one token for indexing.
            
            </summary>
            <param name="field">the field just indexed
            </param>
            <returns> offset gap, added to the next token emitted from {@link #TokenStream(String,Reader)}
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Analyzer.Close">
            <summary>Frees persistent resources used by this Analyzer </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH">
            <summary>Default maximum allowed token length </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardAnalyzer.replaceInvalidAcronym">
            <summary> Specifies whether deprecated acronyms should be replaced with HOST type.
            This is false by default to support backward compatibility.
            
            </summary>
            <deprecated> this should be removed in the next release (3.0).
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.GetDefaultReplaceInvalidAcronym">
            <summary> </summary>
            <returns> true if new instances of StandardTokenizer will
            replace mischaracterized acronyms
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </returns>
            <deprecated> This will be removed (hardwired to true) in 3.0
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.SetDefaultReplaceInvalidAcronym(System.Boolean)">
            <summary> </summary>
            <param name="replaceInvalidAcronym">Set to true to have new
            instances of StandardTokenizer replace mischaracterized
            acronyms by default.  Set to false to preserve the
            previous (before 2.4) buggy behavior.  Alternatively,
            set the system property
            Lucene.Net.Analysis.Standard.StandardAnalyzer.replaceInvalidAcronym
            to false.
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </param>
            <deprecated> This will be removed (hardwired to true) in 3.0
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardAnalyzer.STOP_WORDS">
            <summary>An array containing some common English words that are usually not
            useful for searching. 
            </summary>
            <deprecated> Use {@link #STOP_WORDS_SET} instead 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardAnalyzer.STOP_WORDS_SET">
            <summary>An unmodifiable set containing some common English words that are usually not
            useful for searching. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor">
            <summary>Builds an analyzer with the default stop words ({@link
            #STOP_WORDS_SET}).
            </summary>
            <deprecated> Use {@link #StandardAnalyzer(Version)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(Lucene.Net.Util.Version)">
            <summary>Builds an analyzer with the default stop words ({@link
            #STOP_WORDS}).
            </summary>
            <param name="matchVersion">Lucene version to match See {@link
            <a href="#version">above</a>}
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>Builds an analyzer with the given stop words.</summary>
            <deprecated> Use {@link #StandardAnalyzer(Version, Set)}
            instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(Lucene.Net.Util.Version,System.Collections.Hashtable)">
            <summary>Builds an analyzer with the given stop words.</summary>
            <param name="matchVersion">Lucene version to match See {@link
            <a href="#version">above</a>}
            </param>
            <param name="stopWords">stop words 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.String[])">
            <summary>Builds an analyzer with the given stop words.</summary>
            <deprecated> Use {@link #StandardAnalyzer(Version, Set)} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>Builds an analyzer with the stop words from the given file.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(File)">
            </seealso>
            <deprecated> Use {@link #StandardAnalyzer(Version, File)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(Lucene.Net.Util.Version,System.IO.FileInfo)">
            <summary>Builds an analyzer with the stop words from the given file.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(File)">
            </seealso>
            <param name="matchVersion">Lucene version to match See {@link
            <a href="#version">above</a>}
            </param>
            <param name="stopwords">File to read stop words from 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.IO.TextReader)">
            <summary>Builds an analyzer with the stop words from the given reader.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(Reader)">
            </seealso>
            <deprecated> Use {@link #StandardAnalyzer(Version, Reader)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(Lucene.Net.Util.Version,System.IO.TextReader)">
            <summary>Builds an analyzer with the stop words from the given reader.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(Reader)">
            </seealso>
            <param name="matchVersion">Lucene version to match See {@link
            <a href="#version">above</a>}
            </param>
            <param name="stopwords">Reader to read stop words from 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.Boolean)">
            <summary> </summary>
            <param name="replaceInvalidAcronym">Set to true if this analyzer should replace mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.IO.TextReader,System.Boolean)">
            <param name="stopwords">The stopwords to use
            </param>
            <param name="replaceInvalidAcronym">Set to true if this analyzer should replace mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.IO.FileInfo,System.Boolean)">
            <param name="stopwords">The stopwords to use
            </param>
            <param name="replaceInvalidAcronym">Set to true if this analyzer should replace mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.String[],System.Boolean)">
            <summary> </summary>
            <param name="stopwords">The stopwords to use
            </param>
            <param name="replaceInvalidAcronym">Set to true if this analyzer should replace mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.#ctor(System.Collections.Hashtable,System.Boolean)">
            <param name="stopwords">The stopwords to use
            </param>
            <param name="replaceInvalidAcronym">Set to true if this analyzer should replace mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>Constructs a {@link StandardTokenizer} filtered by a {@link
            StandardFilter}, a {@link LowerCaseFilter} and a {@link StopFilter}. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.SetMaxTokenLength(System.Int32)">
            <summary> Set maximum allowed token length.  If a token is seen
            that exceeds this length then it is discarded.  This
            setting only takes effect the next time tokenStream or
            reusableTokenStream is called.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.GetMaxTokenLength">
            <seealso cref="!:setMaxTokenLength">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.ReusableTokenStream(System.String,System.IO.TextReader)">
            <deprecated> Use {@link #tokenStream} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.IsReplaceInvalidAcronym">
            <summary> </summary>
            <returns> true if this Analyzer is replacing mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </returns>
            <deprecated> This will be removed (hardwired to true) in 3.0
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardAnalyzer.SetReplaceInvalidAcronym(System.Boolean)">
            <summary> </summary>
            <param name="replaceInvalidAcronym">Set to true if this Analyzer is replacing mischaracterized acronyms in the StandardTokenizer
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </param>
            <deprecated> This will be removed (hardwired to true) in 3.0
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Analysis.SimpleAnalyzer">
            <summary>An {@link Analyzer} that filters {@link LetterTokenizer} 
            with {@link LowerCaseFilter} 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.MappingCharFilter">
            <summary> Simplistic {@link CharFilter} that applies the mappings
            contained in a {@link NormalizeCharMap} to the character
            stream, and correcting the resulting changes to the
            offsets.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.BaseCharFilter">
            <summary>
            * Base utility class for implementing a {@link CharFilter}.
            * You subclass this, and then record mappings by calling
            * {@link #addOffCorrectMap}, and then invoke the correct
            * method to correct an offset.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CharFilter">
            <summary> Subclasses of CharFilter can be chained to filter CharStream.
            They can be used as {@link java.io.Reader} with additional offset
            correction. {@link Tokenizer}s will automatically use {@link #CorrectOffset}
            if a CharFilter/CharStream subclass is used.
            
            </summary>
            <version>  $Id$
            
            </version>
        </member>
        <member name="T:Lucene.Net.Analysis.CharStream">
            <summary> CharStream adds {@link #CorrectOffset}
            functionality over {@link Reader}.  All Tokenizers accept a
            CharStream instead of {@link Reader} as input, which enables
            arbitrary character based filtering before tokenization. 
            The {@link #CorrectOffset} method fixed offsets to account for
            removal or insertion of characters, so that the offsets
            reported in the tokens match the character offsets of the
            original Reader.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharStream.CorrectOffset(System.Int32)">
            <summary> Called by CharFilter(s) and Tokenizer to correct token offset.
            
            </summary>
            <param name="currentOff">offset as seen in the output
            </param>
            <returns> corrected offset based on the input
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.CharFilter.Correct(System.Int32)">
            <summary> Subclass may want to override to correct the current offset.
            
            </summary>
            <param name="currentOff">current offset
            </param>
            <returns> corrected offset
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.CharFilter.CorrectOffset(System.Int32)">
            <summary> Chains the corrected offset through the input
            CharFilter.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.BaseCharFilter.Correct(System.Int32)">
            Retrieve the corrected offset. 
        </member>
        <member name="M:Lucene.Net.Analysis.MappingCharFilter.#ctor(Lucene.Net.Analysis.NormalizeCharMap,Lucene.Net.Analysis.CharStream)">
            Default constructor that takes a {@link CharStream}.
        </member>
        <member name="M:Lucene.Net.Analysis.MappingCharFilter.#ctor(Lucene.Net.Analysis.NormalizeCharMap,System.IO.TextReader)">
            Easy-use constructor that takes a {@link Reader}.
        </member>
        <member name="T:Lucene.Net.Analysis.CharReader">
            <summary> CharReader is a Reader wrapper. It reads chars from
            Reader and outputs {@link CharStream}, defining an
            identify function {@link #CorrectOffset} method that
            simply returns the provided offset.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.SortedVIntList">
            <summary> Stores and iterate on sorted integers in compressed form in RAM. <br/>
            The code for compressing the differences between ascending integers was
            borrowed from {@link Lucene.Net.Store.IndexInput} and
            {@link Lucene.Net.Store.IndexOutput}.
            <p/>
            <b>NOTE:</b> this class assumes the stored integers are doc Ids (hence why it
            extends {@link DocIdSet}). Therefore its {@link #Iterator()} assumes {@link
            DocIdSetIterator#NO_MORE_DOCS} can be used as sentinel. If you intent to use
            this value, then make sure it's not used during search flow.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.DocIdSet">
            <summary> A DocIdSet contains a set of doc ids. Implementing classes must
            only implement {@link #iterator} to provide access to the set. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.DocIdSet.EMPTY_DOCIDSET">
            <summary>An empty {@code DocIdSet} instance for easy use, e.g. in Filters that hit no documents. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSet.Iterator">
            <summary>Provides a {@link DocIdSetIterator} to access the set.
            This implementation can return <code>null</code> or
            <code>{@linkplain #EMPTY_DOCIDSET}.iterator()</code> if there
            are no docs that match. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DocIdSet.IsCacheable">
            <summary>This method is a hint for {@link CachingWrapperFilter}, if this <code>DocIdSet</code>
            should be cached without copying it into a BitSet. The default is to return
            <code>false</code>. If you have an own <code>DocIdSet</code> implementation
            that does its iteration very effective and fast without doing disk I/O,
            override this method and return true.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.SortedVIntList.BITS2VINTLIST_SIZE">
            <summary>When a BitSet has fewer than 1 in BITS2VINTLIST_SIZE bits set,
            a SortedVIntList representing the index numbers of the set bits
            will be smaller than that BitSet.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.#ctor(System.Int32[])">
            <summary>  Create a SortedVIntList from all elements of an array of integers.
            
            </summary>
            <param name="sortedInts"> A sorted array of non negative integers.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.#ctor(System.Int32[],System.Int32)">
            <summary> Create a SortedVIntList from an array of integers.</summary>
            <param name="sortedInts"> An array of sorted non negative integers.
            </param>
            <param name="inputSize">  The number of integers to be used from the array.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.#ctor(System.Collections.BitArray)">
            <summary> Create a SortedVIntList from a BitSet.</summary>
            <param name="bits"> A bit set representing a set of integers.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.#ctor(Lucene.Net.Util.OpenBitSet)">
            <summary> Create a SortedVIntList from an OpenBitSet.</summary>
            <param name="bits"> A bit set representing a set of integers.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.#ctor(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Create a SortedVIntList.</summary>
            <param name="docIdSetIterator"> An iterator providing document numbers as a set of integers.
            This DocIdSetIterator is iterated completely when this constructor
            is called and it must provide the integers in non
            decreasing order.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.Size">
            <returns>    The total number of sorted integers.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.GetByteSize">
            <returns> The size of the byte array storing the compressed sorted integers.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.IsCacheable">
            <summary>This DocIdSet implementation is cacheable. </summary>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.Iterator">
            <returns>    An iterator over the sorted integers.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.AnonymousClassDocIdSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.AnonymousClassDocIdSetIterator.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.SortedVIntList.AnonymousClassDocIdSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Util.ScorerDocQueue">
            <summary>A ScorerDocQueue maintains a partial ordering of its Scorers such that the
            least Scorer can always be found in constant time.  Put()'s and pop()'s
            require log(size) time. The ordering is by Scorer.doc().
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.#ctor(System.Int32)">
            <summary>Create a ScorerDocQueue with a maximum size. </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Put(Lucene.Net.Search.Scorer)">
            <summary> Adds a Scorer to a ScorerDocQueue in log(size) time.
            If one tries to add more Scorers than maxSize
            a RuntimeException (ArrayIndexOutOfBound) is thrown.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Insert(Lucene.Net.Search.Scorer)">
            <summary> Adds a Scorer to the ScorerDocQueue in log(size) time if either
            the ScorerDocQueue is not full, or not lessThan(scorer, top()).
            </summary>
            <param name="scorer">
            </param>
            <returns> true if scorer is added, false otherwise.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Top">
            <summary>Returns the least Scorer of the ScorerDocQueue in constant time.
            Should not be used when the queue is empty.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.TopDoc">
            <summary>Returns document number of the least Scorer of the ScorerDocQueue
            in constant time.
            Should not be used when the queue is empty.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Pop">
            <summary>Removes and returns the least scorer of the ScorerDocQueue in log(size)
            time.
            Should not be used when the queue is empty.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.PopNoResult">
            <summary>Removes the least scorer of the ScorerDocQueue in log(size) time.
            Should not be used when the queue is empty.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.AdjustTop">
            <summary>Should be called when the scorer at top changes doc() value.
            Still log(n) worst case, but it's at least twice as fast to <pre>
            { pq.top().change(); pq.adjustTop(); }
            </pre> instead of <pre>
            { o = pq.pop(); o.change(); pq.push(o); }
            </pre>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Size">
            <summary>Returns the number of scorers currently stored in the ScorerDocQueue. </summary>
        </member>
        <member name="M:Lucene.Net.Util.ScorerDocQueue.Clear">
            <summary>Removes all entries from the ScorerDocQueue. </summary>
        </member>
        <member name="T:Lucene.Net.Util.OpenBitSet">
            <summary>An "open" BitSet implementation that allows direct access to the array of words
            storing the bits.
            <p/>
            Unlike java.util.bitset, the fact that bits are packed into an array of longs
            is part of the interface.  This allows efficient implementation of other algorithms
            by someone other than the author.  It also allows one to efficiently implement
            alternate serialization or interchange formats.
            <p/>
            <code>OpenBitSet</code> is faster than <code>java.util.BitSet</code> in most operations
            and *much* faster at calculating cardinality of sets and results of set operations.
            It can also handle sets of larger cardinality (up to 64 * 2**32-1)
            <p/>
            The goals of <code>OpenBitSet</code> are the fastest implementation possible, and
            maximum code reuse.  Extra safety and encapsulation
            may always be built on top, but if that's built in, the cost can never be removed (and
            hence people re-implement their own version in order to get better performance).
            If you want a "safe", totally encapsulated (and slower and limited) BitSet
            class, use <code>java.util.BitSet</code>.
            <p/>
            <h3>Performance Results</h3>
            
            Test system: Pentium 4, Sun Java 1.5_06 -server -Xbatch -Xmx64M
            <br/>BitSet size = 1,000,000
            <br/>Results are java.util.BitSet time divided by OpenBitSet time.
            <table border="1">
            <tr>
            <th></th> <th>cardinality</th> <th>intersect_count</th> <th>union</th> <th>nextSetBit</th> <th>get</th> <th>iterator</th>
            </tr>
            <tr>
            <th>50% full</th> <td>3.36</td> <td>3.96</td> <td>1.44</td> <td>1.46</td> <td>1.99</td> <td>1.58</td>
            </tr>
            <tr>
            <th>1% full</th> <td>3.31</td> <td>3.90</td> <td>&#160;</td> <td>1.04</td> <td>&#160;</td> <td>0.99</td>
            </tr>
            </table>
            <br/>
            Test system: AMD Opteron, 64 bit linux, Sun Java 1.5_06 -server -Xbatch -Xmx64M
            <br/>BitSet size = 1,000,000
            <br/>Results are java.util.BitSet time divided by OpenBitSet time.
            <table border="1">
            <tr>
            <th></th> <th>cardinality</th> <th>intersect_count</th> <th>union</th> <th>nextSetBit</th> <th>get</th> <th>iterator</th>
            </tr>
            <tr>
            <th>50% full</th> <td>2.50</td> <td>3.50</td> <td>1.00</td> <td>1.03</td> <td>1.12</td> <td>1.25</td>
            </tr>
            <tr>
            <th>1% full</th> <td>2.51</td> <td>3.49</td> <td>&#160;</td> <td>1.00</td> <td>&#160;</td> <td>1.02</td>
            </tr>
            </table>
            </summary>
            <version>  $Id$
            </version>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.#ctor(System.Int64)">
            <summary>Constructs an OpenBitSet large enough to hold numBits.
            
            </summary>
            <param name="numBits">
            </param>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.#ctor(System.Int64[],System.Int32)">
            <summary>Constructs an OpenBitSet from an existing long[].
            <br/>
            The first 64 bits are in long[0],
            with bit index 0 at the least significant bit, and bit index 63 at the most significant.
            Given a bit index,
            the word containing it is long[index/64], and it is at bit number index%64 within that word.
            <p/>
            numWords are the number of elements in the array that contain
            set bits (non-zero longs).
            numWords should be &lt;= bits.length, and
            any existing words in the array at position &gt;= numWords should be zero.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.IsCacheable">
            <summary>This DocIdSet implementation is cacheable. </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Capacity">
            <summary>Returns the current capacity in bits (1 greater than the index of the last bit) </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Size">
            <summary> Returns the current capacity of this set.  Included for
            compatibility.  This is *not* equal to {@link #cardinality}
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.IsEmpty">
            <summary>Returns true if there are no set bits </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.GetBits">
            <summary>Expert: returns the long[] storing the bits </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.SetBits(System.Int64[])">
            <summary>Expert: sets a new long[] to use as the bit storage </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.GetNumWords">
            <summary>Expert: gets the number of longs in the array that are in use </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.SetNumWords(System.Int32)">
            <summary>Expert: sets the number of longs in the array that are in use </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Get(System.Int32)">
            <summary>Returns true or false for the specified bit index. </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastGet(System.Int32)">
            <summary>Returns true or false for the specified bit index.
            The index should be less than the OpenBitSet size
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Get(System.Int64)">
            <summary>Returns true or false for the specified bit index</summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastGet(System.Int64)">
            <summary>Returns true or false for the specified bit index.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.GetBit(System.Int32)">
            <summary>returns 1 if the bit is set, 0 if not.
            The index should be less than the OpenBitSet size
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Set(System.Int64)">
            <summary>sets a bit, expanding the set size if necessary </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastSet(System.Int32)">
            <summary>Sets the bit at the specified index.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastSet(System.Int64)">
            <summary>Sets the bit at the specified index.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Set(System.Int64,System.Int64)">
            <summary>Sets a range of bits, expanding the set size if necessary
            
            </summary>
            <param name="startIndex">lower index
            </param>
            <param name="endIndex">one-past the last bit to set
            </param>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastClear(System.Int32)">
            <summary>clears a bit.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastClear(System.Int64)">
            <summary>clears a bit.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Clear(System.Int64)">
            <summary>clears a bit, allowing access beyond the current set size without changing the size.</summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Clear(System.Int32,System.Int32)">
            <summary>Clears a range of bits.  Clearing past the end does not change the size of the set.
            
            </summary>
            <param name="startIndex">lower index
            </param>
            <param name="endIndex">one-past the last bit to clear
            </param>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Clear(System.Int64,System.Int64)">
            <summary>Clears a range of bits.  Clearing past the end does not change the size of the set.
            
            </summary>
            <param name="startIndex">lower index
            </param>
            <param name="endIndex">one-past the last bit to clear
            </param>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.GetAndSet(System.Int32)">
            <summary>Sets a bit and returns the previous value.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.GetAndSet(System.Int64)">
            <summary>Sets a bit and returns the previous value.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastFlip(System.Int32)">
            <summary>flips a bit.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FastFlip(System.Int64)">
            <summary>flips a bit.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Flip(System.Int64)">
            <summary>flips a bit, expanding the set size if necessary </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FlipAndGet(System.Int32)">
            <summary>flips a bit and returns the resulting bit value.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.FlipAndGet(System.Int64)">
            <summary>flips a bit and returns the resulting bit value.
            The index should be less than the OpenBitSet size.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Flip(System.Int64,System.Int64)">
            <summary>Flips a range of bits, expanding the set size if necessary
            
            </summary>
            <param name="startIndex">lower index
            </param>
            <param name="endIndex">one-past the last bit to flip
            </param>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Cardinality">
            <returns> the number of set bits 
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.IntersectionCount(Lucene.Net.Util.OpenBitSet,Lucene.Net.Util.OpenBitSet)">
            <summary>Returns the popcount or cardinality of the intersection of the two sets.
            Neither set is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.UnionCount(Lucene.Net.Util.OpenBitSet,Lucene.Net.Util.OpenBitSet)">
            <summary>Returns the popcount or cardinality of the union of the two sets.
            Neither set is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.AndNotCount(Lucene.Net.Util.OpenBitSet,Lucene.Net.Util.OpenBitSet)">
            <summary>Returns the popcount or cardinality of "a and not b"
            or "intersection(a, not(b))".
            Neither set is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.XorCount(Lucene.Net.Util.OpenBitSet,Lucene.Net.Util.OpenBitSet)">
            <summary>Returns the popcount or cardinality of the exclusive-or of the two sets.
            Neither set is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.NextSetBit(System.Int32)">
            <summary>Returns the index of the first set bit starting at the index specified.
            -1 is returned if there are no more set bits.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.NextSetBit(System.Int64)">
            <summary>Returns the index of the first set bit starting at the index specified.
            -1 is returned if there are no more set bits.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Intersect(Lucene.Net.Util.OpenBitSet)">
            <summary>this = this AND other </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Union(Lucene.Net.Util.OpenBitSet)">
            <summary>this = this OR other </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Remove(Lucene.Net.Util.OpenBitSet)">
            <summary>Remove all elements set in other. this = this AND_NOT other </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Xor(Lucene.Net.Util.OpenBitSet)">
            <summary>this = this XOR other </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Intersects(Lucene.Net.Util.OpenBitSet)">
            <summary>returns true if the sets have any elements in common </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.EnsureCapacityWords(System.Int32)">
            <summary>Expand the long[] with the size given as a number of words (64 bit longs).
            getNumWords() is unchanged by this call.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.EnsureCapacity(System.Int64)">
            <summary>Ensure that the long[] is big enough to hold numBits, expanding it if necessary.
            getNumWords() is unchanged by this call.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.TrimTrailingZeros">
            <summary>Lowers numWords, the number of words in use,
            by checking for trailing zero words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Bits2words(System.Int64)">
            <summary>returns the number of 64 bit words it would take to hold numBits </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSet.Equals(System.Object)">
            <summary>returns true if both sets have the same bits set </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.#ctor(Lucene.Net.Search.DocIdSetIterator,System.Int32)">
            <summary>Construct an OpenBitSetDISI with its bits set
            from the doc ids of the given DocIdSetIterator.
            Also give a maximum size one larger than the largest doc id for which a
            bit may ever be set on this OpenBitSetDISI.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.#ctor(System.Int32)">
            <summary>Construct an OpenBitSetDISI with no bits set, and a given maximum size
            one larger than the largest doc id for which a bit may ever be set
            on this OpenBitSetDISI.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.InPlaceOr(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Perform an inplace OR with the doc ids from a given DocIdSetIterator,
            setting the bit for each such doc id.
            These doc ids should be smaller than the maximum size passed to the
            constructor.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.InPlaceAnd(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Perform an inplace AND with the doc ids from a given DocIdSetIterator,
            leaving only the bits set for which the doc ids are in common.
            These doc ids should be smaller than the maximum size passed to the
            constructor.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.InPlaceNot(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Perform an inplace NOT with the doc ids from a given DocIdSetIterator,
            clearing all the bits for each such doc id.
            These doc ids should be smaller than the maximum size passed to the
            constructor.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetDISI.InPlaceXor(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Perform an inplace XOR with the doc ids from a given DocIdSetIterator,
            flipping all the bits for each such doc id.
            These doc ids should be smaller than the maximum size passed to the
            constructor.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.SimpleFSLockFactory">
            <summary> <p/>Implements {@link LockFactory} using {@link
            File#createNewFile()}.<p/>
            
            <p/><b>NOTE:</b> the <a target="_top" href="http://java.sun.com/j2se/1.4.2/docs/api/java/io/File.html#createNewFile()">javadocs
            for <code>File.createNewFile</code></a> contain a vague
            yet spooky warning about not using the API for file
            locking.  This warning was added due to <a target="_top" href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4676183">this
            bug</a>, and in fact the only known problem with using
            this API for locking is that the Lucene write lock may
            not be released when the JVM exits abnormally.<p/>
            <p/>When this happens, a {@link LockObtainFailedException}
            is hit when trying to create a writer, in which case you
            need to explicitly clear the lock file first.  You can
            either manually remove the file, or use the {@link
            org.apache.lucene.index.IndexReader#unlock(Directory)}
            API.  But, first be certain that no writer is in fact
            writing to the index otherwise you can easily corrupt
            your index.<p/>
            
            <p/>If you suspect that this or any other LockFactory is
            not working properly in your environment, you can easily
            test it by using {@link VerifyingLockFactory}, {@link
            LockVerifyServer} and {@link LockStressTest}.<p/>
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockFactory">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.FSLockFactory">
            <summary> Base class for file system based locking implementation.</summary>
        </member>
        <member name="T:Lucene.Net.Store.LockFactory">
            <summary> <p/>Base class for Locking implementation.  {@link Directory} uses
            instances of this class to implement locking.<p/>
            
            <p/>Note that there are some useful tools to verify that
            your LockFactory is working correctly: {@link
            VerifyingLockFactory}, {@link LockStressTest}, {@link
            LockVerifyServer}.<p/>
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockVerifyServer">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.LockStressTest">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.VerifyingLockFactory">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.LockFactory.SetLockPrefix(System.String)">
            <summary> Set the prefix in use for all locks created in this
            LockFactory.  This is normally called once, when a
            Directory gets this LockFactory instance.  However, you
            can also call this (after this instance is assigned to
            a Directory) to override the prefix in use.  This
            is helpful if you're running Lucene on machines that
            have different mount points for the same shared
            directory.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.LockFactory.GetLockPrefix">
            <summary> Get the prefix in use for all locks created in this LockFactory.</summary>
        </member>
        <member name="M:Lucene.Net.Store.LockFactory.MakeLock(System.String)">
            <summary> Return a new Lock instance identified by lockName.</summary>
            <param name="lockName">name of the lock to be created.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.LockFactory.ClearLock(System.String)">
            <summary> Attempt to clear (forcefully unlock and remove) the
            specified lock.  Only call this at a time when you are
            certain this lock is no longer in use.
            </summary>
            <param name="lockName">name of the lock to be cleared.
            </param>
        </member>
        <member name="F:Lucene.Net.Store.FSLockFactory.lockDir">
            <summary> Directory for the lock files.</summary>
        </member>
        <member name="M:Lucene.Net.Store.FSLockFactory.SetLockDir(System.IO.DirectoryInfo)">
            <summary> Set the lock directory. This method can be only called
            once to initialize the lock directory. It is used by {@link FSDirectory}
            to set the lock directory to itsself.
            Subclasses can also use this method to set the directory
            in the constructor.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSLockFactory.GetLockDir">
            <summary> Retrieve the lock directory.</summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSLockFactory.#ctor">
            <summary> Create a SimpleFSLockFactory instance, with null (unset)
            lock directory. When you pass this factory to a {@link FSDirectory}
            subclass, the lock directory is automatically set to the
            directory itsself. Be sure to create one instance for each directory
            your create!
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSLockFactory.#ctor(System.IO.FileInfo)">
            <summary> Instantiate using the provided directory (as a File instance).</summary>
            <param name="lockDir">where lock files should be created.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSLockFactory.#ctor(System.IO.DirectoryInfo)">
            <summary> Instantiate using the provided directory (as a File instance).</summary>
            <param name="lockDir">where lock files should be created.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSLockFactory.#ctor(System.String)">
            <summary> Instantiate using the provided directory name (String).</summary>
            <param name="lockDirName">where lock files should be created.
            </param>
        </member>
        <member name="T:Lucene.Net.Store.Lock">
            <summary>An interprocess mutex lock.
            <p/>Typical use might look like:<pre>
            new Lock.With(directory.makeLock("my.lock")) {
            public Object doBody() {
            <i>... code to execute while locked ...</i>
            }
            }.run();
            </pre>
            
            
            </summary>
            <version>  $Id: Lock.java 769409 2009-04-28 14:05:43Z mikemccand $
            </version>
            <seealso cref="M:Lucene.Net.Store.Directory.MakeLock(System.String)">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Store.Lock.LOCK_OBTAIN_WAIT_FOREVER">
            <summary>Pass this value to {@link #Obtain(long)} to try
            forever to obtain the lock. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Store.Lock.LOCK_POLL_INTERVAL">
            <summary>How long {@link #Obtain(long)} waits, in milliseconds,
            in between attempts to acquire the lock. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.Obtain">
            <summary>Attempts to obtain exclusive access and immediately return
            upon success or failure.
            </summary>
            <returns> true iff exclusive access is obtained
            </returns>
        </member>
        <member name="F:Lucene.Net.Store.Lock.failureReason">
            <summary> If a lock obtain called, this failureReason may be set
            with the "root cause" Exception as to why the lock was
            not obtained.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.Obtain(System.Int64)">
            <summary>Attempts to obtain an exclusive lock within amount of
            time given. Polls once per {@link #LOCK_POLL_INTERVAL}
            (currently 1000) milliseconds until lockWaitTimeout is
            passed.
            </summary>
            <param name="lockWaitTimeout">length of time to wait in
            milliseconds or {@link
            #LOCK_OBTAIN_WAIT_FOREVER} to retry forever
            </param>
            <returns> true if lock was obtained
            </returns>
            <throws>  LockObtainFailedException if lock wait times out </throws>
            <throws>  IllegalArgumentException if lockWaitTimeout is </throws>
            <summary>         out of bounds
            </summary>
            <throws>  IOException if obtain() throws IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.Lock.Release">
            <summary>Releases exclusive access. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.IsLocked">
            <summary>Returns true if the resource is currently locked.  Note that one must
            still call {@link #Obtain()} before using the resource. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.Lock.With">
            <summary>Utility class for executing code with exclusive access. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.With.#ctor(Lucene.Net.Store.Lock,System.Int64)">
            <summary>Constructs an executor that will grab the named lock. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.With.DoBody">
            <summary>Code to execute with exclusive access. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Lock.With.run">
            <summary>Calls {@link #doBody} while <i>lock</i> is obtained.  Blocks if lock
            cannot be obtained immediately.  Retries to obtain lock once per second
            until it is obtained, or until it has tried ten times. Lock is released when
            {@link #doBody} exits.
            </summary>
            <throws>  LockObtainFailedException if lock could not </throws>
            <summary> be obtained
            </summary>
            <throws>  IOException if {@link Lock#obtain} throws IOException </throws>
        </member>
        <member name="T:Lucene.Net.Store.SimpleFSDirectory">
            <summary>A straightforward implementation of {@link FSDirectory}
            using java.io.RandomAccessFile.  However, this class has
            poor concurrent performance (multiple threads will
            bottleneck) as it synchronizes when multiple threads
            read from the same file.  It's usually better to use
            {@link NIOFSDirectory} or {@link MMapDirectory} instead. 
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "T:Lucene.Net.Store.FSDirectory" -->
        <member name="T:Lucene.Net.Store.Directory">
            <summary>A Directory is a flat list of files.  Files may be written once, when they
            are created.  Once a file is created it may only be opened for read, or
            deleted.  Random access is permitted both when reading and writing.
            
            <p/> Java's i/o APIs not used directly, but rather all i/o is
            through this API.  This permits things such as: <ul>
            <li> implementation of RAM-based indices;</li>
            <li> implementation indices stored in a database, via JDBC;</li>
            <li> implementation of an index as a single file;</li>
            </ul>
            
            Directory locking is implemented by an instance of {@link
            LockFactory}, and can be changed for each Directory
            instance using {@link #setLockFactory}.
            
            </summary>
        </member>
        <member name="F:Lucene.Net.Store.Directory.lockFactory">
            <summary>Holds the LockFactory instance (implements locking for
            this Directory instance). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.List">
            <deprecated> For some Directory implementations ({@link
            FSDirectory}, and its subclasses), this method
            silently filters its results to include only index
            files.  Please use {@link #listAll} instead, which
            does no filtering. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.Directory.ListAll">
            <summary>Returns an array of strings, one for each file in the
            directory.  Unlike {@link #list} this method does no
            filtering of the contents in a directory, and it will
            never return null (throws IOException instead).
            
            Currently this method simply fallsback to {@link
            #list} for Directory impls outside of Lucene's core &amp;
            contrib, but in 3.0 that method will be removed and
            this method will become abstract. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.FileExists(System.String)">
            <summary>Returns true iff a file with the given name exists. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.FileModified(System.String)">
            <summary>Returns the time the named file was last modified. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.TouchFile(System.String)">
            <summary>Set the modified time of an existing file to now. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.DeleteFile(System.String)">
            <summary>Removes an existing file in the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.RenameFile(System.String,System.String)">
            <summary>Renames an existing file in the directory.
            If a file already exists with the new name, then it is replaced.
            This replacement is not guaranteed to be atomic.
            </summary>
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.Directory.FileLength(System.String)">
            <summary>Returns the length of a file in the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.CreateOutput(System.String)">
            <summary>Creates a new, empty file in the directory with the given name.
            Returns a stream writing this file. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.Sync(System.String)">
            <summary>Ensure that any writes to this file are moved to
            stable storage.  Lucene uses this to properly commit
            changes to the index, to prevent a machine/OS crash
            from corrupting the index. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.OpenInput(System.String)">
            <summary>Returns a stream reading an existing file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.OpenInput(System.String,System.Int32)">
            <summary>Returns a stream reading an existing file, with the
            specified read buffer size.  The particular Directory
            implementation may ignore the buffer size.  Currently
            the only Directory implementations that respect this
            parameter are {@link FSDirectory} and {@link
            Lucene.Net.Index.CompoundFileReader}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.MakeLock(System.String)">
            <summary>Construct a {@link Lock}.</summary>
            <param name="name">the name of the lock file
            </param>
        </member>
        <member name="M:Lucene.Net.Store.Directory.ClearLock(System.String)">
            <summary> Attempt to clear (forcefully unlock and remove) the
            specified lock.  Only call this at a time when you are
            certain this lock is no longer in use.
            </summary>
            <param name="name">name of the lock to be cleared.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.Directory.Close">
            <summary>Closes the store. </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.SetLockFactory(Lucene.Net.Store.LockFactory)">
            <summary> Set the LockFactory that this Directory instance should
            use for its locking implementation.  Each * instance of
            LockFactory should only be used for one directory (ie,
            do not share a single instance across multiple
            Directories).
            
            </summary>
            <param name="lockFactory">instance of {@link LockFactory}.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.Directory.GetLockFactory">
            <summary> Get the LockFactory that this Directory instance is
            using for its locking implementation.  Note that this
            may be null for Directory implementations that provide
            their own locking implementation.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.GetLockID">
            <summary> Return a string identifier that uniquely differentiates
            this Directory instance from other Directory instances.
            This ID should be the same if two Directory instances
            (even in different JVMs and/or on different machines)
            are considered "the same index".  This is how locking
            "scopes" to the right index.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.Directory.Copy(Lucene.Net.Store.Directory,Lucene.Net.Store.Directory,System.Boolean)">
            <summary> Copy contents of a directory src to a directory dest.
            If a file in src already exists in dest then the
            one in dest will be blindly overwritten.
            
            <p/><b>NOTE:</b> the source directory cannot change
            while this method is running.  Otherwise the results
            are undefined and you could easily hit a
            FileNotFoundException.
            
            <p/><b>NOTE:</b> this method only copies files that look
            like index files (ie, have extensions matching the
            known extensions of index files).
            
            </summary>
            <param name="src">source directory
            </param>
            <param name="dest">destination directory
            </param>
            <param name="closeDirSrc">if <code>true</code>, call {@link #Close()} method on source directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.Directory.EnsureOpen">
            <throws>  AlreadyClosedException if this Directory is closed </throws>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.DIRECTORIES">
            <summary>This cache of directories ensures that there is a unique Directory
            instance per path, so that synchronization on the Directory can be used to
            synchronize access between readers and writers.  We use
            refcounts to ensure when the last use of an FSDirectory
            instance for a given canonical path is closed, we remove the
            instance from the cache.  See LUCENE-776
            for some relevant discussion.
            </summary>
            <deprecated> Not used by any non-deprecated methods anymore
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.SetDisableLocks(System.Boolean)">
            <summary> Set whether Lucene's use of lock files is disabled. By default, 
            lock files are enabled. They should only be disabled if the index
            is on a read-only medium like a CD-ROM.
            </summary>
            <deprecated> Use a {@link #open(File, LockFactory)} or a constructor
            that takes a {@link LockFactory} and supply
            {@link NoLockFactory#getNoLockFactory}. This setting does not work
            with {@link #open(File)} only the deprecated <code>getDirectory</code>
            respect this setting.   
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDisableLocks">
            <summary> Returns whether Lucene's use of lock files is disabled.</summary>
            <returns> true if locks are disabled, false if locks are enabled.
            </returns>
            <seealso cref="!:setDisableLocks">
            </seealso>
            <deprecated> Use a constructor that takes a {@link LockFactory} and
            supply {@link NoLockFactory#getNoLockFactory}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.IMPL">
            <summary>The default class which implements filesystem-based directories. </summary>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.buffer">
            <summary>A buffer optionally used in renameTo method </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.String)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File)}
            
            </deprecated>
            <param name="path">the path to the directory.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.String,Lucene.Net.Store.LockFactory)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File, LockFactory)}
            
            </deprecated>
            <param name="path">the path to the directory.
            </param>
            <param name="lockFactory">instance of {@link LockFactory} providing the
            locking implementation.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.DirectoryInfo)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File)}
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.FileInfo)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File)}
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.FileInfo,Lucene.Net.Store.LockFactory)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File, LockFactory)}
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <param name="lockFactory">instance of {@link LockFactory} providing the
            locking implementation.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.DirectoryInfo,Lucene.Net.Store.LockFactory)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use {@link #Open(File, LockFactory)}
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <param name="lockFactory">instance of {@link LockFactory} providing the
            locking implementation.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.String,System.Boolean)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use IndexWriter's create flag, instead, to
            create a new index.
            
            </deprecated>
            <param name="path">the path to the directory.
            </param>
            <param name="create">if true, create, or erase any existing contents.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.FileInfo,System.Boolean)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use IndexWriter's create flag, instead, to
            create a new index.
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <param name="create">if true, create, or erase any existing contents.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetDirectory(System.IO.DirectoryInfo,System.Boolean)">
            <summary>Returns the directory instance for the named location.
            
            </summary>
            <deprecated> Use IndexWriter's create flag, instead, to
            create a new index.
            
            </deprecated>
            <param name="file">the path to the directory.
            </param>
            <param name="create">if true, create, or erase any existing contents.
            </param>
            <returns> the FSDirectory for the named file.  
            </returns>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Create">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.InitOutput(System.String)">
            <summary>Initializes the directory to create a new file with the given name.
            This method should be used in {@link #createOutput}. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.directory">
            <summary>The underlying filesystem directory </summary>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.refCount">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.#ctor">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.#ctor(System.IO.DirectoryInfo,Lucene.Net.Store.LockFactory)">
            <summary>Create a new FSDirectory for the named location (ctor for subclasses).</summary>
            <param name="path">the path of the directory
            </param>
            <param name="lockFactory">the lock factory to use, or null for the default
            ({@link NativeFSLockFactory});
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Open(System.IO.FileInfo)">
            <summary>Creates an FSDirectory instance, trying to pick the
            best implementation given the current environment.
            The directory returned uses the {@link NativeFSLockFactory}.
            
            <p/>Currently this returns {@link SimpleFSDirectory} as
            NIOFSDirectory is currently not supported.
            
            <p/>Currently this returns {@link SimpleFSDirectory} as
            NIOFSDirectory is currently not supported.
            
            <p/><b>NOTE</b>: this method may suddenly change which
            implementation is returned from release to release, in
            the event that higher performance defaults become
            possible; if the precise implementation is important to
            your application, please instantiate it directly,
            instead. On 64 bit systems, it may also good to
            return {@link MMapDirectory}, but this is disabled
            because of officially missing unmap support in Java.
            For optimal performance you should consider using
            this implementation on 64 bit JVMs.
            
            <p/>See <a href="#subclasses">above</a> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Open(System.IO.DirectoryInfo)">
            <summary>Creates an FSDirectory instance, trying to pick the
            best implementation given the current environment.
            The directory returned uses the {@link NativeFSLockFactory}.
            
            <p/>Currently this returns {@link SimpleFSDirectory} as
            NIOFSDirectory is currently not supported.
            
            <p/><b>NOTE</b>: this method may suddenly change which
            implementation is returned from release to release, in
            the event that higher performance defaults become
            possible; if the precise implementation is important to
            your application, please instantiate it directly,
            instead. On 64 bit systems, it may also good to
            return {@link MMapDirectory}, but this is disabled
            because of officially missing unmap support in Java.
            For optimal performance you should consider using
            this implementation on 64 bit JVMs.
            
            <p/>See <a href="#subclasses">above</a> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Open(System.IO.DirectoryInfo,Lucene.Net.Store.LockFactory)">
            <summary>Just like {@link #Open(File)}, but allows you to
            also specify a custom {@link LockFactory}. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.ListAll(System.IO.FileInfo)">
            <summary>Lists all files (not subdirectories) in the
            directory.  This method never returns null (throws
            {@link IOException} instead).
            
            </summary>
            <throws>  NoSuchDirectoryException if the directory </throws>
            <summary>   does not exist, or does exist but is not a
            directory.
            </summary>
            <throws>  IOException if list() returns null  </throws>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.ListAll(System.IO.DirectoryInfo)">
            <summary>Lists all files (not subdirectories) in the
            directory.  This method never returns null (throws
            {@link IOException} instead).
            
            </summary>
            <throws>  NoSuchDirectoryException if the directory </throws>
            <summary>   does not exist, or does exist but is not a
            directory.
            </summary>
            <throws>  IOException if list() returns null  </throws>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.ListAll">
            <summary>Lists all files (not subdirectories) in the
            directory.
            </summary>
            <seealso cref="!:ListAll(File)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FileExists(System.String)">
            <summary>Returns true iff a file with the given name exists. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FileModified(System.String)">
            <summary>Returns the time the named file was last modified. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FileModified(System.IO.FileInfo,System.String)">
            <summary>Returns the time the named file was last modified. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.TouchFile(System.String)">
            <summary>Set the modified time of an existing file to now. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FileLength(System.String)">
            <summary>Returns the length in bytes of a file in the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.DeleteFile(System.String)">
            <summary>Removes an existing file in the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.RenameFile(System.String,System.String)">
            <summary>Renames an existing file in the directory. 
            Warning: This is not atomic.
            </summary>
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.CreateOutput(System.String)">
            <summary>Creates an IndexOutput for the file with the given name.
            <em>In 3.0 this method will become abstract.</em> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.OpenInput(System.String,System.Int32)">
            <summary>Creates an IndexInput for the file with the given name.
            <em>In 3.0 this method will become abstract.</em> 
            </summary>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.HEX_DIGITS">
            <summary> So we can do some byte-to-hexchar conversion below</summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Close">
            <summary>Closes the store to future operations. </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.ToString">
            <summary>For debug output. </summary>
        </member>
        <member name="F:Lucene.Net.Store.FSDirectory.DEFAULT_READ_CHUNK_SIZE">
            <summary> Default read chunk size.  This is a conditional
            default: on 32bit JVMs, it defaults to 100 MB.  On
            64bit JVMs, it's <code>Integer.MAX_VALUE</code>.
            </summary>
            <seealso cref="!:setReadChunkSize">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.SetReadChunkSize(System.Int32)">
            <summary> Sets the maximum number of bytes read at once from the
            underlying file during {@link IndexInput#readBytes}.
            The default value is {@link #DEFAULT_READ_CHUNK_SIZE};
            
            <p/> This was introduced due to <a
            href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6478546">Sun
            JVM Bug 6478546</a>, which throws an incorrect
            OutOfMemoryError when attempting to read too many bytes
            at once.  It only happens on 32bit JVMs with a large
            maximum heap size.<p/>
            
            <p/>Changes to this value will not impact any
            already-opened {@link IndexInput}s.  You should call
            this before attempting to open an index on the
            directory.<p/>
            
            <p/> <b>NOTE</b>: This value should be as large as
            possible to reduce any possible performance impact.  If
            you still encounter an incorrect OutOfMemoryError,
            trying lowering the chunk size.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.GetReadChunkSize">
            <summary> The maximum number of bytes to read at once from the
            underlying file during {@link IndexInput#readBytes}.
            </summary>
            <seealso cref="!:setReadChunkSize">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.FSDirectory.FSIndexInput">
            <deprecated> Use SimpleFSDirectory.SimpleFSIndexInput instead 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Store.BufferedIndexInput">
            <summary>Base implementation class for buffered {@link IndexInput}. </summary>
        </member>
        <member name="T:Lucene.Net.Store.IndexInput">
            <summary>Abstract base class for input from a file in a {@link Directory}.  A
            random-access input stream.  Used for all Lucene index input operations.
            </summary>
            <seealso cref="T:Lucene.Net.Store.Directory">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadByte">
            <summary>Reads and returns a single byte.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteByte(System.Byte)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadBytes(System.Byte[],System.Int32,System.Int32)">
            <summary>Reads a specified number of bytes into an array at the specified offset.</summary>
            <param name="b">the array to read bytes into
            </param>
            <param name="offset">the offset in the array to start storing bytes
            </param>
            <param name="len">the number of bytes to read
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteBytes(System.Byte[],System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadBytes(System.Byte[],System.Int32,System.Int32,System.Boolean)">
            <summary>Reads a specified number of bytes into an array at the
            specified offset with control over whether the read
            should be buffered (callers who have their own buffer
            should pass in "false" for useBuffer).  Currently only
            {@link BufferedIndexInput} respects this parameter.
            </summary>
            <param name="b">the array to read bytes into
            </param>
            <param name="offset">the offset in the array to start storing bytes
            </param>
            <param name="len">the number of bytes to read
            </param>
            <param name="useBuffer">set to false if the caller will handle
            buffering.
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteBytes(System.Byte[],System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadInt">
            <summary>Reads four bytes and returns an int.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteInt(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadVInt">
            <summary>Reads an int stored in variable-length format.  Reads between one and
            five bytes.  Smaller values take fewer bytes.  Negative numbers are not
            supported.
            </summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteVInt(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadLong">
            <summary>Reads eight bytes and returns a long.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteLong(System.Int64)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadVLong">
            <summary>Reads a long stored in variable-length format.  Reads between one and
            nine bytes.  Smaller values take fewer bytes.  Negative numbers are not
            supported. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.SetModifiedUTF8StringsMode">
            <summary>Call this if readString should read characters stored
            in the old modified UTF8 format (length in java chars
            and java's modified UTF8 encoding).  This is used for
            indices written pre-2.4 See LUCENE-510 for details. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadString">
            <summary>Reads a string.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteString(System.String)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.ReadChars(System.Char[],System.Int32,System.Int32)">
            <summary>Reads Lucene's old "modified UTF-8" encoded
            characters into an array.
            </summary>
            <param name="buffer">the array to read characters into
            </param>
            <param name="start">the offset in the array to start storing characters
            </param>
            <param name="length">the number of characters to read
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.WriteChars(System.String,System.Int32,System.Int32)">
            </seealso>
            <deprecated> -- please use readString or readBytes
            instead, and construct the string
            from those utf8 bytes
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.SkipChars(System.Int32)">
            <summary> Expert
            
            Similar to {@link #ReadChars(char[], int, int)} but does not do any conversion operations on the bytes it is reading in.  It still
            has to invoke {@link #ReadByte()} just as {@link #ReadChars(char[], int, int)} does, but it does not need a buffer to store anything
            and it does not have to do any of the bitwise operations, since we don't actually care what is in the byte except to determine
            how many more bytes to read
            </summary>
            <param name="length">The number of chars to read
            </param>
            <deprecated> this method operates on old "modified utf8" encoded
            strings
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.Close">
            <summary>Closes the stream to futher operations. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.GetFilePointer">
            <summary>Returns the current position in this file, where the next read will
            occur.
            </summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.Seek(System.Int64)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.Seek(System.Int64)">
            <summary>Sets current position in this file, where the next read will occur.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.GetFilePointer">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.Length">
            <summary>The number of bytes in the file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexInput.Clone">
            <summary>Returns a clone of this stream.
            
            <p/>Clones of a stream access the same data, and are positioned at the same
            point as the stream they were cloned from.
            
            <p/>Expert: Subclasses must ensure that clones may be positioned at
            different points in the input from each other and from the stream they
            were cloned from.
            </summary>
        </member>
        <member name="F:Lucene.Net.Store.BufferedIndexInput.BUFFER_SIZE">
            <summary>Default buffer size </summary>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexInput.#ctor(System.Int32)">
            <summary>Inits BufferedIndexInput with a specific bufferSize </summary>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexInput.SetBufferSize(System.Int32)">
            <summary>Change the buffer size used by this IndexInput </summary>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexInput.GetBufferSize">
            <seealso cref="!:setBufferSize">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexInput.ReadInternal(System.Byte[],System.Int32,System.Int32)">
            <summary>Expert: implements buffer refill.  Reads bytes from the current position
            in the input.
            </summary>
            <param name="b">the array to read bytes into
            </param>
            <param name="offset">the offset in the array to start storing bytes
            </param>
            <param name="length">the number of bytes to read
            </param>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexInput.SeekInternal(System.Int64)">
            <summary>Expert: implements seek.  Sets current position in this file, where the
            next {@link #ReadInternal(byte[],int,int)} will occur.
            </summary>
            <seealso cref="M:Lucene.Net.Store.BufferedIndexInput.ReadInternal(System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.SimpleFSDirectory">
            <summary>A straightforward implementation of {@link FSDirectory}
            using java.io.RandomAccessFile.  However, this class has
            poor concurrent performance (multiple threads will
            bottleneck) as it synchronizes when multiple threads
            read from the same file.  It's usually better to use
            {@link NIOFSDirectory} or {@link MMapDirectory} instead. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.#ctor(System.IO.FileInfo,Lucene.Net.Store.LockFactory)">
            <summary>Create a new SimpleFSDirectory for the named location.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <param name="lockFactory">the lock factory to use, or null for the default.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.#ctor(System.IO.DirectoryInfo,Lucene.Net.Store.LockFactory)">
            <summary>Create a new SimpleFSDirectory for the named location.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <param name="lockFactory">the lock factory to use, or null for the default.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.#ctor(System.IO.FileInfo)">
            <summary>Create a new SimpleFSDirectory for the named location and the default lock factory.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.#ctor">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.#ctor(System.IO.DirectoryInfo)">
            <summary>Create a new SimpleFSDirectory for the named location and the default lock factory.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.CreateOutput(System.String)">
            <summary>Creates an IndexOutput for the file with the given name. </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.OpenInput(System.String,System.Int32)">
            <summary>Creates an IndexInput for the file with the given name. </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexInput.#ctor(System.IO.FileInfo)">
            <deprecated> Please use ctor taking chunkSize 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexInput.#ctor(System.IO.FileInfo,System.Int32)">
            <deprecated> Please use ctor taking chunkSize 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexInput.ReadInternal(System.Byte[],System.Int32,System.Int32)">
            <summary>IndexInput methods </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexInput.IsFDValid">
            <summary>Method used for testing. Returns true if the underlying
            file descriptor is valid.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.BufferedIndexOutput">
            <summary>Base implementation class for buffered {@link IndexOutput}. </summary>
        </member>
        <member name="T:Lucene.Net.Store.IndexOutput">
            <summary>Abstract base class for output to a file in a Directory.  A random-access
            output stream.  Used for all Lucene index output operations.
            </summary>
            <seealso cref="T:Lucene.Net.Store.Directory">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.IndexInput">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteByte(System.Byte)">
            <summary>Writes a single byte.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadByte">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteBytes(System.Byte[],System.Int32)">
            <summary>Writes an array of bytes.</summary>
            <param name="b">the bytes to write
            </param>
            <param name="length">the number of bytes to write
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadBytes(System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteBytes(System.Byte[],System.Int32,System.Int32)">
            <summary>Writes an array of bytes.</summary>
            <param name="b">the bytes to write
            </param>
            <param name="offset">the offset in the byte array
            </param>
            <param name="length">the number of bytes to write
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadBytes(System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteInt(System.Int32)">
            <summary>Writes an int as four bytes.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadInt">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteVInt(System.Int32)">
            <summary>Writes an int in a variable-length format.  Writes between one and
            five bytes.  Smaller values take fewer bytes.  Negative numbers are not
            supported.
            </summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadVInt">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteLong(System.Int64)">
            <summary>Writes a long as eight bytes.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadLong">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteVLong(System.Int64)">
            <summary>Writes an long in a variable-length format.  Writes between one and five
            bytes.  Smaller values take fewer bytes.  Negative numbers are not
            supported.
            </summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadVLong">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteString(System.String)">
            <summary>Writes a string.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadString">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteChars(System.String,System.Int32,System.Int32)">
            <summary>Writes a sub sequence of characters from s as the old
            format (modified UTF-8 encoded bytes).
            </summary>
            <param name="s">the source of the characters
            </param>
            <param name="start">the first character in the sequence
            </param>
            <param name="length">the number of characters in the sequence
            </param>
            <deprecated> -- please pre-convert to utf8 bytes
            instead or use {@link #writeString}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.WriteChars(System.Char[],System.Int32,System.Int32)">
            <summary>Writes a sub sequence of characters from char[] as
            the old format (modified UTF-8 encoded bytes).
            </summary>
            <param name="s">the source of the characters
            </param>
            <param name="start">the first character in the sequence
            </param>
            <param name="length">the number of characters in the sequence
            </param>
            <deprecated> -- please pre-convert to utf8 bytes instead or use {@link #writeString}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.CopyBytes(Lucene.Net.Store.IndexInput,System.Int64)">
            <summary>Copy numBytes bytes from input to ourself. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.Flush">
            <summary>Forces any buffered output to be written. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.Close">
            <summary>Closes this stream to further operations. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.GetFilePointer">
            <summary>Returns the current position in this file, where the next write will
            occur.
            </summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.Seek(System.Int64)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.Seek(System.Int64)">
            <summary>Sets current position in this file, where the next write will occur.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexOutput.GetFilePointer">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.Length">
            <summary>The number of bytes in the file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.IndexOutput.SetLength(System.Int64)">
            <summary>Set the file length. By default, this method does
            nothing (it's optional for a Directory to implement
            it).  But, certain Directory implementations (for
            </summary>
            <seealso cref="T:Lucene.Net.Store.FSDirectory"> can use this to inform the
            underlying IO system to pre-allocate the file to the
            specified size.  If the length is longer than the
            current file length, the bytes added to the file are
            undefined.  Otherwise the file is truncated.
            </seealso>
            <param name="length">file length
            </param>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.WriteByte(System.Byte)">
            <summary>Writes a single byte.</summary>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadByte">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.WriteBytes(System.Byte[],System.Int32,System.Int32)">
            <summary>Writes an array of bytes.</summary>
            <param name="b">the bytes to write
            </param>
            <param name="length">the number of bytes to write
            </param>
            <seealso cref="M:Lucene.Net.Store.IndexInput.ReadBytes(System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.Flush">
            <summary>Forces any buffered output to be written. </summary>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.FlushBuffer(System.Byte[],System.Int32)">
            <summary>Expert: implements buffer write.  Writes bytes at the current position in
            the output.
            </summary>
            <param name="b">the bytes to write
            </param>
            <param name="len">the number of bytes to write
            </param>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.FlushBuffer(System.Byte[],System.Int32,System.Int32)">
            <summary>Expert: implements buffer write.  Writes bytes at the current position in
            the output.
            </summary>
            <param name="b">the bytes to write
            </param>
            <param name="offset">the offset in the byte array
            </param>
            <param name="len">the number of bytes to write
            </param>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.Close">
            <summary>Closes this stream to further operations. </summary>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.GetFilePointer">
            <summary>Returns the current position in this file, where the next write will
            occur.
            </summary>
            <seealso cref="M:Lucene.Net.Store.BufferedIndexOutput.Seek(System.Int64)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.Seek(System.Int64)">
            <summary>Sets current position in this file, where the next write will occur.</summary>
            <seealso cref="M:Lucene.Net.Store.BufferedIndexOutput.GetFilePointer">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.BufferedIndexOutput.Length">
            <summary>The number of bytes in the file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexOutput.FlushBuffer(System.Byte[],System.Int32,System.Int32)">
            <summary>output methods: </summary>
        </member>
        <member name="M:Lucene.Net.Store.SimpleFSDirectory.SimpleFSIndexOutput.Seek(System.Int64)">
            <summary>Random-access methods </summary>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FSIndexInput.#ctor(System.IO.FileInfo)">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FSIndexInput.#ctor(System.IO.FileInfo,System.Int32)">
            <deprecated> 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Store.FSDirectory.FSIndexInput.Descriptor">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FSIndexInput.Descriptor.#ctor(System.IO.FileInfo,System.IO.FileAccess)">
            <deprecated> 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Store.FSDirectory.FSIndexOutput">
            <deprecated> Use SimpleFSDirectory.SimpleFSIndexOutput instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.FSDirectory.FSIndexOutput.#ctor(System.IO.FileInfo)">
            <deprecated> 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Store.LockVerifyServer">
            <summary> Simple standalone server that must be running when you
            use {@link VerifyingLockFactory}.  This server simply
            verifies at most one process holds the lock at a time.
            Run without any args to see usage.
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.VerifyingLockFactory">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.LockStressTest">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.SpanFilterResult">
            <summary>  The results of a SpanQueryFilter.  Wraps the BitSet and the position information from the SpanQuery
            
            <p/>
            NOTE: This API is still experimental and subject to change. 
            
            
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SpanFilterResult.bits">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.#ctor(System.Collections.BitArray,System.Collections.IList)">
            <summary> </summary>
            <param name="bits">The bits for the Filter
            </param>
            <param name="positions">A List of {@link Lucene.Net.Search.SpanFilterResult.PositionInfo} objects
            </param>
            <deprecated> Use {@link #SpanFilterResult(DocIdSet, List)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.#ctor(Lucene.Net.Search.DocIdSet,System.Collections.IList)">
            <summary> </summary>
            <param name="docIdSet">The DocIdSet for the Filter
            </param>
            <param name="positions">A List of {@link Lucene.Net.Search.SpanFilterResult.PositionInfo} objects
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.GetPositions">
            <summary> The first entry in the array corresponds to the first "on" bit.
            Entries are increasing by document order
            </summary>
            <returns> A List of PositionInfo objects
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.GetBits">
            <deprecated> Use {@link #GetDocIdSet()}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.GetDocIdSet">
            <summary>Returns the docIdSet </summary>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.PositionInfo.GetPositions">
            <summary> </summary>
            <returns> A List of {@link Lucene.Net.Search.SpanFilterResult.StartEnd} objects
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.StartEnd.GetEnd">
            <summary> </summary>
            <returns> The end position of this match
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilterResult.StartEnd.GetStart">
            <summary> The Start position</summary>
            <returns> The start position of this match
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.MultiSearcher">
            <summary>Implements search over a set of <code>Searchables</code>.
            
            <p/>Applications usually need only call the inherited {@link #Search(Query)}
            or {@link #Search(Query,Filter)} methods.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Searcher">
            <summary> An abstract base class for search implementations. Implements the main search
            methods.
            
            <p/>
            Note that you can only access hits from a Searcher as long as it is not yet
            closed, otherwise an IOException will be thrown.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Searchable">
            <summary> The interface for search implementations.
            
            <p/>
            Searchable is the abstract network protocol for searching. Implementations
            provide search over a single index, over multiple indices, and over indices
            on remote servers.
            
            <p/>
            Queries, filters and sort criteria are designed to be compact so that they
            may be efficiently passed to a remote index, with only the top-scoring hits
            being returned, rather than every matching hit.
            
            <b>NOTE:</b> this interface is kept public for convenience. Since it is not
            expected to be implemented directly, it may be changed unexpectedly between
            releases.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,Lucene.Net.Search.HitCollector)">
            <summary>Lower-level search API.
            
            <p/>{@link HitCollector#Collect(int,float)} is called for every non-zero
            scoring document.
            <br/>HitCollector-based access to remote indexes is discouraged.
            
            <p/>Applications should only use this if they need <i>all</i> of the
            matching documents.  The high-level search API ({@link
            Searcher#Search(Query)}) is usually more efficient, as it skips
            non-high-scoring hits.
            
            </summary>
            <param name="weight">to match documents
            </param>
            <param name="filter">if non-null, used to permit documents to be collected.
            </param>
            <param name="results">to receive hits
            </param>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> use {@link #Search(Weight, Filter, Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,Lucene.Net.Search.Collector)">
            <summary> Lower-level search API.
            
            <p/>
            {@link Collector#Collect(int)} is called for every document. <br/>
            Collector-based access to remote indexes is discouraged.
            
            <p/>
            Applications should only use this if they need <i>all</i> of the matching
            documents. The high-level search API ({@link Searcher#Search(Query)}) is
            usually more efficient, as it skips non-high-scoring hits.
            
            </summary>
            <param name="weight">to match documents
            </param>
            <param name="filter">if non-null, used to permit documents to be collected.
            </param>
            <param name="collector">to receive hits
            </param>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Close">
            <summary>Frees resources associated with this Searcher.
            Be careful not to call this method while you are still using objects
            like {@link Hits}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.DocFreq(Lucene.Net.Index.Term)">
            <summary>Expert: Returns the number of documents containing <code>term</code>.
            Called by search code to compute term weights.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.DocFreq(Lucene.Net.Index.Term)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.DocFreqs(Lucene.Net.Index.Term[])">
            <summary>Expert: For each term in the terms array, calculates the number of
            documents containing <code>term</code>. Returns an array with these
            document frequencies. Used to minimize number of remote calls.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.MaxDoc">
            <summary>Expert: Returns one greater than the largest possible document number.
            Called by search code to compute term weights.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.MaxDoc">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32)">
            <summary>Expert: Low-level search implementation.  Finds the top <code>n</code>
            hits for <code>query</code>, applying <code>filter</code> if non-null.
            
            <p/>Called by {@link Hits}.
            
            <p/>Applications should usually call {@link Searcher#Search(Query)} or
            {@link Searcher#Search(Query,Filter)} instead.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Doc(System.Int32)">
            <summary>Expert: Returns the stored fields of document <code>i</code>.
            Called by {@link HitCollector} implementations.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Document(System.Int32)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Doc(System.Int32,Lucene.Net.Documents.FieldSelector)">
            <summary> Get the {@link Lucene.Net.Documents.Document} at the <code>n</code><sup>th</sup> position. The {@link Lucene.Net.Documents.FieldSelector}
            may be used to determine what {@link Lucene.Net.Documents.Field}s to load and how they should be loaded.
            
            <b>NOTE:</b> If the underlying Reader (more specifically, the underlying <code>FieldsReader</code>) is closed before the lazy {@link Lucene.Net.Documents.Field} is
            loaded an exception may be thrown.  If you want the value of a lazy {@link Lucene.Net.Documents.Field} to be available after closing you must
            explicitly load it or fetch the Document again with a new loader.
            
            
            </summary>
            <param name="n">Get the document at the <code>n</code><sup>th</sup> position
            </param>
            <param name="fieldSelector">The {@link Lucene.Net.Documents.FieldSelector} to use to determine what Fields should be loaded on the Document.  May be null, in which case all Fields will be loaded.
            </param>
            <returns> The stored fields of the {@link Lucene.Net.Documents.Document} at the nth position
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <summary> 
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.Document(System.Int32,Lucene.Net.Documents.FieldSelector)">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.Fieldable">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.FieldSelector">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.SetBasedFieldSelector">
            </seealso>
            <seealso cref="T:Lucene.Net.Documents.LoadFirstFieldSelector">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Rewrite(Lucene.Net.Search.Query)">
            <summary>Expert: called to re-write queries into primitive queries.</summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Explain(Lucene.Net.Search.Weight,System.Int32)">
            <summary>Expert: low-level implementation method
            Returns an Explanation that describes how <code>doc</code> scored against
            <code>weight</code>.
            
            <p/>This is intended to be used in developing Similarity implementations,
            and, for good performance, should not be displayed with every hit.
            Computing an explanation is as expensive as executing the query over the
            entire index.
            <p/>Applications should call {@link Searcher#Explain(Query, int)}.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            <summary>Expert: Low-level search implementation with arbitrary sorting.  Finds
            the top <code>n</code> hits for <code>query</code>, applying
            <code>filter</code> if non-null, and sorting the hits by the criteria in
            <code>sort</code>.
            
            <p/>Applications should usually call
            {@link Searcher#Search(Query,Filter,int,Sort)} instead.
            
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query)">
            <summary>Returns the documents matching <code>query</code>. </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> Hits will be removed in Lucene 3.0. Use
            {@link #Search(Query, Filter, int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter)">
            <summary>Returns the documents matching <code>query</code> and
            <code>filter</code>.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> Hits will be removed in Lucene 3.0. Use
            {@link #Search(Query, Filter, int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Sort)">
            <summary>Returns documents matching <code>query</code> sorted by
            <code>sort</code>.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> Hits will be removed in Lucene 3.0. Use 
            {@link #Search(Query, Filter, int, Sort)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,Lucene.Net.Search.Sort)">
            <summary>Returns documents matching <code>query</code> and <code>filter</code>,
            sorted by <code>sort</code>.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> Hits will be removed in Lucene 3.0. Use 
            {@link #Search(Query, Filter, int, Sort)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            <summary>Search implementation with arbitrary sorting.  Finds
            the top <code>n</code> hits for <code>query</code>, applying
            <code>filter</code> if non-null, and sorting the hits by the criteria in
            <code>sort</code>.
            
            <p/>NOTE: this does not compute scores by default; use
            {@link IndexSearcher#setDefaultFieldSortScoring} to enable scoring.
            
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.HitCollector)">
            <summary>Lower-level search API.
            
            <p/>{@link HitCollector#Collect(int,float)} is called for every matching
            document.
            
            <p/>Applications should only use this if they need <i>all</i> of the
            matching documents.  The high-level search API ({@link
            Searcher#Search(Query)}) is usually more efficient, as it skips
            non-high-scoring hits.
            <p/>Note: The <code>score</code> passed to this method is a raw score.
            In other words, the score will not necessarily be a float whose value is
            between 0 and 1.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> use {@link #Search(Query, Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Collector)">
            <summary>Lower-level search API.
            
            <p/>{@link Collector#Collect(int)} is called for every matching document.
            
            <p/>Applications should only use this if they need <i>all</i> of the matching
            documents. The high-level search API ({@link Searcher#Search(Query, int)}
            ) is usually more efficient, as it skips non-high-scoring hits.
            <p/>Note: The <code>score</code> passed to this method is a raw score.
            In other words, the score will not necessarily be a float whose value is
            between 0 and 1.
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,Lucene.Net.Search.HitCollector)">
            <summary>Lower-level search API.
            
            <p/>{@link HitCollector#Collect(int,float)} is called for every matching
            document.
            <br/>HitCollector-based access to remote indexes is discouraged.
            
            <p/>Applications should only use this if they need <i>all</i> of the
            matching documents.  The high-level search API ({@link
            Searcher#Search(Query, Filter, int)}) is usually more efficient, as it skips
            non-high-scoring hits.
            
            </summary>
            <param name="query">to match documents
            </param>
            <param name="filter">if non-null, used to permit documents to be collected.
            </param>
            <param name="results">to receive hits
            </param>
            <throws>  BooleanQuery.TooManyClauses </throws>
            <deprecated> use {@link #Search(Query, Filter, Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,Lucene.Net.Search.Collector)">
            <summary>Lower-level search API.
            
            <p/>{@link Collector#Collect(int)} is called for every matching
            document.
            <br/>Collector-based access to remote indexes is discouraged.
            
            <p/>Applications should only use this if they need <i>all</i> of the
            matching documents.  The high-level search API ({@link
            Searcher#Search(Query, Filter, int)}) is usually more efficient, as it skips
            non-high-scoring hits.
            
            </summary>
            <param name="query">to match documents
            </param>
            <param name="filter">if non-null, used to permit documents to be collected.
            </param>
            <param name="results">to receive hits
            </param>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,System.Int32)">
            <summary>Finds the top <code>n</code>
            hits for <code>query</code>, applying <code>filter</code> if non-null.
            
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,System.Int32)">
            <summary>Finds the top <code>n</code>
            hits for <code>query</code>.
            
            </summary>
            <throws>  BooleanQuery.TooManyClauses </throws>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Explain(Lucene.Net.Search.Query,System.Int32)">
            <summary>Returns an Explanation that describes how <code>doc</code> scored against
            <code>query</code>.
            
            <p/>This is intended to be used in developing Similarity implementations,
            and, for good performance, should not be displayed with every hit.
            Computing an explanation is as expensive as executing the query over the
            entire index.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.Searcher.similarity">
            <summary>The Similarity implementation used by this searcher. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.SetSimilarity(Lucene.Net.Search.Similarity)">
            <summary>Expert: Set the Similarity implementation used by this Searcher.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.SetDefault(Lucene.Net.Search.Similarity)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.GetSimilarity">
            <summary>Expert: Return the Similarity implementation used by this Searcher.
            
            <p/>This defaults to the current value of {@link Similarity#GetDefault()}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.CreateWeight(Lucene.Net.Search.Query)">
            <summary> creates a weight for <code>query</code></summary>
            <returns> new weight
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,Lucene.Net.Search.HitCollector)">
            <deprecated> use {@link #Search(Weight, Filter, Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.#ctor(Lucene.Net.Search.Searchable[])">
            <summary>Creates a searcher which searches <i>searchers</i>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.GetSearchables">
            <summary>Return the array of {@link Searchable}s this searches. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.SubSearcher(System.Int32)">
            <summary>Returns index of the searcher for document <code>n</code> in the array
            used to construct this searcher. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.SubDoc(System.Int32)">
            <summary>Returns the document number of document <code>n</code> within its
            sub-index. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.CreateWeight(Lucene.Net.Search.Query)">
            <summary> Create weight in multiple index scenario.
            
            Distributed query processing is done in the following steps:
            1. rewrite query
            2. extract necessary terms
            3. collect dfs for these terms from the Searchables
            4. create query weight using aggregate dfs.
            5. distribute that weight to Searchables
            6. merge results
            
            Steps 1-4 are done here, 5+6 in the search() methods
            
            </summary>
            <returns> rewritten queries
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.MultiSearcher.CachedDfSource">
            <summary> Document Frequency cache acting as a Dummy-Searcher. This class is no
            full-fledged Searcher, but only supports the methods necessary to
            initialize Weights.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiSearcher.CachedDfSource.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Hit">
            <summary> Wrapper used by {@link HitIterator} to provide a lazily loaded hit
            from {@link Hits}.
            
            </summary>
            <deprecated> Use {@link TopScoreDocCollector} and {@link TopDocs} instead. Hits will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Hit.#ctor(Lucene.Net.Search.Hits,System.Int32)">
            <summary> Constructed from {@link HitIterator}</summary>
            <param name="hits">Hits returned from a search
            </param>
            <param name="hitNumber">Hit index in Hits
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Hit.GetDocument">
            <summary> Returns document for this hit.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Hits.Doc(System.Int32)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Search.Hit.GetScore">
            <summary> Returns score for this hit.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Hits.Score(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Hit.GetId">
            <summary> Returns id for this hit.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Hits.Id(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Hit.GetBoost">
            <summary> Returns the boost factor for this hit on any field of the underlying document.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Document.GetBoost">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Search.Hit.Get(System.String)">
            <summary> Returns the string value of the field with the given name if any exist in
            this document, or null.  If multiple fields exist with this name, this
            method returns the first value added. If only binary fields with this name
            exist, returns null.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Document.Get(System.String)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Search.Hit.ToString">
            <summary> Prints the parameters to be used to discover the promised result.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "T:Lucene.Net.Search.Function.CustomScoreProvider" -->
        <member name="M:Lucene.Net.Search.Function.CustomScoreProvider.#ctor(Lucene.Net.Index.IndexReader)">
            <summary>
            Creates a new instance of the provider class for the given IndexReader.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreProvider.CustomScore(System.Int32,System.Single,System.Single[])">
            <summary>
            * Compute a custom score by the subQuery score and a number of 
            ValueSourceQuery scores.
            <p/> 
            Subclasses can override this method to modify the custom score.  
            <p/>
            If your custom scoring is different than the default herein you 
            should override at least one of the two customScore() methods.
            If the number of ValueSourceQueries is always &lt; 2 it is 
            sufficient to override the other 
            {@link #customScore(int, float, float) customScore()} 
            method, which is simpler. 
            <p/>
            The default computation herein is a multiplication of given scores:
            <pre>
                ModifiedScore = valSrcScore * valSrcScores[0] * valSrcScores[1] * ...
            </pre>
            </summary>
            <param name="doc">id of scored doc</param>
            <param name="subQueryScore">score of that doc by the subQuery</param>
            <param name="valSrcScores">scores of that doc by the ValueSourceQuery</param>
            <returns>custom score</returns>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Lucene.Net.Search.Function.CustomScoreProvider.CustomScore(System.Int32,System.Single,System.Single)" -->
        <member name="M:Lucene.Net.Search.Function.CustomScoreProvider.CustomExplain(System.Int32,Lucene.Net.Search.Explanation,Lucene.Net.Search.Explanation[])">
            <summary>
            Explain the custom score.
            Whenever overriding {@link #customScore(int, float, float[])}, 
            this method should also be overridden to provide the correct explanation
            for the part of the custom scoring.
            </summary>
            <param name="doc">doc being explained</param>
            <param name="subQueryExpl">explanation for the sub-query part</param>
            <param name="valSrcExpls">explanation for the value source part</param>
            <returns>an explanation for the custom score</returns>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreProvider.CustomExplain(System.Int32,Lucene.Net.Search.Explanation,Lucene.Net.Search.Explanation)">
            <summary>
            Explain the custom score.
            Whenever overriding {@link #customScore(int, float, float)}, 
            this method should also be overridden to provide the correct explanation
            for the part of the custom scoring.
            
            </summary>
            <param name="doc">doc being explained</param>
            <param name="subQueryExpl">explanation for the sub-query part</param>
            <param name="valSrcExpl">explanation for the value source part</param>
            <returns>an explanation for the custom score</returns>
        </member>
        <member name="T:Lucene.Net.Search.FilteredQuery">
            <summary> A query that applies a filter to the results of another query.
            
            <p/>Note: the bits are retrieved from the filter each time this
            query is used in a search - use a CachingWrapperFilter to avoid
            regenerating the bits every time.
            
            <p/>Created: Apr 20, 2004 8:58:29 AM
            
            </summary>
            <since>   1.4
            </since>
            <version>  $Id: FilteredQuery.java 807821 2009-08-25 21:55:49Z mikemccand $
            </version>
            <seealso cref="T:Lucene.Net.Search.CachingWrapperFilter">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.#ctor(Lucene.Net.Search.Query,Lucene.Net.Search.Filter)">
            <summary> Constructs a new query which applies a filter to the results of the original query.
            Filter.getDocIdSet() will be called every time this query is used in a search.
            </summary>
            <param name="query"> Query to be filtered, cannot be <code>null</code>.
            </param>
            <param name="filter">Filter to apply to query results, cannot be <code>null</code>.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.CreateWeight(Lucene.Net.Search.Searcher)">
            <summary> Returns a Weight that applies the filter to the enclosed query's Weight.
            This is accomplished by overriding the Scorer returned by the Weight.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.Rewrite(Lucene.Net.Index.IndexReader)">
            <summary>Rewrites the wrapped query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.GetHashCode">
            <summary>Returns a hash code value for this object. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Weight">
            <summary> Expert: Calculate query weights and build query scorers.
            <p/>
            The purpose of {@link Weight} is to ensure searching does not
            modify a {@link Query}, so that a {@link Query} instance can be reused. <br/>
            {@link Searcher} dependent state of the query should reside in the
            {@link Weight}. <br/>
            {@link IndexReader} dependent state should reside in the {@link Scorer}.
            <p/>
            A <code>Weight</code> is used in the following way:
            <ol>
            <li>A <code>Weight</code> is constructed by a top-level query, given a
            <code>Searcher</code> ({@link Query#CreateWeight(Searcher)}).</li>
            <li>The {@link #SumOfSquaredWeights()} method is called on the
            <code>Weight</code> to compute the query normalization factor
            {@link Similarity#QueryNorm(float)} of the query clauses contained in the
            query.</li>
            <li>The query normalization factor is passed to {@link #Normalize(float)}. At
            this point the weighting is complete.</li>
            <li>A <code>Scorer</code> is constructed by {@link #Scorer(IndexReader,boolean,boolean)}.</li>
            </ol>
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.Weight.Explain(Lucene.Net.Index.IndexReader,System.Int32)">
            <summary> An explanation of the score computation for the named document.
            
            </summary>
            <param name="reader">sub-reader containing the give doc
            </param>
            <param name="doc">
            </param>
            <returns> an Explanation for the score
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Weight.GetQuery">
            <summary>The query that this concerns. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Weight.GetValue">
            <summary>The weight for this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Weight.Normalize(System.Single)">
            <summary>Assigns the query normalization factor to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Weight.Scorer(Lucene.Net.Index.IndexReader,System.Boolean,System.Boolean)">
            <summary> Returns a {@link Scorer} which scores documents in/out-of order according
            to <code>scoreDocsInOrder</code>.
            <p/>
            <b>NOTE:</b> even if <code>scoreDocsInOrder</code> is false, it is
            recommended to check whether the returned <code>Scorer</code> indeed scores
            documents out of order (i.e., call {@link #ScoresDocsOutOfOrder()}), as
            some <code>Scorer</code> implementations will always return documents
            in-order.<br/>
            <b>NOTE:</b> null can be returned if no documents will be scored by this
            query.
            
            </summary>
            <param name="reader">
            the {@link IndexReader} for which to return the {@link Scorer}.
            </param>
            <param name="scoreDocsInOrder">specifies whether in-order scoring of documents is required. Note
            that if set to false (i.e., out-of-order scoring is required),
            this method can return whatever scoring mode it supports, as every
            in-order scorer is also an out-of-order one. However, an
            out-of-order scorer may not support {@link Scorer#NextDoc()}
            and/or {@link Scorer#Advance(int)}, therefore it is recommended to
            request an in-order scorer if use of these methods is required.
            </param>
            <param name="topScorer">
            if true, {@link Scorer#Score(Collector)} will be called; if false,
            {@link Scorer#NextDoc()} and/or {@link Scorer#Advance(int)} will
            be called.
            </param>
            <returns> a {@link Scorer} which scores documents in/out-of order.
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Weight.SumOfSquaredWeights">
            <summary>The sum of squared weights of contained query clauses. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Weight.ScoresDocsOutOfOrder">
            <summary> Returns true iff this implementation scores docs only out of order. This
            method is used in conjunction with {@link Collector}'s
            {@link Collector#AcceptsDocsOutOfOrder() acceptsDocsOutOfOrder} and
            {@link #Scorer(Lucene.Net.Index.IndexReader, boolean, boolean)} to
            create a matching {@link Scorer} instance for a given {@link Collector}, or
            vice versa.
            <p/>
            <b>NOTE:</b> the default implementation returns <code>false</code>, i.e.
            the <code>Scorer</code> scores documents in-order.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.AnonymousClassWeight.AnonymousClassScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.AnonymousClassWeight.AnonymousClassScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FilteredQuery.AnonymousClassWeight.AnonymousClassScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.FieldDoc">
            <summary> Expert: A ScoreDoc which also contains information about
            how to sort the referenced document.  In addition to the
            document number and score, this object contains an array
            of values for the document from the field(s) used to sort.
            For example, if the sort criteria was to sort by fields
            "a", "b" then "c", the <code>fields</code> object array
            will have three elements, corresponding respectively to
            the term values for the document in fields "a", "b" and "c".
            The class of each element in the array will be either
            Integer, Float or String depending on the type of values
            in the terms of each field.
            
            <p/>Created: Feb 11, 2004 1:23:38 PM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: FieldDoc.java 773194 2009-05-09 10:36:41Z mikemccand $
            </version>
            <seealso cref="T:Lucene.Net.Search.ScoreDoc">
            </seealso>
            <seealso cref="T:Lucene.Net.Search.TopFieldDocs">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.ScoreDoc">
            <summary>Expert: Returned by low-level search implementations.</summary>
            <seealso cref="T:Lucene.Net.Search.TopDocs">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.ScoreDoc.score">
            <summary>Expert: The score of this document for the query. </summary>
        </member>
        <member name="F:Lucene.Net.Search.ScoreDoc.doc">
            <summary>Expert: A hit document's number.</summary>
            <seealso cref="M:Lucene.Net.Search.Searcher.Doc(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.ScoreDoc.#ctor(System.Int32,System.Single)">
            <summary>Expert: Constructs a ScoreDoc. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldDoc.fields">
            <summary>Expert: The values which are used to sort the referenced document.
            The order of these will match the original sort criteria given by a
            Sort object.  Each Object will be either an Integer, Float or String,
            depending on the type of values in the terms of the original field.
            </summary>
            <seealso cref="T:Lucene.Net.Search.Sort">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FieldDoc.#ctor(System.Int32,System.Single)">
            <summary>Expert: Creates one of these objects with empty sort information. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldDoc.#ctor(System.Int32,System.Single,System.IComparable[])">
            <summary>Expert: Creates one of these objects with the given sort information. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheRangeFilter">
            <summary> A range filter built on top of a cached single term field (in {@link FieldCache}).
            
            <p/>FieldCacheRangeFilter builds a single cache for the field the first time it is used.
            Each subsequent FieldCacheRangeFilter on the same field then reuses this cache,
            even if the range itself changes. 
            
            <p/>This means that FieldCacheRangeFilter is much faster (sometimes more than 100x as fast) 
            as building a {@link TermRangeFilter} (or {@link ConstantScoreRangeQuery} on a {@link TermRangeFilter})
            for each query, if using a {@link #newStringRange}. However, if the range never changes it
            is slower (around 2x as slow) than building a CachingWrapperFilter on top of a single TermRangeFilter.
            
            For numeric data types, this filter may be significantly faster than {@link NumericRangeFilter}.
            Furthermore, it does not need the numeric values encoded by {@link NumericField}. But
            it has the problem that it only works with exact one value/document (see below).
            
            <p/>As with all {@link FieldCache} based functionality, FieldCacheRangeFilter is only valid for 
            fields which exact one term for each document (except for {@link #newStringRange}
            where 0 terms are also allowed). Due to a restriction of {@link FieldCache}, for numeric ranges
            all terms that do not have a numeric value, 0 is assumed.
            
            <p/>Thus it works on dates, prices and other single value fields but will not work on
            regular text fields. It is preferable to use a <code>NOT_ANALYZED</code> field to ensure that
            there is only a single term. 
            
            <p/>This class does not have an constructor, use one of the static factory methods available,
            that create a correct instance for different data types supported by {@link FieldCache}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.GetDocIdSet(Lucene.Net.Index.IndexReader)">
            <summary>This method is implemented for each data type </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewStringRange(System.String,System.String,System.String,System.Boolean,System.Boolean)">
            <summary> Creates a string range query using {@link FieldCache#getStringIndex}. This works with all
            fields containing zero or one term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewByteRange(System.String,System.Byte,System.Byte,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetBytes(IndexReader,String)}. This works with all
            byte fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewByteRange(System.String,Lucene.Net.Search.ByteParser,System.Byte,System.Byte,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetBytes(IndexReader,String,FieldCache.ByteParser)}. This works with all
            byte fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewShortRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetShorts(IndexReader,String)}. This works with all
            short fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewShortRange(System.String,Lucene.Net.Search.ShortParser,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetShorts(IndexReader,String,FieldCache.ShortParser)}. This works with all
            short fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewIntRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetInts(IndexReader,String)}. This works with all
            int fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewIntRange(System.String,Lucene.Net.Search.IntParser,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetInts(IndexReader,String,FieldCache.IntParser)}. This works with all
            int fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewLongRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetLongs(IndexReader,String)}. This works with all
            long fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewLongRange(System.String,Lucene.Net.Search.LongParser,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetLongs(IndexReader,String,FieldCache.LongParser)}. This works with all
            long fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewFloatRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetFloats(IndexReader,String)}. This works with all
            float fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewFloatRange(System.String,Lucene.Net.Search.FloatParser,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetFloats(IndexReader,String,FieldCache.FloatParser)}. This works with all
            float fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewDoubleRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetDoubles(IndexReader,String)}. This works with all
            double fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.NewDoubleRange(System.String,Lucene.Net.Search.DoubleParser,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Creates a numeric range query using {@link FieldCache#GetDoubles(IndexReader,String,FieldCache.DoubleParser)}. This works with all
            double fields containing exactly one numeric term in the field. The range can be half-open by setting one
            of the values to <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.MatchDoc(System.Int32)">
            <summary>this method checks, if a doc is a hit, should throw AIOBE, when position invalid </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.IsCacheable">
            <summary>this DocIdSet is cacheable, if it works solely with FieldCache and no TermDocs </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator.Next">
            @deprecated use {@link #NextDoc()} instead. 
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator1.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator1.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheRangeFilter.FieldCacheDocIdSet.AnonymousClassDocIdSetIterator1.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.CachingSpanFilter">
            <summary> Wraps another SpanFilter's result and caches it.  The purpose is to allow
            filters to simply filter, and then wrap with this class to add caching.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.SpanFilter">
            <summary>Abstract base class providing a mechanism to restrict searches to a subset
            of an index and also maintains and returns position information.
            This is useful if you want to compare the positions from a SpanQuery with the positions of items in
            a filter.  For instance, if you had a SpanFilter that marked all the occurrences of the word "foo" in documents,
            and then you entered a new SpanQuery containing bar, you could not only filter by the word foo, but you could
            then compare position information for post processing.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SpanFilter.BitSpans(Lucene.Net.Index.IndexReader)">
            <summary>Returns a SpanFilterResult with true for documents which should be permitted in
            search results, and false for those that should not and Spans for where the true docs match.
            </summary>
            <param name="reader">The {@link Lucene.Net.Index.IndexReader} to load position and DocIdSet information from
            </param>
            <returns> A {@link SpanFilterResult}
            </returns>
            <throws>  java.io.IOException if there was an issue accessing the necessary information </throws>
            <summary> 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.CachingSpanFilter.cache">
            <summary> A transient Filter cache.</summary>
        </member>
        <member name="M:Lucene.Net.Search.CachingSpanFilter.#ctor(Lucene.Net.Search.SpanFilter)">
            <summary>
            New deletions always result in a cache miss, by default
            ({@link CachingWrapperFilter.DeletesMode#RECACHE}.
            <param name="filter">Filter to cache results of
            </param>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.CachingSpanFilter.#ctor(Lucene.Net.Search.SpanFilter,Lucene.Net.Search.CachingWrapperFilter.DeletesMode)">
            @param filter Filter to cache results of
            @param deletesMode See {@link CachingWrapperFilter.DeletesMode}
        </member>
        <member name="M:Lucene.Net.Search.CachingSpanFilter.Bits(Lucene.Net.Index.IndexReader)">
            <deprecated> Use {@link #GetDocIdSet(IndexReader)} instead.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.CachingWrapperFilter">
            <summary> Wraps another filter's result and caches it.  The purpose is to allow
            filters to simply filter, and then wrap with this class to add caching.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.CachingWrapperFilter.#ctor(Lucene.Net.Search.Filter)">
            New deletes are ignored by default, which gives higher
            cache hit rate on reopened readers.  Most of the time
            this is safe, because the filter will be AND'd with a
            Query that fully enforces deletions.  If instead you
            need this filter to always enforce deletions, pass
            either {@link DeletesMode#RECACHE} or {@link
            DeletesMode#DYNAMIC}.
            @param filter Filter to cache results of
        </member>
        <member name="M:Lucene.Net.Search.CachingWrapperFilter.#ctor(Lucene.Net.Search.Filter,Lucene.Net.Search.CachingWrapperFilter.DeletesMode)">
             Expert: by default, the cached filter will be shared
             across reopened segments that only had changes to their
             deletions.  
            
             @param filter Filter to cache results of
             @param deletesMode See {@link DeletesMode}
        </member>
        <member name="M:Lucene.Net.Search.CachingWrapperFilter.Bits(Lucene.Net.Index.IndexReader)">
            <deprecated> Use {@link #GetDocIdSet(IndexReader)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.CachingWrapperFilter.DocIdSetToCache(Lucene.Net.Search.DocIdSet,Lucene.Net.Index.IndexReader)">
            <summary>Provide the DocIdSet to be cached, using the DocIdSet provided
            by the wrapped Filter.
            This implementation returns the given DocIdSet.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.CachingWrapperFilter.DeletesMode">
             Expert: Specifies how new deletions against a reopened
             reader should be handled.
            
             <p>The default is IGNORE, which means the cache entry
             will be re-used for a given segment, even when that
             segment has been reopened due to changes in deletions.
             This is a big performance gain, especially with
             near-real-timer readers, since you don't hit a cache
             miss on every reopened reader for prior segments.</p>
            
             <p>However, in some cases this can cause invalid query
             results, allowing deleted documents to be returned.
             This only happens if the main query does not rule out
             deleted documents on its own, such as a toplevel
             ConstantScoreQuery.  To fix this, use RECACHE to
             re-create the cached filter (at a higher per-reopen
             cost, but at faster subsequent search performance), or
             use DYNAMIC to dynamically intersect deleted docs (fast
             reopen time but some hit to search performance).</p>
        </member>
        <member name="T:Lucene.Net.Util.Parameter">
            <summary> A serializable Enum class.</summary>
        </member>
        <member name="M:Lucene.Net.Util.Parameter.Equals(System.Object)">
            <summary> Resolves the deserialized instance to the local reference for accurate
            equals() and == comparisons.
            
            </summary>
            <returns> a reference to Parameter as resolved in the local VM
            </returns>
            <throws>  ObjectStreamException </throws>
        </member>
        <member name="F:Lucene.Net.Search.CachingWrapperFilter.FilterCache.cache">
            A transient Filter cache (package private because of test)
        </member>
        <member name="T:Lucene.Net.Search.FilteredDocIdSet">
            <summary> Abstract decorator class for a DocIdSet implementation
            that provides on-demand filtering/validation
            mechanism on a given DocIdSet.
            
            <p/>
            
            Technically, this same functionality could be achieved
            with ChainedFilter (under contrib/misc), however the
            benefit of this class is it never materializes the full
            bitset for the filter.  Instead, the {@link #match}
            method is invoked on-demand, per docID visited during
            searching.  If you know few docIDs will be visited, and
            the logic behind {@link #match} is relatively costly,
            this may be a better way to filter than ChainedFilter.
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.DocIdSet">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSet.#ctor(Lucene.Net.Search.DocIdSet)">
            <summary> Constructor.</summary>
            <param name="innerSet">Underlying DocIdSet
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSet.IsCacheable">
            <summary>This DocIdSet implementation is cacheable if the inner set is cacheable. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSet.Match(System.Int32)">
            <summary> Validation method to determine whether a docid should be in the result set.</summary>
            <param name="docid">docid to be tested
            </param>
            <returns> true if input docid should be in the result set, false otherwise.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSet.Iterator">
            <summary> Implementation of the contract to build a DocIdSetIterator.</summary>
            <seealso cref="T:Lucene.Net.Search.DocIdSetIterator">
            </seealso>
            <seealso cref="T:Lucene.Net.Search.FilteredDocIdSetIterator">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.FilteredDocIdSetIterator">
            <summary> Abstract decorator class of a DocIdSetIterator
            implementation that provides on-demand filter/validation
            mechanism on an underlying DocIdSetIterator.  See {@link
            FilteredDocIdSet}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSetIterator.#ctor(Lucene.Net.Search.DocIdSetIterator)">
            <summary> Constructor.</summary>
            <param name="innerIter">Underlying DocIdSetIterator.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSetIterator.Match(System.Int32)">
            <summary> Validation method to determine whether a docid should be in the result set.</summary>
            <param name="doc">docid to be tested
            </param>
            <returns> true if input docid should be in the result set, false otherwise.
            </returns>
            <seealso cref="M:Lucene.Net.Search.FilteredDocIdSetIterator.#ctor(Lucene.Net.Search.DocIdSetIterator)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSetIterator.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FilteredDocIdSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.QueryParsers.ParseException">
            <summary> This exception is thrown when parse errors are encountered.
            You can explicitly create objects of this exception type by
            calling the method generateParseException in the generated
            parser.
            
            You can modify this class to customize your error reporting
            mechanisms so long as you retain the public fields.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.ParseException.#ctor(Lucene.Net.QueryParsers.Token,System.Int32[][],System.String[])">
            <summary> This constructor is used by the method "generateParseException"
            in the generated parser.  Calling this constructor generates
            a new object of this type with the fields "currentToken",
            "expectedTokenSequences", and "tokenImage" set.  The boolean
            flag "specialConstructor" is also set to true to indicate that
            this constructor was used to create this object.
            This constructor calls its super class with the empty string
            to force the "toString" method of parent class "Throwable" to
            print the error message in the form:
            ParseException: &lt;result of getMessage&gt;
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.ParseException.#ctor">
            <summary> The following constructors are for use by you for whatever
            purpose you can think of.  Constructing the exception in this
            manner makes the exception behave in the normal way - i.e., as
            documented in the class "Throwable".  The fields "errorToken",
            "expectedTokenSequences", and "tokenImage" do not contain
            relevant information.  The JavaCC generated code does not use
            these constructors.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.ParseException.#ctor(System.String)">
            <summary>Constructor with message. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.ParseException.#ctor(System.String,System.Exception)">
            <summary>Constructor with message. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.ParseException.specialConstructor">
            <summary> This variable determines which constructor was used to create
            this object and thereby affects the semantics of the
            "getMessage" method (see below).
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.ParseException.currentToken">
            <summary> This is the last token that has been consumed successfully.  If
            this object has been created due to a parse error, the token
            followng this token will (therefore) be the first error token.
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.ParseException.expectedTokenSequences">
            <summary> Each entry in this array is an array of integers.  Each array
            of integers represents a sequence of tokens (by their ordinal
            values) that is expected at this point of the parse.
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.ParseException.tokenImage">
            <summary> This is a reference to the "tokenImage" array of the generated
            parser within which the parse error occurred.  This array is
            defined in the generated ...Constants interface.
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.ParseException.eol">
            <summary> The end of line string for this machine.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.ParseException.Add_escapes(System.String)">
            <summary> Used to convert raw characters to their escaped version
            when these raw version cannot be used as part of an ASCII
            string literal.
            </summary>
        </member>
        <member name="P:Lucene.Net.QueryParsers.ParseException.Message">
            <summary> This method has the standard behavior when this object has been
            created using the standard constructors.  Otherwise, it uses
            "currentToken" and "expectedTokenSequences" to generate a parse
            error message and returns it.  If this object has been created
            due to a parse error, and you do not catch it (it gets thrown
            from the parser), then this method is called during the printing
            of the final stack trace, and hence the correct error message
            gets displayed.
            </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.CharStream">
            <summary> This interface describes a character stream that maintains line and
            column number positions of the characters.  It also has the capability
            to backup the stream to some extent.  An implementation of this
            interface is used in the TokenManager implementation generated by
            JavaCCParser.
            
            All the methods except backup can be implemented in any fashion. backup
            needs to be implemented correctly for the correct operation of the lexer.
            Rest of the methods are all used to get information like line number,
            column number and the String that constitutes a token and are not used
            by the lexer. Hence their implementation won't affect the generated lexer's
            operation.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.ReadChar">
            <summary> Returns the next character from the selected input.  The method
            of selecting the input is the responsibility of the class
            implementing this interface.  Can throw any java.io.IOException.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetColumn">
            <summary> Returns the column position of the character last read.</summary>
            <deprecated>
            </deprecated>
            <seealso cref="!:getEndColumn">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetLine">
            <summary> Returns the line number of the character last read.</summary>
            <deprecated>
            </deprecated>
            <seealso cref="!:getEndLine">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetEndColumn">
            <summary> Returns the column number of the last character for current token (being
            matched after the last call to BeginTOken).
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetEndLine">
            <summary> Returns the line number of the last character for current token (being
            matched after the last call to BeginTOken).
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetBeginColumn">
            <summary> Returns the column number of the first character for current token (being
            matched after the last call to BeginTOken).
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetBeginLine">
            <summary> Returns the line number of the first character for current token (being
            matched after the last call to BeginTOken).
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.Backup(System.Int32)">
            <summary> Backs up the input stream by amount steps. Lexer calls this method if it
            had already read some characters, but could not use them to match a
            (longer) token. So, they will be used again as the prefix of the next
            token and it is the implemetation's responsibility to do this right.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.BeginToken">
            <summary> Returns the next character that marks the beginning of the next token.
            All characters must remain in the buffer between two successive calls
            to this method to implement backup correctly.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetImage">
            <summary> Returns a string made up of characters from the marked token beginning
            to the current buffer position. Implementations have the choice of returning
            anything that they want to. For example, for efficiency, one might decide
            to just return null, which is a valid implementation.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.GetSuffix(System.Int32)">
            <summary> Returns an array of characters that make up the suffix of length 'len' for
            the currently matched token. This is used to build up the matched string
            for use in actions in the case of MORE. A simple and inefficient
            implementation of this is as follows :
            
            {
            String t = GetImage();
            return t.substring(t.length() - len, t.length()).toCharArray();
            }
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.CharStream.Done">
            <summary> The lexer calls this function to indicate that it is done with the stream
            and hence implementations can free any resources held by this class.
            Again, the body of this function can be just empty and it will not
            affect the lexer's operation.
            </summary>
        </member>
        <member name="T:Lucene.Net.Messages.MessageImpl">
            <summary> Default implementation of Message interface.
            For Native Language Support (NLS), system of software internationalization.
            </summary>
        </member>
        <member name="T:Lucene.Net.Messages.Message">
            <summary> Message Interface for a lazy loading.
            For Native Language Support (NLS), system of software internationalization.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.KeepOnlyLastCommitDeletionPolicy">
            <summary> This {@link IndexDeletionPolicy} implementation that
            keeps only the most recent commit and immediately removes
            all prior commits after a new commit is done.  This is
            the default deletion policy.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexDeletionPolicy">
            <summary> <p/>Expert: policy for deletion of stale {@link IndexCommit index commits}. 
            
            <p/>Implement this interface, and pass it to one
            of the {@link IndexWriter} or {@link IndexReader}
            constructors, to customize when older
            {@link IndexCommit point-in-time commits}
            are deleted from the index directory.  The default deletion policy
            is {@link KeepOnlyLastCommitDeletionPolicy}, which always
            removes old commits as soon as a new commit is done (this
            matches the behavior before 2.2).<p/>
            
            <p/>One expected use case for this (and the reason why it
            was first created) is to work around problems with an
            index directory accessed via filesystems like NFS because
            NFS does not provide the "delete on last close" semantics
            that Lucene's "point in time" search normally relies on.
            By implementing a custom deletion policy, such as "a
            commit is only removed once it has been stale for more
            than X minutes", you can give your readers time to
            refresh to the new commit before {@link IndexWriter}
            removes the old commits.  Note that doing so will
            increase the storage requirements of the index.  See <a
            target="top"
            href="http://issues.apache.org/jira/browse/LUCENE-710">LUCENE-710</a>
            for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexDeletionPolicy.OnInit(System.Collections.IList)">
            <summary> <p/>This is called once when a writer is first
            instantiated to give the policy a chance to remove old
            commit points.<p/>
            
            <p/>The writer locates all index commits present in the 
            index directory and calls this method.  The policy may 
            choose to delete some of the commit points, doing so by
            calling method {@link IndexCommit#delete delete()} 
            of {@link IndexCommit}.<p/>
            
            <p/><u>Note:</u> the last CommitPoint is the most recent one,
            i.e. the "front index state". Be careful not to delete it,
            unless you know for sure what you are doing, and unless 
            you can afford to lose the index content while doing that. 
            
            </summary>
            <param name="commits">List of current 
            {@link IndexCommit point-in-time commits},
            sorted by age (the 0th one is the oldest commit).
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexDeletionPolicy.OnCommit(System.Collections.IList)">
            <summary> <p/>This is called each time the writer completed a commit.
            This gives the policy a chance to remove old commit points
            with each commit.<p/>
            
            <p/>The policy may now choose to delete old commit points 
            by calling method {@link IndexCommit#delete delete()} 
            of {@link IndexCommit}.<p/>
            
            <p/>If writer has <code>autoCommit = true</code> then
            this method will in general be called many times during
            one instance of {@link IndexWriter}.  If
            <code>autoCommit = false</code> then this method is
            only called once when {@link IndexWriter#close} is
            called, or not at all if the {@link IndexWriter#abort}
            is called. 
            
            <p/><u>Note:</u> the last CommitPoint is the most recent one,
            i.e. the "front index state". Be careful not to delete it,
            unless you know for sure what you are doing, and unless 
            you can afford to lose the index content while doing that.
            
            </summary>
            <param name="commits">List of {@link IndexCommit},
            sorted by age (the 0th one is the oldest commit).
            </param>
        </member>
        <member name="M:Lucene.Net.Index.KeepOnlyLastCommitDeletionPolicy.OnInit(System.Collections.IList)">
            <summary> Deletes all commits except the most recent one.</summary>
        </member>
        <member name="M:Lucene.Net.Index.KeepOnlyLastCommitDeletionPolicy.OnCommit(System.Collections.IList)">
            <summary> Deletes all commits except the most recent one.</summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldSortedTermVectorMapper">
            <summary> For each Field, store a sorted collection of {@link TermVectorEntry}s
            <p/>
            This is not thread-safe.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermVectorMapper">
            <summary> The TermVectorMapper can be used to map Term Vectors into your own
            structure instead of the parallel array structure used by
            {@link Lucene.Net.Index.IndexReader#GetTermFreqVector(int,String)}.
            <p/>
            It is up to the implementation to make sure it is thread-safe.
            
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.#ctor(System.Boolean,System.Boolean)">
            <summary> </summary>
            <param name="ignoringPositions">true if this mapper should tell Lucene to ignore positions even if they are stored
            </param>
            <param name="ignoringOffsets">similar to ignoringPositions
            </param>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.SetExpectations(System.String,System.Int32,System.Boolean,System.Boolean)">
            <summary> Tell the mapper what to expect in regards to field, number of terms, offset and position storage.
            This method will be called once before retrieving the vector for a field.
            
            This method will be called before {@link #Map(String,int,TermVectorOffsetInfo[],int[])}.
            </summary>
            <param name="field">The field the vector is for
            </param>
            <param name="numTerms">The number of terms that need to be mapped
            </param>
            <param name="storeOffsets">true if the mapper should expect offset information
            </param>
            <param name="storePositions">true if the mapper should expect positions info
            </param>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.Map(System.String,System.Int32,Lucene.Net.Index.TermVectorOffsetInfo[],System.Int32[])">
            <summary> Map the Term Vector information into your own structure</summary>
            <param name="term">The term to add to the vector
            </param>
            <param name="frequency">The frequency of the term in the document
            </param>
            <param name="offsets">null if the offset is not specified, otherwise the offset into the field of the term
            </param>
            <param name="positions">null if the position is not specified, otherwise the position in the field of the term
            </param>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.IsIgnoringPositions">
            <summary> Indicate to Lucene that even if there are positions stored, this mapper is not interested in them and they
            can be skipped over.  Derived classes should set this to true if they want to ignore positions.  The default
            is false, meaning positions will be loaded if they are stored.
            </summary>
            <returns> false
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.IsIgnoringOffsets">
            <summary> </summary>
            <seealso cref="M:Lucene.Net.Index.TermVectorMapper.IsIgnoringPositions"> Same principal as {@link #IsIgnoringPositions()}, but applied to offsets.  false by default.
            </seealso>
            <returns> false
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorMapper.SetDocumentNumber(System.Int32)">
            <summary> Passes down the index of the document whose term vector is currently being mapped,
            once for each top level call to a term vector reader.
            <p/>
            Default implementation IGNORES the document number.  Override if your implementation needs the document number.
            <p/> 
            NOTE: Document numbers are internal to Lucene and subject to change depending on indexing operations.
            
            </summary>
            <param name="documentNumber">index of document currently being mapped
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldSortedTermVectorMapper.#ctor(System.Collections.Generic.IComparer{System.Object})">
            <summary> </summary>
            <param name="comparator">A Comparator for sorting {@link TermVectorEntry}s
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldSortedTermVectorMapper.GetFieldToTerms">
            <summary> Get the mapping between fields and terms, sorted by the comparator
            
            </summary>
            <returns> A map between field names and {@link java.util.SortedSet}s per field.  SortedSet entries are {@link TermVectorEntry}
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.CompoundFileWriter">
            <summary> Combines multiple files into a single compound file.
            The file format:<br/>
            <ul>
            <li>VInt fileCount</li>
            <li>{Directory}
            fileCount entries with the following structure:</li>
            <ul>
            <li>long dataOffset</li>
            <li>String fileName</li>
            </ul>
            <li>{File Data}
            fileCount entries with the raw data of the corresponding file</li>
            </ul>
            
            The fileCount integer indicates how many files are contained in this compound
            file. The {directory} that follows has that many entries. Each directory entry
            contains a long pointer to the start of this file's data section, and a String
            with that file's name.
            
            
            </summary>
            <version>  $Id: CompoundFileWriter.java 690539 2008-08-30 17:33:06Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.#ctor(Lucene.Net.Store.Directory,System.String)">
            <summary>Create the compound stream in the specified file. The file name is the
            entire name (no extensions are added).
            </summary>
            <throws>  NullPointerException if <code>dir</code> or <code>name</code> is null </throws>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.GetDirectory">
            <summary>Returns the directory of the compound file. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.GetName">
            <summary>Returns the name of the compound file. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.AddFile(System.String)">
            <summary>Add a source stream. <code>file</code> is the string by which the 
            sub-stream will be known in the compound stream.
            
            </summary>
            <throws>  IllegalStateException if this writer is closed </throws>
            <throws>  NullPointerException if <code>file</code> is null </throws>
            <throws>  IllegalArgumentException if a file with the same name </throws>
            <summary>   has been added already
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.Close">
            <summary>Merge files with the extensions added up to now.
            All files with these extensions are combined sequentially into the
            compound stream. After successful merge, the source files
            are deleted.
            </summary>
            <throws>  IllegalStateException if close() had been called before or </throws>
            <summary>   if no file has been added to this object
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileWriter.CopyFile(Lucene.Net.Index.CompoundFileWriter.FileEntry,Lucene.Net.Store.IndexOutput,System.Byte[])">
            <summary>Copy the contents of the file with specified extension into the
            provided output stream. Use the provided buffer for moving data
            to reduce memory allocation.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CompoundFileWriter.FileEntry.file">
            <summary>source file </summary>
        </member>
        <member name="F:Lucene.Net.Index.CompoundFileWriter.FileEntry.directoryOffset">
            <summary>temporary holder for the start of directory entry for this file </summary>
        </member>
        <member name="F:Lucene.Net.Index.CompoundFileWriter.FileEntry.dataOffset">
            <summary>temporary holder for the start of this file's data section </summary>
        </member>
        <member name="T:Lucene.Net.Index.CompoundFileReader">
            <summary> Class for accessing a compound stream.
            This class implements a directory, but is limited to only read operations.
            Directory methods that would normally modify data throw an exception.
            
            
            </summary>
            <version>  $Id: CompoundFileReader.java 673371 2008-07-02 11:57:27Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.List">
            <summary>Returns an array of strings, one for each file in the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.FileExists(System.String)">
            <summary>Returns true iff a file with the given name exists. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.FileModified(System.String)">
            <summary>Returns the time the compound file was last modified. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.TouchFile(System.String)">
            <summary>Set the modified time of the compound file to now. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.DeleteFile(System.String)">
            <summary>Not implemented</summary>
            <throws>  UnsupportedOperationException  </throws>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.RenameFile(System.String,System.String)">
            <summary>Not implemented</summary>
            <throws>  UnsupportedOperationException  </throws>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.FileLength(System.String)">
            <summary>Returns the length of a file in the directory.</summary>
            <throws>  IOException if the file does not exist  </throws>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.CreateOutput(System.String)">
            <summary>Not implemented</summary>
            <throws>  UnsupportedOperationException  </throws>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.MakeLock(System.String)">
            <summary>Not implemented</summary>
            <throws>  UnsupportedOperationException  </throws>
        </member>
        <member name="T:Lucene.Net.Index.CompoundFileReader.CSIndexInput">
            <summary>Implementation of an IndexInput that reads from a portion of the
            compound file. The visibility is left as "package" *only* because
            this helps with testing since JUnit test cases in a different class
            can then access package fields of this class.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.CSIndexInput.ReadInternal(System.Byte[],System.Int32,System.Int32)">
            <summary>Expert: implements buffer refill.  Reads bytes from the current
            position in the input.
            </summary>
            <param name="b">the array to read bytes into
            </param>
            <param name="offset">the offset in the array to start storing bytes
            </param>
            <param name="len">the number of bytes to read
            </param>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.CSIndexInput.SeekInternal(System.Int64)">
            <summary>Expert: implements seek.  Sets current position in this file, where
            the next {@link #ReadInternal(byte[],int,int)} will occur.
            </summary>
            <seealso cref="M:Lucene.Net.Index.CompoundFileReader.CSIndexInput.ReadInternal(System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.CompoundFileReader.CSIndexInput.Close">
            <summary>Closes the stream to further operations. </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.PayloadAttributeImpl">
            <summary> The payload of a Token. See also {@link Payload}.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.PayloadAttribute">
            <summary> The payload of a Token. See also {@link Payload}.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttribute.GetPayload">
            <summary> Returns this Token's payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttribute.SetPayload(Lucene.Net.Index.Payload)">
            <summary> Sets this Token's payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttributeImpl.#ctor">
            <summary> Initialize this attribute with no payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttributeImpl.#ctor(Lucene.Net.Index.Payload)">
            <summary> Initialize this attribute with the given payload. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttributeImpl.GetPayload">
            <summary> Returns this Token's payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PayloadAttributeImpl.SetPayload(Lucene.Net.Index.Payload)">
            <summary> Sets this Token's payload.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.OffsetAttribute">
            <summary> The start and end character offset of a Token. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttribute.StartOffset">
            <summary>Returns this Token's starting offset, the position of the first character
            corresponding to this token in the source text.
            Note that the difference between endOffset() and startOffset() may not be
            equal to termText.length(), as the term text may have been altered by a
            stemmer or some other filter. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttribute.SetOffset(System.Int32,System.Int32)">
            <summary>Set the starting and ending offset.
            See StartOffset() and EndOffset()
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttribute.EndOffset">
            <summary>Returns this Token's ending offset, one greater than the position of the
            last character corresponding to this token in the source text. The length
            of the token in the source text is (endOffset - startOffset). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.FlagsAttributeImpl">
            <summary> This attribute can be used to pass different flags down the tokenizer chain,
            eg from one TokenFilter to another one. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.FlagsAttribute">
            <summary> This attribute can be used to pass different flags down the {@link Tokenizer} chain,
            eg from one TokenFilter to another one. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttribute.GetFlags">
            <summary> EXPERIMENTAL:  While we think this is here to stay, we may want to change it to be a long.
            <p/>
            
            Get the bitset for any bits that have been set.  This is completely distinct from {@link TypeAttribute#Type()}, although they do share similar purposes.
            The flags can be used to encode information about the token for use by other {@link Lucene.Net.Analysis.TokenFilter}s.
            
            
            </summary>
            <returns> The bits
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttribute.SetFlags(System.Int32)">
            <seealso cref="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttribute.GetFlags">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttributeImpl.GetFlags">
            <summary> EXPERIMENTAL:  While we think this is here to stay, we may want to change it to be a long.
            <p/>
            
            Get the bitset for any bits that have been set.  This is completely distinct from {@link TypeAttribute#Type()}, although they do share similar purposes.
            The flags can be used to encode information about the token for use by other {@link Lucene.Net.Analysis.TokenFilter}s.
            
            
            </summary>
            <returns> The bits
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttributeImpl.SetFlags(System.Int32)">
            <seealso cref="M:Lucene.Net.Analysis.Tokenattributes.FlagsAttributeImpl.GetFlags">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Util.ReaderUtil">
            <summary> Common util methods for dealing with {@link IndexReader}s.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.ReaderUtil.GatherSubReaders(System.Collections.IList,Lucene.Net.Index.IndexReader)">
            <summary> Gathers sub-readers from reader into a List.
            
            </summary>
            <param name="allSubReaders">
            </param>
            <param name="reader">
            </param>
        </member>
        <member name="M:Lucene.Net.Util.ReaderUtil.SubReader(System.Int32,Lucene.Net.Index.IndexReader)">
            <summary> Returns sub IndexReader that contains the given document id.
            
            </summary>
            <param name="doc">id of document
            </param>
            <param name="reader">parent reader
            </param>
            <returns> sub reader of parent which contains the specified doc id
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.ReaderUtil.SubReader(Lucene.Net.Index.IndexReader,System.Int32)">
            <summary> Returns sub-reader subIndex from reader.
            
            </summary>
            <param name="reader">parent reader
            </param>
            <param name="subIndex">index of desired sub reader
            </param>
            <returns> the subreader at subINdex
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.ReaderUtil.SubIndex(System.Int32,System.Int32[])">
            <summary> Returns index of the searcher/reader for document <code>n</code> in the
            array used to construct this searcher/reader.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.TopFieldDocCollector">
            <summary>A {@link HitCollector} implementation that collects the top-sorting
            documents, returning them as a {@link TopFieldDocs}.  This is used by {@link
            IndexSearcher} to implement {@link TopFieldDocs}-based search.
            
            <p/>This may be extended, overriding the collect method to, e.g.,
            conditionally invoke <code>super()</code> in order to filter which
            documents are collected.
            
            </summary>
            <deprecated> Please use {@link TopFieldCollector} instead.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.TopDocCollector">
            <summary>A {@link HitCollector} implementation that collects the top-scoring
            documents, returning them as a {@link TopDocs}.  This is used by {@link
            IndexSearcher} to implement {@link TopDocs}-based search.
            
            <p/>This may be extended, overriding the collect method to, e.g.,
            conditionally invoke <code>super()</code> in order to filter which
            documents are collected.
            
            </summary>
            <deprecated> Please use {@link TopScoreDocCollector}
            instead, which has better performance.
            
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.HitCollector">
            <summary> Lower-level search API. <br/>
            HitCollectors are primarily meant to be used to implement queries, sorting
            and filtering. See {@link Collector} for a lower level and higher performance
            (on a multi-segment index) API.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.HitCollector)">
            </seealso>
            <version>  $Id: HitCollector.java 764551 2009-04-13 18:33:56Z mikemccand $
            </version>
            <deprecated> Please use {@link Collector} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.HitCollector.Collect(System.Int32,System.Single)">
            <summary>Called once for every document matching a query, with the document
            number and its raw score.
            
            <p/>If, for example, an application wished to collect all of the hits for a
            query in a BitSet, then it might:<pre>
            Searcher searcher = new IndexSearcher(indexReader);
            final BitSet bits = new BitSet(indexReader.maxDoc());
            searcher.search(query, new HitCollector() {
            public void collect(int doc, float score) {
            bits.set(doc);
            }
            });
            </pre>
            
            <p/>Note: This is called in an inner search loop.  For good search
            performance, implementations of this method should not call
            {@link Searcher#Doc(int)} or
            {@link Lucene.Net.Index.IndexReader#Document(int)} on every
            document number encountered.  Doing so can slow searches by an order
            of magnitude or more.
            <p/>Note: The <code>score</code> passed to this method is a raw score.
            In other words, the score will not necessarily be a float whose value is
            between 0 and 1.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopDocCollector.totalHits">
            <summary>The total number of hits the collector encountered. </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopDocCollector.hq">
            <summary>The priority queue which holds the top-scoring documents. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocCollector.#ctor(System.Int32)">
            <summary>Construct to collect a given number of hits.</summary>
            <param name="numHits">the maximum number of hits to collect
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TopDocCollector.#ctor(System.Int32,Lucene.Net.Util.PriorityQueue)">
            <deprecated> use TopDocCollector(hq) instead. numHits is not used by this
            constructor. It will be removed in a future release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TopDocCollector.#ctor(Lucene.Net.Util.PriorityQueue)">
            <summary>Constructor to collect the top-scoring documents by using the given PQ.</summary>
            <param name="hq">the PQ to use by this instance.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TopDocCollector.GetTotalHits">
            <summary>The total number of documents that matched this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocCollector.TopDocs">
            <summary>The top-scoring hits. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopFieldDocCollector.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Search.Sort,System.Int32)">
            <summary>Construct to collect a given number of hits.</summary>
            <param name="reader">the index to be searched
            </param>
            <param name="sort">the sort criteria
            </param>
            <param name="numHits">the maximum number of hits to collect
            </param>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanFirstQuery">
            <summary>Matches spans near the beginning of a field. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanFirstQuery.#ctor(Lucene.Net.Search.Spans.SpanQuery,System.Int32)">
            <summary>Construct a SpanFirstQuery matching spans in <code>match</code> whose end
            position is less than or equal to <code>end</code>. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanFirstQuery.GetMatch">
            <summary>Return the SpanQuery whose matches are filtered. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanFirstQuery.GetEnd">
            <summary>Return the maximum end position permitted in a match. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanFirstQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.PhraseScorer">
            <summary>Expert: Scoring functionality for phrase queries.
            <br/>A document is considered matching if it contains the phrase-query terms  
            at "valid" positons. What "valid positions" are
            depends on the type of the phrase query: for an exact phrase query terms are required 
            to appear in adjacent locations, while for a sloppy phrase query some distance between 
            the terms is allowed. The abstract method {@link #PhraseFreq()} of extending classes
            is invoked for each document containing all the phrase query terms, in order to 
            compute the frequency of the phrase query in that document. A non zero frequency
            means a match. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.PhraseScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.PhraseScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.PhraseScorer.PhraseFreq">
            <summary> For a document containing all the phrase query terms, compute the
            frequency of the phrase in that document. 
            A non zero frequency means a match.
            <br/>Note, that containing all phrase terms does not guarantee a match - they have to be found in matching locations.  
            </summary>
            <returns> frequency of the phrase in current doc, 0 if not found. 
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.MaxPayloadFunction">
            <summary> Returns the maximum payload score seen, else 1 if there are no payloads on the doc.
            <p/>
            Is thread safe and completely reusable.
            
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.PayloadFunction">
            <summary> An abstract class that defines a way for Payload*Query instances
            to transform the cumulative effects of payload scores for a document.
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.Payloads.PayloadTermQuery"> for more information
            
            <p/>
            This class and its derivations are experimental and subject to change
            
            
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadFunction.CurrentScore(System.Int32,System.String,System.Int32,System.Int32,System.Int32,System.Single,System.Single)">
            <summary> Calculate the score up to this point for this doc and field</summary>
            <param name="docId">The current doc
            </param>
            <param name="field">The field
            </param>
            <param name="start">The start position of the matching Span
            </param>
            <param name="end">The end position of the matching Span
            </param>
            <param name="numPayloadsSeen">The number of payloads seen so far
            </param>
            <param name="currentScore">The current score so far
            </param>
            <param name="currentPayloadScore">The score for the current payload
            </param>
            <returns> The new current Score
            
            </returns>
            <seealso cref="T:Lucene.Net.Search.Spans.Spans">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadFunction.DocScore(System.Int32,System.String,System.Int32,System.Single)">
            <summary> Calculate the final score for all the payloads seen so far for this doc/field</summary>
            <param name="docId">The current doc
            </param>
            <param name="field">The current field
            </param>
            <param name="numPayloadsSeen">The total number of payloads seen on this document
            </param>
            <param name="payloadScore">The raw score for those payloads
            </param>
            <returns> The final score for the payloads
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.Function.ByteFieldSource">
            <summary> Expert: obtains single byte field values from the 
            {@link Lucene.Net.Search.FieldCache FieldCache}
            using <code>getBytes()</code> and makes those values 
            available as other numeric types, casting as needed.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.Function.FieldCacheSource"> for requirements"
            on the field. 
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.ByteFieldSource.#ctor(System.String)">
            <summary> Create a cached byte field source with default string-to-byte parser. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ByteFieldSource.#ctor(System.String,Lucene.Net.Search.ByteParser)">
            <summary> Create a cached byte field source with a specific string-to-byte parser. </summary>
        </member>
        <member name="T:Lucene.Net.Search.CreationPlaceholder">
            <summary> Expert: Maintains caches of term values.
            
            <p/>Created: May 19, 2004 11:13:14 AM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: FieldCache.java 807841 2009-08-25 22:27:31Z markrmiller $
            </version>
            <seealso cref="T:Lucene.Net.Util.FieldCacheSanityChecker">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.StringIndex">
            <summary>Expert: Stores term text values and document ordering data. </summary>
        </member>
        <member name="F:Lucene.Net.Search.StringIndex.lookup">
            <summary>All the term values, in natural order. </summary>
        </member>
        <member name="F:Lucene.Net.Search.StringIndex.order">
            <summary>For each document, an index into the lookup array. </summary>
        </member>
        <member name="M:Lucene.Net.Search.StringIndex.#ctor(System.Int32[],System.String[])">
            <summary>Creates one of these objects </summary>
        </member>
        <member name="T:Lucene.Net.Search.CacheEntry">
            <summary> EXPERT: A unique Identifier/Description for each item in the FieldCache. 
            Can be useful for logging/debugging.
            <p/>
            <b>EXPERIMENTAL API:</b> This API is considered extremely advanced 
            and experimental.  It may be removed or altered w/o warning in future 
            releases 
            of Lucene.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.CacheEntry.EstimateSize">
            <seealso cref="M:Lucene.Net.Search.CacheEntry.EstimateSize(Lucene.Net.Util.RamUsageEstimator)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.CacheEntry.EstimateSize(Lucene.Net.Util.RamUsageEstimator)">
            <summary> Computes (and stores) the estimated size of the cache Value </summary>
            <seealso cref="!:getEstimatedSize">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.CacheEntry.GetEstimatedSize">
            <summary> The most recently estimated size of the value, null unless 
            estimateSize has been called.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.STRING_INDEX">
            <summary>Indicator for StringIndex values in the cache. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT">
            <summary>Expert: The cache used internally by sorting and range query classes. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_BYTE_PARSER">
            <summary>The default parser for byte values, which are encoded by {@link Byte#toString(byte)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_SHORT_PARSER">
            <summary>The default parser for short values, which are encoded by {@link Short#toString(short)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_INT_PARSER">
            <summary>The default parser for int values, which are encoded by {@link Integer#toString(int)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_FLOAT_PARSER">
            <summary>The default parser for float values, which are encoded by {@link Float#toString(float)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_LONG_PARSER">
            <summary>The default parser for long values, which are encoded by {@link Long#toString(long)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.DEFAULT_DOUBLE_PARSER">
            <summary>The default parser for double values, which are encoded by {@link Double#toString(double)} </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.NUMERIC_UTILS_INT_PARSER">
            <summary> A parser instance for int values encoded by {@link NumericUtils#IntToPrefixCoded(int)}, e.g. when indexed
            via {@link NumericField}/{@link NumericTokenStream}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.NUMERIC_UTILS_FLOAT_PARSER">
            <summary> A parser instance for float values encoded with {@link NumericUtils}, e.g. when indexed
            via {@link NumericField}/{@link NumericTokenStream}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.NUMERIC_UTILS_LONG_PARSER">
            <summary> A parser instance for long values encoded by {@link NumericUtils#LongToPrefixCoded(long)}, e.g. when indexed
            via {@link NumericField}/{@link NumericTokenStream}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCache_Fields.NUMERIC_UTILS_DOUBLE_PARSER">
            <summary> A parser instance for double values encoded with {@link NumericUtils}, e.g. when indexed
            via {@link NumericField}/{@link NumericTokenStream}.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.ByteParser">
            <summary>Interface to parse bytes from document fields.</summary>
            <seealso cref="!:FieldCache.GetBytes(IndexReader, String, FieldCache.ByteParser)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.Parser">
            <summary> Marker interface as super-interface to all parsers. It
            is used to specify a custom parser to {@link
            SortField#SortField(String, FieldCache.Parser)}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ByteParser.ParseByte(System.String)">
            <summary>Return a single Byte representation of this field's value. </summary>
        </member>
        <member name="T:Lucene.Net.Search.ShortParser">
            <summary>Interface to parse shorts from document fields.</summary>
            <seealso cref="!:FieldCache.GetShorts(IndexReader, String, FieldCache.ShortParser)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.ShortParser.ParseShort(System.String)">
            <summary>Return a short representation of this field's value. </summary>
        </member>
        <member name="T:Lucene.Net.Search.IntParser">
            <summary>Interface to parse ints from document fields.</summary>
            <seealso cref="!:FieldCache.GetInts(IndexReader, String, FieldCache.IntParser)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.IntParser.ParseInt(System.String)">
            <summary>Return an integer representation of this field's value. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FloatParser">
            <summary>Interface to parse floats from document fields.</summary>
            <seealso cref="!:FieldCache.GetFloats(IndexReader, String, FieldCache.FloatParser)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FloatParser.ParseFloat(System.String)">
            <summary>Return an float representation of this field's value. </summary>
        </member>
        <member name="T:Lucene.Net.Search.LongParser">
            <summary>Interface to parse long from document fields.</summary>
            <seealso cref="!:FieldCache.GetLongs(IndexReader, String, FieldCache.LongParser)">
            </seealso>
            <deprecated> Use {@link FieldCache.LongParser}, this will be removed in Lucene 3.0 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.LongParser.ParseLong(System.String)">
            <summary>Return an long representation of this field's value. </summary>
        </member>
        <member name="T:Lucene.Net.Search.DoubleParser">
            <summary>Interface to parse doubles from document fields.</summary>
            <seealso cref="!:FieldCache.GetDoubles(IndexReader, String, FieldCache.DoubleParser)">
            </seealso>
            <deprecated> Use {@link FieldCache.DoubleParser}, this will be removed in Lucene 3.0 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DoubleParser.ParseDouble(System.String)">
            <summary>Return an long representation of this field's value. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetBytes(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if none is
            found, reads the terms in <code>field</code> as a single byte and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the single byte values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetBytes(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ByteParser)">
            <summary>Checks the internal cache for an appropriate entry, and if none is found,
            reads the terms in <code>field</code> as bytes and returns an array of
            size <code>reader.maxDoc()</code> of the value each document has in the
            given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the bytes.
            </param>
            <param name="parser"> Computes byte for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetShorts(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if none is
            found, reads the terms in <code>field</code> as shorts and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the shorts.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetShorts(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ShortParser)">
            <summary>Checks the internal cache for an appropriate entry, and if none is found,
            reads the terms in <code>field</code> as shorts and returns an array of
            size <code>reader.maxDoc()</code> of the value each document has in the
            given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the shorts.
            </param>
            <param name="parser"> Computes short for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetInts(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if none is
            found, reads the terms in <code>field</code> as integers and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the integers.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetInts(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.IntParser)">
            <summary>Checks the internal cache for an appropriate entry, and if none is found,
            reads the terms in <code>field</code> as integers and returns an array of
            size <code>reader.maxDoc()</code> of the value each document has in the
            given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the integers.
            </param>
            <param name="parser"> Computes integer for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetFloats(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if
            none is found, reads the terms in <code>field</code> as floats and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the floats.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetFloats(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.FloatParser)">
            <summary>Checks the internal cache for an appropriate entry, and if
            none is found, reads the terms in <code>field</code> as floats and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the floats.
            </param>
            <param name="parser"> Computes float for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetLongs(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Checks the internal cache for an appropriate entry, and if none is
            found, reads the terms in <code>field</code> as longs and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            
            </summary>
            <param name="reader">Used to get field values.
            </param>
            <param name="field"> Which field contains the longs.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  java.io.IOException If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetLongs(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.LongParser)">
            <summary> Checks the internal cache for an appropriate entry, and if none is found,
            reads the terms in <code>field</code> as longs and returns an array of
            size <code>reader.maxDoc()</code> of the value each document has in the
            given field.
            
            </summary>
            <param name="reader">Used to get field values.
            </param>
            <param name="field"> Which field contains the longs.
            </param>
            <param name="parser">Computes integer for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetDoubles(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Checks the internal cache for an appropriate entry, and if none is
            found, reads the terms in <code>field</code> as integers and returns an array
            of size <code>reader.maxDoc()</code> of the value each document
            has in the given field.
            
            </summary>
            <param name="reader">Used to get field values.
            </param>
            <param name="field"> Which field contains the doubles.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetDoubles(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.DoubleParser)">
            <summary> Checks the internal cache for an appropriate entry, and if none is found,
            reads the terms in <code>field</code> as doubles and returns an array of
            size <code>reader.maxDoc()</code> of the value each document has in the
            given field.
            
            </summary>
            <param name="reader">Used to get field values.
            </param>
            <param name="field"> Which field contains the doubles.
            </param>
            <param name="parser">Computes integer for string values.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetStrings(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if none
            is found, reads the term values in <code>field</code> and returns an array
            of size <code>reader.maxDoc()</code> containing the value each document
            has in the given field.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the strings.
            </param>
            <returns> The values in the given field for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetStringIndex(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if none
            is found reads the term values in <code>field</code> and returns
            an array of them in natural order, along with an array telling
            which element in the term array each document uses.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the strings.
            </param>
            <returns> Array of terms and index into the array for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetAuto(Lucene.Net.Index.IndexReader,System.String)">
            <summary>Checks the internal cache for an appropriate entry, and if
            none is found reads <code>field</code> to see if it contains integers, longs, floats
            or strings, and then calls one of the other methods in this class to get the
            values.  For string values, a StringIndex is returned.  After
            calling this method, there is an entry in the cache for both
            type <code>AUTO</code> and the actual found type.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the values.
            </param>
            <returns> int[], long[], float[] or StringIndex.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
            <deprecated> Please specify the exact type, instead.
            Especially, guessing does <b>not</b> work with the new
            {@link NumericField} type.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetCustom(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.SortComparator)">
            <summary>Checks the internal cache for an appropriate entry, and if none
            is found reads the terms out of <code>field</code> and calls the given SortComparator
            to get the sort values.  A hit in the cache will happen if <code>reader</code>,
            <code>field</code>, and <code>comparator</code> are the same (using <code>equals()</code>)
            as a previous call to this method.
            </summary>
            <param name="reader"> Used to get field values.
            </param>
            <param name="field">  Which field contains the values.
            </param>
            <param name="comparator">Used to convert terms into something to sort by.
            </param>
            <returns> Array of sort objects, one for each document.
            </returns>
            <throws>  IOException  If any error occurs. </throws>
            <deprecated> Please implement {@link
            FieldComparatorSource} directly, instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetCacheEntries">
            <summary> EXPERT: Generates an array of CacheEntry objects representing all items 
            currently in the FieldCache.
            <p/>
            NOTE: These CacheEntry objects maintain a strong refrence to the 
            Cached Values.  Maintaining refrences to a CacheEntry the IndexReader 
            associated with it has garbage collected will prevent the Value itself
            from being garbage collected when the Cache drops the WeakRefrence.
            <p/>
            <p/>
            <b>EXPERIMENTAL API:</b> This API is considered extremely advanced 
            and experimental.  It may be removed or altered w/o warning in future 
            releases 
            of Lucene.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.PurgeAllCaches">
            <summary> <p/>
            EXPERT: Instructs the FieldCache to forcibly expunge all entries 
            from the underlying caches.  This is intended only to be used for 
            test methods as a way to ensure a known base state of the Cache 
            (with out needing to rely on GC to free WeakReferences).  
            It should not be relied on for "Cache maintenance" in general 
            application code.
            <p/>
            <p/>
            <b>EXPERIMENTAL API:</b> This API is considered extremely advanced 
            and experimental.  It may be removed or altered w/o warning in future 
            releases 
            of Lucene.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.Purge(Lucene.Net.Index.IndexReader)">
            <summary>
            Expert: drops all cache entries associated with this
            reader.  NOTE: this reader must precisely match the
            reader that the cache entry is keyed on. If you pass a
            top-level reader, it usually will have no effect as
            Lucene now caches at the segment reader level.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.SetInfoStream(System.IO.StreamWriter)">
            <summary> If non-null, FieldCacheImpl will warn whenever
            entries are created that are not sane according to
            {@link Lucene.Net.Util.FieldCacheSanityChecker}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCache.GetInfoStream">
            <summary>counterpart of {@link #SetInfoStream(PrintStream)} </summary>
        </member>
        <member name="T:Lucene.Net.Search.ComplexExplanation">
            <summary>Expert: Describes the score computation for document and query, and
            can distinguish a match independent of a positive value. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Explanation">
            <summary>Expert: Describes the score computation for document and query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.IsMatch">
            <summary> Indicates whether or not this Explanation models a good match.
            
            <p/>
            By default, an Explanation represents a "match" if the value is positive.
            <p/>
            </summary>
            <seealso cref="!:getValue">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.GetValue">
            <summary>The value assigned to this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.SetValue(System.Single)">
            <summary>Sets the value assigned to this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.GetDescription">
            <summary>A description of this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.SetDescription(System.String)">
            <summary>Sets the description of this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.GetSummary">
            <summary> A short one line summary which should contain all high level
            information about this Explanation, without the "Details"
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.GetDetails">
            <summary>The sub-nodes of this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.AddDetail(Lucene.Net.Search.Explanation)">
            <summary>Adds a sub-node to this explanation node. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.ToString">
            <summary>Render an explanation as text. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.ToHtml">
            <summary>Render an explanation as HTML. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Explanation.IDFExplanation">
            <summary> Small Util class used to pass both an idf factor as well as an
            explanation for that factor.
            
            This class will likely be held on a {@link Weight}, so be aware 
            before storing any large or un-serializable fields.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.IDFExplanation.GetIdf">
            <returns> the idf factor
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Explanation.IDFExplanation.Explain">
            <summary> This should be calculated lazily if possible.
            
            </summary>
            <returns> the explanation for the idf factor.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ComplexExplanation.GetMatch">
            <summary> The match status of this explanation node.</summary>
            <returns> May be null if match status is unknown
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ComplexExplanation.SetMatch(System.Nullable{System.Boolean})">
            <summary> Sets the match status assigned to this explanation node.</summary>
            <param name="match">May be null if match status is unknown
            </param>
        </member>
        <member name="M:Lucene.Net.Search.ComplexExplanation.IsMatch">
            <summary> Indicates whether or not this Explanation models a good match.
            
            <p/>
            If the match status is explicitly set (i.e.: not null) this method
            uses it; otherwise it defers to the superclass.
            <p/>
            </summary>
            <seealso cref="!:getMatch">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermDocs.Read(System.Int32[],System.Int32[])">
            <summary>Optimized implementation. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermDocs.SkipProx(System.Int64,System.Int32)">
            <summary>Overridden by SegmentTermPositions to skip in prox stream. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermDocs.SkipTo(System.Int32)">
            <summary>Optimized implementation. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermPositions.SkipProx(System.Int64,System.Int32)">
            <summary>Called by super.skipTo(). </summary>
        </member>
        <member name="T:Lucene.Net.Index.RawPostingList">
            <summary>This is the base class for an in-memory posting list,
            keyed by a Token.  {@link TermsHash} maintains a hash
            table holding one instance of this per unique Token.
            Consumers of TermsHash ({@link TermsHashConsumer}) must
            subclass this class with its own concrete class.
            FreqProxTermsWriter.PostingList is a private inner class used 
            for the freq/prox postings, and 
            TermVectorsTermsWriter.PostingList is a private inner class
            used to hold TermVectors postings. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexModifier">
            <summary> <p/>[Note that as of <b>2.1</b>, all but one of the
            methods in this class are available via {@link
            IndexWriter}.  The one method that is not available is
            {@link #DeleteDocument(int)}.]<p/>
            
            A class to modify an index, i.e. to delete and add documents. This
            class hides {@link IndexReader} and {@link IndexWriter} so that you
            do not need to care about implementation details such as that adding
            documents is done via IndexWriter and deletion is done via IndexReader.
            
            <p/>Note that you cannot create more than one <code>IndexModifier</code> object
            on the same directory at the same time.
            
            <p/>Example usage:
            
            <!-- ======================================================== -->
            <!-- = Java Sourcecode to HTML automatically converted code = -->
            <!-- =   Java2Html Converter V4.1 2004 by Markus Gebhard  markus@jave.de   = -->
            <!-- =     Further information: http://www.java2html.de     = -->
            <div align="left" class="java">
            <table border="0" cellpadding="3" cellspacing="0" bgcolor="#ffffff">
            <tr>
            <!-- start source code -->
            <td nowrap="nowrap" valign="top" align="left">
            <code>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">Analyzer&#160;analyzer&#160;=&#160;</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">StandardAnalyzer</font><font color="#000000">()</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#3f7f5f">//&#160;create&#160;an&#160;index&#160;in&#160;/tmp/index,&#160;overwriting&#160;an&#160;existing&#160;one:</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">IndexModifier&#160;indexModifier&#160;=&#160;</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">IndexModifier</font><font color="#000000">(</font><font color="#2a00ff">&#34;/tmp/index&#34;</font><font color="#000000">,&#160;analyzer,&#160;</font><font color="#7f0055"><b>true</b></font><font color="#000000">)</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">Document&#160;doc&#160;=&#160;</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">Document</font><font color="#000000">()</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">doc.add</font><font color="#000000">(</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">Field</font><font color="#000000">(</font><font color="#2a00ff">&#34;id&#34;</font><font color="#000000">,&#160;</font><font color="#2a00ff">&#34;1&#34;</font><font color="#000000">,&#160;Field.Store.YES,&#160;Field.Index.NOT_ANALYZED</font><font color="#000000">))</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">doc.add</font><font color="#000000">(</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">Field</font><font color="#000000">(</font><font color="#2a00ff">&#34;body&#34;</font><font color="#000000">,&#160;</font><font color="#2a00ff">&#34;a&#160;simple&#160;test&#34;</font><font color="#000000">,&#160;Field.Store.YES,&#160;Field.Index.ANALYZED</font><font color="#000000">))</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">indexModifier.addDocument</font><font color="#000000">(</font><font color="#000000">doc</font><font color="#000000">)</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#7f0055"><b>int&#160;</b></font><font color="#000000">deleted&#160;=&#160;indexModifier.delete</font><font color="#000000">(</font><font color="#7f0055"><b>new&#160;</b></font><font color="#000000">Term</font><font color="#000000">(</font><font color="#2a00ff">&#34;id&#34;</font><font color="#000000">,&#160;</font><font color="#2a00ff">&#34;1&#34;</font><font color="#000000">))</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">System.out.println</font><font color="#000000">(</font><font color="#2a00ff">&#34;Deleted&#160;&#34;&#160;</font><font color="#000000">+&#160;deleted&#160;+&#160;</font><font color="#2a00ff">&#34;&#160;document&#34;</font><font color="#000000">)</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">indexModifier.flush</font><font color="#000000">()</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">System.out.println</font><font color="#000000">(</font><font color="#000000">indexModifier.docCount</font><font color="#000000">()&#160;</font><font color="#000000">+&#160;</font><font color="#2a00ff">&#34;&#160;docs&#160;in&#160;index&#34;</font><font color="#000000">)</font><font color="#000000">;</font><br/>
            <font color="#ffffff">&#160;&#160;&#160;&#160;</font><font color="#000000">indexModifier.close</font><font color="#000000">()</font><font color="#000000">;</font></code>
            </td>
            <!-- end source code -->
            </tr>
            </table>
            </div>
            <!-- =       END of automatically generated HTML code       = -->
            <!-- ======================================================== -->
            
            <p/>Not all methods of IndexReader and IndexWriter are offered by this
            class. If you need access to additional methods, either use those classes
            directly or implement your own class that extends <code>IndexModifier</code>.
            
            <p/>Although an instance of this class can be used from more than one
            thread, you will not get the best performance. You might want to use
            IndexReader and IndexWriter directly for that (but you will need to
            care about synchronization yourself then).
            
            <p/>While you can freely mix calls to add() and delete() using this class,
            you should batch you calls for best performance. For example, if you
            want to update 20 documents, you should first delete all those documents,
            then add all the new documents.
            
            </summary>
            <deprecated> Please use {@link IndexWriter} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Open an index with write access.
            
            </summary>
            <param name="directory">the index directory
            </param>
            <param name="analyzer">the analyzer to use for adding new documents
            </param>
            <param name="create"><code>true</code> to create the index or overwrite the existing one;
            <code>false</code> to append to the existing index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.#ctor(System.String,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Open an index with write access.
            
            </summary>
            <param name="dirName">the index directory
            </param>
            <param name="analyzer">the analyzer to use for adding new documents
            </param>
            <param name="create"><code>true</code> to create the index or overwrite the existing one;
            <code>false</code> to append to the existing index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.#ctor(System.IO.FileInfo,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Open an index with write access.
            
            </summary>
            <param name="file">the index directory
            </param>
            <param name="analyzer">the analyzer to use for adding new documents
            </param>
            <param name="create"><code>true</code> to create the index or overwrite the existing one;
            <code>false</code> to append to the existing index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.Init(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Initialize an IndexWriter.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.AssureOpen">
            <summary> Throw an IllegalStateException if the index is closed.</summary>
            <throws>  IllegalStateException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.CreateIndexWriter">
            <summary> Close the IndexReader and open an IndexWriter.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.CreateIndexReader">
            <summary> Close the IndexWriter and open an IndexReader.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.Flush">
            <summary> Make sure all changes are written to disk.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.AddDocument(Lucene.Net.Documents.Document,Lucene.Net.Analysis.Analyzer)">
            <summary> Adds a document to this index, using the provided analyzer instead of the
            one specific in the constructor.  If the document contains more than
            {@link #SetMaxFieldLength(int)} terms for a given field, the remainder are
            discarded.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.AddDocument(Lucene.Net.Documents.Document,Lucene.Net.Analysis.Analyzer)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.AddDocument(Lucene.Net.Documents.Document)">
            <summary> Adds a document to this index.  If the document contains more than
            {@link #SetMaxFieldLength(int)} terms for a given field, the remainder are
            discarded.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.AddDocument(Lucene.Net.Documents.Document)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.DeleteDocuments(Lucene.Net.Index.Term)">
            <summary> Deletes all documents containing <code>term</code>.
            This is useful if one uses a document field to hold a unique ID string for
            the document.  Then to delete such a document, one merely constructs a
            term with the appropriate field and the unique ID string as its text and
            passes it to this method.  Returns the number of documents deleted.
            </summary>
            <returns> the number of documents deleted
            </returns>
            <seealso cref="M:Lucene.Net.Index.IndexReader.DeleteDocuments(Lucene.Net.Index.Term)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.DeleteDocument(System.Int32)">
            <summary> Deletes the document numbered <code>docNum</code>.</summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.DeleteDocument(System.Int32)">
            </seealso>
            <throws>  StaleReaderException if the index has changed </throws>
            <summary>  since this reader was opened
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.DocCount">
            <summary> Returns the number of documents currently in this
            index.  If the writer is currently open, this returns
            {@link IndexWriter#DocCount()}, else {@link
            IndexReader#NumDocs()}.  But, note that {@link
            IndexWriter#DocCount()} does not take deletions into
            account, unlike {@link IndexReader#numDocs}.
            </summary>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.Optimize">
            <summary> Merges all segments together into a single segment, optimizing an index
            for search.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.Optimize">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.SetInfoStream(System.IO.StreamWriter)">
            <summary> If non-null, information about merges and a message when
            {@link #GetMaxFieldLength()} is reached will be printed to this.
            <p/>Example: <tt>index.setInfoStream(System.err);</tt>
            </summary>
            <seealso cref="!:IndexWriter.SetInfoStream(PrintStream)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.GetInfoStream">
            <seealso cref="!:IndexModifier.SetInfoStream(PrintStream)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.SetUseCompoundFile(System.Boolean)">
            <summary> Setting to turn on usage of a compound file. When on, multiple files
            for each segment are merged into a single file once the segment creation
            is finished. This is done regardless of what directory is in use.
            </summary>
            <seealso cref="!:IndexWriter.SetUseCompoundFile(boolean)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.GetUseCompoundFile">
            <seealso cref="!:IndexModifier.SetUseCompoundFile(boolean)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.SetMaxFieldLength(System.Int32)">
            <summary> The maximum number of terms that will be indexed for a single field in a
            document.  This limits the amount of memory required for indexing, so that
            collections with very large files will not crash the indexing process by
            running out of memory.<p/>
            Note that this effectively truncates large documents, excluding from the
            index terms that occur further in the document.  If you know your source
            documents are large, be sure to set this value high enough to accommodate
            the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
            is your memory, but you should anticipate an OutOfMemoryError.<p/>
            By default, no more than 10,000 terms will be indexed for a field.
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetMaxFieldLength(System.Int32)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.GetMaxFieldLength">
            <seealso cref="M:Lucene.Net.Index.IndexModifier.SetMaxFieldLength(System.Int32)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.SetMaxBufferedDocs(System.Int32)">
            <summary> Determines the minimal number of documents required before the buffered
            in-memory documents are merging and a new Segment is created.
            Since Documents are merged in a {@link Lucene.Net.Store.RAMDirectory},
            large value gives faster indexing.  At the same time, mergeFactor limits
            the number of files open in a FSDirectory.
            
            <p/>The default value is 10.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetMaxBufferedDocs(System.Int32)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
            <throws>  IllegalArgumentException if maxBufferedDocs is smaller than 2 </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.GetMaxBufferedDocs">
            <seealso cref="M:Lucene.Net.Index.IndexModifier.SetMaxBufferedDocs(System.Int32)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.SetMergeFactor(System.Int32)">
            <summary> Determines how often segment indices are merged by addDocument().  With
            smaller values, less RAM is used while indexing, and searches on
            unoptimized indices are faster, but indexing speed is slower.  With larger
            values, more RAM is used during indexing, and while searches on unoptimized
            indices are slower, indexing is faster.  Thus larger values (&gt; 10) are best
            for batch index creation, and smaller values (&lt; 10) for indices that are
            interactively maintained.
            <p/>This must never be less than 2.  The default value is 10.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetMergeFactor(System.Int32)">
            </seealso>
            <throws>  IllegalStateException if the index is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.GetMergeFactor">
            <seealso cref="M:Lucene.Net.Index.IndexModifier.SetMergeFactor(System.Int32)">
            </seealso>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexModifier.Close">
            <summary> Close this index, writing all pending changes to disk.
            
            </summary>
            <throws>  IllegalStateException if the index has been closed before already </throws>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="T:Lucene.Net.Index.DocumentsWriterThreadState">
            <summary>Used by DocumentsWriter to maintain per-thread state.
            We keep a separate Posting hash and other state for each
            thread and then merge postings hashes from all threads
            when writing the segment. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TeeTokenFilter">
            <summary> Works in conjunction with the SinkTokenizer to provide the ability to set aside tokens
            that have already been analyzed.  This is useful in situations where multiple fields share
            many common analysis steps and then go their separate ways.
            <p/>
            It is also useful for doing things like entity extraction or proper noun analysis as
            part of the analysis workflow and saving off those tokens for use in another field.
            
            <pre>
            SinkTokenizer sink1 = new SinkTokenizer();
            SinkTokenizer sink2 = new SinkTokenizer();
            TokenStream source1 = new TeeTokenFilter(new TeeTokenFilter(new WhitespaceTokenizer(reader1), sink1), sink2);
            TokenStream source2 = new TeeTokenFilter(new TeeTokenFilter(new WhitespaceTokenizer(reader2), sink1), sink2);
            TokenStream final1 = new LowerCaseFilter(source1);
            TokenStream final2 = source2;
            TokenStream final3 = new EntityDetect(sink1);
            TokenStream final4 = new URLDetect(sink2);
            d.add(new Field("f1", final1));
            d.add(new Field("f2", final2));
            d.add(new Field("f3", final3));
            d.add(new Field("f4", final4));
            </pre>
            In this example, <code>sink1</code> and <code>sink2</code> will both get tokens from both
            <code>reader1</code> and <code>reader2</code> after whitespace tokenizer
            and now we can further wrap any of these in extra analysis, and more "sources" can be inserted if desired.
            It is important, that tees are consumed before sinks (in the above example, the field names must be
            less the sink's field names).
            Note, the EntityDetect and URLDetect TokenStreams are for the example and do not currently exist in Lucene
            <p/>
            
            See <a href="http://issues.apache.org/jira/browse/LUCENE-1058">LUCENE-1058</a>.
            <p/>
            WARNING: {@link TeeTokenFilter} and {@link SinkTokenizer} only work with the old TokenStream API.
            If you switch to the new API, you need to use {@link TeeSinkTokenFilter} instead, which offers 
            the same functionality.
            </summary>
            <seealso cref="T:Lucene.Net.Analysis.SinkTokenizer">
            </seealso>
            <deprecated> Use {@link TeeSinkTokenFilter} instead
            
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Analysis.LowerCaseTokenizer">
            <summary> LowerCaseTokenizer performs the function of LetterTokenizer
            and LowerCaseFilter together.  It divides text at non-letters and converts
            them to lower case.  While it is functionally equivalent to the combination
            of LetterTokenizer and LowerCaseFilter, there is a performance advantage
            to doing the two tasks at once, hence this (redundant) implementation.
            <p/>
            Note: this does a decent job for most European languages, but does a terrible
            job for some Asian languages, where words are not separated by spaces.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.LetterTokenizer">
            <summary>A LetterTokenizer is a tokenizer that divides text at non-letters.  That's
            to say, it defines tokens as maximal strings of adjacent letters, as defined
            by java.lang.Character.isLetter() predicate.
            Note: this does a decent job for most European languages, but does a terrible
            job for some Asian languages, where words are not separated by spaces. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CharTokenizer">
            <summary>An abstract base class for simple, character-oriented tokenizers.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenizer">
            <summary> A Tokenizer is a TokenStream whose input is a Reader.
            <p/>
            This is an abstract class; subclasses must override {@link #IncrementToken()}
            <p/>
            NOTE: Subclasses overriding {@link #next(Token)} must call
            {@link AttributeSource#ClearAttributes()} before setting attributes.
            Subclasses overriding {@link #IncrementToken()} must call
            {@link Token#Clear()} before setting Token attributes.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Tokenizer.input">
            <summary>The text source for this Tokenizer. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor">
            <summary>Construct a tokenizer with null input. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor(System.IO.TextReader)">
            <summary>Construct a token stream processing the given input. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory)">
            <summary>Construct a tokenizer with null input using the given AttributeFactory. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader)">
            <summary>Construct a token stream processing the given input using the given AttributeFactory. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor(Lucene.Net.Util.AttributeSource)">
            <summary>Construct a token stream processing the given input using the given AttributeSource. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader)">
            <summary>Construct a token stream processing the given input using the given AttributeSource. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.Close">
            <summary>By default, closes the input Reader. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.CorrectOffset(System.Int32)">
            <summary>Return the corrected offset. If {@link #input} is a {@link CharStream} subclass
            this method calls {@link CharStream#CorrectOffset}, else returns <code>currentOff</code>.
            </summary>
            <param name="currentOff">offset as seen in the output
            </param>
            <returns> corrected offset based on the input
            </returns>
            <seealso cref="M:Lucene.Net.Analysis.CharStream.CorrectOffset(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenizer.Reset(System.IO.TextReader)">
            <summary>Expert: Reset the tokenizer to a new reader.  Typically, an
            analyzer (in its reusableTokenStream method) will use
            this to re-use a previously created tokenizer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharTokenizer.IsTokenChar(System.Char)">
            <summary>Returns true iff a character should be included in a token.  This
            tokenizer generates as tokens adjacent sequences of characters which
            satisfy this predicate.  Characters for which this is false are used to
            define token boundaries and are not included in tokens. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharTokenizer.Normalize(System.Char)">
            <summary>Called on each token character to normalize it before it is added to the
            token.  The default implementation does nothing.  Subclasses may use this
            to, e.g., lowercase tokens. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharTokenizer.Next(Lucene.Net.Analysis.Token)">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.CharTokenizer.Next">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.LetterTokenizer.#ctor(System.IO.TextReader)">
            <summary>Construct a new LetterTokenizer. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LetterTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader)">
            <summary>Construct a new LetterTokenizer using a given {@link AttributeSource}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LetterTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader)">
            <summary>Construct a new LetterTokenizer using a given {@link Lucene.Net.Util.AttributeSource.AttributeFactory}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LetterTokenizer.IsTokenChar(System.Char)">
            <summary>Collects only characters which satisfy
            {@link Character#isLetter(char)}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LowerCaseTokenizer.#ctor(System.IO.TextReader)">
            <summary>Construct a new LowerCaseTokenizer. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LowerCaseTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader)">
            <summary>Construct a new LowerCaseTokenizer using a given {@link AttributeSource}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LowerCaseTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader)">
            <summary>Construct a new LowerCaseTokenizer using a given {@link Lucene.Net.Util.AttributeSource.AttributeFactory}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LowerCaseTokenizer.Normalize(System.Char)">
            <summary>Converts char to lower case
            {@link Character#toLowerCase(char)}.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.RAMInputStream">
            <summary> A memory-resident {@link IndexInput} implementation.
            
            </summary>
            <version>  $Id: RAMInputStream.java 632120 2008-02-28 21:13:59Z mikemccand $
            </version>
        </member>
        <member name="T:Lucene.Net.Search.SortComparator">
            <summary> Abstract base class for sorting hits returned by a Query.
            
            <p/>
            This class should only be used if the other SortField types (SCORE, DOC,
            STRING, INT, FLOAT) do not provide an adequate sorting. It maintains an
            internal cache of values which could be quite large. The cache is an array of
            Comparable, one for each document in the index. There is a distinct
            Comparable for each unique term in the field - if some documents have the
            same term in the field, the cache array will have entries which reference the
            same Comparable.
            
            This class will be used as part of a key to a FieldCache value. You must
            implement hashCode and equals to avoid an explosion in RAM usage if you use
            instances that are not the same instance. If you are searching using the
            Remote contrib, the same instance of this class on the client will be a new
            instance on every call to the server, so hashCode/equals is very important in
            that situation.
            
            <p/>
            Created: Apr 21, 2004 5:08:38 PM
            
            
            </summary>
            <version>  $Id: SortComparator.java 800119 2009-08-02 17:59:21Z markrmiller $
            </version>
            <since> 1.4
            </since>
            <deprecated> Please use {@link FieldComparatorSource} instead.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.SortComparatorSource">
            <summary> Expert: returns a comparator for sorting ScoreDocs.
            
            <p/>
            Created: Apr 21, 2004 3:49:28 PM
            
            This class will be used as part of a key to a FieldCache value. You must
            implement hashCode and equals to avoid an explosion in RAM usage if you use
            instances that are not the same instance. If you are searching using the
            Remote contrib, the same instance of this class on the client will be a new
            instance on every call to the server, so hashCode/equals is very important in
            that situation.
            
            </summary>
            <version>  $Id: SortComparatorSource.java 747019 2009-02-23 13:59:50Z
            mikemccand $
            </version>
            <since> 1.4
            </since>
            <deprecated> Please use {@link FieldComparatorSource} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortComparatorSource.NewComparator(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Creates a comparator for the field in the given index.</summary>
            <param name="reader">Index to create comparator for.
            </param>
            <param name="fieldname"> Name of the field to create comparator for.
            </param>
            <returns> Comparator of ScoreDoc objects.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.SortComparator.GetComparable(System.String)">
            <summary> Returns an object which, when sorted according to natural order,
            will order the Term values in the correct order.
            <p/>For example, if the Terms contained integer values, this method
            would return <code>new Integer(termtext)</code>.  Note that this
            might not always be the most efficient implementation - for this
            particular example, a better implementation might be to make a
            ScoreDocLookupComparator that uses an internal lookup table of int.
            </summary>
            <param name="termtext">The textual value of the term.
            </param>
            <returns> An object representing <code>termtext</code> that sorts according to the natural order of <code>termtext</code>.
            </returns>
            <seealso cref="!:Comparable">
            </seealso>
            <seealso cref="T:Lucene.Net.Search.ScoreDocComparator">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.ScoreDocComparator.Compare(Lucene.Net.Search.ScoreDoc,Lucene.Net.Search.ScoreDoc)">
            <summary> Compares two ScoreDoc objects and returns a result indicating their
            sort order.
            </summary>
            <param name="i">First ScoreDoc
            </param>
            <param name="j">Second ScoreDoc
            </param>
            <returns> a negative integer if <code>i</code> should come before <code>j</code><br/>
            a positive integer if <code>i</code> should come after <code>j</code><br/>
            <code>0</code> if they are equal
            </returns>
            <seealso cref="!:java.util.Comparator">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.ScoreDocComparator.SortValue(Lucene.Net.Search.ScoreDoc)">
            <summary> Returns the value used to sort the given document.  The
            object returned must implement the java.io.Serializable
            interface.  This is used by multisearchers to determine how
            to collate results from their searchers.
            </summary>
            <seealso cref="T:Lucene.Net.Search.FieldDoc">
            </seealso>
            <param name="i">Document
            </param>
            <returns> Serializable object
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ScoreDocComparator.SortType">
            <summary> Returns the type of sort.  Should return <code>SortField.SCORE</code>,
            <code>SortField.DOC</code>, <code>SortField.STRING</code>,
            <code>SortField.INTEGER</code>, <code>SortField.FLOAT</code> or
            <code>SortField.CUSTOM</code>.  It is not valid to return
            <code>SortField.AUTO</code>.
            This is used by multisearchers to determine how to collate results
            from their searchers.
            </summary>
            <returns> One of the constants in SortField.
            </returns>
            <seealso cref="T:Lucene.Net.Search.SortField">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.ScoreCachingWrappingScorer">
            <summary> A {@link Scorer} which wraps another scorer and caches the score of the
            current document. Successive calls to {@link #Score()} will return the same
            result and will not invoke the wrapped Scorer's score() method, unless the
            current document has changed.<br/>
            This class might be useful due to the changes done to the {@link Collector}
            interface, in which the score is not computed for a document by default, only
            if the collector requests it. Some collectors may need to use the score in
            several places, however all they have in hand is a {@link Scorer} object, and
            might end up computing the score of a document more than once.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ScoreCachingWrappingScorer.#ctor(Lucene.Net.Search.Scorer)">
            <summary>Creates a new instance by wrapping the given scorer. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ScoreCachingWrappingScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ScoreCachingWrappingScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ScoreCachingWrappingScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.HitCollectorWrapper">
            <summary> Wrapper for ({@link HitCollector}) implementations, which simply re-bases the
            incoming docID before calling {@link HitCollector#collect}.
            
            </summary>
            <deprecated> Please migrate custom HitCollectors to the new {@link Collector}
            class. This class will be removed when {@link HitCollector} is
            removed.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.Function.IntFieldSource">
            <summary> Expert: obtains int field values from the 
            {@link Lucene.Net.Search.FieldCache FieldCache}
            using <code>getInts()</code> and makes those values 
            available as other numeric types, casting as needed.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.Function.FieldCacheSource"> for requirements
            on the field.
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.IntFieldSource.#ctor(System.String)">
            <summary> Create a cached int field source with default string-to-int parser. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.IntFieldSource.#ctor(System.String,Lucene.Net.Search.IntParser)">
            <summary> Create a cached int field source with a specific string-to-int parser. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldSortedHitQueue">
            <summary> Expert: A hit queue for sorting by hits by terms in more than one field.
            Uses <code>FieldCache.DEFAULT</code> for maintaining internal term lookup tables.
            
            <p/>Created: Dec 8, 2003 12:56:03 PM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: FieldSortedHitQueue.java 803676 2009-08-12 19:31:38Z hossman $
            </version>
            <seealso cref="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            </seealso>
            <seealso cref="T:Lucene.Net.Search.FieldCache">
            </seealso>
            <deprecated> see {@link FieldValueHitQueue}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Search.SortField[],System.Int32)">
            <summary> Creates a hit queue sorted by the given list of fields.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fields">Fieldable names, in priority order (highest priority first).  Cannot be <code>null</code> or empty.
            </param>
            <param name="size"> The number of hits to retain.  Must be greater than zero.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="F:Lucene.Net.Search.FieldSortedHitQueue.comparators">
            <summary>Stores a comparator corresponding to each field being sorted by </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldSortedHitQueue.fields">
            <summary>Stores the sort criteria being used. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldSortedHitQueue.maxscore">
            <summary>Stores the maximum score value encountered, needed for normalizing. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.GetMaxScore">
            <summary>returns the maximum score encountered by elements inserted via insert()</summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.LessThan(System.Object,System.Object)">
            <summary> Returns whether <code>a</code> is less relevant than <code>b</code>.</summary>
            <param name="a">ScoreDoc
            </param>
            <param name="b">ScoreDoc
            </param>
            <returns> <code>true</code> if document <code>a</code> should be sorted after document <code>b</code>.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.FillFields(Lucene.Net.Search.FieldDoc)">
            <summary> Given a FieldDoc object, stores the values used
            to sort the given document.  These values are not the raw
            values out of the index, but the internal representation
            of them.  This is so the given search hit can be collated
            by a MultiSearcher with other search hits.
            </summary>
            <param name="doc"> The FieldDoc to store sort values into.
            </param>
            <returns>  The same FieldDoc passed in.
            </returns>
            <seealso cref="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.GetFields">
            <summary>Returns the SortFields being used by this hit queue. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldSortedHitQueue.Comparators">
            <summary>Internal cache of comparators. Similar to FieldCache, only
            caches comparators instead of term values. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorByte(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ByteParser)">
            <summary> Returns a comparator for sorting hits according to a field containing bytes.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing integer values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorShort(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ShortParser)">
            <summary> Returns a comparator for sorting hits according to a field containing shorts.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing integer values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorInt(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.IntParser)">
            <summary> Returns a comparator for sorting hits according to a field containing integers.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing integer values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorLong(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.LongParser)">
            <summary> Returns a comparator for sorting hits according to a field containing integers.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing integer values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorFloat(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.FloatParser)">
            <summary> Returns a comparator for sorting hits according to a field containing floats.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing float values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorDouble(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.DoubleParser)">
            <summary> Returns a comparator for sorting hits according to a field containing doubles.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing float values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorString(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Returns a comparator for sorting hits according to a field containing strings.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing string values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.comparatorStringLocale(Lucene.Net.Index.IndexReader,System.String,System.Globalization.CultureInfo)">
            <summary> Returns a comparator for sorting hits according to a field containing strings.</summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing string values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldSortedHitQueue.ComparatorAuto(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Returns a comparator for sorting hits according to values in the given field.
            The terms in the field are looked at to determine whether they contain integers,
            floats or strings.  Once the type is determined, one of the other static methods
            in this class is called to get the comparator.
            </summary>
            <param name="reader"> Index to use.
            </param>
            <param name="fieldname"> Fieldable containing values.
            </param>
            <returns>  Comparator for sorting hits.
            </returns>
            <throws>  IOException If an error occurs reading the index. </throws>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.Cache">
            <summary>Expert: Internal cache. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl">
            <summary> Expert: The default cache implementation, storing all values in memory.
            A WeakHashMap is used for storage.
            
            <p/>Created: May 19, 2004 4:40:36 PM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: FieldCacheImpl.java 807572 2009-08-25 11:44:45Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Search.ExtendedFieldCache_old.ExtendedFieldCache.GetLongs(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.LongParser)">
            <deprecated> Will be removed in 3.0, this is for binary compatibility only 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ExtendedFieldCache_old.ExtendedFieldCache.GetDoubles(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.DoubleParser)">
            <deprecated> Will be removed in 3.0, this is for binary compatibility only 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.GetLongs(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ExtendedFieldCache_old.LongParser)">
            <deprecated> Will be removed in 3.0, this is for binary compatibility only 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.GetDoubles(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.ExtendedFieldCache_old.DoubleParser)">
            <deprecated> Will be removed in 3.0, this is for binary compatibility only 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.GetAuto(Lucene.Net.Index.IndexReader,System.String)">
            <summary>The pattern used to detect float values in a field </summary>
            <summary> removed for java 1.3 compatibility
            protected static final Object pFloats = Pattern.compile ("[0-9+\\-\\.eEfFdD]+");
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.GetCustom(Lucene.Net.Index.IndexReader,System.String,Lucene.Net.Search.SortComparator)">
            <deprecated> 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.FieldCacheImpl.CacheEntryImpl.sortFieldType">
            <deprecated> Only needed because of Entry (ab)use by 
            FieldSortedHitQueue, remove when FieldSortedHitQueue 
            is removed
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.FieldCacheImpl.CacheEntryImpl.locale">
            <deprecated> Only needed because of Entry (ab)use by 
            FieldSortedHitQueue, remove when FieldSortedHitQueue 
            is removed
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.CacheEntryImpl.ToString">
            <summary> Adds warning to super.toString if Local or sortFieldType were specified</summary>
            <deprecated> Only needed because of Entry (ab)use by 
            FieldSortedHitQueue, remove when FieldSortedHitQueue 
            is removed
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.StopFillCacheException">
            <summary> Hack: When thrown from a Parser (NUMERIC_UTILS_* ones), this stops
            processing terms and returns the current FieldCache
            array.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.Cache">
            <summary>Expert: Internal cache. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Cache.Purge(Lucene.Net.Index.IndexReader)">
            Remove this reader from the cache, if present. 
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.Entry">
            <summary>Expert: Every composite-key in the internal cache is of this type. </summary>
        </member>
        <member name="F:Lucene.Net.Search.FieldCacheImpl.Entry.type">
            <deprecated> Only (ab)used by FieldSortedHitQueue, 
            remove when FieldSortedHitQueue is removed
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.FieldCacheImpl.Entry.locale">
            <deprecated> Only (ab)used by FieldSortedHitQueue, 
            remove when FieldSortedHitQueue is removed
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Entry.#ctor(System.String,System.Int32,System.Globalization.CultureInfo)">
            <deprecated> Only (ab)used by FieldSortedHitQueue, 
            remove when FieldSortedHitQueue is removed
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Entry.#ctor(System.String,System.Object)">
            <summary>Creates one of these objects for a custom comparator/parser. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Entry.#ctor(System.String,System.Int32,Lucene.Net.Search.Parser)">
            <deprecated> Only (ab)used by FieldSortedHitQueue, 
            remove when FieldSortedHitQueue is removed
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Entry.Equals(System.Object)">
            <summary>Two of these are equal iff they reference the same field and type. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheImpl.Entry.GetHashCode">
            <summary>Composes a hashcode based on the field and type. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.AutoCache">
            <deprecated> Please specify the exact type, instead.
            Especially, guessing does <b>not</b> work with the new
            {@link NumericField} type.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheImpl.CustomCache">
            <deprecated> 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator">
            <summary> Expert: a FieldComparator compares hits so as to determine their
            sort order when collecting the top results with {@link
            TopFieldCollector}.  The concrete public FieldComparator
            classes here correspond to the SortField types.
            
            <p/>This API is designed to achieve high performance
            sorting, by exposing a tight interaction with {@link
            FieldValueHitQueue} as it visits hits.  Whenever a hit is
            competitive, it's enrolled into a virtual slot, which is
            an int ranging from 0 to numHits-1.  The {@link
            FieldComparator} is made aware of segment transitions
            during searching in case any internal state it's tracking
            needs to be recomputed during these transitions.<p/>
            
            <p/>A comparator must define these functions:<p/>
            
            <ul>
            
            <li> {@link #compare} Compare a hit at 'slot a'
            with hit 'slot b'.</li>
            
            <li> {@link #setBottom} This method is called by
            {@link FieldValueHitQueue} to notify the
            FieldComparator of the current weakest ("bottom")
            slot.  Note that this slot may not hold the weakest
            value according to your comparator, in cases where
            your comparator is not the primary one (ie, is only
            used to break ties from the comparators before it).</li>
            
            <li> {@link #compareBottom} Compare a new hit (docID)
            against the "weakest" (bottom) entry in the queue.</li>
            
            <li> {@link #copy} Installs a new hit into the
            priority queue.  The {@link FieldValueHitQueue}
            calls this method when a new hit is competitive.</li>
            
            <li> {@link #setNextReader} Invoked
            when the search is switching to the next segment.
            You may need to update internal state of the
            comparator, for example retrieving new values from
            the {@link FieldCache}.</li>
            
            <li> {@link #value} Return the sort value stored in
            the specified slot.  This is only called at the end
            of the search, in order to populate {@link
            FieldDoc#fields} when returning the top results.</li>
            </ul>
            
            <b>NOTE:</b> This API is experimental and might change in
            incompatible ways in the next release.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.Compare(System.Int32,System.Int32)">
            <summary> Compare hit at slot1 with hit at slot2.
            
            </summary>
            <param name="slot1">first slot to compare
            </param>
            <param name="slot2">second slot to compare
            </param>
            <returns> any N &lt; 0 if slot2's value is sorted after
            slot1, any N > 0 if the slot2's value is sorted before
            slot1 and 0 if they are equal
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.SetBottom(System.Int32)">
            <summary> Set the bottom slot, ie the "weakest" (sorted last)
            entry in the queue.  When {@link #compareBottom} is
            called, you should compare against this slot.  This
            will always be called before {@link #compareBottom}.
            
            </summary>
            <param name="slot">the currently weakest (sorted last) slot in the queue
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.CompareBottom(System.Int32)">
            <summary> Compare the bottom of the queue with doc.  This will
            only invoked after setBottom has been called.  This
            should return the same result as {@link
            #Compare(int,int)}} as if bottom were slot1 and the new
            document were slot 2.
            
            <p/>For a search that hits many results, this method
            will be the hotspot (invoked by far the most
            frequently).<p/>
            
            </summary>
            <param name="doc">that was hit
            </param>
            <returns> any N &lt; 0 if the doc's value is sorted after
            the bottom entry (not competitive), any N > 0 if the
            doc's value is sorted before the bottom entry and 0 if
            they are equal.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.Copy(System.Int32,System.Int32)">
            <summary> This method is called when a new hit is competitive.
            You should copy any state associated with this document
            that will be required for future comparisons, into the
            specified slot.
            
            </summary>
            <param name="slot">which slot to copy the hit to
            </param>
            <param name="doc">docID relative to current reader
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.SetNextReader(Lucene.Net.Index.IndexReader,System.Int32)">
            <summary> Set a new Reader. All doc correspond to the current Reader.
            
            </summary>
            <param name="reader">current reader
            </param>
            <param name="docBase">docBase of this reader 
            </param>
            <throws>  IOException </throws>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.SetScorer(Lucene.Net.Search.Scorer)">
            <summary>Sets the Scorer to use in case a document's score is
            needed.
            
            </summary>
            <param name="scorer">Scorer instance that you should use to
            obtain the current hit's score, if necessary. 
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparator.Value(System.Int32)">
            <summary> Return the actual value in the slot.
            
            </summary>
            <param name="slot">the value
            </param>
            <returns> value in this slot upgraded to Comparable
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.ByteComparator">
            <summary>Parses field's values as byte (using {@link
            FieldCache#getBytes} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.DocComparator">
            <summary>Sorts by ascending docID </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.DoubleComparator">
            <summary>Parses field's values as double (using {@link
            FieldCache#getDoubles} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.FloatComparator">
            <summary>Parses field's values as float (using {@link
            FieldCache#getFloats} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.IntComparator">
            <summary>Parses field's values as int (using {@link
            FieldCache#getInts} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.LongComparator">
            <summary>Parses field's values as long (using {@link
            FieldCache#getLongs} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.RelevanceComparator">
            <summary>Sorts by descending relevance.  NOTE: if you are
            sorting only by descending relevance and then
            secondarily by ascending docID, peformance is faster
            using {@link TopScoreDocCollector} directly (which {@link
            IndexSearcher#search} uses when no {@link Sort} is
            specified). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.ShortComparator">
            <summary>Parses field's values as short (using {@link
            FieldCache#getShorts} and sorts by ascending value 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.StringComparatorLocale">
            <summary>Sorts by a field's value using the Collator for a
            given Locale.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.StringOrdValComparator">
            <summary>Sorts by field's natural String sort order, using
            ordinals.  This is functionally equivalent to {@link
            StringValComparator}, but it first resolves the string
            to their relative ordinal positions (using the index
            returned by {@link FieldCache#getStringIndex}), and
            does most comparisons using the ordinals.  For medium
            to large results, this comparator will be much faster
            than {@link StringValComparator}.  For very small
            result sets it may be slower. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparator.StringValComparator">
            <summary>Sorts by field's natural String sort order.  All
            comparisons are done using String.compareTo, which is
            slow for medium to large result sets but possibly
            very fast for very small results sets. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsTermsWriterPerField.Finish">
            <summary>Called once per field per document if term vectors
            are enabled, to write the vectors to
            RAMOutputStream, which is then quickly flushed to
            the real term vectors files in the Directory. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.SnapshotDeletionPolicy">
            <summary>A {@link IndexDeletionPolicy} that wraps around any other
            {@link IndexDeletionPolicy} and adds the ability to hold and
            later release a single "snapshot" of an index.  While
            the snapshot is held, the {@link IndexWriter} will not
            remove any files associated with it even if the index is
            otherwise being actively, arbitrarily changed.  Because
            we wrap another arbitrary {@link IndexDeletionPolicy}, this
            gives you the freedom to continue using whatever {@link
            IndexDeletionPolicy} you would normally want to use with your
            index.  Note that you can re-use a single instance of
            SnapshotDeletionPolicy across multiple writers as long
            as they are against the same index Directory.  Any
            snapshot held when a writer is closed will "survive"
            when the next writer is opened.
            
            <p/><b>WARNING</b>: This API is a new and experimental and
            may suddenly change.<p/> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SnapshotDeletionPolicy.Snapshot">
            <summary>Take a snapshot of the most recent commit to the
            index.  You must call release() to free this snapshot.
            Note that while the snapshot is held, the files it
            references will not be deleted, which will consume
            additional disk space in your index. If you take a
            snapshot at a particularly bad time (say just before
            you call optimize()) then in the worst case this could
            consume an extra 1X of your total index size, until
            you release the snapshot. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SnapshotDeletionPolicy.Release">
            <summary>Release the currently held snapshot. </summary>
        </member>
        <member name="T:Lucene.Net.Index.DirectoryReader">
            <summary> An IndexReader which reads indexes with multiple segments.</summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Index.SegmentInfos,Lucene.Net.Index.IndexDeletionPolicy,System.Boolean,System.Int32)">
            <summary>Construct reading the named set of readers. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Index.SegmentInfos,Lucene.Net.Index.SegmentReader[],System.Int32[],System.Collections.IDictionary,System.Boolean,System.Boolean,System.Int32)">
            <summary>This constructor is only used for {@link #Reopen()} </summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.GetVersion">
            <summary>Version number when this IndexReader was opened. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.IsOptimized">
            <summary> Checks is the index is optimized (if it has a single segment and no deletions)</summary>
            <returns> <code>true</code> if the index is optimized; <code>false</code> otherwise
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.AcquireWriteLock">
            <summary> Tries to acquire the WriteLock on this directory. this method is only valid if this IndexReader is directory
            owner.
            
            </summary>
            <throws>  StaleReaderException  if the index has changed since this reader was opened </throws>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  Lucene.Net.Store.LockObtainFailedException </throws>
            <summary>                               if another writer has this index open (<code>write.lock</code> could not be
            obtained)
            </summary>
            <throws>  IOException           if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.DoCommit">
            <deprecated>  
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.DoCommit(System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary> Commit changes resulting from delete, undeleteAll, or setNorm operations
            <p/>
            If an exception is hit, then either no changes or all changes will have been committed to the index (transactional
            semantics).
            
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.Directory">
            <summary>Returns the directory this index resides in. </summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.GetIndexCommit">
            <summary> Expert: return the IndexCommit that this reader has opened.
            <p/>
            <p/><b>WARNING</b>: this API is new and experimental and may suddenly change.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.ListCommits(Lucene.Net.Store.Directory)">
            <seealso cref="!:Lucene.Net.Index.IndexReader.listCommits">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.DirectoryReader.MultiTermDocs.Read(System.Int32[],System.Int32[])">
            <summary>Optimized implementation. </summary>
        </member>
        <member name="T:Lucene.Net.Index.PositionBasedTermVectorMapper">
            <summary> For each Field, store position by position information.  It ignores frequency information
            <p/>
            This is not thread-safe.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.PositionBasedTermVectorMapper.currentPositions">
            <summary> A Map of Integer and TVPositionInfo</summary>
        </member>
        <member name="M:Lucene.Net.Index.PositionBasedTermVectorMapper.#ctor">
            <summary> 
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.PositionBasedTermVectorMapper.IsIgnoringPositions">
            <summary> Never ignores positions.  This mapper doesn't make much sense unless there are positions</summary>
            <returns> false
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.PositionBasedTermVectorMapper.Map(System.String,System.Int32,Lucene.Net.Index.TermVectorOffsetInfo[],System.Int32[])">
            <summary> Callback for the TermVectorReader. </summary>
            <param name="term">
            </param>
            <param name="frequency">
            </param>
            <param name="offsets">
            </param>
            <param name="positions">
            </param>
        </member>
        <member name="M:Lucene.Net.Index.PositionBasedTermVectorMapper.SetExpectations(System.String,System.Int32,System.Boolean,System.Boolean)">
            <summary> Callback mechanism used by the TermVectorReader</summary>
            <param name="field"> The field being read
            </param>
            <param name="numTerms">The number of terms in the vector
            </param>
            <param name="storeOffsets">Whether offsets are available
            </param>
            <param name="storePositions">Whether positions are available
            </param>
        </member>
        <member name="M:Lucene.Net.Index.PositionBasedTermVectorMapper.GetFieldToTerms">
            <summary> Get the mapping between fields and terms, sorted by the comparator
            
            </summary>
            <returns> A map between field names and a Map.  The sub-Map key is the position as the integer, the value is {@link Lucene.Net.Index.PositionBasedTermVectorMapper.TVPositionInfo}.
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.PositionBasedTermVectorMapper.TVPositionInfo">
            <summary> Container for a term at a position</summary>
        </member>
        <member name="P:Lucene.Net.Index.PositionBasedTermVectorMapper.TVPositionInfo.Position">
            <summary> </summary>
            <returns> The position of the term
            </returns>
        </member>
        <member name="P:Lucene.Net.Index.PositionBasedTermVectorMapper.TVPositionInfo.Terms">
            <summary> Note, there may be multiple terms at the same position</summary>
            <returns> A List of Strings
            </returns>
        </member>
        <member name="P:Lucene.Net.Index.PositionBasedTermVectorMapper.TVPositionInfo.Offsets">
            <summary> Parallel list (to {@link #getTerms()}) of TermVectorOffsetInfo objects.  There may be multiple entries since there may be multiple terms at a position</summary>
            <returns> A List of TermVectorOffsetInfo objects, if offsets are store.
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.FormatPostingsDocsConsumer">
            <summary> NOTE: this API is experimental and will likely change</summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsDocsConsumer.AddDoc(System.Int32,System.Int32)">
            <summary>Adds a new doc in this term.  If this returns null
            then we just skip consuming positions/payloads. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsDocsConsumer.Finish">
            <summary>Called when we are done adding docs to this term </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocInverterPerField">
            <summary> Holds state for inverting all occurrences of a single
            field in the document.  This class doesn't do anything
            itself; instead, it forwards the tokens produced by
            analysis to its own consumer
            (InvertedDocConsumerPerField).  It also interacts with an
            endConsumer (InvertedDocEndConsumerPerField).
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocConsumerPerThread.ProcessDocument">
            <summary>Process the document. If there is
            something for this document to be done in docID order,
            you should encapsulate that as a
            DocumentsWriter.DocWriter and return it.
            DocumentsWriter then calls finish() on this object
            when it's its turn. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.AbstractAllTermDocs">
            <summary>
            Base class for enumerating all but deleted docs.
            
            <p/>NOTE: this class is meant only to be used internally
            by Lucene; it's only public so it can be shared across
            packages.  This means the API is freely subject to
            change, and, the class could be removed entirely, in any
            Lucene release.  Use directly at your own risk! */
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.LoadFirstFieldSelector">
            <summary> Load the First field and break.
            <p/>
            See {@link FieldSelectorResult#LOAD_AND_BREAK}
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.FieldSelector">
            <summary> Similar to a {@link java.io.FileFilter}, the FieldSelector allows one to make decisions about
            what Fields get loaded on a {@link Document} by {@link Lucene.Net.Index.IndexReader#Document(int,Lucene.Net.Documents.FieldSelector)}
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.FieldSelector.Accept(System.String)">
            <summary> </summary>
            <param name="fieldName">the field to accept or reject
            </param>
            <returns> an instance of {@link FieldSelectorResult}
            if the {@link Field} named <code>fieldName</code> should be loaded.
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.WordlistLoader">
            <summary> Loader for text files that represent a list of stopwords.
            
            
            </summary>
            <version>  $Id: WordlistLoader.java 706342 2008-10-20 17:19:29Z gsingers $
            </version>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordSet(System.IO.FileInfo)">
            <summary> Loads a text file and adds every line as an entry to a HashSet (omitting
            leading and trailing whitespace). Every line of the file should contain only
            one word. The words need to be in lowercase if you make use of an
            Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
            
            </summary>
            <param name="wordfile">File containing the wordlist
            </param>
            <returns> A HashSet with the file's words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordSet(System.IO.FileInfo,System.String)">
            <summary> Loads a text file and adds every non-comment line as an entry to a HashSet (omitting
            leading and trailing whitespace). Every line of the file should contain only
            one word. The words need to be in lowercase if you make use of an
            Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
            
            </summary>
            <param name="wordfile">File containing the wordlist
            </param>
            <param name="comment">The comment string to ignore
            </param>
            <returns> A HashSet with the file's words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordSet(System.IO.TextReader)">
            <summary> Reads lines from a Reader and adds every line as an entry to a HashSet (omitting
            leading and trailing whitespace). Every line of the Reader should contain only
            one word. The words need to be in lowercase if you make use of an
            Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
            
            </summary>
            <param name="reader">Reader containing the wordlist
            </param>
            <returns> A HashSet with the reader's words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordSet(System.IO.TextReader,System.String)">
            <summary> Reads lines from a Reader and adds every non-comment line as an entry to a HashSet (omitting
            leading and trailing whitespace). Every line of the Reader should contain only
            one word. The words need to be in lowercase if you make use of an
            Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
            
            </summary>
            <param name="reader">Reader containing the wordlist
            </param>
            <param name="comment">The string representing a comment.
            </param>
            <returns> A HashSet with the reader's words
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetStemDict(System.IO.FileInfo)">
            <summary> Reads a stem dictionary. Each line contains:
            <pre>word<b>\t</b>stem</pre>
            (i.e. two tab seperated words)
            
            </summary>
            <returns> stem dictionary that overrules the stemming algorithm
            </returns>
            <throws>  IOException  </throws>
        </member>
        <member name="T:Lucene.Net.Store.FileSwitchDirectory">
            <summary> Expert: A Directory instance that switches files between
            two other Directory instances.
            <p/>Files with the specified extensions are placed in the
            primary directory; others are placed in the secondary
            directory.  The provided Set must not change once passed
            to this class, and must allow multiple threads to call
            contains at once.<p/>
            
            <p/><b>NOTE</b>: this API is new and experimental and is
            subject to suddenly change in the next release.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FileSwitchDirectory.GetPrimaryDir">
            <summary>Return the primary directory </summary>
        </member>
        <member name="M:Lucene.Net.Store.FileSwitchDirectory.GetSecondaryDir">
            <summary>Return the secondary directory </summary>
        </member>
        <member name="M:Lucene.Net.Store.FileSwitchDirectory.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.FileSwitchDirectory.GetExtension(System.String)">
            <summary>Utility method to return a file's extension. </summary>
        </member>
        <member name="T:Lucene.Net.Search.TopFieldCollector">
            <summary> A {@link Collector} that sorts by {@link SortField} using
            {@link FieldComparator}s.
            <p/>
            See the {@link #create(Lucene.Net.Search.Sort, int, boolean, boolean, boolean, boolean)} method
            for instantiating a TopFieldCollector.
            
            <p/><b>NOTE:</b> This API is experimental and might change in
            incompatible ways in the next release.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopFieldCollector.create(Lucene.Net.Search.Sort,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary> Creates a new {@link TopFieldCollector} from the given
            arguments.
            
            <p/><b>NOTE</b>: The instances returned by this method
            pre-allocate a full array of length
            <code>numHits</code>.
            
            </summary>
            <param name="sort">the sort criteria (SortFields).
            </param>
            <param name="numHits">the number of results to collect.
            </param>
            <param name="fillFields">specifies whether the actual field values should be returned on
            the results (FieldDoc).
            </param>
            <param name="trackDocScores">specifies whether document scores should be tracked and set on the
            results. Note that if set to false, then the results' scores will
            be set to Float.NaN. Setting this to true affects performance, as
            it incurs the score computation on each competitive result.
            Therefore if document scores are not required by the application,
            it is recommended to set it to false.
            </param>
            <param name="trackMaxScore">specifies whether the query's maxScore should be tracked and set
            on the resulting {@link TopDocs}. Note that if set to false,
            {@link TopDocs#GetMaxScore()} returns Float.NaN. Setting this to
            true affects performance as it incurs the score computation on
            each result. Also, setting this true automatically sets
            <code>trackDocScores</code> to true as well.
            </param>
            <param name="docsScoredInOrder">specifies whether documents are scored in doc Id order or not by
            the given {@link Scorer} in {@link #SetScorer(Scorer)}.
            </param>
            <returns> a {@link TopFieldCollector} instance which will sort the results by
            the sort criteria.
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Search.QueryWrapperFilter">
            <summary> Constrains search results to only match those which also match a provided
            query.  
            
            <p/> This could be used, for example, with a {@link TermRangeQuery} on a suitably
            formatted date field to implement date filtering.  One could re-use a single
            QueryFilter that matches, e.g., only documents modified within the last
            week.  The QueryFilter and TermRangeQuery would only need to be reconstructed
            once per day.
            
            </summary>
            <version>  $Id:$
            </version>
        </member>
        <member name="M:Lucene.Net.Search.QueryWrapperFilter.#ctor(Lucene.Net.Search.Query)">
            <summary>Constructs a filter which only matches documents matching
            <code>query</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.QueryWrapperFilter.Bits(Lucene.Net.Index.IndexReader)">
            <deprecated> Use {@link #GetDocIdSet(IndexReader)} instead.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.DisjunctionSumScorer">
            <summary>A Scorer for OR like queries, counterpart of <code>ConjunctionScorer</code>.
            This Scorer implements {@link Scorer#SkipTo(int)} and uses skipTo() on the given Scorers. 
            TODO: Implement score(HitCollector, int).
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.nrScorers">
            <summary>The number of subscorers. </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.subScorers">
            <summary>The subscorers. </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.minimumNrMatchers">
            <summary>The minimum number of scorers that should match. </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.scorerDocQueue">
            <summary>The scorerDocQueue contains all subscorers ordered by their current doc(),
            with the minimum at the top.
            <br/>The scorerDocQueue is initialized the first time next() or skipTo() is called.
            <br/>An exhausted scorer is immediately removed from the scorerDocQueue.
            <br/>If less than the minimumNrMatchers scorers
            remain in the scorerDocQueue next() and skipTo() return false.
            <p/>
            After each to call to next() or skipTo()
            <code>currentSumScore</code> is the total score of the current matching doc,
            <code>nrMatchers</code> is the number of matching scorers,
            and all scorers are after the matching doc, or are exhausted.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.currentDoc">
            <summary>The document number of the current match. </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionSumScorer.nrMatchers">
            <summary>The number of subscorers that provide the current match. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.#ctor(System.Collections.IList,System.Int32)">
            <summary>Construct a <code>DisjunctionScorer</code>.</summary>
            <param name="subScorers">A collection of at least two subscorers.
            </param>
            <param name="minimumNrMatchers">The positive minimum number of subscorers that should
            match to match this query.
            <br/>When <code>minimumNrMatchers</code> is bigger than
            the number of <code>subScorers</code>,
            no matches will be produced.
            <br/>When minimumNrMatchers equals the number of subScorers,
            it more efficient to use <code>ConjunctionScorer</code>.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.#ctor(System.Collections.IList)">
            <summary>Construct a <code>DisjunctionScorer</code>, using one as the minimum number
            of matching subscorers.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.InitScorerDocQueue">
            <summary>Called the first time next() or skipTo() is called to
            initialize <code>scorerDocQueue</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Score(Lucene.Net.Search.HitCollector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
            <deprecated> use {@link #Score(Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Score(Lucene.Net.Search.Collector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="collector">The collector to which all matching documents are passed through.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Score(Lucene.Net.Search.HitCollector,System.Int32)">
            <summary>Expert: Collects matching documents in a range.  Hook for optimization.
            Note that {@link #Next()} must be called once before this method is called
            for the first time.
            </summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            </param>
            <param name="max">Do not score documents past this.
            </param>
            <returns> true if more matching documents may remain.
            </returns>
            <deprecated> use {@link #Score(Collector, int, int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Score(Lucene.Net.Search.Collector,System.Int32,System.Int32)">
            <summary>Expert: Collects matching documents in a range.  Hook for optimization.
            Note that {@link #Next()} must be called once before this method is called
            for the first time.
            </summary>
            <param name="collector">The collector to which all matching documents are passed through.
            </param>
            <param name="max">Do not score documents past this.
            </param>
            <returns> true if more matching documents may remain.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.AdvanceAfterCurrent">
            <summary>Advance all subscorers after the current document determined by the
            top of the <code>scorerDocQueue</code>.
            Repeat until at least the minimum number of subscorers match on the same
            document and all subscorers are after that document or are exhausted.
            <br/>On entry the <code>scorerDocQueue</code> has at least <code>minimumNrMatchers</code>
            available. At least the scorer with the minimum document number will be advanced.
            </summary>
            <returns> true iff there is a match.
            <br/>In case there is a match, <code>currentDoc</code>, <code>currentSumScore</code>,
            and <code>nrMatchers</code> describe the match.
            
            TODO: Investigate whether it is possible to use skipTo() when
            the minimum number of matchers is bigger than one, ie. try and use the
            character of ConjunctionScorer for the minimum number of matchers.
            Also delay calling score() on the sub scorers until the minimum number of
            matchers is reached.
            <br/>For this, a Scorer array with minimumNrMatchers elements might
            hold Scorers at currentDoc that are temporarily popped from scorerQueue.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Score">
            <summary>Returns the score of the current document matching the query.
            Initially invalid, until {@link #Next()} is called the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.NrMatchers">
            <summary>Returns the number of subscorers matching the current document.
            Initially invalid, until {@link #Next()} is called the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.SkipTo(System.Int32)">
            <summary> Skips to the first match beyond the current whose document number is
            greater than or equal to a given target. <br/>
            When this method is used the {@link #Explain(int)} method should not be
            used. <br/>
            The implementation uses the skipTo() method on the subscorers.
            
            </summary>
            <param name="target">The target document number.
            </param>
            <returns> true iff there is such a match.
            </returns>
            <deprecated> use {@link #Advance(int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Advance(System.Int32)">
            <summary> Advances to the first match beyond the current whose document number is
            greater than or equal to a given target. <br/>
            When this method is used the {@link #Explain(int)} method should not be
            used. <br/>
            The implementation uses the skipTo() method on the subscorers.
            
            </summary>
            <param name="target">The target document number.
            </param>
            <returns> the document whose number is greater than or equal to the given
            target, or -1 if none exist.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionSumScorer.Explain(System.Int32)">
            <returns> An explanation for the score of a given document. 
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.BooleanScorer2">
            <summary>An alternative to BooleanScorer that also allows a minimum number
            of optional scorers that should match.
            <br/>Implements skipTo(), and has no limitations on the numbers of added scorers.
            <br/>Uses ConjunctionScorer, DisjunctionScorer, ReqOptScorer and ReqExclScorer.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanScorer2.countingSumScorer">
            <summary>The scorer to which all scoring will be delegated,
            except for computing and using the coordination factor.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanScorer2.minNrShouldMatch">
            <summary>The number of optionalScorers that need to match (if there are any) </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.#ctor(Lucene.Net.Search.Similarity,System.Int32,System.Collections.IList,System.Collections.IList,System.Collections.IList)">
            <summary> Creates a {@link Scorer} with the given similarity and lists of required,
            prohibited and optional scorers. In no required scorers are added, at least
            one of the optional scorers will have to match during the search.
            
            </summary>
            <param name="similarity">The similarity to be used.
            </param>
            <param name="minNrShouldMatch">The minimum number of optional added scorers that should match
            during the search. In case no required scorers are added, at least
            one of the optional scorers will have to match during the search.
            </param>
            <param name="required">the list of required scorers.
            </param>
            <param name="prohibited">the list of prohibited scorers.
            </param>
            <param name="optional">the list of optional scorers.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.MakeCountingSumScorer">
            <summary>Returns the scorer to be used for match counting and score summing.
            Uses requiredScorers, optionalScorers and prohibitedScorers.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.AddProhibitedScorers(Lucene.Net.Search.Scorer)">
            <summary>Returns the scorer to be used for match counting and score summing.
            Uses the given required scorer and the prohibitedScorers.
            </summary>
            <param name="requiredCountingSumScorer">A required scorer already built.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Score(Lucene.Net.Search.HitCollector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
            <deprecated> use {@link #Score(Collector)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Score(Lucene.Net.Search.Collector)">
            <summary>Scores and collects all matching documents.</summary>
            <param name="collector">The collector to which all matching documents are passed through.
            <br/>When this method is used the {@link #Explain(int)} method should not be used.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Score(Lucene.Net.Search.HitCollector,System.Int32)">
            <summary>Expert: Collects matching documents in a range.
            <br/>Note that {@link #Next()} must be called once before this method is
            called for the first time.
            </summary>
            <param name="hc">The collector to which all matching documents are passed through
            {@link HitCollector#Collect(int, float)}.
            </param>
            <param name="max">Do not score documents past this.
            </param>
            <returns> true if more matching documents may remain.
            </returns>
            <deprecated> use {@link #Score(Collector, int, int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.Explain(System.Int32)">
            <summary>Throws an UnsupportedOperationException.
            TODO: Implement an explanation of the coordination factor.
            </summary>
            <param name="doc">The document number for the explanation.
            </param>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="T:Lucene.Net.Search.ConjunctionScorer">
            <summary>Scorer for conjunctions, sets of queries, all of which are required. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConjunctionScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ConjunctionScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ConjunctionScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.BooleanScorer2.SingleMatchScorer">
            <summary>Count a scorer as a single match. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.SingleMatchScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.SingleMatchScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer2.SingleMatchScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.QueryParsers.QueryParser">
            <summary> This class is generated by JavaCC.  The most important method is
            {@link #Parse(String)}.
            
            The syntax for query strings is as follows:
            A Query is a series of clauses.
            A clause may be prefixed by:
            <ul>
            <li> a plus (<code>+</code>) or a minus (<code>-</code>) sign, indicating
            that the clause is required or prohibited respectively; or</li>
            <li> a term followed by a colon, indicating the field to be searched.
            This enables one to construct queries which search multiple fields.</li>
            </ul>
            
            A clause may be either:
            <ul>
            <li> a term, indicating all the documents that contain this term; or</li>
            <li> a nested query, enclosed in parentheses.  Note that this may be used
            with a <code>+</code>/<code>-</code> prefix to require any of a set of
            terms.</li>
            </ul>
            
            Thus, in BNF, the query grammar is:
            <pre>
            Query  ::= ( Clause )*
            Clause ::= ["+", "-"] [&lt;TERM&gt; ":"] ( &lt;TERM&gt; | "(" Query ")" )
            </pre>
            
            <p/>
            Examples of appropriately formatted queries can be found in the <a
            href="../../../../../../queryparsersyntax.html">query syntax
            documentation</a>.
            <p/>
            
            <p/>
            In {@link TermRangeQuery}s, QueryParser tries to detect date values, e.g.
            <tt>date:[6/1/2005 TO 6/4/2005]</tt> produces a range query that searches
            for "date" fields between 2005-06-01 and 2005-06-04. Note that the format
            of the accepted input depends on {@link #SetLocale(Locale) the locale}.
            By default a date is converted into a search term using the deprecated
            {@link DateField} for compatibility reasons.
            To use the new {@link DateTools} to convert dates, a
            {@link Lucene.Net.Documents.DateTools.Resolution} has to be set.
            <p/>
            <p/>
            The date resolution that shall be used for RangeQueries can be set
            using {@link #SetDateResolution(DateTools.Resolution)}
            or {@link #SetDateResolution(String, DateTools.Resolution)}. The former
            sets the default date resolution for all fields, whereas the latter can
            be used to set field specific date resolutions. Field specific date
            resolutions take, if set, precedence over the default date resolution.
            <p/>
            <p/>
            If you use neither {@link DateField} nor {@link DateTools} in your
            index, you can create your own
            query parser that inherits QueryParser and overwrites
            {@link #GetRangeQuery(String, String, String, boolean)} to
            use a different method for date conversion.
            <p/>
            
            <p/>Note that QueryParser is <em>not</em> thread-safe.<p/> 
            
            <p/><b>NOTE</b>: there is a new QueryParser in contrib, which matches
            the same syntax as this class, but is more modular,
            enabling substantial customization to how a query is created.
            
            <p/><b>NOTE</b>: there is a new QueryParser in contrib, which matches
            the same syntax as this class, but is more modular,
            enabling substantial customization to how a query is created.
            <b>NOTE</b>: You must specify the required {@link Version} compatibility when
            creating QueryParser:
            <ul>
            <li>As of 2.9, {@link #SetEnablePositionIncrements} is true by default.</li>
            </ul>
            </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.QueryParserConstants">
            <summary> Token literal values and constants.
            Generated by org.javacc.parser.OtherFilesGen#start()
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.EOF">
            <summary>End of File. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._NUM_CHAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._ESCAPED_CHAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._TERM_START_CHAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._TERM_CHAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._WHITESPACE">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants._QUOTED_CHAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.AND">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.OR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.NOT">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.PLUS">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.MINUS">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.LPAREN">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RPAREN">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.COLON">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.STAR">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.CARAT">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.QUOTED">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.TERM">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.FUZZY_SLOP">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.PREFIXTERM">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.WILDTERM">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEIN_START">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEEX_START">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.NUMBER">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEIN_TO">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEIN_END">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEIN_QUOTED">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEIN_GOOP">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEEX_TO">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEEX_END">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEEX_QUOTED">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RANGEEX_GOOP">
            <summary>RegularExpression Id. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.Boost">
            <summary>Lexical state. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RangeEx">
            <summary>Lexical state. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.RangeIn">
            <summary>Lexical state. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.DEFAULT">
            <summary>Lexical state. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserConstants.tokenImage">
            <summary>Literal token values. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.AND_OPERATOR">
            <summary>Alternative form of QueryParser.Operator.AND </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.OR_OPERATOR">
            <summary>Alternative form of QueryParser.Operator.OR </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.operator_Renamed">
            <summary>The actual operator that parser uses to combine query terms </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.#ctor(System.String,Lucene.Net.Analysis.Analyzer)">
            <summary>Constructs a query parser.</summary>
            <param name="f"> the default field for query terms.
            </param>
            <param name="a">  used to find terms in the query text.
            </param>
            <deprecated> Use {@link #QueryParser(Version, String, Analyzer)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.#ctor(Lucene.Net.Util.Version,System.String,Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs a query parser.
            
            </summary>
            <param name="matchVersion">Lucene version to match. See <a href="#version">above</a>)
            </param>
            <param name="f">the default field for query terms.
            </param>
            <param name="a">used to find terms in the query text.
            </param>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.Parse(System.String)">
            <summary>Parses a query string, returning a {@link Lucene.Net.Search.Query}.</summary>
            <param name="query"> the query string to be parsed.
            </param>
            <throws>  ParseException if the parsing fails </throws>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetAnalyzer">
            <returns> Returns the analyzer.
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetField">
            <returns> Returns the field.
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetFuzzyMinSim">
            <summary> Get the minimal similarity for fuzzy queries.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetFuzzyMinSim(System.Single)">
            <summary> Set the minimum similarity for fuzzy queries.
            Default is 0.5f.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetFuzzyPrefixLength">
            <summary> Get the prefix length for fuzzy queries. </summary>
            <returns> Returns the fuzzyPrefixLength.
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetFuzzyPrefixLength(System.Int32)">
            <summary> Set the prefix length for fuzzy queries. Default is 0.</summary>
            <param name="fuzzyPrefixLength">The fuzzyPrefixLength to set.
            </param>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetPhraseSlop(System.Int32)">
            <summary> Sets the default slop for phrases.  If zero, then exact phrase matches
            are required.  Default value is zero.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetPhraseSlop">
            <summary> Gets the default slop for phrases.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetAllowLeadingWildcard(System.Boolean)">
            <summary> Set to <code>true</code> to allow leading wildcard characters.
            <p/>
            When set, <code>*</code> or <code>?</code> are allowed as 
            the first character of a PrefixQuery and WildcardQuery.
            Note that this can produce very slow
            queries on big indexes. 
            <p/>
            Default: false.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetAllowLeadingWildcard">
            <seealso cref="!:SetAllowLeadingWildcard(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetEnablePositionIncrements(System.Boolean)">
            <summary> Set to <code>true</code> to enable position increments in result query.
            <p/>
            When set, result phrase and multi-phrase queries will
            be aware of position increments.
            Useful when e.g. a StopFilter increases the position increment of
            the token that follows an omitted token.
            <p/>
            Default: false.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetEnablePositionIncrements">
            <seealso cref="!:SetEnablePositionIncrements(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetDefaultOperator(Lucene.Net.QueryParsers.QueryParser.Operator)">
            <summary> Sets the boolean operator of the QueryParser.
            In default mode (<code>OR_OPERATOR</code>) terms without any modifiers
            are considered optional: for example <code>capital of Hungary</code> is equal to
            <code>capital OR of OR Hungary</code>.<br/>
            In <code>AND_OPERATOR</code> mode terms are considered to be in conjunction: the
            above mentioned query is parsed as <code>capital AND of AND Hungary</code>
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetDefaultOperator">
            <summary> Gets implicit operator setting, which will be either AND_OPERATOR
            or OR_OPERATOR.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetLowercaseExpandedTerms(System.Boolean)">
            <summary> Whether terms of wildcard, prefix, fuzzy and range queries are to be automatically
            lower-cased or not.  Default is <code>true</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetLowercaseExpandedTerms">
            <seealso cref="!:SetLowercaseExpandedTerms(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetUseOldRangeQuery(System.Boolean)">
            <deprecated> Please use {@link #setMultiTermRewriteMethod} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetUseOldRangeQuery">
            <deprecated> Please use {@link #getMultiTermRewriteMethod} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetMultiTermRewriteMethod(Lucene.Net.Search.MultiTermQuery.RewriteMethod)">
            <summary> By default QueryParser uses {@link MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
            when creating a PrefixQuery, WildcardQuery or RangeQuery. This implementation is generally preferable because it 
            a) Runs faster b) Does not have the scarcity of terms unduly influence score 
            c) avoids any "TooManyBooleanClauses" exception.
            However, if your application really needs to use the
            old-fashioned BooleanQuery expansion rewriting and the above
            points are not relevant then use this to change
            the rewrite method.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetMultiTermRewriteMethod">
            <seealso cref="!:setMultiTermRewriteMethod">
            </seealso>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetLocale(System.Globalization.CultureInfo)">
            <summary> Set locale used by date range parsing.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetLocale">
            <summary> Returns current locale, allowing access by subclasses.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetDateResolution(Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Sets the default date resolution used by RangeQueries for fields for which no
            specific date resolutions has been set. Field specific resolutions can be set
            with {@link #SetDateResolution(String, DateTools.Resolution)}.
            
            </summary>
            <param name="dateResolution">the default date resolution to set
            </param>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetDateResolution(System.String,Lucene.Net.Documents.DateTools.Resolution)">
            <summary> Sets the date resolution used by RangeQueries for a specific field.
            
            </summary>
            <param name="fieldName">field for which the date resolution is to be set 
            </param>
            <param name="dateResolution">date resolution to set
            </param>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetDateResolution(System.String)">
            <summary> Returns the date resolution that is used by RangeQueries for the given field. 
            Returns null, if no default or field specific date resolution has been set
            for the given field.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.SetRangeCollator(System.Globalization.CompareInfo)">
            <summary> Sets the collator used to determine index term inclusion in ranges
            for RangeQuerys.
            <p/>
            <strong>WARNING:</strong> Setting the rangeCollator to a non-null
            collator using this method will cause every single index Term in the
            Field referenced by lowerTerm and/or upperTerm to be examined.
            Depending on the number of index Terms in this Field, the operation could
            be very slow.
            
            </summary>
            <param name="rc"> the collator to use when constructing RangeQuerys
            </param>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetRangeCollator">
            <returns> the collator used to determine index term inclusion in ranges
            for RangeQuerys.
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.AddClause(System.Collections.ArrayList,System.Int32,System.Int32,Lucene.Net.Search.Query)">
            <deprecated> use {@link #AddClause(List, int, int, Query)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetFieldQuery(System.String,System.String)">
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetFieldQuery(System.String,System.String,System.Int32)">
            <summary> Base implementation delegates to {@link #GetFieldQuery(String,String)}.
            This method may be overridden, for example, to return
            a SpanNearQuery instead of a PhraseQuery.
            
            </summary>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetRangeQuery(System.String,System.String,System.String,System.Boolean)">
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewBooleanQuery(System.Boolean)">
            <summary> Builds a new BooleanQuery instance</summary>
            <param name="disableCoord">disable coord
            </param>
            <returns> new BooleanQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewBooleanClause(Lucene.Net.Search.Query,Lucene.Net.Search.BooleanClause.Occur)">
            <summary> Builds a new BooleanClause instance</summary>
            <param name="q">sub query
            </param>
            <param name="occur">how this clause should occur when matching documents
            </param>
            <returns> new BooleanClause instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewTermQuery(Lucene.Net.Index.Term)">
            <summary> Builds a new TermQuery instance</summary>
            <param name="term">term
            </param>
            <returns> new TermQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewPhraseQuery">
            <summary> Builds a new PhraseQuery instance</summary>
            <returns> new PhraseQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewMultiPhraseQuery">
            <summary> Builds a new MultiPhraseQuery instance</summary>
            <returns> new MultiPhraseQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewPrefixQuery(Lucene.Net.Index.Term)">
            <summary> Builds a new PrefixQuery instance</summary>
            <param name="prefix">Prefix term
            </param>
            <returns> new PrefixQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewFuzzyQuery(Lucene.Net.Index.Term,System.Single,System.Int32)">
            <summary> Builds a new FuzzyQuery instance</summary>
            <param name="term">Term
            </param>
            <param name="minimumSimilarity">minimum similarity
            </param>
            <param name="prefixLength">prefix length
            </param>
            <returns> new FuzzyQuery Instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewRangeQuery(System.String,System.String,System.String,System.Boolean)">
            <summary> Builds a new TermRangeQuery instance</summary>
            <param name="field">Field
            </param>
            <param name="part1">min
            </param>
            <param name="part2">max
            </param>
            <param name="inclusive">true if range is inclusive
            </param>
            <returns> new TermRangeQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewMatchAllDocsQuery">
            <summary> Builds a new MatchAllDocsQuery instance</summary>
            <returns> new MatchAllDocsQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.NewWildcardQuery(Lucene.Net.Index.Term)">
            <summary> Builds a new WildcardQuery instance</summary>
            <param name="t">wildcard term
            </param>
            <returns> new WildcardQuery instance
            </returns>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetBooleanQuery(System.Collections.ArrayList)">
            <summary> Factory method for generating query, given a set of clauses.
            By default creates a boolean query composed of clauses passed in.
            
            Can be overridden by extending classes, to modify query being
            returned.
            
            </summary>
            <param name="clauses">List that contains {@link BooleanClause} instances
            to join.
            
            </param>
            <returns> Resulting {@link Query} object.
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
            <deprecated> use {@link #GetBooleanQuery(List)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetBooleanQuery(System.Collections.IList)">
            <summary> Factory method for generating query, given a set of clauses.
            By default creates a boolean query composed of clauses passed in.
            
            Can be overridden by extending classes, to modify query being
            returned.
            
            </summary>
            <param name="clauses">List that contains {@link BooleanClause} instances
            to join.
            
            </param>
            <returns> Resulting {@link Query} object.
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetBooleanQuery(System.Collections.ArrayList,System.Boolean)">
            <summary> Factory method for generating query, given a set of clauses.
            By default creates a boolean query composed of clauses passed in.
            
            Can be overridden by extending classes, to modify query being
            returned.
            
            </summary>
            <param name="clauses">List that contains {@link BooleanClause} instances
            to join.
            </param>
            <param name="disableCoord">true if coord scoring should be disabled.
            
            </param>
            <returns> Resulting {@link Query} object.
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
            <deprecated> use {@link #GetBooleanQuery(List, boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetBooleanQuery(System.Collections.IList,System.Boolean)">
            <summary> Factory method for generating query, given a set of clauses.
            By default creates a boolean query composed of clauses passed in.
            
            Can be overridden by extending classes, to modify query being
            returned.
            
            </summary>
            <param name="clauses">List that contains {@link BooleanClause} instances
            to join.
            </param>
            <param name="disableCoord">true if coord scoring should be disabled.
            
            </param>
            <returns> Resulting {@link Query} object.
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetWildcardQuery(System.String,System.String)">
            <summary> Factory method for generating a query. Called when parser
            parses an input term token that contains one or more wildcard
            characters (? and *), but is not a prefix term token (one
            that has just a single * character at the end)
            <p/>
            Depending on settings, prefix term may be lower-cased
            automatically. It will not go through the default Analyzer,
            however, since normal Analyzers are unlikely to work properly
            with wildcard templates.
            <p/>
            Can be overridden by extending classes, to provide custom handling for
            wildcard queries, which may be necessary due to missing analyzer calls.
            
            </summary>
            <param name="field">Name of the field query will use.
            </param>
            <param name="termStr">Term token that contains one or more wild card
            characters (? or *), but is not simple prefix term
            
            </param>
            <returns> Resulting {@link Query} built for the term
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetPrefixQuery(System.String,System.String)">
            <summary> Factory method for generating a query (similar to
            {@link #getWildcardQuery}). Called when parser parses an input term
            token that uses prefix notation; that is, contains a single '*' wildcard
            character as its last character. Since this is a special case
            of generic wildcard term, and such a query can be optimized easily,
            this usually results in a different query object.
            <p/>
            Depending on settings, a prefix term may be lower-cased
            automatically. It will not go through the default Analyzer,
            however, since normal Analyzers are unlikely to work properly
            with wildcard templates.
            <p/>
            Can be overridden by extending classes, to provide custom handling for
            wild card queries, which may be necessary due to missing analyzer calls.
            
            </summary>
            <param name="field">Name of the field query will use.
            </param>
            <param name="termStr">Term token to use for building term for the query
            (<b>without</b> trailing '*' character!)
            
            </param>
            <returns> Resulting {@link Query} built for the term
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetFuzzyQuery(System.String,System.String,System.Single)">
            <summary> Factory method for generating a query (similar to
            {@link #getWildcardQuery}). Called when parser parses
            an input term token that has the fuzzy suffix (~) appended.
            
            </summary>
            <param name="field">Name of the field query will use.
            </param>
            <param name="termStr">Term token to use for building term for the query
            
            </param>
            <returns> Resulting {@link Query} built for the term
            </returns>
            <exception cref="T:Lucene.Net.QueryParsers.ParseException">throw in overridden method to disallow
            </exception>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.DiscardEscapeChar(System.String)">
            <summary> Returns a String where the escape char has been
            removed, or kept only once if there was a double escape.
            
            Supports escaped unicode characters, e. g. translates
            <code>\\u0041</code> to <code>A</code>.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.HexToInt(System.Char)">
            <summary>Returns the numeric value of the hexadecimal character </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.Escape(System.String)">
            <summary> Returns a String where those characters that QueryParser
            expects to be escaped are escaped by a preceding <code>\</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.Main(System.String[])">
            <summary> Command line tool to test QueryParser, using {@link Lucene.Net.Analysis.SimpleAnalyzer}.
            Usage:<br/>
            <code>java Lucene.Net.QueryParsers.QueryParser &lt;input&gt;</code>
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.token_source">
            <summary>Generated Token Manager. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.token">
            <summary>Current token. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParser.jj_nt">
            <summary>Next token. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.#ctor(Lucene.Net.QueryParsers.CharStream)">
            <summary>Constructor with user supplied CharStream. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.ReInit(Lucene.Net.QueryParsers.CharStream)">
            <summary>Reinitialise. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.#ctor(Lucene.Net.QueryParsers.QueryParserTokenManager)">
            <summary>Constructor with generated Token Manager. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.ReInit(Lucene.Net.QueryParsers.QueryParserTokenManager)">
            <summary>Reinitialise. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetNextToken">
            <summary>Get the next Token. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GetToken(System.Int32)">
            <summary>Get the specific Token. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.GenerateParseException">
            <summary>Generate ParseException. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.Enable_tracing">
            <summary>Enable tracing. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParser.Disable_tracing">
            <summary>Disable tracing. </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.QueryParser.Operator">
            <summary>The default operator for parsing queries. 
            Use {@link QueryParser#setDefaultOperator} to change it.
            </summary>
        </member>
        <member name="T:Lucene.Net.Messages.NLSException">
            <summary> Interface that exceptions should implement to support lazy loading of messages.
            
            For Native Language Support (NLS), system of software internationalization.
            
            This Interface should be implemented by all exceptions that require
            translation
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Messages.NLSException.GetMessageObject">
            <returns> a instance of a class that implements the Message interface
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.TermVectorEntryFreqSortedComparator">
            <summary> Compares {@link Lucene.Net.Index.TermVectorEntry}s first by frequency and then by
            the term (case-sensitive)
            
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermFreqVector">
            <summary>Provides access to stored term vector of 
            a document field.  The vector consists of the name of the field, an array of the terms tha occur in the field of the
            {@link Lucene.Net.Documents.Document} and a parallel array of frequencies.  Thus, getTermFrequencies()[5] corresponds with the
            frequency of getTerms()[5], assuming there are at least 5 terms in the Document.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.GetField">
            <summary> The {@link Lucene.Net.Documents.Fieldable} name. </summary>
            <returns> The name of the field this vector is associated with.
            
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.Size">
            <returns> The number of terms in the term vector.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.GetTerms">
            <returns> An Array of term texts in ascending order.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.GetTermFrequencies">
            <summary>Array of term frequencies. Locations of the array correspond one to one
            to the terms in the array obtained from <code>getTerms</code>
            method. Each location in the array contains the number of times this
            term occurs in the document or the document field.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.IndexOf(System.String)">
            <summary>Return an index in the term numbers array returned from
            <code>getTerms</code> at which the term with the specified
            <code>term</code> appears. If this term does not appear in the array,
            return -1.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermFreqVector.IndexesOf(System.String[],System.Int32,System.Int32)">
            <summary>Just like <code>indexOf(int)</code> but searches for a number of terms
            at the same time. Returns an array that has the same size as the number
            of terms searched for, each slot containing the result of searching for
            that term number.
            
            </summary>
            <param name="terms">array containing terms to look for
            </param>
            <param name="start">index in the array where the list of terms starts
            </param>
            <param name="len">the number of terms in the list
            </param>
        </member>
        <member name="T:Lucene.Net.Index.NormsWriterPerField">
            <summary>Taps into DocInverter, as an InvertedDocEndConsumer,
            which is called at the end of inverting each field.  We
            just look at the length for the field (docState.length)
            and record the norm. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexWriter">
            <summary>An <code>IndexWriter</code> creates and maintains an index.
            <p/>The <code>create</code> argument to the {@link
            #IndexWriter(Directory, Analyzer, boolean) constructor} determines 
            whether a new index is created, or whether an existing index is
            opened.  Note that you can open an index with <code>create=true</code>
            even while readers are using the index.  The old readers will 
            continue to search the "point in time" snapshot they had opened, 
            and won't see the newly created index until they re-open.  There are
            also {@link #IndexWriter(Directory, Analyzer) constructors}
            with no <code>create</code> argument which will create a new index
            if there is not already an index at the provided path and otherwise 
            open the existing index.<p/>
            <p/>In either case, documents are added with {@link #AddDocument(Document)
            addDocument} and removed with {@link #DeleteDocuments(Term)} or {@link
            #DeleteDocuments(Query)}. A document can be updated with {@link
            #UpdateDocument(Term, Document) updateDocument} (which just deletes
            and then adds the entire document). When finished adding, deleting 
            and updating documents, {@link #Close() close} should be called.<p/>
            <a name="flush"></a>
            <p/>These changes are buffered in memory and periodically
            flushed to the {@link Directory} (during the above method
            calls).  A flush is triggered when there are enough
            buffered deletes (see {@link #setMaxBufferedDeleteTerms})
            or enough added documents since the last flush, whichever
            is sooner.  For the added documents, flushing is triggered
            either by RAM usage of the documents (see {@link
            #setRAMBufferSizeMB}) or the number of added documents.
            The default is to flush when RAM usage hits 16 MB.  For
            best indexing speed you should flush by RAM usage with a
            large RAM buffer.  Note that flushing just moves the
            internal buffered state in IndexWriter into the index, but
            these changes are not visible to IndexReader until either
            {@link #Commit()} or {@link #close} is called.  A flush may
            also trigger one or more segment merges which by default
            run with a background thread so as not to block the
            addDocument calls (see <a href="#mergePolicy">below</a>
            for changing the {@link MergeScheduler}).<p/>
            <a name="autoCommit"></a>
            <p/>The optional <code>autoCommit</code> argument to the {@link
            #IndexWriter(Directory, boolean, Analyzer) constructors}
            controls visibility of the changes to {@link IndexReader}
            instances reading the same index.  When this is
            <code>false</code>, changes are not visible until {@link
            #Close()} or {@link #Commit()} is called.  Note that changes will still be
            flushed to the {@link Directory} as new files, but are 
            not committed (no new <code>segments_N</code> file is written 
            referencing the new files, nor are the files sync'd to stable storage)
            until {@link #Close()} or {@link #Commit()} is called.  If something
            goes terribly wrong (for example the JVM crashes), then
            the index will reflect none of the changes made since the
            last commit, or the starting state if commit was not called.
            You can also call {@link #Rollback()}, which closes the writer
            without committing any changes, and removes any index
            files that had been flushed but are now unreferenced.
            This mode is useful for preventing readers from refreshing
            at a bad time (for example after you've done all your
            deletes but before you've done your adds).  It can also be
            used to implement simple single-writer transactional
            semantics ("all or none").  You can do a two-phase commit
            by calling {@link #PrepareCommit()}
            followed by {@link #Commit()}. This is necessary when
            Lucene is working with an external resource (for example,
            a database) and both must either commit or rollback the
            transaction.<p/>
            <p/>When <code>autoCommit</code> is <code>true</code> then
            the writer will periodically commit on its own.  [<b>Deprecated</b>: Note that in 3.0, IndexWriter will
            no longer accept autoCommit=true (it will be hardwired to
            false).  You can always call {@link #Commit()} yourself
            when needed]. There is
            no guarantee when exactly an auto commit will occur (it
            used to be after every flush, but it is now after every
            completed merge, as of 2.4).  If you want to force a
            commit, call {@link #Commit()}, or, close the writer.  Once
            a commit has finished, newly opened {@link IndexReader} instances will
            see the changes to the index as of that commit.  When
            running in this mode, be careful not to refresh your
            readers while optimize or segment merges are taking place
            as this can tie up substantial disk space.<p/>
            </summary>
            <summary><p/>Regardless of <code>autoCommit</code>, an {@link
            IndexReader} or {@link Lucene.Net.Search.IndexSearcher} will only see the
            index as of the "point in time" that it was opened.  Any
            changes committed to the index after the reader was opened
            are not visible until the reader is re-opened.<p/>
            <p/>If an index will not have more documents added for a while and optimal search
            performance is desired, then either the full {@link #Optimize() optimize}
            method or partial {@link #Optimize(int)} method should be
            called before the index is closed.<p/>
            <p/>Opening an <code>IndexWriter</code> creates a lock file for the directory in use. Trying to open
            another <code>IndexWriter</code> on the same directory will lead to a
            {@link LockObtainFailedException}. The {@link LockObtainFailedException}
            is also thrown if an IndexReader on the same directory is used to delete documents
            from the index.<p/>
            </summary>
            <summary><a name="deletionPolicy"></a>
            <p/>Expert: <code>IndexWriter</code> allows an optional
            {@link IndexDeletionPolicy} implementation to be
            specified.  You can use this to control when prior commits
            are deleted from the index.  The default policy is {@link
            KeepOnlyLastCommitDeletionPolicy} which removes all prior
            commits as soon as a new commit is done (this matches
            behavior before 2.2).  Creating your own policy can allow
            you to explicitly keep previous "point in time" commits
            alive in the index for some time, to allow readers to
            refresh to the new commit without having the old commit
            deleted out from under them.  This is necessary on
            filesystems like NFS that do not support "delete on last
            close" semantics, which Lucene's "point in time" search
            normally relies on. <p/>
            <a name="mergePolicy"></a> <p/>Expert:
            <code>IndexWriter</code> allows you to separately change
            the {@link MergePolicy} and the {@link MergeScheduler}.
            The {@link MergePolicy} is invoked whenever there are
            changes to the segments in the index.  Its role is to
            select which merges to do, if any, and return a {@link
            MergePolicy.MergeSpecification} describing the merges.  It
            also selects merges to do for optimize().  (The default is
            {@link LogByteSizeMergePolicy}.  Then, the {@link
            MergeScheduler} is invoked with the requested merges and
            it decides when and how to run the merges.  The default is
            {@link ConcurrentMergeScheduler}. <p/>
            <a name="OOME"></a><p/><b>NOTE</b>: if you hit an
            OutOfMemoryError then IndexWriter will quietly record this
            fact and block all future segment commits.  This is a
            defensive measure in case any internal state (buffered
            documents and deletions) were corrupted.  Any subsequent
            calls to {@link #Commit()} will throw an
            IllegalStateException.  The only course of action is to
            call {@link #Close()}, which internally will call {@link
            #Rollback()}, to undo any changes to the index since the
            last commit.  If you opened the writer with autoCommit
            false you can also just call {@link #Rollback()}
            directly.<p/>
            <a name="thread-safety"></a><p/><b>NOTE</b>: {@link
            <code>IndexWriter</code>} instances are completely thread
            safe, meaning multiple threads can call any of its
            methods, concurrently.  If your application requires
            external synchronization, you should <b>not</b>
            synchronize on the <code>IndexWriter</code> instance as
            this may cause deadlock; use your own (non-Lucene) objects
            instead. <p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.WRITE_LOCK_NAME">
            <summary> Name of the write lock in the index.</summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DISABLE_AUTO_FLUSH">
            <summary> Value to denote a flush trigger is disabled</summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_RAM_BUFFER_SIZE_MB">
            <summary> Default value is 16 MB (which means flush when buffered
            docs consume 16 MB RAM).  Change using {@link #setRAMBufferSizeMB}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MAX_FIELD_LENGTH">
            <summary> Default value is 10,000. Change using {@link #SetMaxFieldLength(int)}.</summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_TERM_INDEX_INTERVAL">
            <summary> Default value is 128. Change using {@link #SetTermIndexInterval(int)}.</summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.WRITE_LOCK_TIMEOUT">
            <summary> Default value for the write lock timeout (1,000).</summary>
            <seealso cref="!:setDefaultWriteLockTimeout">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MERGE_FACTOR">
            <deprecated>
            </deprecated>
            <seealso cref="F:Lucene.Net.Index.LogMergePolicy.DEFAULT_MERGE_FACTOR">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MAX_BUFFERED_DOCS">
            <summary> Disabled by default (because IndexWriter flushes by RAM usage
            by default). Change using {@link #SetMaxBufferedDocs(int)}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MAX_BUFFERED_DELETE_TERMS">
            <summary> Disabled by default (because IndexWriter flushes by RAM usage
            by default). Change using {@link #SetMaxBufferedDeleteTerms(int)}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MAX_MERGE_DOCS">
            <deprecated>
            </deprecated>
            <seealso cref="!:LogDocMergePolicy.DEFAULT_MAX_MERGE_DOCS">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.MAX_TERM_LENGTH">
            <summary> Absolute hard maximum length for a term.  If a term
            arrives from the analyzer longer than this length, it
            is skipped and a message is printed to infoStream, if
            set (see {@link #setInfoStream}).
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.DEFAULT_MAX_SYNC_PAUSE_SECONDS">
            <summary> Default for {@link #getMaxSyncPauseSeconds}.  On
            Windows this defaults to 10.0 seconds; elsewhere it's
            0.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetReader">
            <summary> Expert: returns a readonly reader, covering all committed as well as
            un-committed changes to the index. This provides "near real-time"
            searching, in that changes made during an IndexWriter session can be
            quickly made available for searching without closing the writer nor
            calling {@link #commit}.
            
            <p/>
            Note that this is functionally equivalent to calling {#commit} and then
            using {@link IndexReader#open} to open a new reader. But the turarnound
            time of this method should be faster since it avoids the potentially
            costly {@link #commit}.
            <p/>
            
            You must close the {@link IndexReader} returned by  this method once you are done using it.
            
            <p/>
            It's <i>near</i> real-time because there is no hard
            guarantee on how quickly you can get a new reader after
            making changes with IndexWriter.  You'll have to
            experiment in your situation to determine if it's
            faster enough.  As this is a new and experimental
            feature, please report back on your findings so we can
            learn, improve and iterate.<p/>
            
            <p/>The resulting reader suppports {@link
            IndexReader#reopen}, but that call will simply forward
            back to this method (though this may change in the
            future).<p/>
            
            <p/>The very first time this method is called, this
            writer instance will make every effort to pool the
            readers that it opens for doing merges, applying
            deletes, etc.  This means additional resources (RAM,
            file descriptors, CPU time) will be consumed.<p/>
            
            <p/>For lower latency on reopening a reader, you should call {@link #setMergedSegmentWarmer} 
            to call {@link #setMergedSegmentWarmer} to
            pre-warm a newly merged segment before it's committed
            to the index. This is important for minimizing index-to-search 
            delay after a large merge.
            
            <p/>If an addIndexes* call is running in another thread,
            then this reader will only search those segments from
            the foreign index that have been successfully copied
            over, so far<p/>.
            
            <p/><b>NOTE</b>: Once the writer is closed, any
            outstanding readers may continue to be used.  However,
            if you attempt to reopen any of those readers, you'll
            hit an {@link AlreadyClosedException}.<p/>
            
            <p/><b>NOTE:</b> This API is experimental and might
            change in incompatible ways in the next release.<p/>
            
            </summary>
            <returns> IndexReader that covers entire index plus all
            changes made so far by this IndexWriter instance
            
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetReader(System.Int32)">
            <summary>Expert: like {@link #getReader}, except you can
            specify which termInfosIndexDivisor should be used for
            any newly opened readers.
            </summary>
            <param name="termInfosIndexDivisor">Subsambles which indexed
            terms are loaded into RAM. This has the same effect as {@link
            IndexWriter#setTermIndexInterval} except that setting
            must be done at indexing time while this setting can be
            set per reader.  When set to N, then one in every
            N*termIndexInterval terms in the index is loaded into
            memory.  By setting this to a value > 1 you can reduce
            memory usage, at the expense of higher latency when
            loading a TermInfo.  The default value is 1.  Set this
            to -1 to skip loading the terms index entirely. 
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.NumDeletedDocs(Lucene.Net.Index.SegmentInfo)">
            <summary> Obtain the number of deleted docs for a pooled reader.
            If the reader isn't being pooled, the segmentInfo's 
            delCount is returned.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.EnsureOpen(System.Boolean)">
            <summary> Used internally to throw an {@link
            AlreadyClosedException} if this IndexWriter has been
            closed.
            </summary>
            <throws>  AlreadyClosedException if this IndexWriter is </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Message(System.String)">
            <summary> Prints a message to the infoStream (if non-null),
            prefixed with the identifying information for this
            writer and the thread that's calling it.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetLogMergePolicy">
            <summary> Casts current mergePolicy to LogMergePolicy, and throws
            an exception if the mergePolicy is not a LogMergePolicy.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetUseCompoundFile">
            <summary><p/>Get the current setting of whether newly flushed
            segments will use the compound file format.  Note that
            this just returns the value previously set with
            setUseCompoundFile(boolean), or the default value
            (true).  You cannot use this to query the status of
            previously flushed segments.<p/>
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.getUseCompoundFile as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            
            </summary>
            <seealso cref="!:SetUseCompoundFile(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetUseCompoundFile(System.Boolean)">
            <summary><p/>Setting to turn on usage of a compound file. When on,
            multiple files for each segment are merged into a
            single file when a new segment is flushed.<p/>
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.setUseCompoundFile as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetSimilarity(Lucene.Net.Search.Similarity)">
            <summary>Expert: Set the Similarity implementation used by this IndexWriter.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.SetDefault(Lucene.Net.Search.Similarity)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetSimilarity">
            <summary>Expert: Return the Similarity implementation used by this IndexWriter.
            
            <p/>This defaults to the current value of {@link Similarity#GetDefault()}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetTermIndexInterval(System.Int32)">
            <summary>Expert: Set the interval between indexed terms.  Large values cause less
            memory to be used by IndexReader, but slow random-access to terms.  Small
            values cause more memory to be used by an IndexReader, and speed
            random-access to terms.
            
            This parameter determines the amount of computation required per query
            term, regardless of the number of documents that contain that term.  In
            particular, it is the maximum number of other terms that must be
            scanned before a term is located and its frequency and position information
            may be processed.  In a large index with user-entered query terms, query
            processing time is likely to be dominated not by term lookup but rather
            by the processing of frequency and positional data.  In a small index
            or when many uncommon query terms are generated (e.g., by wildcard
            queries) term lookup may become a dominant cost.
            
            In particular, <code>numUniqueTerms/interval</code> terms are read into
            memory by an IndexReader, and, on average, <code>interval/2</code> terms
            must be scanned for each random term access.
            
            </summary>
            <seealso cref="F:Lucene.Net.Index.IndexWriter.DEFAULT_TERM_INDEX_INTERVAL">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetTermIndexInterval">
            <summary>Expert: Return the interval between indexed terms.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetTermIndexInterval(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.String,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in <code>path</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>path</code>, replacing the index already there,
            if any.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="mfl">Maximum field length in number of tokens/terms: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> Use {@link #IndexWriter(Directory, Analyzer,
            boolean, MaxFieldLength)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.String,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Constructs an IndexWriter for the index in <code>path</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>path</code>, replacing the index already there, if any.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,boolean,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.IO.FileInfo,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in <code>path</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>path</code>, replacing the index already there, if any.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="mfl">Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> Use {@link #IndexWriter(Directory,
            Analyzer, boolean, MaxFieldLength)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.IO.FileInfo,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Constructs an IndexWriter for the index in <code>path</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>path</code>, replacing the index already there, if any.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,boolean,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>d</code>, replacing the index already there, if any.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="mfl">Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Constructs an IndexWriter for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>d</code>, replacing the index already there, if any.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0
            release, and call {@link #Commit()} when needed.
            Use {@link #IndexWriter(Directory,Analyzer,boolean,MaxFieldLength)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.String,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in
            <code>path</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="mfl">Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> Use {@link #IndexWriter(Directory, Analyzer, MaxFieldLength)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.String,Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs an IndexWriter for the index in
            <code>path</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0
            release, and call {@link #Commit()} when needed.
            Use {@link #IndexWriter(Directory,Analyzer,MaxFieldLength)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.IO.FileInfo,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in
            <code>path</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="mfl">Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> Use {@link #IndexWriter(Directory,
            Analyzer, MaxFieldLength)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(System.IO.FileInfo,Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs an IndexWriter for the index in
            <code>path</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            </summary>
            <param name="path">the path to the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link #IndexWriter(Directory,Analyzer,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Constructs an IndexWriter for the index in
            <code>d</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="mfl">Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
            via the MaxFieldLength constructor.
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs an IndexWriter for the index in
            <code>d</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,System.Boolean,Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs an IndexWriter for the index in
            <code>d</code>, first creating it if it does not
            already exist.  Text will be analyzed with
            <code>a</code>.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="autoCommit">see <a href="#autoCommit">above</a>
            </param>
            <param name="a">the analyzer to use
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,System.Boolean,Lucene.Net.Analysis.Analyzer,System.Boolean)">
            <summary> Constructs an IndexWriter for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If <code>create</code>
            is true, then a new, empty index will be created in
            <code>d</code>, replacing the index already there, if any.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="autoCommit">see <a href="#autoCommit">above</a>
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,boolean,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexDeletionPolicy,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Expert: constructs an IndexWriter with a custom {@link
            IndexDeletionPolicy}, for the index in <code>d</code>,
            first creating it if it does not already exist.  Text
            will be analyzed with <code>a</code>.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <param name="mfl">whether or not to limit field lengths
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,System.Boolean,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexDeletionPolicy)">
            <summary> Expert: constructs an IndexWriter with a custom {@link
            IndexDeletionPolicy}, for the index in <code>d</code>,
            first creating it if it does not already exist.  Text
            will be analyzed with <code>a</code>.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="autoCommit">see <a href="#autoCommit">above</a>
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be </throws>
            <summary>  read/written to or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,IndexDeletionPolicy,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexDeletionPolicy,Lucene.Net.Index.IndexWriter.MaxFieldLength)">
            <summary> Expert: constructs an IndexWriter with a custom {@link
            IndexDeletionPolicy}, for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If
            <code>create</code> is true, then a new, empty index
            will be created in <code>d</code>, replacing the index
            already there, if any.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <param name="mfl">{@link Lucene.Net.Index.IndexWriter.MaxFieldLength}, whether or not to limit field lengths.  Value is in number of terms/tokens
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexDeletionPolicy,Lucene.Net.Index.IndexWriter.MaxFieldLength,Lucene.Net.Index.DocumentsWriter.IndexingChain,Lucene.Net.Index.IndexCommit)">
            <summary> Expert: constructs an IndexWriter with a custom {@link
            IndexDeletionPolicy} and {@link IndexingChain}, 
            for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If
            <code>create</code> is true, then a new, empty index
            will be created in <code>d</code>, replacing the index
            already there, if any.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <param name="mfl">whether or not to limit field lengths, value is in number of terms/tokens.  See {@link Lucene.Net.Index.IndexWriter.MaxFieldLength}.
            </param>
            <param name="indexingChain">the {@link DocConsumer} chain to be used to 
            process documents
            </param>
            <param name="commit">which commit to open
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,System.Boolean,Lucene.Net.Analysis.Analyzer,System.Boolean,Lucene.Net.Index.IndexDeletionPolicy)">
            <summary> Expert: constructs an IndexWriter with a custom {@link
            IndexDeletionPolicy}, for the index in <code>d</code>.
            Text will be analyzed with <code>a</code>.  If
            <code>create</code> is true, then a new, empty index
            will be created in <code>d</code>, replacing the index
            already there, if any.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="autoCommit">see <a href="#autoCommit">above</a>
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="create"><code>true</code> to create the index or overwrite
            the existing one; <code>false</code> to append to the existing
            index
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
            <deprecated> This constructor will be removed in the 3.0 release.
            Use {@link
            #IndexWriter(Directory,Analyzer,boolean,IndexDeletionPolicy,MaxFieldLength)}
            instead, and call {@link #Commit()} when needed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.#ctor(Lucene.Net.Store.Directory,Lucene.Net.Analysis.Analyzer,Lucene.Net.Index.IndexDeletionPolicy,Lucene.Net.Index.IndexWriter.MaxFieldLength,Lucene.Net.Index.IndexCommit)">
            <summary> Expert: constructs an IndexWriter on specific commit
            point, with a custom {@link IndexDeletionPolicy}, for
            the index in <code>d</code>.  Text will be analyzed
            with <code>a</code>.
            
            <p/> This is only meaningful if you've used a {@link
            IndexDeletionPolicy} in that past that keeps more than
            just the last commit.
            
            <p/>This operation is similar to {@link #Rollback()},
            except that method can only rollback what's been done
            with the current instance of IndexWriter since its last
            commit, whereas this method can rollback to an
            arbitrary commit point from the past, assuming the
            {@link IndexDeletionPolicy} has preserved past
            commits.
            
            <p/><b>NOTE</b>: autoCommit (see <a
            href="#autoCommit">above</a>) is set to false with this
            constructor.
            
            </summary>
            <param name="d">the index directory
            </param>
            <param name="a">the analyzer to use
            </param>
            <param name="deletionPolicy">see <a href="#deletionPolicy">above</a>
            </param>
            <param name="mfl">whether or not to limit field lengths, value is in number of terms/tokens.  See {@link Lucene.Net.Index.IndexWriter.MaxFieldLength}.
            </param>
            <param name="commit">which commit to open
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  LockObtainFailedException if another writer </throws>
            <summary>  has this index open (<code>write.lock</code> could not
            be obtained)
            </summary>
            <throws>  IOException if the directory cannot be read/written to, or </throws>
            <summary>  if it does not exist and <code>create</code> is
            <code>false</code> or if there is any other low-level
            IO error
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMergePolicy(Lucene.Net.Index.MergePolicy)">
            <summary> Expert: set the merge policy used by this writer.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMergePolicy">
            <summary> Expert: returns the current MergePolicy in use by this writer.</summary>
            <seealso cref="!:setMergePolicy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMergeScheduler(Lucene.Net.Index.MergeScheduler)">
            <summary> Expert: set the merge scheduler used by this writer.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMergeScheduler">
            <summary> Expert: returns the current MergePolicy in use by this
            writer.
            </summary>
            <seealso cref="!:setMergePolicy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMaxMergeDocs(System.Int32)">
            <summary><p/>Determines the largest segment (measured by
            document count) that may be merged with other segments.
            Small values (e.g., less than 10,000) are best for
            interactive indexing, as this limits the length of
            pauses while indexing to a few seconds.  Larger values
            are best for batched indexing and speedier
            searches.<p/>
            
            <p/>The default value is {@link Integer#MAX_VALUE}.<p/>
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.setMaxMergeDocs as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            
            <p/>The default merge policy ({@link
            LogByteSizeMergePolicy}) also allows you to set this
            limit by net size (in MB) of the segment, using {@link
            LogByteSizeMergePolicy#setMaxMergeMB}.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMaxMergeDocs">
            <summary> <p/>Returns the largest segment (measured by document
            count) that may be merged with other segments.<p/>
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.getMaxMergeDocs as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            
            </summary>
            <seealso cref="!:setMaxMergeDocs">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMaxFieldLength(System.Int32)">
            <summary> The maximum number of terms that will be indexed for a single field in a
            document.  This limits the amount of memory required for indexing, so that
            collections with very large files will not crash the indexing process by
            running out of memory.  This setting refers to the number of running terms,
            not to the number of different terms.<p/>
            <strong>Note:</strong> this silently truncates large documents, excluding from the
            index all terms that occur further in the document.  If you know your source
            documents are large, be sure to set this value high enough to accomodate
            the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
            is your memory, but you should anticipate an OutOfMemoryError.<p/>
            By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms
            will be indexed for a field.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMaxFieldLength">
            <summary> Returns the maximum number of terms that will be
            indexed for a single field in a document.
            </summary>
            <seealso cref="!:setMaxFieldLength">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetReaderTermsIndexDivisor(System.Int32)">
            Sets the termsIndexDivisor passed to any readers that
            IndexWriter opens, for example when applying deletes
            or creating a near-real-time reader in {@link
            IndexWriter#getReader}.  Default value is {@link
            IndexReader#DEFAULT_TERMS_INDEX_DIVISOR}. 
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetReaderTermsIndexDivisor">
            @see #setReaderTermsIndexDivisor 
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMaxBufferedDocs(System.Int32)">
            <summary>Determines the minimal number of documents required
            before the buffered in-memory documents are flushed as
            a new Segment.  Large values generally gives faster
            indexing.
            
            <p/>When this is set, the writer will flush every
            maxBufferedDocs added documents.  Pass in {@link
            #DISABLE_AUTO_FLUSH} to prevent triggering a flush due
            to number of buffered documents.  Note that if flushing
            by RAM usage is also enabled, then the flush will be
            triggered by whichever comes first.<p/>
            
            <p/>Disabled by default (writer flushes by RAM usage).<p/>
            
            </summary>
            <throws>  IllegalArgumentException if maxBufferedDocs is </throws>
            <summary> enabled but smaller than 2, or it disables maxBufferedDocs
            when ramBufferSize is already disabled
            </summary>
            <seealso cref="!:setRAMBufferSizeMB">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.PushMaxBufferedDocs">
            <summary> If we are flushing by doc count (not by RAM usage), and
            using LogDocMergePolicy then push maxBufferedDocs down
            as its minMergeDocs, to keep backwards compatibility.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMaxBufferedDocs">
            <summary> Returns the number of buffered added documents that will
            trigger a flush if enabled.
            </summary>
            <seealso cref="!:setMaxBufferedDocs">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetRAMBufferSizeMB(System.Double)">
            <summary>Determines the amount of RAM that may be used for
            buffering added documents and deletions before they are
            flushed to the Directory.  Generally for faster
            indexing performance it's best to flush by RAM usage
            instead of document count and use as large a RAM buffer
            as you can.
            
            <p/>When this is set, the writer will flush whenever
            buffered documents and deletions use this much RAM.
            Pass in {@link #DISABLE_AUTO_FLUSH} to prevent
            triggering a flush due to RAM usage.  Note that if
            flushing by document count is also enabled, then the
            flush will be triggered by whichever comes first.<p/>
            
            <p/> <b>NOTE</b>: the account of RAM usage for pending
            deletions is only approximate.  Specifically, if you
            delete by Query, Lucene currently has no way to measure
            the RAM usage if individual Queries so the accounting
            will under-estimate and you should compensate by either
            calling commit() periodically yourself, or by using
            {@link #setMaxBufferedDeleteTerms} to flush by count
            instead of RAM usage (each buffered delete Query counts
            as one).
            
            <p/>
            <b>NOTE</b>: because IndexWriter uses <code>int</code>s when managing its
            internal storage, the absolute maximum value for this setting is somewhat
            less than 2048 MB. The precise limit depends on various factors, such as
            how large your documents are, how many fields have norms, etc., so it's
            best to set this value comfortably under 2048.
            <p/>
            
            <p/> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.<p/>
            
            </summary>
            <throws>  IllegalArgumentException if ramBufferSize is </throws>
            <summary> enabled but non-positive, or it disables ramBufferSize
            when maxBufferedDocs is already disabled
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetRAMBufferSizeMB">
            <summary> Returns the value set by {@link #setRAMBufferSizeMB} if enabled.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMaxBufferedDeleteTerms(System.Int32)">
            <summary> <p/>Determines the minimal number of delete terms required before the buffered
            in-memory delete terms are applied and flushed. If there are documents
            buffered in memory at the time, they are merged and a new segment is
            created.<p/>
            <p/>Disabled by default (writer flushes by RAM usage).<p/>
            
            </summary>
            <throws>  IllegalArgumentException if maxBufferedDeleteTerms </throws>
            <summary> is enabled but smaller than 1
            </summary>
            <seealso cref="!:setRAMBufferSizeMB">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMaxBufferedDeleteTerms">
            <summary> Returns the number of buffered deleted terms that will
            trigger a flush if enabled.
            </summary>
            <seealso cref="!:setMaxBufferedDeleteTerms">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMergeFactor(System.Int32)">
            <summary>Determines how often segment indices are merged by addDocument().  With
            smaller values, less RAM is used while indexing, and searches on
            unoptimized indices are faster, but indexing speed is slower.  With larger
            values, more RAM is used during indexing, and while searches on unoptimized
            indices are slower, indexing is faster.  Thus larger values (> 10) are best
            for batch index creation, and smaller values (&lt; 10) for indices that are
            interactively maintained.
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.setMergeFactor as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            
            <p/>This must never be less than 2.  The default value is 10.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMergeFactor">
            <summary> <p/>Returns the number of segments that are merged at
            once and also controls the total number of segments
            allowed to accumulate in the index.<p/>
            
            <p/>Note that this method is a convenience method: it
            just calls mergePolicy.getMergeFactor as long as
            mergePolicy is an instance of {@link LogMergePolicy}.
            Otherwise an IllegalArgumentException is thrown.<p/>
            
            </summary>
            <seealso cref="!:setMergeFactor">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMaxSyncPauseSeconds">
            <summary> Expert: returns max delay inserted before syncing a
            commit point.  On Windows, at least, pausing before
            syncing can increase net indexing throughput.  The
            delay is variable based on size of the segment's files,
            and is only inserted when using
            ConcurrentMergeScheduler for merges.
            </summary>
            <deprecated> This will be removed in 3.0, when
            autoCommit=true is removed from IndexWriter.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMaxSyncPauseSeconds(System.Double)">
            <summary> Expert: sets the max delay before syncing a commit
            point.
            </summary>
            <seealso cref="!:getMaxSyncPauseSeconds">
            </seealso>
            <deprecated> This will be removed in 3.0, when
            autoCommit=true is removed from IndexWriter.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetDefaultInfoStream(System.IO.StreamWriter)">
            <summary>If non-null, this will be the default infoStream used
            by a newly instantiated IndexWriter.
            </summary>
            <seealso cref="!:setInfoStream">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetDefaultInfoStream">
            <summary> Returns the current default infoStream for newly
            instantiated IndexWriters.
            </summary>
            <seealso cref="!:setDefaultInfoStream">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetInfoStream(System.IO.StreamWriter)">
            <summary>If non-null, information about merges, deletes and a
            message when maxFieldLength is reached will be printed
            to this.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetInfoStream">
            <summary> Returns the current infoStream in use by this writer.</summary>
            <seealso cref="!:setInfoStream">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Verbose">
            <summary>Returns true if verbosing is enabled (i.e., infoStream != null). </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetWriteLockTimeout(System.Int64)">
            <seealso cref="!:setDefaultWriteLockTimeout"> to change the default value for all instances of IndexWriter.
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetWriteLockTimeout">
            <summary> Returns allowed timeout when acquiring the write lock.</summary>
            <seealso cref="!:setWriteLockTimeout">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetDefaultWriteLockTimeout(System.Int64)">
            <summary> Sets the default (for any instance of IndexWriter) maximum time to wait for a write lock (in
            milliseconds).
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetDefaultWriteLockTimeout">
            <summary> Returns default write lock timeout for newly
            instantiated IndexWriters.
            </summary>
            <seealso cref="!:setDefaultWriteLockTimeout">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Close">
            <summary> Commits all changes to an index and closes all
            associated files.  Note that this may be a costly
            operation, so, try to re-use a single writer instead of
            closing and opening a new one.  See {@link #Commit()} for
            caveats about write caching done by some IO devices.
            
            <p/> If an Exception is hit during close, eg due to disk
            full or some other reason, then both the on-disk index
            and the internal state of the IndexWriter instance will
            be consistent.  However, the close will not be complete
            even though part of it (flushing buffered documents)
            may have succeeded, so the write lock will still be
            held.<p/>
            
            <p/> If you can correct the underlying cause (eg free up
            some disk space) then you can call close() again.
            Failing that, if you want to force the write lock to be
            released (dangerous, because you may then lose buffered
            docs in the IndexWriter instance) then you can do
            something like this:<p/>
            
            <pre>
            try {
            writer.close();
            } finally {
            if (IndexWriter.isLocked(directory)) {
            IndexWriter.unlock(directory);
            }
            }
            </pre>
            
            after which, you must be certain not to use the writer
            instance anymore.<p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer, again.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Close(System.Boolean)">
            <summary> Closes the index with or without waiting for currently
            running merges to finish.  This is only meaningful when
            using a MergeScheduler that runs merges in background
            threads.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer, again.  See <a
            href="#OOME">above</a> for details.<p/>
            
            <p/><b>NOTE</b>: it is dangerous to always call
            close(false), especially when IndexWriter is not open
            for very long, because this can result in "merge
            starvation" whereby long merges will never have a
            chance to finish.  This will cause too many segments in
            your index over time.<p/>
            
            </summary>
            <param name="waitForMerges">if true, this call will block
            until all merges complete; else, it will ask all
            running merges to abort, wait until those merges have
            finished (which should be at most a few seconds), and
            then return.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.FlushDocStores">
            <summary>Tells the docWriter to close its currently open shared
            doc stores (stored fields &amp; vectors files).
            Return value specifices whether new doc store files are compound or not.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetDirectory">
            <summary>Returns the Directory used by this index. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetAnalyzer">
            <summary>Returns the analyzer used by this index. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DocCount">
            <summary>Returns the number of documents currently in this
            index, not counting deletions.
            </summary>
            <deprecated> Please use {@link #MaxDoc()} (same as this
            method) or {@link #NumDocs()} (also takes deletions
            into account), instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MaxDoc">
            <summary>Returns total number of docs in this index, including
            docs not yet flushed (still in the RAM buffer),
            not counting deletions.
            </summary>
            <seealso cref="!:numDocs">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.NumDocs">
            <summary>Returns total number of docs in this index, including
            docs not yet flushed (still in the RAM buffer), and
            including deletions.  <b>NOTE:</b> buffered deletions
            are not counted.  If you really need these to be
            counted you should call {@link #Commit()} first.
            </summary>
            <seealso cref="!:numDocs">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.maxFieldLength">
            <summary> The maximum number of terms that will be indexed for a single field in a
            document.  This limits the amount of memory required for indexing, so that
            collections with very large files will not crash the indexing process by
            running out of memory.<p/>
            Note that this effectively truncates large documents, excluding from the
            index terms that occur further in the document.  If you know your source
            documents are large, be sure to set this value high enough to accomodate
            the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
            is your memory, but you should anticipate an OutOfMemoryError.<p/>
            By default, no more than 10,000 terms will be indexed for a field.
            
            </summary>
            <seealso cref="T:Lucene.Net.Index.IndexWriter.MaxFieldLength">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.AddDocument(Lucene.Net.Documents.Document)">
            <summary> Adds a document to this index.  If the document contains more than
            {@link #SetMaxFieldLength(int)} terms for a given field, the remainder are
            discarded.
            
            <p/> Note that if an Exception is hit (for example disk full)
            then the index will be consistent, but this document
            may not have been added.  Furthermore, it's possible
            the index will have one segment in non-compound format
            even when using compound files (when a merge has
            partially succeeded).<p/>
            
            <p/> This method periodically flushes pending documents
            to the Directory (see <a href="#flush">above</a>), and
            also periodically triggers segment merges in the index
            according to the {@link MergePolicy} in use.<p/>
            
            <p/>Merges temporarily consume space in the
            directory. The amount of space required is up to 1X the
            size of all segments being merged, when no
            readers/searchers are open against the index, and up to
            2X the size of all segments being merged when
            readers/searchers are open against the index (see
            {@link #Optimize()} for details). The sequence of
            primitive merge operations performed is governed by the
            merge policy.
            
            <p/>Note that each term in the document can be no longer
            than 16383 characters, otherwise an
            IllegalArgumentException will be thrown.<p/>
            
            <p/>Note that it's possible to create an invalid Unicode
            string in java if a UTF16 surrogate pair is malformed.
            In this case, the invalid characters are silently
            replaced with the Unicode replacement character
            U+FFFD.<p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.AddDocument(Lucene.Net.Documents.Document,Lucene.Net.Analysis.Analyzer)">
            <summary> Adds a document to this index, using the provided analyzer instead of the
            value of {@link #GetAnalyzer()}.  If the document contains more than
            {@link #SetMaxFieldLength(int)} terms for a given field, the remainder are
            discarded.
            
            <p/>See {@link #AddDocument(Document)} for details on
            index and IndexWriter state after an Exception, and
            flushing/merging temporary free space requirements.<p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DeleteDocuments(Lucene.Net.Index.Term)">
            <summary> Deletes the document(s) containing <code>term</code>.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="term">the term to identify the documents to be deleted
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DeleteDocuments(Lucene.Net.Index.Term[])">
            <summary> Deletes the document(s) containing any of the
            terms. All deletes are flushed at the same time.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="terms">array of terms to identify the documents
            to be deleted
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DeleteDocuments(Lucene.Net.Search.Query)">
            <summary> Deletes the document(s) matching the provided query.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="query">the query to identify the documents to be deleted
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DeleteDocuments(Lucene.Net.Search.Query[])">
            <summary> Deletes the document(s) matching any of the provided queries.
            All deletes are flushed at the same time.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="queries">array of queries to identify the documents
            to be deleted
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.UpdateDocument(Lucene.Net.Index.Term,Lucene.Net.Documents.Document)">
            <summary> Updates a document by first deleting the document(s)
            containing <code>term</code> and then adding the new
            document.  The delete and then add are atomic as seen
            by a reader on the same index (flush may happen only after
            the add).
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="term">the term to identify the document(s) to be
            deleted
            </param>
            <param name="doc">the document to be added
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.UpdateDocument(Lucene.Net.Index.Term,Lucene.Net.Documents.Document,Lucene.Net.Analysis.Analyzer)">
            <summary> Updates a document by first deleting the document(s)
            containing <code>term</code> and then adding the new
            document.  The delete and then add are atomic as seen
            by a reader on the same index (flush may happen only after
            the add).
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="term">the term to identify the document(s) to be
            deleted
            </param>
            <param name="doc">the document to be added
            </param>
            <param name="analyzer">the analyzer to use when analyzing the document
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.infoStream">
            <summary>If non-null, information about merges will be printed to this.</summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Optimize">
            <summary> Requests an "optimize" operation on an index, priming the index
            for the fastest available search. Traditionally this has meant
            merging all segments into a single segment as is done in the
            default merge policy, but individaul merge policies may implement
            optimize in different ways.
            
            <p/>It is recommended that this method be called upon completion of indexing.  In
            environments with frequent updates, optimize is best done during low volume times, if at all. 
            
            <p/>
            <p/>See http://www.gossamer-threads.com/lists/lucene/java-dev/47895 for more discussion. <p/>
            
            <p/>Note that optimize requires 2X the index size free
            space in your Directory (3X if you're using compound
            file format).  For example, if your index
            size is 10 MB then you need 20 MB free for optimize to
            complete (30 MB if you're using compound fiel format).<p/>
            
            <p/>If some but not all readers re-open while an
            optimize is underway, this will cause &gt; 2X temporary
            space to be consumed as those new readers will then
            hold open the partially optimized segments at that
            time.  It is best not to re-open readers while optimize
            is running.<p/>
            
            <p/>The actual temporary usage could be much less than
            these figures (it depends on many factors).<p/>
            
            <p/>In general, once the optimize completes, the total size of the
            index will be less than the size of the starting index.
            It could be quite a bit smaller (if there were many
            pending deletes) or just slightly smaller.<p/>
            
            <p/>If an Exception is hit during optimize(), for example
            due to disk full, the index will not be corrupt and no
            documents will have been lost.  However, it may have
            been partially optimized (some segments were merged but
            not all), and it's possible that one of the segments in
            the index will be in non-compound format even when
            using compound file format.  This will occur when the
            Exception is hit during conversion of the segment into
            compound format.<p/>
            
            <p/>This call will optimize those segments present in
            the index when the call started.  If other threads are
            still adding documents and flushing segments, those
            newly created segments will not be optimized unless you
            call optimize again.<p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <seealso cref="!:LogMergePolicy.findMergesForOptimize">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Optimize(System.Int32)">
            <summary> Optimize the index down to &lt;= maxNumSegments.  If
            maxNumSegments==1 then this is the same as {@link
            #Optimize()}.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="maxNumSegments">maximum number of segments left
            in the index after optimization finishes
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Optimize(System.Boolean)">
            <summary>Just like {@link #Optimize()}, except you can specify
            whether the call should block until the optimize
            completes.  This is only meaningful with a
            {@link MergeScheduler} that is able to run merges in
            background threads.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Optimize(System.Int32,System.Boolean)">
            <summary>Just like {@link #Optimize(int)}, except you can
            specify whether the call should block until the
            optimize completes.  This is only meaningful with a
            {@link MergeScheduler} that is able to run merges in
            background threads.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.OptimizeMergesPending">
            <summary>Returns true if any merges in pendingMerges or
            runningMerges are optimization merges. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ExpungeDeletes(System.Boolean)">
            <summary>Just like {@link #ExpungeDeletes()}, except you can
            specify whether the call should block until the
            operation completes.  This is only meaningful with a
            {@link MergeScheduler} that is able to run merges in
            background threads.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ExpungeDeletes">
            <summary>Expunges all deletes from the index.  When an index
            has many document deletions (or updates to existing
            documents), it's best to either call optimize or
            expungeDeletes to remove all unused data in the index
            associated with the deleted documents.  To see how
            many deletions you have pending in your index, call
            {@link IndexReader#numDeletedDocs}
            This saves disk space and memory usage while
            searching.  expungeDeletes should be somewhat faster
            than optimize since it does not insist on reducing the
            index to a single segment (though, this depends on the
            {@link MergePolicy}; see {@link
            MergePolicy#findMergesToExpungeDeletes}.). Note that
            this call does not first commit any buffered
            documents, so you must do so yourself if necessary.
            See also {@link #ExpungeDeletes(boolean)}
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MaybeMerge">
            <summary> Expert: asks the mergePolicy whether any merges are
            necessary now and if so, runs the requested merges and
            then iterate (test again if merges are needed) until no
            more merges are returned by the mergePolicy.
            
            Explicit calls to maybeMerge() are usually not
            necessary. The most common case is when merge policy
            parameters have changed.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetNextMerge">
            <summary>Expert: the {@link MergeScheduler} calls this method
            to retrieve the next merge requested by the
            MergePolicy 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetNextExternalMerge">
            <summary>Like getNextMerge() except only returns a merge if it's
            external. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Abort">
            <deprecated> Please use {@link #rollback} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Rollback">
            <summary> Close the <code>IndexWriter</code> without committing
            any changes that have occurred since the last commit
            (or since it was opened, if commit hasn't been called).
            This removes any temporary files that had been created,
            after which the state of the index will be the same as
            it was when commit() was last called or when this
            writer was first opened.  This can only be called when
            this IndexWriter was opened with
            <code>autoCommit=false</code>.  This also clears a
            previous call to {@link #prepareCommit}.
            </summary>
            <throws>  IllegalStateException if this is called when </throws>
            <summary>  the writer was opened with <code>autoCommit=true</code>.
            </summary>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DeleteAll">
            <summary> Delete all documents in the index.
            
            <p/>This method will drop all buffered documents and will 
            remove all segments from the index. This change will not be
            visible until a {@link #Commit()} has been called. This method
            can be rolled back using {@link #Rollback()}.<p/>
            
            <p/>NOTE: this method is much faster than using deleteDocuments( new MatchAllDocsQuery() ).<p/>
            
            <p/>NOTE: this method will forcefully abort all merges
            in progress.  If other threads are running {@link
            #Optimize()} or any of the addIndexes methods, they
            will receive {@link MergePolicy.MergeAbortedException}s.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.WaitForMerges">
            <summary> Wait for any currently outstanding merges to finish.
            
            <p/>It is guaranteed that any merges started prior to calling this method 
            will have completed once this method completes.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.AddIndexes(Lucene.Net.Store.Directory[])">
            <summary>Merges all segments from an array of indexes into this index.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <deprecated> Use {@link #addIndexesNoOptimize} instead,
            then separately call {@link #optimize} afterwards if
            you need to.
            
            </deprecated>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.AddIndexesNoOptimize(Lucene.Net.Store.Directory[])">
            <summary> Merges all segments from an array of indexes into this
            index.
            
            <p/>This may be used to parallelize batch indexing.  A large document
            collection can be broken into sub-collections.  Each sub-collection can be
            indexed in parallel, on a different thread, process or machine.  The
            complete index can then be created by merging sub-collection indexes
            with this method.
            
            <p/><b>NOTE:</b> the index in each Directory must not be
            changed (opened by a writer) while this method is
            running.  This method does not acquire a write lock in
            each input Directory, so it is up to the caller to
            enforce this.
            
            <p/><b>NOTE:</b> while this is running, any attempts to
            add or delete documents (with another thread) will be
            paused until this method completes.
            
            <p/>This method is transactional in how Exceptions are
            handled: it does not commit a new segments_N file until
            all indexes are added.  This means if an Exception
            occurs (for example disk full), then either no indexes
            will have been added or they all will have been.<p/>
            
            <p/>Note that this requires temporary free space in the
            Directory up to 2X the sum of all input indexes
            (including the starting index).  If readers/searchers
            are open against the starting index, then temporary
            free space required will be higher by the size of the
            starting index (see {@link #Optimize()} for details).
            <p/>
            
            <p/>Once this completes, the final size of the index
            will be less than the sum of all input index sizes
            (including the starting index).  It could be quite a
            bit smaller (if there were many pending deletes) or
            just slightly smaller.<p/>
            
            <p/>
            This requires this index not be among those to be added.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.AddIndexes(Lucene.Net.Index.IndexReader[])">
            <summary>Merges the provided indexes into this index.
            <p/>After this completes, the index is optimized. <p/>
            <p/>The provided IndexReaders are not closed.<p/>
            
            <p/><b>NOTE:</b> while this is running, any attempts to
            add or delete documents (with another thread) will be
            paused until this method completes.
            
            <p/>See {@link #AddIndexesNoOptimize(Directory[])} for
            details on transactional semantics, temporary free
            space required in the Directory, and non-CFS segments
            on an Exception.<p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DoAfterFlush">
            <summary>
             A hook for extending classes to execute operations after pending added and
             deleted documents have been flushed to the Directory but before the change
             is committed (new segments_N file written).
            </summary>   
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Flush">
            <summary> Flush all in-memory buffered updates (adds and deletes)
            to the Directory. 
            <p/>Note: while this will force buffered docs to be
            pushed into the index, it will not make these docs
            visible to a reader.  Use {@link #Commit()} instead
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <deprecated> please call {@link #Commit()}) instead
            
            </deprecated>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DoBeforeFlush">
            <summary>
             A hook for extending classes to execute operations before pending added and
             deleted documents are flushed to the Directory.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.PrepareCommit">
            <summary>Expert: prepare for commit.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a href="#OOME">above</a> for details.<p/>
            
            </summary>
            <seealso cref="!:PrepareCommit(Map)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.PrepareCommit(System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary><p/>Expert: prepare for commit, specifying
            commitUserData Map (String -> String).  This does the
            first phase of 2-phase commit.  You can only call this
            when autoCommit is false.  This method does all steps
            necessary to commit changes since this writer was
            opened: flushes pending added and deleted docs, syncs
            the index files, writes most of next segments_N file.
            After calling this you must call either {@link
            #Commit()} to finish the commit, or {@link
            #Rollback()} to revert the commit and undo all changes
            done since the writer was opened.<p/>
            
            You can also just call {@link #Commit(Map)} directly
            without prepareCommit first in which case that method
            will internally call prepareCommit.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            
            </summary>
            <param name="commitUserData">Opaque Map (String->String)
            that's recorded into the segments file in the index,
            and retrievable by {@link
            IndexReader#getCommitUserData}.  Note that when
            IndexWriter commits itself, for example if open with
            autoCommit=true, or, during {@link #close}, the
            commitUserData is unchanged (just carried over from
            the prior commit).  If this is null then the previous
            commitUserData is kept.  Also, the commitUserData will
            only "stick" if there are actually changes in the
            index to commit.  Therefore it's best to use this
            feature only when autoCommit is false.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Commit">
            <summary> <p/>Commits all pending changes (added &amp; deleted
            documents, optimizations, segment merges, added
            indexes, etc.) to the index, and syncs all referenced
            index files, such that a reader will see the changes
            and the index updates will survive an OS or machine
            crash or power loss.  Note that this does not wait for
            any running background merges to finish.  This may be a
            costly operation, so you should test the cost in your
            application and do it only when really necessary.<p/>
            
            <p/> Note that this operation calls Directory.sync on
            the index files.  That call should not return until the
            file contents &amp; metadata are on stable storage.  For
            FSDirectory, this calls the OS's fsync.  But, beware:
            some hardware devices may in fact cache writes even
            during fsync, and return before the bits are actually
            on stable storage, to give the appearance of faster
            performance.  If you have such a device, and it does
            not have a battery backup (for example) then on power
            loss it may still lose data.  Lucene cannot guarantee
            consistency on such devices.  <p/>
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a href="#OOME">above</a> for details.<p/>
            
            </summary>
            <seealso cref="!:prepareCommit">
            </seealso>
            <seealso cref="!:Commit(Map)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Commit(System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary>Commits all changes to the index, specifying a
            commitUserData Map (String -> String).  This just
            calls {@link #PrepareCommit(Map)} (if you didn't
            already call it) and then {@link #finishCommit}.
            
            <p/><b>NOTE</b>: if this method hits an OutOfMemoryError
            you should immediately close the writer.  See <a
            href="#OOME">above</a> for details.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Flush(System.Boolean,System.Boolean,System.Boolean)">
            <summary> Flush all in-memory buffered udpates (adds and deletes)
            to the Directory.
            </summary>
            <param name="triggerMerge">if true, we may merge segments (if
            deletes or docs were flushed) if necessary
            </param>
            <param name="flushDocStores">if false we are allowed to keep
            doc stores open to share with the next segment
            </param>
            <param name="flushDeletes">whether pending deletes should also
            be flushed
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.RamSizeInBytes">
            <summary>Expert:  Return the total size of all index files currently cached in memory.
            Useful for size management with flushRamDocs()
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.NumRamDocs">
            <summary>Expert:  Return the number of documents currently
            buffered in RAM. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.CommitMergedDeletes(Lucene.Net.Index.MergePolicy.OneMerge,Lucene.Net.Index.SegmentReader)">
            <summary>Carefully merges deletes for the segments we just
            merged.  This is tricky because, although merging will
            clear all deletes (compacts the documents), new
            deletes may have been flushed to the segments since
            the merge was started.  This method "carries over"
            such new deletes onto the newly merged segment, and
            saves the resulting deletes file (incrementing the
            delete generation for merge.info).  If no deletes were
            flushed, no new deletes file is saved. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Merge(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary> Merges the indicated segments, replacing them in the stack with a
            single segment.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MergeSuccess(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Hook that's called when the specified merge is complete. </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.RegisterMerge(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Checks whether this merge involves any segments
            already participating in a merge.  If not, this merge
            is "registered", meaning we record that its segments
            are now participating in a merge, and true is
            returned.  Else (the merge conflicts) false is
            returned. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MergeInit(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Does initial setup for a merge, which is fast but holds
            the synchronized lock on IndexWriter instance.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.DoCommitBeforeMergeCFS(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>This is called after merging a segment and before
            building its CFS.  Return true if the files should be
            sync'd.  If you return false, then the source segment
            files that were merged cannot be deleted until the CFS
            file is built &amp; sync'd.  So, returning false consumes
            more transient disk space, but saves performance of
            not having to sync files which will shortly be deleted
            anyway.
            </summary>
            <deprecated> -- this will be removed in 3.0 when
            autoCommit is hardwired to false 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MergeFinish(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Does fininishing for a merge, which is fast but holds
            the synchronized lock on IndexWriter instance. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MergeMiddle(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Does the actual (time-consuming) work of the merge,
            but without holding synchronized lock on IndexWriter
            instance 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.WaitForAllSynced(System.Collections.Generic.ICollection{System.String})">
            <summary>Blocks until all files in syncing are sync'd </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SyncPause(System.Int64)">
            <summary>Pauses before syncing.  On Windows, at least, it's
            best (performance-wise) to pause in order to let OS
            flush writes to disk on its own, before forcing a
            sync.
            </summary>
            <deprecated> -- this will be removed in 3.0 when
            autoCommit is hardwired to false 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.StartCommit(System.Int64,System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary>Walk through all files referenced by the current
            segmentInfos and ask the Directory to sync each file,
            if it wasn't already.  If that succeeds, then we
            prepare a new segments_N file but do not fully commit
            it. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.IsLocked(Lucene.Net.Store.Directory)">
            <summary> Returns <code>true</code> iff the index in the named directory is
            currently locked.
            </summary>
            <param name="directory">the directory to check for a lock
            </param>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.IsLocked(System.String)">
            <summary> Returns <code>true</code> iff the index in the named directory is
            currently locked.
            </summary>
            <param name="directory">the directory to check for a lock
            </param>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #IsLocked(Directory)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.Unlock(Lucene.Net.Store.Directory)">
            <summary> Forcibly unlocks the index in the named directory.
            <p/>
            Caution: this should only be used by failure recovery code,
            when it is known that no other process nor thread is in fact
            currently accessing this index.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetMergedSegmentWarmer(Lucene.Net.Index.IndexWriter.IndexReaderWarmer)">
            <summary>Set the merged segment warmer.  See {@link
            IndexReaderWarmer}. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.GetMergedSegmentWarmer">
            <summary>Returns the current merged segment warmer.  See {@link
            IndexReaderWarmer}. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.SetAllowMinus1Position">
            <summary>Deprecated: emulates IndexWriter's buggy behavior when
            first token(s) have positionIncrement==0 (ie, prior to
            fixing LUCENE-1542) 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexWriter.ReaderPool">
            <summary>Holds shared SegmentReader instances. IndexWriter uses
            SegmentReaders for 1) applying deletes, 2) doing
            merges, 3) handing out a real-time reader.  This pool
            reuses instances of the SegmentReaders in all these
            places if it is in "near real-time mode" (getReader()
            has been called on this instance). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Clear(Lucene.Net.Index.SegmentInfos)">
            <summary>Forcefully clear changes for the specifed segments,
            and remove from the pool.   This is called on succesful merge. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Release(Lucene.Net.Index.SegmentReader)">
            <summary> Release the segment reader (i.e. decRef it and close if there
            are no more references.
            </summary>
            <param name="sr">
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Release(Lucene.Net.Index.SegmentReader,System.Boolean)">
            <summary> Release the segment reader (i.e. decRef it and close if there
            are no more references.
            </summary>
            <param name="sr">
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Close">
            <summary>Remove all our references to readers, and commits
            any pending changes. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Commit">
            <summary> Commit all segment reader in the pool.</summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.GetReadOnlyClone(Lucene.Net.Index.SegmentInfo,System.Boolean,System.Int32)">
            <summary> Returns a ref to a clone.  NOTE: this clone is not
            enrolled in the pool, so you should simply close()
            it when you're done (ie, do not call release()).
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Get(Lucene.Net.Index.SegmentInfo,System.Boolean)">
            <summary> Obtain a SegmentReader from the readerPool.  The reader
            must be returned by calling {@link #Release(SegmentReader)}
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.ReaderPool.Release(Lucene.Net.Index.SegmentReader)">
            </seealso>
            <param name="info">
            </param>
            <param name="doOpenStores">
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.ReaderPool.Get(Lucene.Net.Index.SegmentInfo,System.Boolean,System.Int32,System.Int32)">
            <summary> Obtain a SegmentReader from the readerPool.  The reader
            must be returned by calling {@link #Release(SegmentReader)}
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.ReaderPool.Release(Lucene.Net.Index.SegmentReader)">
            </seealso>
            <param name="info">
            </param>
            <param name="doOpenStores">
            </param>
            <param name="readBufferSize">
            </param>
            <param name="termsIndexDivisor">
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Index.IndexWriter.MaxFieldLength">
            <summary> Specifies maximum field length (in number of tokens/terms) in {@link IndexWriter} constructors.
            {@link #SetMaxFieldLength(int)} overrides the value set by
            the constructor.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MaxFieldLength.#ctor(System.String,System.Int32)">
            <summary> Private type-safe-enum-pattern constructor.
            
            </summary>
            <param name="name">instance name
            </param>
            <param name="limit">maximum field length
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexWriter.MaxFieldLength.#ctor(System.Int32)">
            <summary> Public constructor to allow users to specify the maximum field size limit.
            
            </summary>
            <param name="limit">The maximum field length
            </param>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.MaxFieldLength.UNLIMITED">
            <summary>Sets the maximum field length to {@link Integer#MAX_VALUE}. </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexWriter.MaxFieldLength.LIMITED">
            <summary>  Sets the maximum field length to 
            {@link #DEFAULT_MAX_FIELD_LENGTH} 
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexWriter.IndexReaderWarmer">
            <summary>If {@link #getReader} has been called (ie, this writer
            is in near real-time mode), then after a merge
            completes, this class can be invoked to warm the
            reader on the newly merged segment, before the merge
            commits.  This is not required for near real-time
            search, but will reduce search latency on opening a
            new near real-time reader after a merge completes.
            
            <p/><b>NOTE:</b> This API is experimental and might
            change in incompatible ways in the next release.<p/>
            
            <p/><b>NOTE</b>: warm is called before any deletes have
            been carried over to the merged segment. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsDocsWriter.AddDoc(System.Int32,System.Int32)">
            <summary>Adds a new doc in this term.  If this returns null
            then we just skip consuming positions/payloads. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsDocsWriter.Finish">
            <summary>Called when we are done adding docs to this term </summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldInvertState">
            <summary> This class tracks the number and position / offset parameters of terms
            being added to the index. The information collected in this class is
            also used to calculate the normalization factor for a field.
            
            <p/><b>WARNING</b>: This API is new and experimental, and may suddenly
            change.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.Reset(System.Single)">
            <summary> Re-initialize the state, using this boost value.</summary>
            <param name="docBoost">boost value to use.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.GetPosition">
            <summary> Get the last processed term position.</summary>
            <returns> the position
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.GetLength">
            <summary> Get total number of terms in this field.</summary>
            <returns> the length
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.GetNumOverlap">
            <summary> Get the number of terms with <code>positionIncrement == 0</code>.</summary>
            <returns> the numOverlap
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.GetOffset">
            <summary> Get end offset of the last processed term.</summary>
            <returns> the offset
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.FieldInvertState.GetBoost">
            <summary> Get boost value. This is the cumulative product of
            document boost and field boost for all field instances
            sharing the same field name.
            </summary>
            <returns> the boost
            </returns>
        </member>
        <member name="T:Lucene.Net.Documents.DateField">
            <summary> Provides support for converting dates to strings and vice-versa.
            The strings are structured so that lexicographic sorting orders by date,
            which makes them suitable for use as field values and search terms.
            
            <p/>Note that this class saves dates with millisecond granularity,
            which is bad for {@link TermRangeQuery} and {@link PrefixQuery}, as those
            queries are expanded to a BooleanQuery with a potentially large number
            of terms when searching. Thus you might want to use
            {@link DateTools} instead.
            
            <p/>
            Note: dates before 1970 cannot be used, and therefore cannot be
            indexed when using this class. See {@link DateTools} for an
            alternative without such a limitation.
            
            <p/>
            Another approach is {@link NumericUtils}, which provides
            a sortable binary representation (prefix encoded) of numeric values, which
            date/time are.
            For indexing a {@link Date} or {@link Calendar}, just get the unix timestamp as
            <code>long</code> using {@link Date#getTime} or {@link Calendar#getTimeInMillis} and
            index this as a numeric value with {@link NumericField}
            and use {@link NumericRangeQuery} to query it.
            
            </summary>
            <deprecated> If you build a new index, use {@link DateTools} or 
            {@link NumericField} instead.
            This class is included for use with existing
            indices and will be removed in a future release.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.DateField.DateToString(System.DateTime)">
            <summary> Converts a Date to a string suitable for indexing.</summary>
            <throws>  RuntimeException if the date specified in the </throws>
            <summary> method argument is before 1970
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateField.TimeToString(System.Int64)">
            <summary> Converts a millisecond time to a string suitable for indexing.</summary>
            <throws>  RuntimeException if the time specified in the </throws>
            <summary> method argument is negative, that is, before 1970
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateField.StringToTime(System.String)">
            <summary>Converts a string-encoded date into a millisecond time. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.DateField.StringToDate(System.String)">
            <summary>Converts a string-encoded date into a Date object. </summary>
        </member>
        <member name="T:Lucene.Net.Documents.CompressionTools">
            <summary>Simple utility class providing static methods to
            compress and decompress binary data for stored fields.
            This class uses java.util.zip.Deflater and Inflater
            classes to compress and decompress, which is the same
            format previously used by the now deprecated
            Field.Store.COMPRESS.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.Compress(System.Byte[],System.Int32,System.Int32,System.Int32)">
            <summary>Compresses the specified byte range using the
            specified compressionLevel (constants are defined in
            java.util.zip.Deflater). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.Compress(System.Byte[],System.Int32,System.Int32)">
            <summary>Compresses the specified byte range, with default BEST_COMPRESSION level </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.Compress(System.Byte[])">
            <summary>Compresses all bytes in the array, with default BEST_COMPRESSION level </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.CompressString(System.String)">
            <summary>Compresses the String value, with default BEST_COMPRESSION level </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.CompressString(System.String,System.Int32)">
            <summary>Compresses the String value using the specified
            compressionLevel (constants are defined in
            java.util.zip.Deflater). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.Decompress(System.Byte[])">
            <summary>Decompress the byte array previously returned by
            compress 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.CompressionTools.DecompressString(System.Byte[])">
            <summary>Decompress the byte array previously returned by
            compressString back into a String 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.OffsetAttributeImpl">
            <summary> The start and end character offset of a Token. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttributeImpl.StartOffset">
            <summary>Returns this Token's starting offset, the position of the first character
            corresponding to this token in the source text.
            Note that the difference between endOffset() and startOffset() may not be
            equal to termText.length(), as the term text may have been altered by a
            stemmer or some other filter. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttributeImpl.SetOffset(System.Int32,System.Int32)">
            <summary>Set the starting and ending offset.
            See StartOffset() and EndOffset()
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.OffsetAttributeImpl.EndOffset">
            <summary>Returns this Token's ending offset, one greater than the position of the
            last character corresponding to this token in the source text. The length
            of the token in the source text is (endOffset - startOffset). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.NumericUtils">
            <summary> This is a helper class to generate prefix-encoded representations for numerical values
            and supplies converters to represent float/double values as sortable integers/longs.
            
            <p/>To quickly execute range queries in Apache Lucene, a range is divided recursively
            into multiple intervals for searching: The center of the range is searched only with
            the lowest possible precision in the trie, while the boundaries are matched
            more exactly. This reduces the number of terms dramatically.
            
            <p/>This class generates terms to achive this: First the numerical integer values need to
            be converted to strings. For that integer values (32 bit or 64 bit) are made unsigned
            and the bits are converted to ASCII chars with each 7 bit. The resulting string is
            sortable like the original integer value. Each value is also prefixed
            (in the first char) by the <code>shift</code> value (number of bits removed) used
            during encoding.
            
            <p/>To also index floating point numbers, this class supplies two methods to convert them
            to integer values by changing their bit layout: {@link #doubleToSortableLong},
            {@link #floatToSortableInt}. You will have no precision loss by
            converting floating point numbers to integers and back (only that the integer form
            is not usable). Other data types like dates can easily converted to longs or ints (e.g.
            date to long: {@link java.util.Date#getTime}).
            
            <p/>For easy usage, the trie algorithm is implemented for indexing inside
            {@link NumericTokenStream} that can index <code>int</code>, <code>long</code>,
            <code>float</code>, and <code>double</code>. For querying,
            {@link NumericRangeQuery} and {@link NumericRangeFilter} implement the query part
            for the same data types.
            
            <p/>This class can also be used, to generate lexicographically sortable (according
            {@link String#compareTo(String)}) representations of numeric data types for other
            usages (e.g. sorting).
            
            <p/><font color="red"><b>NOTE:</b> This API is experimental and
            might change in incompatible ways in the next release.</font>
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="F:Lucene.Net.Util.NumericUtils.PRECISION_STEP_DEFAULT">
            <summary> The default precision step used by {@link NumericField}, {@link NumericTokenStream},
            {@link NumericRangeQuery}, and {@link NumericRangeFilter} as default
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.NumericUtils.BUF_SIZE_LONG">
            <summary> Expert: The maximum term length (used for <code>char[]</code> buffer size)
            for encoding <code>long</code> values.
            </summary>
            <seealso cref="M:Lucene.Net.Util.NumericUtils.LongToPrefixCoded(System.Int64,System.Int32,System.Char[])">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Util.NumericUtils.BUF_SIZE_INT">
            <summary> Expert: The maximum term length (used for <code>char[]</code> buffer size)
            for encoding <code>int</code> values.
            </summary>
            <seealso cref="M:Lucene.Net.Util.NumericUtils.IntToPrefixCoded(System.Int32,System.Int32,System.Char[])">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Util.NumericUtils.SHIFT_START_LONG">
            <summary> Expert: Longs are stored at lower precision by shifting off lower bits. The shift count is
            stored as <code>SHIFT_START_LONG+shift</code> in the first character
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.NumericUtils.SHIFT_START_INT">
            <summary> Expert: Integers are stored at lower precision by shifting off lower bits. The shift count is
            stored as <code>SHIFT_START_INT+shift</code> in the first character
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.LongToPrefixCoded(System.Int64,System.Int32,System.Char[])">
            <summary> Expert: Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
            This is method is used by {@link NumericTokenStream}.
            </summary>
            <param name="val">the numeric value
            </param>
            <param name="shift">how many bits to strip from the right
            </param>
            <param name="buffer">that will contain the encoded chars, must be at least of {@link #BUF_SIZE_LONG}
            length
            </param>
            <returns> number of chars written to buffer
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.LongToPrefixCoded(System.Int64,System.Int32)">
            <summary> Expert: Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
            This is method is used by {@link LongRangeBuilder}.
            </summary>
            <param name="val">the numeric value
            </param>
            <param name="shift">how many bits to strip from the right
            </param>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.LongToPrefixCoded(System.Int64)">
            <summary> This is a convenience method, that returns prefix coded bits of a long without
            reducing the precision. It can be used to store the full precision value as a
            stored field in index.
            <p/>To decode, use {@link #prefixCodedToLong}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.IntToPrefixCoded(System.Int32,System.Int32,System.Char[])">
            <summary> Expert: Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
            This is method is used by {@link NumericTokenStream}.
            </summary>
            <param name="val">the numeric value
            </param>
            <param name="shift">how many bits to strip from the right
            </param>
            <param name="buffer">that will contain the encoded chars, must be at least of {@link #BUF_SIZE_INT}
            length
            </param>
            <returns> number of chars written to buffer
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.IntToPrefixCoded(System.Int32,System.Int32)">
            <summary> Expert: Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
            This is method is used by {@link IntRangeBuilder}.
            </summary>
            <param name="val">the numeric value
            </param>
            <param name="shift">how many bits to strip from the right
            </param>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.IntToPrefixCoded(System.Int32)">
            <summary> This is a convenience method, that returns prefix coded bits of an int without
            reducing the precision. It can be used to store the full precision value as a
            stored field in index.
            <p/>To decode, use {@link #prefixCodedToInt}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.PrefixCodedToLong(System.String)">
            <summary> Returns a long from prefixCoded characters.
            Rightmost bits will be zero for lower precision codes.
            This method can be used to decode e.g. a stored field.
            </summary>
            <throws>  NumberFormatException if the supplied string is </throws>
            <summary> not correctly prefix encoded.
            </summary>
            <seealso cref="M:Lucene.Net.Util.NumericUtils.LongToPrefixCoded(System.Int64)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.PrefixCodedToInt(System.String)">
            <summary> Returns an int from prefixCoded characters.
            Rightmost bits will be zero for lower precision codes.
            This method can be used to decode e.g. a stored field.
            </summary>
            <throws>  NumberFormatException if the supplied string is </throws>
            <summary> not correctly prefix encoded.
            </summary>
            <seealso cref="M:Lucene.Net.Util.NumericUtils.IntToPrefixCoded(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.DoubleToSortableLong(System.Double)">
            <summary> Converts a <code>double</code> value to a sortable signed <code>long</code>.
            The value is converted by getting their IEEE 754 floating-point "double format"
            bit layout and then some bits are swapped, to be able to compare the result as long.
            By this the precision is not reduced, but the value can easily used as a long.
            </summary>
            <seealso cref="!:sortableLongToDouble">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.DoubleToPrefixCoded(System.Double)">
            <summary> Convenience method: this just returns:
            longToPrefixCoded(doubleToSortableLong(val))
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.SortableLongToDouble(System.Int64)">
            <summary> Converts a sortable <code>long</code> back to a <code>double</code>.</summary>
            <seealso cref="!:doubleToSortableLong">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.PrefixCodedToDouble(System.String)">
            <summary> Convenience method: this just returns:
            sortableLongToDouble(prefixCodedToLong(val))
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.FloatToSortableInt(System.Single)">
            <summary> Converts a <code>float</code> value to a sortable signed <code>int</code>.
            The value is converted by getting their IEEE 754 floating-point "float format"
            bit layout and then some bits are swapped, to be able to compare the result as int.
            By this the precision is not reduced, but the value can easily used as an int.
            </summary>
            <seealso cref="!:sortableIntToFloat">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.FloatToPrefixCoded(System.Single)">
            <summary> Convenience method: this just returns:
            intToPrefixCoded(floatToSortableInt(val))
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.SortableIntToFloat(System.Int32)">
            <summary> Converts a sortable <code>int</code> back to a <code>float</code>.</summary>
            <seealso cref="!:floatToSortableInt">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.PrefixCodedToFloat(System.String)">
            <summary> Convenience method: this just returns:
            sortableIntToFloat(prefixCodedToInt(val))
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.SplitLongRange(Lucene.Net.Util.NumericUtils.LongRangeBuilder,System.Int32,System.Int64,System.Int64)">
            <summary> Expert: Splits a long range recursively.
            You may implement a builder that adds clauses to a
            {@link Lucene.Net.Search.BooleanQuery} for each call to its
            {@link LongRangeBuilder#AddRange(String,String)}
            method.
            <p/>This method is used by {@link NumericRangeQuery}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.SplitIntRange(Lucene.Net.Util.NumericUtils.IntRangeBuilder,System.Int32,System.Int32,System.Int32)">
            <summary> Expert: Splits an int range recursively.
            You may implement a builder that adds clauses to a
            {@link Lucene.Net.Search.BooleanQuery} for each call to its
            {@link IntRangeBuilder#AddRange(String,String)}
            method.
            <p/>This method is used by {@link NumericRangeQuery}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.SplitRange(System.Object,System.Int32,System.Int32,System.Int64,System.Int64)">
            <summary>This helper does the splitting for both 32 and 64 bit. </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.AddRange(System.Object,System.Int32,System.Int64,System.Int64,System.Int32)">
            <summary>Helper that delegates to correct range builder </summary>
        </member>
        <member name="T:Lucene.Net.Util.NumericUtils.LongRangeBuilder">
            <summary> Expert: Callback for {@link #splitLongRange}.
            You need to overwrite only one of the methods.
            <p/><font color="red"><b>NOTE:</b> This is a very low-level interface,
            the method signatures may change in later versions.</font>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.LongRangeBuilder.AddRange(System.String,System.String)">
            <summary> Overwrite this method, if you like to receive the already prefix encoded range bounds.
            You can directly build classical (inclusive) range queries from them.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.LongRangeBuilder.AddRange(System.Int64,System.Int64,System.Int32)">
            <summary> Overwrite this method, if you like to receive the raw long range bounds.
            You can use this for e.g. debugging purposes (print out range bounds).
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.NumericUtils.IntRangeBuilder">
            <summary> Expert: Callback for {@link #splitIntRange}.
            You need to overwrite only one of the methods.
            <p/><font color="red"><b>NOTE:</b> This is a very low-level interface,
            the method signatures may change in later versions.</font>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.IntRangeBuilder.AddRange(System.String,System.String)">
            <summary> Overwrite this method, if you like to receive the already prefix encoded range bounds.
            You can directly build classical range (inclusive) queries from them.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.NumericUtils.IntRangeBuilder.AddRange(System.Int32,System.Int32,System.Int32)">
            <summary> Overwrite this method, if you like to receive the raw int range bounds.
            You can use this for e.g. debugging purposes (print out range bounds).
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.NIOFSDirectory">
            <summary>
            Not implemented. Waiting for volunteers.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.NIOFSDirectory.NIOFSIndexInput">
            <summary>
            Not implemented. Waiting for volunteers.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.LockStressTest">
            <summary> Simple standalone tool that forever acquires &amp; releases a
            lock using a specific LockFactory.  Run without any args
            to see usage.
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.VerifyingLockFactory">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.LockVerifyServer">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.WildcardTermEnum">
            <summary> Subclass of FilteredTermEnum for enumerating all terms that match the
            specified wildcard filter term.
            <p/>
            Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.
            
            </summary>
            <version>  $Id: WildcardTermEnum.java 783371 2009-06-10 14:39:56Z mikemccand $
            </version>
        </member>
        <member name="F:Lucene.Net.Search.WildcardTermEnum.WILDCARD_STRING">
            <summary>*****************************************
            String equality with support for wildcards
            ******************************************
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.WildcardTermEnum.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term)">
            <summary> Creates a new <code>WildcardTermEnum</code>.
            <p/>
            After calling the constructor the enumeration is already pointing to the first 
            valid term if such a term exists.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.WildcardTermEnum.WildcardEquals(System.String,System.Int32,System.String,System.Int32)">
            <summary> Determines if a word matches a wildcard pattern.
            <small>Work released by Granta Design Ltd after originally being done on
            company time.</small>
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.TopDocs">
            <summary> Represents hits returned by {@link
            * Searcher#search(Query,Filter,int)} and {@link
            * Searcher#search(Query,int)
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopDocs.totalHits">
            <summary>The total number of hits for the query.</summary>
            <seealso cref="M:Lucene.Net.Search.Hits.Length">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.TopDocs.scoreDocs">
            <summary>The top hits for the query. </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopDocs.maxScore">
            <summary>Stores the maximum score value encountered, needed for normalizing. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocs.GetMaxScore">
            <summary>Returns the maximum score value encountered. Note that in case
            scores are not tracked, this returns {@link Float#NaN}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocs.SetMaxScore(System.Single)">
            <summary>Sets the maximum score value encountered. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocs.#ctor(System.Int32,Lucene.Net.Search.ScoreDoc[])">
            <summary>Constructs a TopDocs with a default maxScore=Float.NaN. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopDocs.#ctor(System.Int32,Lucene.Net.Search.ScoreDoc[],System.Single)">
            <summary></summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanTermQuery">
            <summary>Matches spans containing a term. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanTermQuery.#ctor(Lucene.Net.Index.Term)">
            <summary>Construct a SpanTermQuery matching the named term's spans. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanTermQuery.GetTerm">
            <summary>Return the term whose spans are matched. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanTermQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.Spans.NearSpansUnordered">
            <summary> Similar to {@link NearSpansOrdered}, but for the unordered case.
            
            Expert:
            Only public for subclassing.  Most implementations should not need this class
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansUnordered.GetPayload">
            <summary> WARNING: The List is not necessarily in order of the the positions</summary>
            <returns> Collection of <code>byte[]</code> payloads
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Search.Spans.NearSpansUnordered.SpansCell">
            <summary>Wraps a Spans, and can be used to form a linked list. </summary>
        </member>
        <member name="M:Lucene.Net.Search.SloppyPhraseScorer.PhraseFreq">
            <summary> Score a candidate doc for all slop-valid position-combinations (matches) 
            encountered while traversing/hopping the PhrasePositions.
            <br/> The score contribution of a match depends on the distance: 
            <br/> - highest score for distance=0 (exact match).
            <br/> - score gets lower as distance gets higher.
            <br/>Example: for query "a b"~2, a document "x a b a y" can be scored twice: 
            once for "a b" (distance=0), and once for "b a" (distance=2).
            <br/>Possibly not all valid combinations are encountered, because for efficiency  
            we always propagate the least PhrasePosition. This allows to base on 
            PriorityQueue and move forward faster. 
            As result, for example, document "a b c b a"
            would score differently for queries "a b c"~4 and "c b a"~4, although 
            they really are equivalent. 
            Similarly, for doc "a b c b a f g", query "c b"~2 
            would get same score as "g f"~2, although "c b"~2 could be matched twice.
            We may want to fix this in the future (currently not, for performance reasons).
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SloppyPhraseScorer.InitPhrasePositions">
            <summary> Init PhrasePositions in place.
            There is a one time initialization for this scorer:
            <br/>- Put in repeats[] each pp that has another pp with same position in the doc.
            <br/>- Also mark each such pp by pp.repeats = true.
            <br/>Later can consult with repeats[] in termPositionsDiffer(pp), making that check efficient.
            In particular, this allows to score queries with no repetitions with no overhead due to this computation.
            <br/>- Example 1 - query with no repetitions: "ho my"~2
            <br/>- Example 2 - query with repetitions: "ho my my"~2
            <br/>- Example 3 - query with repetitions: "my ho my"~2
            <br/>Init per doc w/repeats in query, includes propagating some repeating pp's to avoid false phrase detection.  
            </summary>
            <returns> end (max position), or -1 if any term ran out (i.e. done) 
            </returns>
            <throws>  IOException  </throws>
        </member>
        <member name="M:Lucene.Net.Search.SloppyPhraseScorer.TermPositionsDiffer(Lucene.Net.Search.PhrasePositions)">
            <summary> We disallow two pp's to have the same TermPosition, thereby verifying multiple occurrences 
            in the query of the same word would go elsewhere in the matched doc.
            </summary>
            <returns> null if differ (i.e. valid) otherwise return the higher offset PhrasePositions
            out of the first two PPs found to not differ.
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.MatchAllDocsQuery">
            <summary> A query that matches all documents.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MatchAllDocsQuery.#ctor(System.String)">
            <param name="normsField">Field used for normalization factor (document boost). Null if nothing.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.MatchAllDocsQuery.MatchAllScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MatchAllDocsQuery.MatchAllScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MatchAllDocsQuery.MatchAllScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.Function.OrdFieldSource">
            <summary> Expert: obtains the ordinal of the field value from the default Lucene 
            {@link Lucene.Net.Search.FieldCache Fieldcache} using getStringIndex().
            <p/>
            The native lucene index order is used to assign an ordinal value for each field value.
            <p/>
            Field values (terms) are lexicographically ordered by unicode value, and numbered starting at 1.
            <p/>
            Example:
            <br/>If there were only three field values: "apple","banana","pear"
            <br/>then ord("apple")=1, ord("banana")=2, ord("pear")=3
            <p/>
            WARNING: 
            ord() depends on the position in an index and can thus change 
            when other documents are inserted or deleted,
            or if a MultiSearcher is used. 
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.OrdFieldSource.#ctor(System.String)">
            <summary> Constructor for a certain field.</summary>
            <param name="field">field whose values order is used.  
            </param>
        </member>
        <member name="T:Lucene.Net.Search.DisjunctionMaxScorer">
            <summary> The Scorer for DisjunctionMaxQuery's.  The union of all documents generated by the the subquery scorers
            is generated in document number order.  The score for each document is the maximum of the scores computed
            by the subquery scorers that generate that document, plus tieBreakerMultiplier times the sum of the scores
            for the other subqueries that generate the document.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.#ctor(System.Single,Lucene.Net.Search.Similarity,Lucene.Net.Search.Scorer[],System.Int32)">
            <summary> Creates a new instance of DisjunctionMaxScorer
            
            </summary>
            <param name="tieBreakerMultiplier">Multiplier applied to non-maximum-scoring subqueries for a
            document as they are summed into the result.
            </param>
            <param name="similarity">-- not used since our definition involves neither coord nor terms
            directly
            </param>
            <param name="subScorers">The sub scorers this Scorer should iterate on
            </param>
            <param name="numScorers">The actual number of scorers to iterate on. Note that the array's
            length may be larger than the actual number of scorers.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.Next">
            <summary> Generate the next document matching our associated DisjunctionMaxQuery.
            
            </summary>
            <returns> true iff there is a next document
            </returns>
            <deprecated> use {@link #NextDoc()} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.Score">
            <summary>Determine the current document score.  Initially invalid, until {@link #Next()} is called the first time.</summary>
            <returns> the score of the current generated document
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.SkipTo(System.Int32)">
            <summary> Advance to the first document beyond the current whose number is greater
            than or equal to target.
            
            </summary>
            <param name="target">the minimum number of the next desired document
            </param>
            <returns> true iff there is a document to be generated whose number is at
            least target
            </returns>
            <deprecated> use {@link #Advance(int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxScorer.Explain(System.Int32)">
            <summary>Explain a score that we computed.  UNSUPPORTED -- see explanation capability in DisjunctionMaxQuery.</summary>
            <param name="doc">the number of a document we scored
            </param>
            <returns> the Explanation for our score
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.ConstantScoreRangeQuery">
            <summary> A range query that returns a constant score equal to its boost for
            all documents in the exclusive range of terms.
            
            <p/>It does not have an upper bound on the number of clauses covered in the range.
            
            <p/>This query matches the documents looking for terms that fall into the
            supplied range according to {@link String#compareTo(String)}. It is not intended
            for numerical ranges, use {@link NumericRangeQuery} instead.
            
            <p/>This query is hardwired to {@link MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}.
            If you want to change this, use {@link TermRangeQuery} instead.
            
            </summary>
            <deprecated> Use {@link TermRangeQuery} for term ranges or
            {@link NumericRangeQuery} for numeric ranges instead.
            This class will be removed in Lucene 3.0.
            </deprecated>
            <version>  $Id: ConstantScoreRangeQuery.java 797694 2009-07-25 00:03:33Z mikemccand $
            </version>
        </member>
        <member name="T:Lucene.Net.Search.TermRangeQuery">
            <summary> A Query that matches documents within an exclusive range of terms.
            
            <p/>This query matches the documents looking for terms that fall into the
            supplied range according to {@link String#compareTo(String)}. It is not intended
            for numerical ranges, use {@link NumericRangeQuery} instead.
            
            <p/>This query uses the {@link
            MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
            rewrite method.
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="T:Lucene.Net.Search.MultiTermQuery">
            <summary> An abstract {@link Query} that matches documents
            containing a subset of terms provided by a {@link
            FilteredTermEnum} enumeration.
            
            <p/>This query cannot be used directly; you must subclass
            it and define {@link #getEnum} to provide a {@link
            FilteredTermEnum} that iterates through the terms to be
            matched.
            
            <p/><b>NOTE</b>: if {@link #setRewriteMethod} is either
            {@link #CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE} or {@link
            #SCORING_BOOLEAN_QUERY_REWRITE}, you may encounter a
            {@link BooleanQuery.TooManyClauses} exception during
            searching, which happens when the number of terms to be
            searched exceeds {@link
            BooleanQuery#GetMaxClauseCount()}.  Setting {@link
            #setRewriteMethod} to {@link #CONSTANT_SCORE_FILTER_REWRITE}
            prevents this.
            
            <p/>The recommended rewrite method is {@link
            #CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}: it doesn't spend CPU
            computing unhelpful scores, and it tries to pick the most
            performant rewrite method given the query.
            
            Note that {@link QueryParser} produces
            MultiTermQueries using {@link
            #CONSTANT_SCORE_AUTO_REWRITE_DEFAULT} by default.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE">
            <summary>A rewrite method that first creates a private Filter,
            by visiting each term in sequence and marking all docs
            for that term.  Matching documents are assigned a
            constant score equal to the query's boost.
            
            <p/> This method is faster than the BooleanQuery
            rewrite methods when the number of matched terms or
            matched documents is non-trivial. Also, it will never
            hit an errant {@link BooleanQuery.TooManyClauses}
            exception.
            
            </summary>
            <seealso cref="!:setRewriteMethod">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE">
            <summary>A rewrite method that first translates each term into
            {@link BooleanClause.Occur#SHOULD} clause in a
            BooleanQuery, and keeps the scores as computed by the
            query.  Note that typically such scores are
            meaningless to the user, and require non-trivial CPU
            to compute, so it's almost always better to use {@link
            #CONSTANT_SCORE_AUTO_REWRITE_DEFAULT} instead.
            
            <p/><b>NOTE</b>: This rewrite method will hit {@link
            BooleanQuery.TooManyClauses} if the number of terms
            exceeds {@link BooleanQuery#getMaxClauseCount}.
            
            </summary>
            <seealso cref="!:setRewriteMethod">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.MultiTermQuery.CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE">
            <summary>Like {@link #SCORING_BOOLEAN_QUERY_REWRITE} except
            scores are not computed.  Instead, each matching
            document receives a constant score equal to the
            query's boost.
            
            <p/><b>NOTE</b>: This rewrite method will hit {@link
            BooleanQuery.TooManyClauses} if the number of terms
            exceeds {@link BooleanQuery#getMaxClauseCount}.
            
            </summary>
            <seealso cref="!:setRewriteMethod">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT">
            <summary>Read-only default instance of {@link
            ConstantScoreAutoRewrite}, with {@link
            ConstantScoreAutoRewrite#setTermCountCutoff} set to
            {@link
            ConstantScoreAutoRewrite#DEFAULT_TERM_COUNT_CUTOFF}
            and {@link
            ConstantScoreAutoRewrite#setDocCountPercent} set to
            {@link
            ConstantScoreAutoRewrite#DEFAULT_DOC_COUNT_PERCENT}.
            Note that you cannot alter the configuration of this
            instance; you'll need to create a private instance
            instead. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.#ctor(Lucene.Net.Index.Term)">
            <summary> Constructs a query for terms matching <code>term</code>.</summary>
            <deprecated> check sub class for possible term access - the Term does not
            make sense for all MultiTermQuerys and will be removed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.#ctor">
            <summary> Constructs a query matching terms that cannot be represented with a single
            Term.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.GetTerm">
            <summary> Returns the pattern term.</summary>
            <deprecated> check sub class for possible term access - getTerm does not
            make sense for all MultiTermQuerys and will be removed.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.GetEnum(Lucene.Net.Index.IndexReader)">
            <summary>Construct the enumeration to be used, expanding the pattern term. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.GetTotalNumberOfTerms">
            <summary> Expert: Return the number of unique terms visited during execution of the query.
            If there are many of them, you may consider using another query type
            or optimize your total term count in index.
            <p/>This method is not thread safe, be sure to only call it when no query is running!
            If you re-use the same query instance for another
            search, be sure to first reset the term counter
            with {@link #clearTotalNumberOfTerms}.
            <p/>On optimized indexes / no MultiReaders, you get the correct number of
            unique terms for the whole index. Use this number to compare different queries.
            For non-optimized indexes this number can also be achived in
            non-constant-score mode. In constant-score mode you get the total number of
            terms seeked for all segments / sub-readers.
            </summary>
            <seealso cref="!:clearTotalNumberOfTerms">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.ClearTotalNumberOfTerms">
            <summary> Expert: Resets the counting of unique terms.
            Do this before executing the query/filter.
            </summary>
            <seealso cref="!:getTotalNumberOfTerms">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.GetRewriteMethod">
            <seealso cref="!:setRewriteMethod">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.SetRewriteMethod(Lucene.Net.Search.MultiTermQuery.RewriteMethod)">
            <summary> Sets the rewrite method to be used when executing the
            query.  You can use one of the four core methods, or
            implement your own subclass of {@link RewriteMethod}. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.MultiTermQuery.ConstantScoreAutoRewrite">
            <summary>A rewrite method that tries to pick the best
            constant-score rewrite method based on term and
            document counts from the query.  If both the number of
            terms and documents is small enough, then {@link
            #CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE} is used.
            Otherwise, {@link #CONSTANT_SCORE_FILTER_REWRITE} is
            used.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.MultiTermQuery.RewriteMethod">
            <summary>Abstract class that defines how the query is rewritten. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.ConstantScoreAutoRewrite.SetTermCountCutoff(System.Int32)">
            <summary>If the number of terms in this query is equal to or
            larger than this setting then {@link
            #CONSTANT_SCORE_FILTER_REWRITE} is used. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.ConstantScoreAutoRewrite.GetTermCountCutoff">
            <seealso cref="!:setTermCountCutoff">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.ConstantScoreAutoRewrite.SetDocCountPercent(System.Double)">
            <summary>If the number of documents to be visited in the
            postings exceeds this specified percentage of the
            maxDoc() for the index, then {@link
            #CONSTANT_SCORE_FILTER_REWRITE} is used.
            </summary>
            <param name="percent">0.0 to 100.0 
            </param>
        </member>
        <member name="M:Lucene.Net.Search.MultiTermQuery.ConstantScoreAutoRewrite.GetDocCountPercent">
            <seealso cref="!:setDocCountPercent">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean)">
            <summary> Constructs a query selecting all terms greater/equal than <code>lowerTerm</code>
            but less/equal than <code>upperTerm</code>. 
            
            <p/>
            If an endpoint is null, it is said 
            to be "open". Either or both endpoints may be open.  Open endpoints may not 
            be exclusive (you can't select all but the first or last term without 
            explicitly specifying the term to exclude.)
            
            </summary>
            <param name="field">The field that holds both lower and upper terms.
            </param>
            <param name="lowerTerm">The term text at the lower end of the range
            </param>
            <param name="upperTerm">The term text at the upper end of the range
            </param>
            <param name="includeLower">If true, the <code>lowerTerm</code> is
            included in the range.
            </param>
            <param name="includeUpper">If true, the <code>upperTerm</code> is
            included in the range.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean,System.Globalization.CompareInfo)">
            <summary>Constructs a query selecting all terms greater/equal than
            <code>lowerTerm</code> but less/equal than <code>upperTerm</code>.
            <p/>
            If an endpoint is null, it is said 
            to be "open". Either or both endpoints may be open.  Open endpoints may not 
            be exclusive (you can't select all but the first or last term without 
            explicitly specifying the term to exclude.)
            <p/>
            If <code>collator</code> is not null, it will be used to decide whether
            index terms are within the given range, rather than using the Unicode code
            point order in which index terms are stored.
            <p/>
            <strong>WARNING:</strong> Using this constructor and supplying a non-null
            value in the <code>collator</code> parameter will cause every single 
            index Term in the Field referenced by lowerTerm and/or upperTerm to be
            examined.  Depending on the number of index Terms in this Field, the 
            operation could be very slow.
            
            </summary>
            <param name="lowerTerm">The Term text at the lower end of the range
            </param>
            <param name="upperTerm">The Term text at the upper end of the range
            </param>
            <param name="includeLower">If true, the <code>lowerTerm</code> is
            included in the range.
            </param>
            <param name="includeUpper">If true, the <code>upperTerm</code> is
            included in the range.
            </param>
            <param name="collator">The collator to use to collate index Terms, to determine
            their membership in the range bounded by <code>lowerTerm</code> and
            <code>upperTerm</code>.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.GetField">
            <summary>Returns the field name for this query </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.GetLowerTerm">
            <summary>Returns the lower value of this range query </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.GetUpperTerm">
            <summary>Returns the upper value of this range query </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.IncludesLower">
            <summary>Returns <code>true</code> if the lower endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.IncludesUpper">
            <summary>Returns <code>true</code> if the upper endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.GetCollator">
            <summary>Returns the collator used to determine range inclusion, if any. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreRangeQuery.SetRewriteMethod(Lucene.Net.Search.MultiTermQuery.RewriteMethod)">
            <summary>Changes of mode are not supported by this class (fixed to constant score rewrite mode) </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.Score(Lucene.Net.Search.HitCollector,System.Int32)">
            <deprecated> use {@link #Score(Collector, int, int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.Score(Lucene.Net.Search.HitCollector)">
            <deprecated> use {@link #Score(Collector)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.BucketScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.BucketScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanScorer.BucketScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.BooleanScorer.BucketTable">
            <summary>A simple hash table of document scores within a range. </summary>
        </member>
        <member name="T:Lucene.Net.Index.SerialMergeScheduler">
            <summary>A {@link MergeScheduler} that simply does each merge
            sequentially, using the current thread. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MergeScheduler">
            <summary><p/>Expert: {@link IndexWriter} uses an instance
            implementing this interface to execute the merges
            selected by a {@link MergePolicy}.  The default
            MergeScheduler is {@link ConcurrentMergeScheduler}.<p/>
            
            <p/><b>NOTE:</b> This API is new and still experimental
            (subject to change suddenly in the next release)<p/>
            
            <p/><b>NOTE</b>: This class typically requires access to
            package-private APIs (eg, SegmentInfos) to do its job;
            if you implement your own MergePolicy, you'll need to put
            it in package Lucene.Net.Index in order to use
            these APIs.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergeScheduler.Merge(Lucene.Net.Index.IndexWriter)">
            <summary>Run the merges provided by {@link IndexWriter#GetNextMerge()}. </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergeScheduler.Close">
            <summary>Close this MergeScheduler. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SerialMergeScheduler.Merge(Lucene.Net.Index.IndexWriter)">
            <summary>Just do the merges in sequence. We do this
            "synchronized" so that even if the application is using
            multiple threads, only one merge may run at a time. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.ReusableStringReader">
            <summary>Used by DocumentsWriter to implemented a StringReader
            that can be reset to a new string; we use this when
            tokenizing the string value from a Field. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocFieldProcessorPerThread">
            <summary> Gathers all Fieldables for a document under the same
            name, updates FieldInfos, and calls per-field consumers
            to process field by field.
            
            Currently, only a single thread visits the fields,
            sequentially, for processing.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DocFieldProcessorPerThread.TrimFields(Lucene.Net.Index.SegmentWriteState)">
            <summary>If there are fields we've seen but did not see again
            in the last run, then free them up. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.MapFieldSelector">
            <summary> A {@link FieldSelector} based on a Map of field names to {@link FieldSelectorResult}s
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.MapFieldSelector.#ctor(System.Collections.IDictionary)">
            <summary>Create a a MapFieldSelector</summary>
            <param name="fieldSelections">maps from field names (String) to {@link FieldSelectorResult}s
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.MapFieldSelector.#ctor(System.Collections.IList)">
            <summary>Create a a MapFieldSelector</summary>
            <param name="fields">fields to LOAD.  List of Strings.  All other fields are NO_LOAD.
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.MapFieldSelector.#ctor(System.String[])">
            <summary>Create a a MapFieldSelector</summary>
            <param name="fields">fields to LOAD.  All other fields are NO_LOAD.
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.MapFieldSelector.Accept(System.String)">
            <summary>Load field according to its associated value in fieldSelections</summary>
            <param name="field">a field name
            </param>
            <returns> the fieldSelections value that field maps to or NO_LOAD if none.
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.NumericTokenStream">
            <summary> <b>Expert:</b> This class provides a {@link TokenStream}
            for indexing numeric values that can be used by {@link
            NumericRangeQuery} or {@link NumericRangeFilter}.
            
            <p/>Note that for simple usage, {@link NumericField} is
            recommended.  {@link NumericField} disables norms and
            term freqs, as they are not usually needed during
            searching.  If you need to change these settings, you
            should use this class.
            
            <p/>See {@link NumericField} for capabilities of fields
            indexed numerically.<p/>
            
            <p/>Here's an example usage, for an <code>int</code> field:
            
            <pre>
             Field field = new Field(name, new NumericTokenStream(precisionStep).setIntValue(value));
             field.setOmitNorms(true);
             field.setOmitTermFreqAndPositions(true);
             document.add(field);
            </pre>
            
            <p/>For optimal performance, re-use the TokenStream and Field instance
            for more than one document:
            
            <pre>
             NumericTokenStream stream = new NumericTokenStream(precisionStep);
             Field field = new Field(name, stream);
             field.setOmitNorms(true);
             field.setOmitTermFreqAndPositions(true);
             Document document = new Document();
             document.add(field);
            
             for(all documents) {
               stream.setIntValue(value)
               writer.addDocument(document);
             }
            </pre>
            
            <p/>This stream is not intended to be used in analyzers;
            it's more for iterating the different precisions during
            indexing a specific numeric value.<p/>
            
            <p/><b>NOTE</b>: as token streams are only consumed once
            the document is added to the index, if you index more
            than one numeric field, use a separate <code>NumericTokenStream</code>
            instance for each.<p/>
            
            <p/>See {@link NumericRangeQuery} for more details on the
            <a
            href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
            parameter as well as how numeric fields work under the hood.<p/>
            
            <p/><font color="red"><b>NOTE:</b> This API is experimental and
            might change in incompatible ways in the next release.</font>
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="F:Lucene.Net.Analysis.NumericTokenStream.TOKEN_TYPE_FULL_PREC">
            <summary>The full precision token gets this token type assigned. </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.NumericTokenStream.TOKEN_TYPE_LOWER_PREC">
            <summary>The lower precision tokens gets this token type assigned. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.#ctor">
            <summary> Creates a token stream for numeric values using the default <code>precisionStep</code>
            {@link NumericUtils#PRECISION_STEP_DEFAULT} (4). The stream is not yet initialized,
            before using set a value using the various set<em>???</em>Value() methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.#ctor(System.Int32)">
            <summary> Creates a token stream for numeric values with the specified
            <code>precisionStep</code>. The stream is not yet initialized,
            before using set a value using the various set<em>???</em>Value() methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.#ctor(Lucene.Net.Util.AttributeSource,System.Int32)">
            <summary> Expert: Creates a token stream for numeric values with the specified
            <code>precisionStep</code> using the given {@link AttributeSource}.
            The stream is not yet initialized,
            before using set a value using the various set<em>???</em>Value() methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.Int32)">
            <summary> Expert: Creates a token stream for numeric values with the specified
            <code>precisionStep</code> using the given
            {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
            The stream is not yet initialized,
            before using set a value using the various set<em>???</em>Value() methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.SetLongValue(System.Int64)">
            <summary> Initializes the token stream with the supplied <code>long</code> value.</summary>
            <param name="value">the value, for which this TokenStream should enumerate tokens.
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>new Field(name, new NumericTokenStream(precisionStep).SetLongValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.SetIntValue(System.Int32)">
            <summary> Initializes the token stream with the supplied <code>int</code> value.</summary>
            <param name="value">the value, for which this TokenStream should enumerate tokens.
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>new Field(name, new NumericTokenStream(precisionStep).SetIntValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.SetDoubleValue(System.Double)">
            <summary> Initializes the token stream with the supplied <code>double</code> value.</summary>
            <param name="value">the value, for which this TokenStream should enumerate tokens.
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>new Field(name, new NumericTokenStream(precisionStep).SetDoubleValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.NumericTokenStream.SetFloatValue(System.Single)">
            <summary> Initializes the token stream with the supplied <code>float</code> value.</summary>
            <param name="value">the value, for which this TokenStream should enumerate tokens.
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>new Field(name, new NumericTokenStream(precisionStep).SetFloatValue(value))</code>
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.NormalizeCharMap">
            <summary> Holds a map of String input to String output, to be used
            with {@link MappingCharFilter}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.NormalizeCharMap.Add(System.String,System.String)">
            <summary>Records a replacement to be applied to the inputs
            stream.  Whenever <code>singleMatch</code> occurs in
            the input, it will be replaced with
            <code>replacement</code>.
            
            </summary>
            <param name="singleMatch">input String to be replaced
            </param>
            <param name="replacement">output String
            </param>
        </member>
        <member name="T:Lucene.Net.Util.SmallFloat">
            <summary>Floating point numbers smaller than 32 bits.
            
            </summary>
            <version>  $Id$
            </version>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.FloatToByte(System.Single,System.Int32,System.Int32)">
            <summary>Converts a 32 bit float to an 8 bit float.
            <br/>Values less than zero are all mapped to zero.
            <br/>Values are truncated (rounded down) to the nearest 8 bit value.
            <br/>Values between zero and the smallest representable value
            are rounded up.
            
            </summary>
            <param name="f">the 32 bit float to be converted to an 8 bit float (byte)
            </param>
            <param name="numMantissaBits">the number of mantissa bits to use in the byte, with the remainder to be used in the exponent
            </param>
            <param name="zeroExp">the zero-point in the range of exponent values
            </param>
            <returns> the 8 bit float representation
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.ByteToFloat(System.Byte,System.Int32,System.Int32)">
            <summary>Converts an 8 bit float to a 32 bit float. </summary>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.FloatToByte315(System.Single)">
            <summary>floatToByte(b, mantissaBits=3, zeroExponent=15)
            <br/>smallest non-zero value = 5.820766E-10
            <br/>largest value = 7.5161928E9
            <br/>epsilon = 0.125
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.Byte315ToFloat(System.Byte)">
            <summary>byteToFloat(b, mantissaBits=3, zeroExponent=15) </summary>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.FloatToByte52(System.Single)">
            <summary>floatToByte(b, mantissaBits=5, zeroExponent=2)
            <br/>smallest nonzero value = 0.033203125
            <br/>largest value = 1984.0
            <br/>epsilon = 0.03125
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.SmallFloat.Byte52ToFloat(System.Byte)">
            <summary>byteToFloat(b, mantissaBits=5, zeroExponent=2) </summary>
        </member>
        <member name="T:Lucene.Net.Util.FieldCacheSanityChecker">
            <summary> Provides methods for sanity checking that entries in the FieldCache 
            are not wasteful or inconsistent.
            <p/>
            <p/>
            Lucene 2.9 Introduced numerous enhancements into how the FieldCache 
            is used by the low levels of Lucene searching (for Sorting and 
            ValueSourceQueries) to improve both the speed for Sorting, as well 
            as reopening of IndexReaders.  But these changes have shifted the 
            usage of FieldCache from "top level" IndexReaders (frequently a 
            MultiReader or DirectoryReader) down to the leaf level SegmentReaders.  
            As a result, existing applications that directly access the FieldCache 
            may find RAM usage increase significantly when upgrading to 2.9 or 
            Later.  This class provides an API for these applications (or their 
            Unit tests) to check at run time if the FieldCache contains "insane" 
            usages of the FieldCache.
            <p/>
            <p/>
            <b>EXPERIMENTAL API:</b> This API is considered extremely advanced and 
            experimental.  It may be removed or altered w/o warning in future releases 
            of Lucene.
            <p/>
            </summary>
            <seealso cref="T:Lucene.Net.Search.FieldCache">
            </seealso>
            <seealso cref="T:Lucene.Net.Util.FieldCacheSanityChecker.Insanity">
            </seealso>
            <seealso cref="T:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.SetRamUsageEstimator(Lucene.Net.Util.RamUsageEstimator)">
            <summary> If set, will be used to estimate size for all CacheEntry objects 
            dealt with.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.CheckSanity(Lucene.Net.Search.FieldCache)">
            <summary> Quick and dirty convenience method</summary>
            <seealso cref="!:check">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.CheckSanity(Lucene.Net.Search.CacheEntry[])">
            <summary> Quick and dirty convenience method that instantiates an instance with 
            "good defaults" and uses it to test the CacheEntry[]
            </summary>
            <seealso cref="!:check">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.Check(Lucene.Net.Search.CacheEntry[])">
            <summary> Tests a CacheEntry[] for indication of "insane" cache usage.
            <p/>
            NOTE:FieldCache CreationPlaceholder objects are ignored.
            (:TODO: is this a bad idea? are we masking a real problem?)
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.CheckValueMismatch(Lucene.Net.Util.MapOfSets{System.Int32,Lucene.Net.Search.CacheEntry},Lucene.Net.Util.MapOfSets{Lucene.Net.Util.FieldCacheSanityChecker.ReaderField,System.Int32},System.Collections.Generic.Dictionary{Lucene.Net.Util.FieldCacheSanityChecker.ReaderField,Lucene.Net.Util.FieldCacheSanityChecker.ReaderField})">
            <summary> Internal helper method used by check that iterates over 
            valMismatchKeys and generates a Collection of Insanity 
            instances accordingly.  The MapOfSets are used to populate 
            the Insantiy objects. 
            </summary>
            <seealso cref="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.VALUEMISMATCH">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.CheckSubreaders(Lucene.Net.Util.MapOfSets{System.Int32,Lucene.Net.Search.CacheEntry},Lucene.Net.Util.MapOfSets{Lucene.Net.Util.FieldCacheSanityChecker.ReaderField,System.Int32})">
            <summary> Internal helper method used by check that iterates over 
            the keys of readerFieldToValIds and generates a Collection 
            of Insanity instances whenever two (or more) ReaderField instances are 
            found that have an ancestery relationships.  
            
            </summary>
            <seealso cref="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.SUBREADER">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.GetAllDecendentReaderKeys(System.Object)">
            <summary> Checks if the seed is an IndexReader, and if so will walk
            the hierarchy of subReaders building up a list of the objects 
            returned by obj.getFieldCacheKey()
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.FieldCacheSanityChecker.ReaderField">
            <summary> Simple pair object for using "readerKey + fieldName" a Map key</summary>
        </member>
        <member name="T:Lucene.Net.Util.FieldCacheSanityChecker.Insanity">
            <summary> Simple container for a collection of related CacheEntry objects that 
            in conjunction with eachother represent some "insane" usage of the 
            FieldCache.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.Insanity.GetType">
            <summary> Type of insane behavior this object represents</summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.Insanity.GetMsg">
            <summary> Description of hte insane behavior</summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.Insanity.GetCacheEntries">
            <summary> CacheEntry objects which suggest a problem</summary>
        </member>
        <member name="M:Lucene.Net.Util.FieldCacheSanityChecker.Insanity.ToString">
            <summary> Multi-Line representation of this Insanity object, starting with 
            the Type and Msg, followed by each CacheEntry.toString() on it's 
            own line prefaced by a tab character
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType">
            <summary> An Enumaration of the differnet types of "insane" behavior that 
            may be detected in a FieldCache.
            
            </summary>
            <seealso cref="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.SUBREADER">
            </seealso>
            <seealso cref="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.VALUEMISMATCH">
            </seealso>
            <seealso cref="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.EXPECTED">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.SUBREADER">
            <summary> Indicates an overlap in cache usage on a given field 
            in sub/super readers.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.VALUEMISMATCH">
            <summary> <p/>
            Indicates entries have the same reader+fieldname but 
            different cached values.  This can happen if different datatypes, 
            or parsers are used -- and while it's not necessarily a bug 
            it's typically an indication of a possible problem.
            <p/>
            <p/>
            PNOTE: Only the reader, fieldname, and cached value are actually 
            tested -- if two cache entries have different parsers or datatypes but 
            the cached values are the same Object (== not just equal()) this method 
            does not consider that a red flag.  This allows for subtle variations 
            in the way a Parser is specified (null vs DEFAULT_LONG_PARSER, etc...)
            <p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.FieldCacheSanityChecker.InsanityType.EXPECTED">
            <summary> Indicates an expected bit of "insanity".  This may be useful for 
            clients that wish to preserve/log information about insane usage 
            but indicate that it was expected. 
            </summary>
        </member>
        <member name="T:IThreadRunnable">
            <summary>
            This interface should be implemented by any class whose instances are intended 
            to be executed by a thread.
            </summary>
        </member>
        <member name="M:IThreadRunnable.Run">
            <summary>
            This method has to be implemented in order that starting of the thread causes the object's 
            run method to be called in that separately executing thread.
            </summary>
        </member>
        <member name="T:SupportClass">
            <summary>
            Contains conversion support elements such as classes, interfaces and static methods.
            </summary>
        </member>
        <member name="M:SupportClass.TextSupport.GetCharsFromString(System.String,System.Int32,System.Int32,System.Char[],System.Int32)">
            <summary>
            Copies an array of chars obtained from a String into a specified array of chars
            </summary>
            <param name="sourceString">The String to get the chars from</param>
            <param name="sourceStart">Position of the String to start getting the chars</param>
            <param name="sourceEnd">Position of the String to end getting the chars</param>
            <param name="destinationArray">Array to return the chars</param>
            <param name="destinationStart">Position of the destination array of chars to start storing the chars</param>
            <returns>An array of chars</returns>
        </member>
        <member name="T:SupportClass.ThreadClass">
            <summary>
            Support class used to handle threads
            </summary>
        </member>
        <member name="F:SupportClass.ThreadClass.threadField">
            <summary>
            The instance of System.Threading.Thread
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.#ctor">
            <summary>
            Initializes a new instance of the ThreadClass class
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.#ctor(System.String)">
            <summary>
            Initializes a new instance of the Thread class.
            </summary>
            <param name="Name">The name of the thread</param>
        </member>
        <member name="M:SupportClass.ThreadClass.#ctor(System.Threading.ThreadStart)">
            <summary>
            Initializes a new instance of the Thread class.
            </summary>
            <param name="Start">A ThreadStart delegate that references the methods to be invoked when this thread begins executing</param>
        </member>
        <member name="M:SupportClass.ThreadClass.#ctor(System.Threading.ThreadStart,System.String)">
            <summary>
            Initializes a new instance of the Thread class.
            </summary>
            <param name="Start">A ThreadStart delegate that references the methods to be invoked when this thread begins executing</param>
            <param name="Name">The name of the thread</param>
        </member>
        <member name="M:SupportClass.ThreadClass.Run">
            <summary>
            This method has no functionality unless the method is overridden
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Start">
            <summary>
            Causes the operating system to change the state of the current thread instance to ThreadState.Running
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Interrupt">
            <summary>
            Interrupts a thread that is in the WaitSleepJoin thread state
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Join">
            <summary>
            Blocks the calling thread until a thread terminates
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Join(System.Int64)">
            <summary>
            Blocks the calling thread until a thread terminates or the specified time elapses
            </summary>
            <param name="MiliSeconds">Time of wait in milliseconds</param>
        </member>
        <member name="M:SupportClass.ThreadClass.Join(System.Int64,System.Int32)">
            <summary>
            Blocks the calling thread until a thread terminates or the specified time elapses
            </summary>
            <param name="MiliSeconds">Time of wait in milliseconds</param>
            <param name="NanoSeconds">Time of wait in nanoseconds</param>
        </member>
        <member name="M:SupportClass.ThreadClass.Resume">
            <summary>
            Resumes a thread that has been suspended
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Abort">
            <summary>
            Raises a ThreadAbortException in the thread on which it is invoked, 
            to begin the process of terminating the thread. Calling this method 
            usually terminates the thread
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.Abort(System.Object)">
            <summary>
            Raises a ThreadAbortException in the thread on which it is invoked, 
            to begin the process of terminating the thread while also providing
            exception information about the thread termination. 
            Calling this method usually terminates the thread.
            </summary>
            <param name="stateInfo">An object that contains application-specific information, such as state, which can be used by the thread being aborted</param>
        </member>
        <member name="M:SupportClass.ThreadClass.Suspend">
            <summary>
            Suspends the thread, if the thread is already suspended it has no effect
            </summary>
        </member>
        <member name="M:SupportClass.ThreadClass.ToString">
            <summary>
            Obtain a String that represents the current object
            </summary>
            <returns>A String that represents the current object</returns>
        </member>
        <member name="M:SupportClass.ThreadClass.Current">
            <summary>
            Gets the currently running thread
            </summary>
            <returns>The currently running thread</returns>
        </member>
        <member name="P:SupportClass.ThreadClass.Instance">
            <summary>
            Gets the current thread instance
            </summary>
        </member>
        <member name="P:SupportClass.ThreadClass.Name">
            <summary>
            Gets or sets the name of the thread
            </summary>
        </member>
        <member name="P:SupportClass.ThreadClass.Priority">
            <summary>
            Gets or sets a value indicating the scheduling priority of a thread
            </summary>
        </member>
        <member name="P:SupportClass.ThreadClass.IsAlive">
            <summary>
            Gets a value indicating the execution status of the current thread
            </summary>
        </member>
        <member name="P:SupportClass.ThreadClass.IsBackground">
            <summary>
            Gets or sets a value indicating whether or not a thread is a background thread.
            </summary>
        </member>
        <member name="T:SupportClass.FileSupport">
            <summary>
            Represents the methods to support some operations over files.
            </summary>
        </member>
        <member name="M:SupportClass.FileSupport.GetFiles(System.IO.FileInfo)">
            <summary>
            Returns an array of abstract pathnames representing the files and directories of the specified path.
            </summary>
            <param name="path">The abstract pathname to list it childs.</param>
            <returns>An array of abstract pathnames childs of the path specified or null if the path is not a directory</returns>
        </member>
        <member name="M:SupportClass.FileSupport.GetLuceneIndexFiles(System.String,Lucene.Net.Index.IndexFileNameFilter)">
            <summary>
            Returns a list of files in a give directory.
            </summary>
            <param name="fullName">The full path name to the directory.</param>
            <param name="indexFileNameFilter"></param>
            <returns>An array containing the files.</returns>
        </member>
        <member name="M:SupportClass.FileSupport.Sync(System.IO.FileStream)">
            <summary>
            Flushes the specified file stream. Ensures that all buffered
            data is actually written to the file system.
            </summary>
            <param name="fileStream">The file stream.</param>
        </member>
        <member name="T:SupportClass.Number">
            <summary>
            A simple class for number conversions.
            </summary>
        </member>
        <member name="F:SupportClass.Number.MIN_RADIX">
            <summary>
            Min radix value.
            </summary>
        </member>
        <member name="F:SupportClass.Number.MAX_RADIX">
            <summary>
            Max radix value.
            </summary>
        </member>
        <member name="M:SupportClass.Number.ToString(System.Int64)">
            <summary>
            Converts a number to System.String.
            </summary>
            <param name="number"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Number.ToString(System.Single)">
            <summary>
            Converts a number to System.String.
            </summary>
            <param name="f"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Number.ToString(System.Int64,System.Int32)">
            <summary>
            Converts a number to System.String in the specified radix.
            </summary>
            <param name="i">A number to be converted.</param>
            <param name="radix">A radix.</param>
            <returns>A System.String representation of the number in the specified redix.</returns>
        </member>
        <member name="M:SupportClass.Number.Parse(System.String,System.Int32)">
            <summary>
            Parses a number in the specified radix.
            </summary>
            <param name="s">An input System.String.</param>
            <param name="radix">A radix.</param>
            <returns>The parsed number in the specified radix.</returns>
        </member>
        <member name="M:SupportClass.Number.URShift(System.Int32,System.Int32)">
            <summary>
            Performs an unsigned bitwise right shift with the specified number
            </summary>
            <param name="number">Number to operate on</param>
            <param name="bits">Ammount of bits to shift</param>
            <returns>The resulting number from the shift operation</returns>
        </member>
        <member name="M:SupportClass.Number.URShift(System.Int64,System.Int32)">
            <summary>
            Performs an unsigned bitwise right shift with the specified number
            </summary>
            <param name="number">Number to operate on</param>
            <param name="bits">Ammount of bits to shift</param>
            <returns>The resulting number from the shift operation</returns>
        </member>
        <member name="M:SupportClass.Number.NextSetBit(System.Collections.BitArray,System.Int32)">
            <summary>
            Returns the index of the first bit that is set to true that occurs 
            on or after the specified starting index. If no such bit exists 
            then -1 is returned.
            </summary>
            <param name="bits">The BitArray object.</param>
            <param name="fromIndex">The index to start checking from (inclusive).</param>
            <returns>The index of the next set bit.</returns>
        </member>
        <member name="M:SupportClass.Number.ToInt64(System.String)">
            <summary>
            Converts a System.String number to long.
            </summary>
            <param name="s"></param>
            <returns></returns>
        </member>
        <member name="T:SupportClass.Character">
            <summary>
            Mimics Java's Character class.
            </summary>
        </member>
        <member name="M:SupportClass.Character.ForDigit(System.Int32,System.Int32)">
            <summary>
            
            </summary>
            <param name="digit"></param>
            <param name="radix"></param>
            <returns></returns>
        </member>
        <member name="P:SupportClass.Character.MAX_RADIX">
            <summary>
            </summary>
        </member>
        <member name="P:SupportClass.Character.MIN_RADIX">
            <summary>
            </summary>
        </member>
        <member name="T:SupportClass.Double">
            <summary>
            
            </summary>
        </member>
        <member name="T:SupportClass.Single">
            <summary>
            
            </summary>
        </member>
        <member name="M:SupportClass.Single.Parse(System.String,System.Globalization.NumberStyles,System.IFormatProvider)">
            <summary>
            
            </summary>
            <param name="s"></param>
            <param name="style"></param>
            <param name="provider"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Single.Parse(System.String,System.IFormatProvider)">
            <summary>
            
            </summary>
            <param name="s"></param>
            <param name="provider"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Single.Parse(System.String,System.Globalization.NumberStyles)">
            <summary>
            
            </summary>
            <param name="s"></param>
            <param name="style"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Single.Parse(System.String)">
            <summary>
            
            </summary>
            <param name="s"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Single.ToString(System.Single)">
            <summary>
            
            </summary>
            <param name="f"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.Single.ToString(System.Single,System.String)">
            <summary>
            
            </summary>
            <param name="f"></param>
            <param name="format"></param>
            <returns></returns>
        </member>
        <member name="T:SupportClass.AppSettings">
            <summary>
            
            </summary>
        </member>
        <member name="M:SupportClass.AppSettings.Set(System.String,System.Int32)">
            <summary>
            
            </summary>
            <param name="key"></param>
            <param name="defValue"></param>
        </member>
        <member name="M:SupportClass.AppSettings.Set(System.String,System.Int64)">
            <summary>
            
            </summary>
            <param name="key"></param>
            <param name="defValue"></param>
        </member>
        <member name="M:SupportClass.AppSettings.Set(System.String,System.String)">
            <summary>
            
            </summary>
            <param name="Key"></param>
            <param name="Value"></param>
        </member>
        <member name="M:SupportClass.AppSettings.Set(System.String,System.Boolean)">
            <summary>
            
            </summary>
            <param name="Key"></param>
            <param name="Value"></param>
        </member>
        <member name="M:SupportClass.AppSettings.Get(System.String,System.Int32)">
            <summary>
            
            </summary>
            <param name="key"></param>
            <param name="defValue"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.AppSettings.Get(System.String,System.Int64)">
            <summary>
            
            </summary>
            <param name="key"></param>
            <param name="defValue"></param>
            <returns></returns>
        </member>
        <member name="M:SupportClass.AppSettings.Get(System.String,System.String)">
            <summary>
            
            </summary>
            <param name="key"></param>
            <param name="defValue"></param>
            <returns></returns>
        </member>
        <member name="T:SupportClass.BitSetSupport">
            <summary>
            This class provides supporting methods of java.util.BitSet
            that are not present in System.Collections.BitArray.
            </summary>
        </member>
        <member name="M:SupportClass.BitSetSupport.NextSetBit(System.Collections.BitArray,System.Int32)">
            <summary>
            Returns the next set bit at or after index, or -1 if no such bit exists.
            </summary>
            <param name="bitArray"></param>
            <param name="index">the index of bit array at which to start checking</param>
            <returns>the next set bit or -1</returns>
        </member>
        <member name="M:SupportClass.BitSetSupport.NextClearBit(System.Collections.BitArray,System.Int32)">
            <summary>
            Returns the next un-set bit at or after index, or -1 if no such bit exists.
            </summary>
            <param name="bitArray"></param>
            <param name="index">the index of bit array at which to start checking</param>
            <returns>the next set bit or -1</returns>
        </member>
        <member name="M:SupportClass.BitSetSupport.Cardinality(System.Collections.BitArray)">
            <summary>
            Returns the number of bits set to true in this BitSet.
            </summary>
            <param name="bits">The BitArray object.</param>
            <returns>The number of bits set to true in this BitSet.</returns>
        </member>
        <member name="T:SupportClass.Compare">
            <summary>
            Summary description for TestSupportClass.
            </summary>
        </member>
        <member name="M:SupportClass.Compare.CompareTermArrays(Lucene.Net.Index.Term[],Lucene.Net.Index.Term[])">
            <summary>
            Compares two Term arrays for equality.
            </summary>
            <param name="t1">First Term array to compare</param>
            <param name="t2">Second Term array to compare</param>
            <returns>true if the Terms are equal in both arrays, false otherwise</returns>
        </member>
        <member name="T:SupportClass.WeakHashTable">
            <summary>
            A Hashtable which holds weak references to its keys so they
            can be collected during GC. 
            </summary>
        </member>
        <member name="F:SupportClass.WeakHashTable.collectableObject">
            <summary>
            Serves as a simple "GC Monitor" that indicates whether cleanup is needed. 
            If collectableObject.IsAlive is false, GC has occurred and we should perform cleanup
            </summary>
        </member>
        <member name="M:SupportClass.WeakHashTable.KeyEquals(System.Object,System.Object)">
            <summary>
            Customize the hashtable lookup process by overriding KeyEquals. KeyEquals
            will compare both WeakKey to WeakKey and WeakKey to real keys
            </summary>
        </member>
        <member name="M:SupportClass.WeakHashTable.CleanIfNeeded">
            <summary>
            Perform cleanup if GC occurred
            </summary>
        </member>
        <member name="M:SupportClass.WeakHashTable.Clean">
            <summary>
            Iterate over all keys and remove keys that were collected
            </summary>
        </member>
        <member name="M:SupportClass.WeakHashTable.Add(System.Object,System.Object)">
            <summary>
            Wrap each key with a WeakKey and add it to the hashtable
            </summary>
        </member>
        <member name="P:SupportClass.WeakHashTable.Keys">
            <summary>
            Create a temporary copy of the real keys and return that
            </summary>
        </member>
        <member name="T:SupportClass.WeakHashTable.WeakKey">
            <summary>
            A weak referene wrapper for the hashtable keys. Whenever a key\value pair 
            is added to the hashtable, the key is wrapped using a WeakKey. WeakKey saves the
            value of the original object hashcode for fast comparison.
            </summary>
        </member>
        <member name="T:SupportClass.WeakHashTable.WeakDictionaryEnumerator">
            <summary>
            A Dictionary enumerator which wraps the original hashtable enumerator 
            and performs 2 tasks: Extract the real key from a WeakKey and skip keys
            that were already collected.
            </summary>
        </member>
        <member name="T:SupportClass.CollectionsHelper">
            <summary>
            Support class used to handle Hashtable addition, which does a check 
            first to make sure the added item is unique in the hash.
            </summary>
        </member>
        <member name="M:SupportClass.CollectionsHelper.CollectionToString(System.Collections.ICollection)">
            <summary>
            Converts the specified collection to its string representation.
            </summary>
            <param name="c">The collection to convert to string.</param>
            <returns>A string representation of the specified collection.</returns>
        </member>
        <member name="M:SupportClass.CollectionsHelper.CompareStringArrays(System.String[],System.String[])">
            <summary>
            Compares two string arrays for equality.
            </summary>
            <param name="l1">First string array list to compare</param>
            <param name="l2">Second string array list to compare</param>
            <returns>true if the strings are equal in both arrays, false otherwise</returns>
        </member>
        <member name="M:SupportClass.CollectionsHelper.Sort(System.Collections.IList,System.Collections.IComparer)">
            <summary>
            Sorts an IList collections
            </summary>
            <param name="list">The System.Collections.IList instance that will be sorted</param>
            <param name="Comparator">The Comparator criteria, null to use natural comparator.</param>
        </member>
        <member name="M:SupportClass.CollectionsHelper.Fill(System.Array,System.Int32,System.Int32,System.Object)">
            <summary>
            Fills the array with an specific value from an specific index to an specific index.
            </summary>
            <param name="array">The array to be filled.</param>
            <param name="fromindex">The first index to be filled.</param>
            <param name="toindex">The last index to be filled.</param>
            <param name="val">The value to fill the array with.</param>
        </member>
        <member name="M:SupportClass.CollectionsHelper.Fill(System.Array,System.Object)">
            <summary>
            Fills the array with an specific value.
            </summary>
            <param name="array">The array to be filled.</param>
            <param name="val">The value to fill the array with.</param>
        </member>
        <member name="M:SupportClass.CollectionsHelper.Equals(System.Array,System.Array)">
            <summary>
            Compares the entire members of one array whith the other one.
            </summary>
            <param name="array1">The array to be compared.</param>
            <param name="array2">The array to be compared with.</param>
            <returns>Returns true if the two specified arrays of Objects are equal 
            to one another. The two arrays are considered equal if both arrays 
            contain the same number of elements, and all corresponding pairs of 
            elements in the two arrays are equal. Two objects e1 and e2 are 
            considered equal if (e1==null ? e2==null : e1.equals(e2)). In other 
            words, the two arrays are equal if they contain the same elements in 
            the same order. Also, two array references are considered equal if 
            both are null.</returns>
        </member>
        <member name="T:SupportClass.GeneralKeyedCollection`2">
            <summary>A collection of <typeparamref name="TItem"/> which can be
            looked up by instances of <typeparamref name="TKey"/>.</summary>
            <typeparam name="TItem">The type of the items contains in this
            collection.</typeparam>
            <typeparam name="TKey">The type of the keys that can be used to look
            up the items.</typeparam>
        </member>
        <member name="M:SupportClass.GeneralKeyedCollection`2.#ctor(System.Converter{`1,`0})">
            <summary>Creates a new instance of the
            <see cref="!:GeneralKeyedCollection"/> class.</summary>
            <param name="converter">The <see cref="T:System.Converter`2"/> which will convert
            instances of <typeparamref name="TItem"/> to <typeparamref name="TKey"/>
            when the override of <see cref="M:SupportClass.GeneralKeyedCollection`2.GetKeyForItem(`1)"/> is called.</param>
        </member>
        <member name="F:SupportClass.GeneralKeyedCollection`2.converter">
            <summary>The <see cref="T:System.Converter`2"/> which will convert
            instances of <typeparamref name="TItem"/> to <typeparamref name="TKey"/>
            when the override of <see cref="M:SupportClass.GeneralKeyedCollection`2.GetKeyForItem(`1)"/> is called.</summary>
        </member>
        <member name="M:SupportClass.GeneralKeyedCollection`2.GetKeyForItem(`1)">
            <summary>Converts an item that is added to the collection to
            a key.</summary>
            <param name="item">The instance of <typeparamref name="TItem"/>
            to convert into an instance of <typeparamref name="TKey"/>.</param>
            <returns>The instance of <typeparamref name="TKey"/> which is the
            key for this item.</returns>
        </member>
        <member name="M:SupportClass.GeneralKeyedCollection`2.ContainsKey(`0)">
            <summary>Determines if a key for an item exists in this
            collection.</summary>
            <param name="key">The instance of <typeparamref name="TKey"/>
            to see if it exists in this collection.</param>
            <returns>True if the key exists in the collection, false otherwise.</returns>
        </member>
        <member name="T:SupportClass.EquatableList`1">
            <summary>Represents a strongly typed list of objects that can be accessed by index.
            Provides methods to search, sort, and manipulate lists. Also provides functionality
            to compare lists against each other through an implementations of
            <see cref="T:System.IEquatable`1"/>.</summary>
            <typeparam name="T">The type of elements in the list.</typeparam>
        </member>
        <member name="M:SupportClass.EquatableList`1.#ctor">
            <summary>Initializes a new instance of the 
            <see cref="!:ComparableList&lt;T&gt;"/> class that is empty and has the 
            default initial capacity.</summary>
        </member>
        <member name="M:SupportClass.EquatableList`1.#ctor(System.Collections.Generic.IEnumerable{`0})">
            <summary>Initializes a new instance of the <see cref="!:ComparableList&lt;T&gt;"/>
            class that contains elements copied from the specified collection and has
            sufficient capacity to accommodate the number of elements copied.</summary>
            <param name="collection">The collection whose elements are copied to the new list.</param>
        </member>
        <member name="M:SupportClass.EquatableList`1.#ctor(System.Int32)">
            <summary>Initializes a new instance of the <see cref="!:ComparableList&lt;T&gt;"/> 
            class that is empty and has the specified initial capacity.</summary>
            <param name="capacity">The number of elements that the new list can initially store.</param>
        </member>
        <member name="M:SupportClass.EquatableList`1.AddRange(System.Collections.ICollection)">
            <summary>Adds a range of objects represented by the <see cref="T:System.Collections.ICollection"/>
            implementation.</summary>
            <param name="c">The <see cref="T:System.Collections.ICollection"/>
            implementation to add to this list.</param>
        </member>
        <member name="M:SupportClass.EquatableList`1.EnumerableCountsEqual(System.Collections.Generic.IEnumerable{`0},System.Collections.Generic.IEnumerable{`0})">
            <summary>Compares the counts of two <see cref="!:IEnumerable&lt;T&gt;"/>
            implementations.</summary>
            <remarks>This uses a trick in LINQ, sniffing types for implementations
            of interfaces that might supply shortcuts when trying to make comparisons.
            In this case, that is the <see cref="!:ICollection&lt;T&gt;"/> and
            <see cref="T:System.Collections.ICollection"/> interfaces, either of which can provide a count
            which can be used in determining the equality of sequences (if they don't have
            the same count, then they can't be equal).</remarks>
            <param name="x">The <see cref="!:IEnumerable&lt;T&gt;"/> from the left hand side of the
            comparison to check the count of.</param>
            <param name="y">The <see cref="!:IEnumerable&lt;T&gt;"/> from the right hand side of the
            comparison to check the count of.</param>
            <returns>Null if the result is indeterminate.  This occurs when either <paramref name="x"/>
            or <paramref name="y"/> doesn't implement <see cref="T:System.Collections.ICollection"/> or <see cref="!:ICollection&lt;T&gt;"/>.
            Otherwise, it will get the count from each and return true if they are equal, false otherwise.</returns>
        </member>
        <member name="M:SupportClass.EquatableList`1.Equals(System.Collections.Generic.IEnumerable{`0},System.Collections.Generic.IEnumerable{`0})">
            <summary>Compares the contents of a <see cref="!:IEnumerable&lt;T&gt;"/>
            implementation to another one to determine equality.</summary>
            <remarks>Thinking of the <see cref="!:IEnumerable&lt;T&gt;"/> implementation as
            a string with any number of characters, the algorithm checks
            each item in each list.  If any item of the list is not equal (or
            one list contains all the elements of another list), then that list
            element is compared to the other list element to see which
            list is greater.</remarks>
            <param name="x">The <see cref="!:IEnumerable&lt;T&gt;"/> implementation
            that is considered the left hand side.</param>
            <param name="y">The <see cref="!:IEnumerable&lt;T&gt;"/> implementation
            that is considered the right hand side.</param>
            <returns>True if the items are equal, false otherwise.</returns>
        </member>
        <member name="M:SupportClass.EquatableList`1.Equals(System.Collections.Generic.IEnumerable{`0})">
            <summary>Compares this sequence to another <see cref="!:IEnumerable&lt;T&gt;"/>
            implementation, returning true if they are equal, false otherwise.</summary>
            <param name="other">The other <see cref="!:IEnumerable&lt;T&gt;"/> implementation
            to compare against.</param>
            <returns>True if the sequence in <paramref name="other"/> 
            is the same as this one.</returns>
        </member>
        <member name="M:SupportClass.EquatableList`1.Equals(System.Object)">
            <summary>Compares this object for equality against other.</summary>
            <param name="obj">The other object to compare this object against.</param>
            <returns>True if this object and <paramref name="obj"/> are equal, false
            otherwise.</returns>
        </member>
        <member name="M:SupportClass.EquatableList`1.GetHashCode">
            <summary>Gets the hash code for the list.</summary>
            <returns>The hash code value.</returns>
        </member>
        <!-- Badly formed XML comment ignored for member "M:SupportClass.EquatableList`1.GetHashCode(System.Collections.Generic.IEnumerable{`0})" -->
        <member name="M:SupportClass.EquatableList`1.Clone">
            <summary>Clones the <see cref="T:SupportClass.EquatableList`1"/>.</summary>
            <remarks>This is a shallow clone.</remarks>
            <returns>A new shallow clone of this
            <see cref="T:SupportClass.EquatableList`1"/>.</returns>
        </member>
        <member name="T:SupportClass.AttributeImplItem">
            <summary>
            A simple wrapper to allow for the use of the GeneralKeyedCollection.  The
            wrapper is required as there can be several keys for an object depending
            on how many interfaces it implements.
            </summary>
        </member>
        <member name="T:SupportClass.OS">
            <summary>
            Provides platform infos.
            </summary>
        </member>
        <member name="P:SupportClass.OS.IsUnix">
            <summary>
            Whether we run under a Unix platform.
            </summary>
        </member>
        <member name="P:SupportClass.OS.IsWindows">
            <summary>
            Whether we run under a supported Windows platform.
            </summary>
        </member>
        <member name="T:SupportClass.CloseableThreadLocalProfiler">
            <summary>
            For Debuging purposes.
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.ChecksumIndexInput">
            <summary>Writes bytes through to a primary IndexOutput, computing
            checksum as it goes. Note that you cannot use seek(). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanWeight">
            <summary> Expert-only.  Public for use by other weight implementations</summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.NearSpansOrdered">
            <summary>A Spans that is formed from the ordered subspans of a SpanNearQuery
            where the subspans do not overlap and have a maximum slop between them.
            <p/>
            The formed spans only contains minimum slop matches.<br/>
            The matching slop is computed from the distance(s) between
            the non overlapping matching Spans.<br/>
            Successive matches are always formed from the successive Spans
            of the SpanNearQuery.
            <p/>
            The formed spans may contain overlaps when the slop is at least 1.
            For example, when querying using
            <pre>t1 t2 t3</pre>
            with slop at least 1, the fragment:
            <pre>t1 t2 t1 t3 t2 t3</pre>
            matches twice:
            <pre>t1 t2 .. t3      </pre>
            <pre>      t1 .. t2 t3</pre>
            
            
            Expert:
            Only public for subclassing.  Most implementations should not need this class
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.Spans.NearSpansOrdered.subSpans">
            <summary>The spans in the same order as the SpanNearQuery </summary>
        </member>
        <member name="F:Lucene.Net.Search.Spans.NearSpansOrdered.inSameDoc">
            <summary>Indicates that all subSpans have same doc() </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.AdvanceAfterOrdered">
            <summary>Advances the subSpans to just after an ordered match with a minimum slop
            that is smaller than the slop allowed by the SpanNearQuery.
            </summary>
            <returns> true iff there is such a match.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.ToSameDoc">
            <summary>Advance the subSpans to the same document </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.DocSpansOrdered(Lucene.Net.Search.Spans.Spans,Lucene.Net.Search.Spans.Spans)">
            <summary>Check whether two Spans in the same document are ordered.</summary>
            <param name="spans1">
            </param>
            <param name="spans2">
            </param>
            <returns> true iff spans1 starts before spans2
            or the spans start at the same position,
            and spans1 ends before spans2.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.DocSpansOrdered(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>Like {@link #DocSpansOrdered(Spans,Spans)}, but use the spans
            starts and ends as parameters.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.StretchToOrder">
            <summary>Order the subSpans within the same document by advancing all later spans
            after the previous one.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.NearSpansOrdered.ShrinkToAfterShortestMatch">
            <summary>The subSpans are ordered in the same doc, so there is a possible match.
            Compute the slop while making the match as short as possible by advancing
            all subSpans except the last one in reverse order.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.PhrasePositions">
            <summary> Position of a term in a document that takes into account the term offset within the phrase. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhrasePositions.NextPosition">
            <summary> Go to next location of this term current document, and set 
            <code>position</code> as <code>location - offset</code>, so that a 
            matching exact phrase is easily identified when all PhrasePositions 
            have exactly the same <code>position</code>.
            </summary>
        </member>
        <member name="T:Lucene.Net.LucenePackage">
            <summary>Lucene's package information, including version. *</summary>
        </member>
        <member name="T:Lucene.Net.Index.TermVectorOffsetInfo">
            <summary> The TermVectorOffsetInfo class holds information pertaining to a Term in a {@link Lucene.Net.Index.TermPositionVector}'s
            offset information.  This offset information is the character offset as set during the Analysis phase (and thus may not be the actual offset in the
            original content).
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.TermVectorOffsetInfo.EMPTY_OFFSET_INFO">
            <summary> Convenience declaration when creating a {@link Lucene.Net.Index.TermPositionVector} that stores only position information.</summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorOffsetInfo.GetEndOffset">
            <summary> The accessor for the ending offset for the term</summary>
            <returns> The offset
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorOffsetInfo.GetStartOffset">
            <summary> The accessor for the starting offset of the term.
            
            </summary>
            <returns> The offset
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorOffsetInfo.Equals(System.Object)">
            <summary> Two TermVectorOffsetInfos are equals if both the start and end offsets are the same</summary>
            <param name="o">The comparison Object
            </param>
            <returns> true if both {@link #GetStartOffset()} and {@link #GetEndOffset()} are the same for both objects.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermsHashPerField.SortPostings">
            <summary>Collapse the hash table &amp; sort in-place. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermsHashPerField.ComparePostings(Lucene.Net.Index.RawPostingList,Lucene.Net.Index.RawPostingList)">
            <summary>Compares term text for two Posting instance and
            returns -1 if p1 &lt; p2; 1 if p1 &gt; p2; else 0. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermsHashPerField.PostingEquals(System.Char[],System.Int32)">
            <summary>Test whether the text for current RawPostingList p equals
            current tokenText. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermsHashPerField.RehashPostings(System.Int32)">
            <summary>Called when postings hash is too small (> 50%
            occupied) or too large (&lt; 20% occupied). 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexFileNameFilter">
            <summary> Filename filter that accept filenames and extensions only created by Lucene.
            
            </summary>
            <version>  $rcs = ' $Id: Exp $ ' ;
            </version>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileNameFilter.IsCFSFile(System.String)">
            <summary> Returns true if this is a file that would be contained
            in a CFS file.  This function should only be called on
            files that pass the above "accept" (ie, are already
            known to be a Lucene index file).
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FormatPostingsTermsConsumer">
            <summary> NOTE: this API is experimental and will likely change</summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsTermsConsumer.AddTerm(System.Char[],System.Int32)">
            <summary>Adds a new term in this field; term ends with U+FFFF
            char 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsTermsConsumer.Finish">
            <summary>Called when we are done adding terms to this field </summary>
        </member>
        <member name="T:Lucene.Net.Index.FormatPostingsFieldsConsumer">
            <summary>Abstract API that consumes terms, doc, freq, prox and
            payloads postings.  Concrete implementations of this
            actually do "something" with the postings (write it into
            the index in a specific format).
            
            NOTE: this API is experimental and will likely change
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsFieldsConsumer.AddField(Lucene.Net.Index.FieldInfo)">
            <summary>Add a new field </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsFieldsConsumer.Finish">
            <summary>Called when we are done adding everything. </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsFieldsWriter.AddField(Lucene.Net.Index.FieldInfo)">
            <summary>Add a new field </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsFieldsWriter.Finish">
            <summary>Called when we are done adding everything. </summary>
        </member>
        <member name="T:Lucene.Net.Index.DefaultSkipListReader">
            <summary> Implements the skip list reader for the default posting list format
            that stores positions and payloads.
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MultiLevelSkipListReader">
            <summary> This abstract class reads skip lists with multiple levels.
            
            See {@link MultiLevelSkipListWriter} for the information about the encoding 
            of the multi level skip lists. 
            
            Subclasses must implement the abstract method {@link #ReadSkipData(int, IndexInput)}
            which defines the actual format of the skip data.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.GetDoc">
            <summary>Returns the id of the doc to which the last call of {@link #SkipTo(int)}
            has skipped.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.SkipTo(System.Int32)">
            <summary>Skips entries to the first beyond the current whose document number is
            greater than or equal to <i>target</i>. Returns the current doc count. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.SeekChild(System.Int32)">
            <summary>Seeks the skip entry on the given level </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.Init(System.Int64,System.Int32)">
            <summary>initializes the reader </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.LoadSkipLevels">
            <summary>Loads the skip levels  </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.ReadSkipData(System.Int32,Lucene.Net.Store.IndexInput)">
            <summary> Subclasses must implement the actual skip data encoding in this method.
            
            </summary>
            <param name="level">the level skip data shall be read from
            </param>
            <param name="skipStream">the skip stream to read from
            </param>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListReader.SetLastSkipData(System.Int32)">
            <summary>Copies the values of the last read skip entry on this level </summary>
        </member>
        <member name="T:Lucene.Net.Index.MultiLevelSkipListReader.SkipBuffer">
            <summary>used to buffer the top skip levels </summary>
        </member>
        <member name="M:Lucene.Net.Index.DefaultSkipListReader.GetFreqPointer">
            <summary>Returns the freq pointer of the doc to which the last call of 
            {@link MultiLevelSkipListReader#SkipTo(int)} has skipped.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DefaultSkipListReader.GetProxPointer">
            <summary>Returns the prox pointer of the doc to which the last call of 
            {@link MultiLevelSkipListReader#SkipTo(int)} has skipped.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.DefaultSkipListReader.GetPayloadLength">
            <summary>Returns the payload length of the payload stored just before 
            the doc to which the last call of {@link MultiLevelSkipListReader#SkipTo(int)} 
            has skipped.  
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.SinkTokenizer">
            <summary> A SinkTokenizer can be used to cache Tokens for use in an Analyzer
            <p/>
            WARNING: {@link TeeTokenFilter} and {@link SinkTokenizer} only work with the old TokenStream API.
            If you switch to the new API, you need to use {@link TeeSinkTokenFilter} instead, which offers 
            the same functionality.
            </summary>
            <seealso cref="T:Lucene.Net.Analysis.TeeTokenFilter">
            </seealso>
            <deprecated> Use {@link TeeSinkTokenFilter} instead
            
            
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.SinkTokenizer.GetTokens">
            <summary> Get the tokens in the internal List.
            <p/>
            WARNING: Adding tokens to this list requires the {@link #Reset()} method to be called in order for them
            to be made available.  Also, this Tokenizer does nothing to protect against {@link java.util.ConcurrentModificationException}s
            in the case of adds happening while {@link #Next(Lucene.Net.Analysis.Token)} is being called.
            <p/>
            WARNING: Since this SinkTokenizer can be reset and the cached tokens made available again, do not modify them. Modify clones instead.
            
            </summary>
            <returns> A List of {@link Lucene.Net.Analysis.Token}s
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.SinkTokenizer.Next(Lucene.Net.Analysis.Token)">
            <summary> Returns the next token out of the list of cached tokens</summary>
            <returns> The next {@link Lucene.Net.Analysis.Token} in the Sink.
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Analysis.SinkTokenizer.Add(Lucene.Net.Analysis.Token)">
            <summary> Override this method to cache only certain tokens, or new tokens based
            on the old tokens.
            
            </summary>
            <param name="t">The {@link Lucene.Net.Analysis.Token} to add to the sink
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.SinkTokenizer.Reset">
            <summary> Reset the internal data structures to the start at the front of the list of tokens.  Should be called
            if tokens were added to the list after an invocation of {@link #Next(Token)}
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Util.StringHelper">
            <summary> Methods for manipulating strings.
            
            $Id: StringHelper.java 801344 2009-08-05 18:05:06Z yonik $
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.StringHelper.interner">
            <summary> Expert:
            The StringInterner implementation used by Lucene.
            This shouldn't be changed to an incompatible implementation after other Lucene APIs have been used.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.StringHelper.Intern(System.String)">
            <summary>Return the same string object for all equal strings </summary>
        </member>
        <member name="M:Lucene.Net.Util.StringHelper.BytesDifference(System.Byte[],System.Int32,System.Byte[],System.Int32)">
            <summary> Compares two byte[] arrays, element by element, and returns the
            number of elements common to both arrays.
            
            </summary>
            <param name="bytes1">The first byte[] to compare
            </param>
            <param name="bytes2">The second byte[] to compare
            </param>
            <returns> The number of common elements.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.StringHelper.StringDifference(System.String,System.String)">
            <summary> Compares two strings, character by character, and returns the
            first position where the two strings differ from one another.
            
            </summary>
            <param name="s1">The first string to compare
            </param>
            <param name="s2">The second string to compare
            </param>
            <returns> The first position where the two strings differ.
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.WildcardQuery">
            <summary>Implements the wildcard search query. Supported wildcards are <code>*</code>, which
            matches any character sequence (including the empty one), and <code>?</code>,
            which matches any single character. Note this query can be slow, as it
            needs to iterate over many terms. In order to prevent extremely slow WildcardQueries,
            a Wildcard term should not start with one of the wildcards <code>*</code> or
            <code>?</code>.
            
            <p/>This query uses the {@link
            MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
            rewrite method.
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.WildcardTermEnum">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.WildcardQuery.GetTerm">
            <summary> Returns the pattern term.</summary>
        </member>
        <member name="M:Lucene.Net.Search.WildcardQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="T:Lucene.Net.Search.TermQuery">
            <summary>A Query that matches documents containing a term.
            This may be combined with other terms with a {@link BooleanQuery}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermQuery.#ctor(Lucene.Net.Index.Term)">
            <summary>Constructs a query for the term <code>t</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermQuery.GetTerm">
            <summary>Returns the term of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermQuery.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Search.SimilarityDelegator">
            <summary>Expert: Delegating scoring implementation.  Useful in {@link
            Query#GetSimilarity(Searcher)} implementations, to override only certain
            methods of a Searcher's Similiarty implementation.. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Similarity">
            <summary>Expert: Scoring API.
            <p/>Subclasses implement search scoring.
            
            <p/>The score of query <code>q</code> for document <code>d</code> correlates to the
            cosine-distance or dot-product between document and query vectors in a
            <a href="http://en.wikipedia.org/wiki/Vector_Space_Model">
            Vector Space Model (VSM) of Information Retrieval</a>.
            A document whose vector is closer to the query vector in that model is scored higher.
            
            The score is computed as follows:
            
            <p/>
            <table cellpadding="1" cellspacing="0" border="1" align="center">
            <tr><td>
            <table cellpadding="1" cellspacing="0" border="0" align="center">
            <tr>
            <td valign="middle" align="right" rowspan="1">
            score(q,d)  = 
            <A HREF="#formula_coord">coord(q,d)</A> 
            <A HREF="#formula_queryNorm">queryNorm(q)</A> 
            </td>
            <td valign="bottom" align="center" rowspan="1">
            <big><big><big></big></big></big>
            </td>
            <td valign="middle" align="right" rowspan="1">
            <big><big>(</big></big>
            <A HREF="#formula_tf">tf(t in d)</A> 
            <A HREF="#formula_idf">idf(t)</A><sup>2</sup> 
            <A HREF="#formula_termBoost">t.getBoost()</A>
            <A HREF="#formula_norm">norm(t,d)</A>
            <big><big>)</big></big>
            </td>
            </tr>
            <tr valigh="top">
            <td></td>
            <td align="center"><small>t in q</small></td>
            <td></td>
            </tr>
            </table>
            </td></tr>
            </table>
            
            <p/> where
            <ol>
            <li>
            <A NAME="formula_tf"></A>
            <b>tf(t in d)</b>
            correlates to the term's <i>frequency</i>,
            defined as the number of times term <i>t</i> appears in the currently scored document <i>d</i>.
            Documents that have more occurrences of a given term receive a higher score.
            The default computation for <i>tf(t in d)</i> in
            {@link Lucene.Net.Search.DefaultSimilarity#Tf(float) DefaultSimilarity} is:
            
            <br/><br/>
            <table cellpadding="2" cellspacing="2" border="0" align="center">
            <tr>
            <td valign="middle" align="right" rowspan="1">
            {@link Lucene.Net.Search.DefaultSimilarity#Tf(float) tf(t in d)}  = 
            </td>
            <td valign="top" align="center" rowspan="1">
            frequency<sup><big></big></sup>
            </td>
            </tr>
            </table>
            <br/><br/>
            </li>
            
            <li>
            <A NAME="formula_idf"></A>
            <b>idf(t)</b> stands for Inverse Document Frequency. This value
            correlates to the inverse of <i>docFreq</i>
            (the number of documents in which the term <i>t</i> appears).
            This means rarer terms give higher contribution to the total score.
            The default computation for <i>idf(t)</i> in
            {@link Lucene.Net.Search.DefaultSimilarity#Idf(int, int) DefaultSimilarity} is:
            
            <br/><br/>
            <table cellpadding="2" cellspacing="2" border="0" align="center">
            <tr>
            <td valign="middle" align="right">
            {@link Lucene.Net.Search.DefaultSimilarity#Idf(int, int) idf(t)} = 
            </td>
            <td valign="middle" align="center">
            1 + log <big>(</big>
            </td>
            <td valign="middle" align="center">
            <table>
            <tr><td align="center"><small>numDocs</small></td></tr>
            <tr><td align="center"></td></tr>
            <tr><td align="center"><small>docFreq+1</small></td></tr>
            </table>
            </td>
            <td valign="middle" align="center">
            <big>)</big>
            </td>
            </tr>
            </table>
            <br/><br/>
            </li>
            
            <li>
            <A NAME="formula_coord"></A>
            <b>coord(q,d)</b>
            is a score factor based on how many of the query terms are found in the specified document.
            Typically, a document that contains more of the query's terms will receive a higher score
            than another document with fewer query terms.
            This is a search time factor computed in
            {@link #Coord(int, int) coord(q,d)}
            by the Similarity in effect at search time.
            <br/><br/>
            </li>
            
            <li><b>
            <A NAME="formula_queryNorm"></A>
            queryNorm(q)
            </b>
            is a normalizing factor used to make scores between queries comparable.
            This factor does not affect document ranking (since all ranked documents are multiplied by the same factor),
            but rather just attempts to make scores from different queries (or even different indexes) comparable.
            This is a search time factor computed by the Similarity in effect at search time.
            
            The default computation in
            {@link Lucene.Net.Search.DefaultSimilarity#QueryNorm(float) DefaultSimilarity}
            is:
            <br/><br/>
            <table cellpadding="1" cellspacing="0" border="0" align="center">
            <tr>
            <td valign="middle" align="right" rowspan="1">
            queryNorm(q)   = 
            {@link Lucene.Net.Search.DefaultSimilarity#QueryNorm(float) queryNorm(sumOfSquaredWeights)}
             = 
            </td>
            <td valign="middle" align="center" rowspan="1">
            <table>
            <tr><td align="center"><big>1</big></td></tr>
            <tr><td align="center"><big>
            
            </big></td></tr>
            <tr><td align="center">sumOfSquaredWeights<sup><big></big></sup></td></tr>
            </table>
            </td>
            </tr>
            </table>
            <br/><br/>
            
            The sum of squared weights (of the query terms) is
            computed by the query {@link Lucene.Net.Search.Weight} object.
            For example, a {@link Lucene.Net.Search.BooleanQuery boolean query}
            computes this value as:
            
            <br/><br/>
            <table cellpadding="1" cellspacing="0" border="0" align="center">
            <tr>
            <td valign="middle" align="right" rowspan="1">
            {@link Lucene.Net.Search.Weight#SumOfSquaredWeights() sumOfSquaredWeights}  = 
            {@link Lucene.Net.Search.Query#GetBoost() q.getBoost()} <sup><big>2</big></sup>
            
            </td>
            <td valign="bottom" align="center" rowspan="1">
            <big><big><big></big></big></big>
            </td>
            <td valign="middle" align="right" rowspan="1">
            <big><big>(</big></big>
            <A HREF="#formula_idf">idf(t)</A> 
            <A HREF="#formula_termBoost">t.getBoost()</A>
            <big><big>) <sup>2</sup> </big></big>
            </td>
            </tr>
            <tr valigh="top">
            <td></td>
            <td align="center"><small>t in q</small></td>
            <td></td>
            </tr>
            </table>
            <br/><br/>
            
            </li>
            
            <li>
            <A NAME="formula_termBoost"></A>
            <b>t.getBoost()</b>
            is a search time boost of term <i>t</i> in the query <i>q</i> as
            specified in the query text
            (see <A HREF="../../../../../../queryparsersyntax.html#Boosting a Term">query syntax</A>),
            or as set by application calls to
            {@link Lucene.Net.Search.Query#SetBoost(float) setBoost()}.
            Notice that there is really no direct API for accessing a boost of one term in a multi term query,
            but rather multi terms are represented in a query as multi
            {@link Lucene.Net.Search.TermQuery TermQuery} objects,
            and so the boost of a term in the query is accessible by calling the sub-query
            {@link Lucene.Net.Search.Query#GetBoost() getBoost()}.
            <br/><br/>
            </li>
            
            <li>
            <A NAME="formula_norm"></A>
            <b>norm(t,d)</b> encapsulates a few (indexing time) boost and length factors:
            
            <ul>
            <li><b>Document boost</b> - set by calling
            {@link Lucene.Net.Documents.Document#SetBoost(float) doc.setBoost()}
            before adding the document to the index.
            </li>
            <li><b>Field boost</b> - set by calling
            {@link Lucene.Net.Documents.Fieldable#SetBoost(float) field.setBoost()}
            before adding the field to a document.
            </li>
            <li>{@link #LengthNorm(String, int) <b>lengthNorm</b>(field)} - computed
            when the document is added to the index in accordance with the number of tokens
            of this field in the document, so that shorter fields contribute more to the score.
            LengthNorm is computed by the Similarity class in effect at indexing.
            </li>
            </ul>
            
            <p/>
            When a document is added to the index, all the above factors are multiplied.
            If the document has multiple fields with the same name, all their boosts are multiplied together:
            
            <br/><br/>
            <table cellpadding="1" cellspacing="0" border="0" align="center">
            <tr>
            <td valign="middle" align="right" rowspan="1">
            norm(t,d)  = 
            {@link Lucene.Net.Documents.Document#GetBoost() doc.getBoost()}
            
            {@link #LengthNorm(String, int) lengthNorm(field)}
            
            </td>
            <td valign="bottom" align="center" rowspan="1">
            <big><big><big></big></big></big>
            </td>
            <td valign="middle" align="right" rowspan="1">
            {@link Lucene.Net.Documents.Fieldable#GetBoost() f.getBoost}()
            </td>
            </tr>
            <tr valigh="top">
            <td></td>
            <td align="center"><small>field <i><b>f</b></i> in <i>d</i> named as <i><b>t</b></i></small></td>
            <td></td>
            </tr>
            </table>
            <br/><br/>
            However the resulted <i>norm</i> value is {@link #EncodeNorm(float) encoded} as a single byte
            before being stored.
            At search time, the norm byte value is read from the index
            {@link Lucene.Net.Store.Directory directory} and
            {@link #DecodeNorm(byte) decoded} back to a float <i>norm</i> value.
            This encoding/decoding, while reducing index size, comes with the price of
            precision loss - it is not guaranteed that decode(encode(x)) = x.
            For instance, decode(encode(0.89)) = 0.75.
            Also notice that search time is too late to modify this <i>norm</i> part of scoring, e.g. by
            using a different {@link Similarity} for search.
            <br/><br/>
            </li>
            </ol>
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.SetDefault(Lucene.Net.Search.Similarity)">
            </seealso>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Searcher.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.SetDefault(Lucene.Net.Search.Similarity)">
            <summary>Set the default Similarity implementation used by indexing and search
            code.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Searcher.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.GetDefault">
            <summary>Return the default Similarity implementation used by indexing and search
            code.
            
            <p/>This is initially an instance of {@link DefaultSimilarity}.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Searcher.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
            <seealso cref="M:Lucene.Net.Index.IndexWriter.SetSimilarity(Lucene.Net.Search.Similarity)">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.NORM_TABLE">
            <summary>Cache of decoded bytes. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.DecodeNorm(System.Byte)">
            <summary>Decodes a normalization factor stored in an index.</summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.EncodeNorm(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.GetNormDecoder">
            <summary>Returns a table for decoding normalization bytes.</summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.EncodeNorm(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.ComputeNorm(System.String,Lucene.Net.Index.FieldInvertState)">
            <summary> Compute the normalization value for a field, given the accumulated
            state of term processing for this field (see {@link FieldInvertState}).
            
            <p/>Implementations should calculate a float value based on the field
            state and then return that value.
            
            <p/>For backward compatibility this method by default calls
            {@link #LengthNorm(String, int)} passing
            {@link FieldInvertState#GetLength()} as the second argument, and
            then multiplies this value by {@link FieldInvertState#GetBoost()}.<p/>
            
            <p/><b>WARNING</b>: This API is new and experimental and may
            suddenly change.<p/>
            
            </summary>
            <param name="field">field name
            </param>
            <param name="state">current processing state for this field
            </param>
            <returns> the calculated float norm
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.LengthNorm(System.String,System.Int32)">
            <summary>Computes the normalization value for a field given the total number of
            terms contained in a field.  These values, together with field boosts, are
            stored in an index and multipled into scores for hits on each field by the
            search code.
            
            <p/>Matches in longer fields are less precise, so implementations of this
            method usually return smaller values when <code>numTokens</code> is large,
            and larger values when <code>numTokens</code> is small.
            
            <p/>Note that the return values are computed under 
            {@link Lucene.Net.Index.IndexWriter#AddDocument(Lucene.Net.Documents.Document)} 
            and then stored using
            {@link #EncodeNorm(float)}.  
            Thus they have limited precision, and documents
            must be re-indexed if this method is altered.
            
            </summary>
            <param name="fieldName">the name of the field
            </param>
            <param name="numTokens">the total number of tokens contained in fields named
            <i>fieldName</i> of <i>doc</i>.
            </param>
            <returns> a normalization factor for hits on this field of this document
            
            </returns>
            <seealso cref="!:Lucene.Net.Documents.Field.SetBoost(float)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.QueryNorm(System.Single)">
            <summary>Computes the normalization value for a query given the sum of the squared
            weights of each of the query terms.  This value is then multipled into the
            weight of each query term.
            
            <p/>This does not affect ranking, but rather just attempts to make scores
            from different queries comparable.
            
            </summary>
            <param name="sumOfSquaredWeights">the sum of the squares of query term weights
            </param>
            <returns> a normalization factor for query weights
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.EncodeNorm(System.Single)">
            <summary>Encodes a normalization factor for storage in an index.
            
            <p/>The encoding uses a three-bit mantissa, a five-bit exponent, and
            the zero-exponent point at 15, thus
            representing values from around 7x10^9 to 2x10^-9 with about one
            significant decimal digit of accuracy.  Zero is also represented.
            Negative numbers are rounded up to zero.  Values too large to represent
            are rounded down to the largest representable value.  Positive values too
            small to represent are rounded up to the smallest positive representable
            value.
            
            </summary>
            <seealso cref="!:Lucene.Net.Documents.Field.SetBoost(float)">
            </seealso>
            <seealso cref="T:Lucene.Net.Util.SmallFloat">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Tf(System.Int32)">
            <summary>Computes a score factor based on a term or phrase's frequency in a
            document.  This value is multiplied by the {@link #Idf(Term, Searcher)}
            factor for each term in the query and these products are then summed to
            form the initial score for a document.
            
            <p/>Terms and phrases repeated in a document indicate the topic of the
            document, so implementations of this method usually return larger values
            when <code>freq</code> is large, and smaller values when <code>freq</code>
            is small.
            
            <p/>The default implementation calls {@link #Tf(float)}.
            
            </summary>
            <param name="freq">the frequency of a term within a document
            </param>
            <returns> a score factor based on a term's within-document frequency
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.SloppyFreq(System.Int32)">
            <summary>Computes the amount of a sloppy phrase match, based on an edit distance.
            This value is summed for each sloppy phrase match in a document to form
            the frequency that is passed to {@link #Tf(float)}.
            
            <p/>A phrase match with a small edit distance to a document passage more
            closely matches the document, so implementations of this method usually
            return larger values when the edit distance is small and smaller values
            when it is large.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.PhraseQuery.SetSlop(System.Int32)">
            </seealso>
            <param name="distance">the edit distance of this sloppy phrase match
            </param>
            <returns> the frequency increment for this match
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Tf(System.Single)">
            <summary>Computes a score factor based on a term or phrase's frequency in a
            document.  This value is multiplied by the {@link #Idf(Term, Searcher)}
            factor for each term in the query and these products are then summed to
            form the initial score for a document.
            
            <p/>Terms and phrases repeated in a document indicate the topic of the
            document, so implementations of this method usually return larger values
            when <code>freq</code> is large, and smaller values when <code>freq</code>
            is small.
            
            </summary>
            <param name="freq">the frequency of a term within a document
            </param>
            <returns> a score factor based on a term's within-document frequency
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Idf(Lucene.Net.Index.Term,Lucene.Net.Search.Searcher)">
            <summary>Computes a score factor for a simple term.
            
            <p/>The default implementation is:<pre>
            return idf(searcher.docFreq(term), searcher.maxDoc());
            </pre>
            
            Note that {@link Searcher#MaxDoc()} is used instead of
            {@link Lucene.Net.Index.IndexReader#NumDocs()} because it is proportional to
            {@link Searcher#DocFreq(Term)} , i.e., when one is inaccurate,
            so is the other, and in the same direction.
            
            </summary>
            <param name="term">the term in question
            </param>
            <param name="searcher">the document collection being searched
            </param>
            <returns> a score factor for the term
            </returns>
            <deprecated> see {@link #IdfExplain(Term, Searcher)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.IdfExplain(Lucene.Net.Index.Term,Lucene.Net.Search.Searcher)">
            <summary> Computes a score factor for a simple term and returns an explanation
            for that score factor.
            
            <p/>
            The default implementation uses:
            
            <pre>
            idf(searcher.docFreq(term), searcher.maxDoc());
            </pre>
            
            Note that {@link Searcher#MaxDoc()} is used instead of
            {@link Lucene.Net.Index.IndexReader#NumDocs()} because it is
            proportional to {@link Searcher#DocFreq(Term)} , i.e., when one is
            inaccurate, so is the other, and in the same direction.
            
            </summary>
            <param name="term">the term in question
            </param>
            <param name="searcher">the document collection being searched
            </param>
            <returns> an IDFExplain object that includes both an idf score factor 
            and an explanation for the term.
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Idf(System.Collections.ICollection,Lucene.Net.Search.Searcher)">
            <summary>Computes a score factor for a phrase.
            
            <p/>The default implementation sums the {@link #Idf(Term,Searcher)} factor
            for each term in the phrase.
            
            </summary>
            <param name="terms">the terms in the phrase
            </param>
            <param name="searcher">the document collection being searched
            </param>
            <returns> idf score factor
            </returns>
            <deprecated> see {@link #idfExplain(Collection, Searcher)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.idfExplain(System.Collections.ICollection,Lucene.Net.Search.Searcher)">
            <summary> Computes a score factor for a phrase.
            
            <p/>
            The default implementation sums the idf factor for
            each term in the phrase.
            
            </summary>
            <param name="terms">the terms in the phrase
            </param>
            <param name="searcher">the document collection being searched
            </param>
            <returns> an IDFExplain object that includes both an idf 
            score factor for the phrase and an explanation 
            for each term.
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Idf(System.Int32,System.Int32)">
            <summary>Computes a score factor based on a term's document frequency (the number
            of documents which contain the term).  This value is multiplied by the
            {@link #Tf(int)} factor for each term in the query and these products are
            then summed to form the initial score for a document.
            
            <p/>Terms that occur in fewer documents are better indicators of topic, so
            implementations of this method usually return larger values for rare terms,
            and smaller values for common terms.
            
            </summary>
            <param name="docFreq">the number of documents which contain the term
            </param>
            <param name="numDocs">the total number of documents in the collection
            </param>
            <returns> a score factor based on the term's document frequency
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.Coord(System.Int32,System.Int32)">
            <summary>Computes a score factor based on the fraction of all query terms that a
            document contains.  This value is multiplied into scores.
            
            <p/>The presence of a large portion of the query terms indicates a better
            match with the query, so implementations of this method usually return
            larger values when the ratio between these parameters is large and smaller
            values when the ratio between them is small.
            
            </summary>
            <param name="overlap">the number of query terms matched in the document
            </param>
            <param name="maxOverlap">the total number of terms in the query
            </param>
            <returns> a score factor based on term overlap with the query
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.ScorePayload(System.String,System.Byte[],System.Int32,System.Int32)">
            <summary> Calculate a scoring factor based on the data in the payload.  Overriding implementations
            are responsible for interpreting what is in the payload.  Lucene makes no assumptions about
            what is in the byte array.
            <p/>
            The default implementation returns 1.
            
            </summary>
            <param name="fieldName">The fieldName of the term this payload belongs to
            </param>
            <param name="payload">The payload byte array to be scored
            </param>
            <param name="offset">The offset into the payload array
            </param>
            <param name="length">The length in the array
            </param>
            <returns> An implementation dependent float to be used as a scoring factor
            
            </returns>
            <deprecated> See {@link #ScorePayload(int, String, int, int, byte[], int, int)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.ScorePayload(System.Int32,System.String,System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32)">
            <summary> Calculate a scoring factor based on the data in the payload.  Overriding implementations
            are responsible for interpreting what is in the payload.  Lucene makes no assumptions about
            what is in the byte array.
            <p/>
            The default implementation returns 1.
            
            </summary>
            <param name="docId">The docId currently being scored.  If this value is {@link #NO_DOC_ID_PROVIDED}, then it should be assumed that the PayloadQuery implementation does not provide document information
            </param>
            <param name="fieldName">The fieldName of the term this payload belongs to
            </param>
            <param name="start">The start position of the payload
            </param>
            <param name="end">The end position of the payload
            </param>
            <param name="payload">The payload byte array to be scored
            </param>
            <param name="offset">The offset into the payload array
            </param>
            <param name="length">The length in the array
            </param>
            <returns> An implementation dependent float to be used as a scoring factor
            
            </returns>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.SupportedMethods">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.knownMethodSupport">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Similarity.GetSupportedMethods(System.Type)">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.defaultImpl">
            <summary>The Similarity implementation used by default. 
            TODO: move back to top when old API is removed! 
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Similarity.MethodSupport">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.MethodSupport.T_IDF_METHOD_PARAMS">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.Similarity.MethodSupport.C_IDF_METHOD_PARAMS">
            <deprecated> Remove this when old API is removed! 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SimilarityDelegator.#ctor(Lucene.Net.Search.Similarity)">
            <summary>Construct a {@link Similarity} that delegates all methods to another.
            
            </summary>
            <param name="delegee">the Similarity implementation to delegate to
            </param>
        </member>
        <member name="T:Lucene.Net.Search.RangeQuery">
            <summary> A Query that matches documents within an exclusive range of terms.
            
            <p/>This query matches the documents looking for terms that fall into the
            supplied range according to {@link Term#CompareTo(Term)}. It is not intended
            for numerical ranges, use {@link NumericRangeQuery} instead.
            
            <p/>This query uses {@linkplain
            MultiTermQuery#SCORING_BOOLEAN_QUERY_REWRITE}.  If you
            want to change this, use the new {@link TermRangeQuery}
            instead.
            
            </summary>
            <deprecated> Use {@link TermRangeQuery} for term ranges or
            {@link NumericRangeQuery} for numeric ranges instead.
            This class will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.#ctor(Lucene.Net.Index.Term,Lucene.Net.Index.Term,System.Boolean)">
            <summary>Constructs a query selecting all terms greater than
            <code>lowerTerm</code> but less than <code>upperTerm</code>.
            There must be at least one term and either term may be null,
            in which case there is no bound on that side, but if there are
            two terms, both terms <b>must</b> be for the same field.
            
            </summary>
            <param name="lowerTerm">The Term at the lower end of the range
            </param>
            <param name="upperTerm">The Term at the upper end of the range
            </param>
            <param name="inclusive">If true, both <code>lowerTerm</code> and
            <code>upperTerm</code> will themselves be included in the range.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.#ctor(Lucene.Net.Index.Term,Lucene.Net.Index.Term,System.Boolean,System.Globalization.CompareInfo)">
            <summary>Constructs a query selecting all terms greater than
            <code>lowerTerm</code> but less than <code>upperTerm</code>.
            There must be at least one term and either term may be null,
            in which case there is no bound on that side, but if there are
            two terms, both terms <b>must</b> be for the same field.
            <p/>
            If <code>collator</code> is not null, it will be used to decide whether
            index terms are within the given range, rather than using the Unicode code
            point order in which index terms are stored.
            <p/>
            <strong>WARNING:</strong> Using this constructor and supplying a non-null
            value in the <code>collator</code> parameter will cause every single 
            index Term in the Field referenced by lowerTerm and/or upperTerm to be
            examined.  Depending on the number of index Terms in this Field, the 
            operation could be very slow.
            
            </summary>
            <param name="lowerTerm">The Term at the lower end of the range
            </param>
            <param name="upperTerm">The Term at the upper end of the range
            </param>
            <param name="inclusive">If true, both <code>lowerTerm</code> and
            <code>upperTerm</code> will themselves be included in the range.
            </param>
            <param name="collator">The collator to use to collate index Terms, to determine
            their membership in the range bounded by <code>lowerTerm</code> and
            <code>upperTerm</code>.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.GetField">
            <summary>Returns the field name for this query </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.GetLowerTerm">
            <summary>Returns the lower term of this range query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.GetUpperTerm">
            <summary>Returns the upper term of this range query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.IsInclusive">
            <summary>Returns <code>true</code> if the range query is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.GetCollator">
            <summary>Returns the collator used to determine range inclusion, if any. </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeQuery.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Search.RangeFilter">
            <summary> A Filter that restricts search results to a range of values in a given
            field.
            
            <p/>This filter matches the documents looking for terms that fall into the
            supplied range according to {@link String#compareTo(String)}. It is not intended
            for numerical ranges, use {@link NumericRangeFilter} instead.
            
            <p/>If you construct a large number of range filters with different ranges but on the 
            same field, {@link FieldCacheRangeFilter} may have significantly better performance. 
            
            </summary>
            <deprecated> Use {@link TermRangeFilter} for term ranges or
            {@link NumericRangeFilter} for numeric ranges instead.
            This class will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.RangeFilter.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean)">
            <param name="fieldName">The field this range applies to
            </param>
            <param name="lowerTerm">The lower bound on this range
            </param>
            <param name="upperTerm">The upper bound on this range
            </param>
            <param name="includeLower">Does this range include the lower bound?
            </param>
            <param name="includeUpper">Does this range include the upper bound?
            </param>
            <throws>  IllegalArgumentException if both terms are null or if </throws>
            <summary>  lowerTerm is null and includeLower is true (similar for upperTerm
            and includeUpper)
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeFilter.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean,System.Globalization.CompareInfo)">
            <summary> <strong>WARNING:</strong> Using this constructor and supplying a non-null
            value in the <code>collator</code> parameter will cause every single 
            index Term in the Field referenced by lowerTerm and/or upperTerm to be
            examined.  Depending on the number of index Terms in this Field, the 
            operation could be very slow.
            
            </summary>
            <param name="lowerTerm">The lower bound on this range
            </param>
            <param name="upperTerm">The upper bound on this range
            </param>
            <param name="includeLower">Does this range include the lower bound?
            </param>
            <param name="includeUpper">Does this range include the upper bound?
            </param>
            <param name="collator">The collator to use when determining range inclusion; set
            to null to use Unicode code point ordering instead of collation.
            </param>
            <throws>  IllegalArgumentException if both terms are null or if </throws>
            <summary>  lowerTerm is null and includeLower is true (similar for upperTerm
            and includeUpper)
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeFilter.Less(System.String,System.String)">
            <summary> Constructs a filter for field <code>fieldName</code> matching
            less than or equal to <code>upperTerm</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.RangeFilter.More(System.String,System.String)">
            <summary> Constructs a filter for field <code>fieldName</code> matching
            greater than or equal to <code>lowerTerm</code>.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.PositiveScoresOnlyCollector">
            <summary> A {@link Collector} implementation which wraps another
            {@link Collector} and makes sure only documents with
            scores &gt; 0 are collected.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.PayloadTermQuery">
            <summary> This class is very similar to
            {@link Lucene.Net.Search.Spans.SpanTermQuery} except that it factors
            in the value of the payload located at each of the positions where the
            {@link Lucene.Net.Index.Term} occurs.
            <p/>
            In order to take advantage of this, you must override
            {@link Lucene.Net.Search.Similarity#ScorePayload(String, byte[],int,int)}
            which returns 1 by default.
            <p/>
            Payload scores are aggregated using a pluggable {@link PayloadFunction}.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadTermQuery.PayloadTermWeight.PayloadTermSpanScorer.Score">
            <summary> </summary>
            <returns> {@link #GetSpanScore()} * {@link #GetPayloadScore()}
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadTermQuery.PayloadTermWeight.PayloadTermSpanScorer.GetSpanScore">
            <summary> Returns the SpanScorer score only.
            <p/>
            Should not be overriden without good cause!
            
            </summary>
            <returns> the score for just the Span part w/o the payload
            </returns>
            <throws>  IOException </throws>
            <summary> 
            </summary>
            <seealso cref="M:Lucene.Net.Search.Payloads.PayloadTermQuery.PayloadTermWeight.PayloadTermSpanScorer.Score">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadTermQuery.PayloadTermWeight.PayloadTermSpanScorer.GetPayloadScore">
            <summary> The score for the payload
            
            </summary>
            <returns> The score, as calculated by
            {@link PayloadFunction#DocScore(int, String, int, float)}
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.AveragePayloadFunction">
            <summary> Calculate the final score as the average score of all payloads seen.
            <p/>
            Is thread safe and completely reusable. 
            
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldDocSortedHitQueue">
            <summary> Expert: Collects sorted results from Searchable's and collates them.
            The elements put into this queue must be of type FieldDoc.
            
            <p/>Created: Feb 11, 2004 2:04:21 PM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: FieldDocSortedHitQueue.java 695514 2008-09-15 15:42:11Z otis $
            </version>
        </member>
        <member name="M:Lucene.Net.Search.FieldDocSortedHitQueue.#ctor(Lucene.Net.Search.SortField[],System.Int32)">
            <summary> Creates a hit queue sorted by the given list of fields.</summary>
            <param name="fields">Fieldable names, in priority order (highest priority first).
            </param>
            <param name="size"> The number of hits to retain.  Must be greater than zero.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FieldDocSortedHitQueue.SetFields(Lucene.Net.Search.SortField[])">
            <summary> Allows redefinition of sort fields if they are <code>null</code>.
            This is to handle the case using ParallelMultiSearcher where the
            original list contains AUTO and we don't know the actual sort
            type until the values come back.  The fields can only be set once.
            This method is thread safe.
            </summary>
            <param name="fields">
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FieldDocSortedHitQueue.GetFields">
            <summary>Returns the fields being used to sort. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldDocSortedHitQueue.HasCollators(Lucene.Net.Search.SortField[])">
            <summary>Returns an array of collators, possibly <code>null</code>.  The collators
            correspond to any SortFields which were given a specific locale.
            </summary>
            <param name="fields">Array of sort fields.
            </param>
            <returns> Array, possibly <code>null</code>.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FieldDocSortedHitQueue.LessThan(System.Object,System.Object)">
            <summary> Returns whether <code>a</code> is less relevant than <code>b</code>.</summary>
            <param name="a">ScoreDoc
            </param>
            <param name="b">ScoreDoc
            </param>
            <returns> <code>true</code> if document <code>a</code> should be sorted after document <code>b</code>.
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.BooleanQuery">
            <summary>A Query that matches documents matching boolean combinations of other
            queries, e.g. {@link TermQuery}s, {@link PhraseQuery}s or other
            BooleanQuerys.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetMaxClauseCount">
            <summary>Return the maximum number of clauses permitted, 1024 by default.
            Attempts to add more than the permitted number of clauses cause {@link
            TooManyClauses} to be thrown.
            </summary>
            <seealso cref="M:Lucene.Net.Search.BooleanQuery.SetMaxClauseCount(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.SetMaxClauseCount(System.Int32)">
            <summary> Set the maximum number of clauses permitted per BooleanQuery.
            Default value is 1024.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.#ctor">
            <summary>Constructs an empty boolean query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.#ctor(System.Boolean)">
            <summary>Constructs an empty boolean query.
            
            {@link Similarity#Coord(int,int)} may be disabled in scoring, as
            appropriate. For example, this score factor does not make sense for most
            automatically generated queries, like {@link WildcardQuery} and {@link
            FuzzyQuery}.
            
            </summary>
            <param name="disableCoord">disables {@link Similarity#Coord(int,int)} in scoring.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.IsCoordDisabled">
            <summary>Returns true iff {@link Similarity#Coord(int,int)} is disabled in
            scoring for this query instance.
            </summary>
            <seealso cref="!:BooleanQuery(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.SetMinimumNumberShouldMatch(System.Int32)">
            <summary> Specifies a minimum number of the optional BooleanClauses
            which must be satisfied.
            
            <p/>
            By default no optional clauses are necessary for a match
            (unless there are no required clauses).  If this method is used,
            then the specified number of clauses is required.
            <p/>
            <p/>
            Use of this method is totally independent of specifying that
            any specific clauses are required (or prohibited).  This number will
            only be compared against the number of matching optional clauses.
            <p/>
            <p/>
            EXPERT NOTE: Using this method may force collecting docs in order,
            regardless of whether setAllowDocsOutOfOrder(true) has been called.
            <p/>
            
            </summary>
            <param name="min">the number of optional clauses that must match
            </param>
            <seealso cref="!:setAllowDocsOutOfOrder">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetMinimumNumberShouldMatch">
            <summary> Gets the minimum number of the optional BooleanClauses
            which must be satisifed.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.Add(Lucene.Net.Search.Query,Lucene.Net.Search.BooleanClause.Occur)">
            <summary>Adds a clause to a boolean query.
            
            </summary>
            <throws>  TooManyClauses if the new number of clauses exceeds the maximum clause number </throws>
            <seealso cref="M:Lucene.Net.Search.BooleanQuery.GetMaxClauseCount">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.Add(Lucene.Net.Search.BooleanClause)">
            <summary>Adds a clause to a boolean query.</summary>
            <throws>  TooManyClauses if the new number of clauses exceeds the maximum clause number </throws>
            <seealso cref="M:Lucene.Net.Search.BooleanQuery.GetMaxClauseCount">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetClauses">
            <summary>Returns the set of clauses in this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.Clauses">
            <summary>Returns the list of clauses in this query. </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanQuery.allowDocsOutOfOrder">
            <summary> Whether hit docs may be collected out of docid order.
            
            </summary>
            <deprecated> this will not be needed anymore, as
            {@link Weight#ScoresDocsOutOfOrder()} is used.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.SetAllowDocsOutOfOrder(System.Boolean)">
            <summary> Expert: Indicates whether hit docs may be collected out of docid order.
            
            <p/>
            Background: although the contract of the Scorer class requires that
            documents be iterated in order of doc id, this was not true in early
            versions of Lucene. Many pieces of functionality in the current Lucene code
            base have undefined behavior if this contract is not upheld, but in some
            specific simple cases may be faster. (For example: disjunction queries with
            less than 32 prohibited clauses; This setting has no effect for other
            queries.)
            <p/>
            
            <p/>
            Specifics: By setting this option to true, docid N might be scored for a
            single segment before docid N-1. Across multiple segments, docs may be
            scored out of order regardless of this setting - it only applies to scoring
            a single segment.
            
            Being static, this setting is system wide.
            <p/>
            
            </summary>
            <deprecated> this is not needed anymore, as
            {@link Weight#ScoresDocsOutOfOrder()} is used.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetAllowDocsOutOfOrder">
            <summary> Whether hit docs may be collected out of docid order.
            
            </summary>
            <seealso cref="!:SetAllowDocsOutOfOrder(boolean)">
            </seealso>
            <deprecated> this is not needed anymore, as
            {@link Weight#ScoresDocsOutOfOrder()} is used.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.SetUseScorer14(System.Boolean)">
            <deprecated> Use {@link #SetAllowDocsOutOfOrder(boolean)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetUseScorer14">
            <deprecated> Use {@link #GetAllowDocsOutOfOrder()} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanQuery.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Search.BooleanQuery.TooManyClauses">
            <summary>Thrown when an attempt is made to add more than {@link
            #GetMaxClauseCount()} clauses. This typically happens if
            a PrefixQuery, FuzzyQuery, WildcardQuery, or TermRangeQuery 
            is expanded to many terms during search. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.BooleanQuery.BooleanWeight">
            <summary> Expert: the Weight for BooleanQuery, used to
            normalize, score and explain these queries.
            
            <p/>NOTE: this API and implementation is subject to
            change suddenly in the next release.<p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanQuery.BooleanWeight.similarity">
            <summary>The Similarity implementation. </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermsHash">
            <summary>This class implements {@link InvertedDocConsumer}, which
            is passed each token produced by the analyzer on each
            field.  It stores these tokens in a hash table, and
            allocates separate byte streams per token.  Consumers of
            this class, eg {@link FreqProxTermsWriter} and {@link
            TermVectorsTermsWriter}, write their own byte streams
            under each term.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.InvertedDocConsumer.AddThread(Lucene.Net.Index.DocInverterPerThread)">
            <summary>Add a new thread </summary>
        </member>
        <member name="M:Lucene.Net.Index.InvertedDocConsumer.Abort">
            <summary>Abort (called after hitting AbortException) </summary>
        </member>
        <member name="M:Lucene.Net.Index.InvertedDocConsumer.Flush(System.Collections.IDictionary,Lucene.Net.Index.SegmentWriteState)">
            <summary>Flush a new segment </summary>
        </member>
        <member name="M:Lucene.Net.Index.InvertedDocConsumer.CloseDocStore(Lucene.Net.Index.SegmentWriteState)">
            <summary>Close doc stores </summary>
        </member>
        <member name="M:Lucene.Net.Index.InvertedDocConsumer.FreeRAM">
            <summary>Attempt to free RAM, returning true if any RAM was
            freed 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.StoredFieldsWriter">
            <summary>This is a DocFieldConsumer that writes stored fields. </summary>
        </member>
        <member name="M:Lucene.Net.Index.StoredFieldsWriter.Fill(System.Int32)">
            <summary>Fills in any hole in the docIDs </summary>
        </member>
        <member name="T:Lucene.Net.Index.SegmentReader">
            <version>  $Id 
            </version>
            <summary> <p/><b>NOTE:</b> This API is new and still experimental
            (subject to change suddenly in the next release)<p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentReader.IMPL">
            <summary>The class which implements SegmentReader. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Get(Lucene.Net.Index.SegmentInfo)">
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated>
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Get(System.Boolean,Lucene.Net.Index.SegmentInfo,System.Int32)">
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Get(Lucene.Net.Index.SegmentInfo,System.Int32,System.Boolean,System.Int32)">
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated>
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Get(System.Boolean,Lucene.Net.Store.Directory,Lucene.Net.Index.SegmentInfo,System.Int32,System.Boolean,System.Int32)">
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.CloneNormBytes(System.Byte[])">
            <summary> Clones the norm bytes.  May be overridden by subclasses.  New and experimental.</summary>
            <param name="bytes">Byte array to clone
            </param>
            <returns> New BitVector
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.CloneDeletedDocs(Lucene.Net.Util.BitVector)">
            <summary> Clones the deleteDocs BitVector.  May be overridden by subclasses. New and experimental.</summary>
            <param name="bv">BitVector to clone
            </param>
            <returns> New BitVector
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.DoCommit">
            <deprecated>  
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetFieldNames(Lucene.Net.Index.IndexReader.FieldOption)">
            <seealso cref="M:Lucene.Net.Index.IndexReader.GetFieldNames(Lucene.Net.Index.IndexReader.FieldOption)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Norms(System.String,System.Byte[],System.Int32)">
            <summary>Read norms into a pre-allocated array. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetTermVectorsReader">
            <summary> Create a clone from the initial TermVectorsReader and store it in the ThreadLocal.</summary>
            <returns> TermVectorsReader
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetTermFreqVector(System.Int32,System.String)">
            <summary>Return a term frequency vector for the specified document and field. The
            vector returned contains term numbers and frequencies for all terms in
            the specified field of this document, if the field had storeTermVector
            flag set.  If the flag was not set, the method returns null.
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetTermFreqVectors(System.Int32)">
            <summary>Return an array of term frequency vectors for the specified document.
            The array contains a vector for each vectorized field in the document.
            Each vector vector contains term numbers and frequencies for all terms
            in a given vectorized field.
            If no such fields existed, the method returns null.
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetSegmentName">
            <summary> Return the name of the segment this reader is reading.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetSegmentInfo">
            <summary> Return the SegmentInfo of the segment this reader is reading.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.Directory">
            <summary>Returns the directory this index resides in. </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentReader.GetOnlySegmentReader(Lucene.Net.Store.Directory)">
            <summary> Lotsa tests did hacks like:<br/>
            SegmentReader reader = (SegmentReader) IndexReader.open(dir);<br/>
            They broke. This method serves as a hack to keep hacks working
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.SegmentReader.FieldsReaderLocal">
            <summary> Sets the initial value </summary>
        </member>
        <member name="T:Lucene.Net.Util.CloseableThreadLocal">
            <summary>Java's builtin ThreadLocal has a serious flaw:
            it can take an arbitrarily long amount of time to
            dereference the things you had stored in it, even once the
            ThreadLocal instance itself is no longer referenced.
            This is because there is single, master map stored for
            each thread, which all ThreadLocals share, and that
            master map only periodically purges "stale" entries.
            
            While not technically a memory leak, because eventually
            the memory will be reclaimed, it can take a long time
            and you can easily hit OutOfMemoryError because from the
            GC's standpoint the stale entries are not reclaimaible.
            
            This class works around that, by only enrolling
            WeakReference values into the ThreadLocal, and
            separately holding a hard reference to each stored
            value.  When you call {@link #close}, these hard
            references are cleared and then GC is freely able to
            reclaim space by objects stored in it. 
            </summary>
            
        </member>
        <member name="T:Lucene.Net.Index.SegmentReader.Norm">
            <summary> Byte[] referencing is used because a new norm object needs 
            to be created for each clone, and the byte array is all 
            that is needed for sharing between cloned readers.  The 
            current norm referencing is for sharing between readers 
            whereas the byte[] referencing is for copy on write which 
            is independent of reader references (i.e. incRef, decRef).
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FreqProxFieldMergeState">
            <summary>Used by DocumentsWriter to merge the postings from
            multiple ThreadStates when creating a segment 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DefaultSkipListWriter">
            <summary> Implements the skip list writer for the default posting list format
            that stores positions and payloads.
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MultiLevelSkipListWriter">
            <summary> This abstract class writes skip lists with multiple levels.
            
            Example for skipInterval = 3:
            c            (skip level 2)
            c                 c                 c            (skip level 1) 
            x     x     x     x     x     x     x     x     x     x      (skip level 0)
            d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d  (posting list)
            3     6     9     12    15    18    21    24    27    30     (df)
            
            d - document
            x - skip data
            c - skip data with child pointer
            
            Skip level i contains every skipInterval-th entry from skip level i-1.
            Therefore the number of entries on level i is: floor(df / ((skipInterval ^ (i + 1))).
            
            Each skip entry on a level i>0 contains a pointer to the corresponding skip entry in list i-1.
            This guarantess a logarithmic amount of skips to find the target document.
            
            While this class takes care of writing the different skip levels,
            subclasses must define the actual format of the skip data.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListWriter.WriteSkipData(System.Int32,Lucene.Net.Store.IndexOutput)">
            <summary> Subclasses must implement the actual skip data encoding in this method.
            
            </summary>
            <param name="level">the level skip data shall be writting for
            </param>
            <param name="skipBuffer">the skip buffer to write to
            </param>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListWriter.BufferSkip(System.Int32)">
            <summary> Writes the current skip data to the buffers. The current document frequency determines
            the max level is skip data is to be written to. 
            
            </summary>
            <param name="df">the current document frequency 
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultiLevelSkipListWriter.WriteSkip(Lucene.Net.Store.IndexOutput)">
            <summary> Writes the buffered skip lists to the given output.
            
            </summary>
            <param name="output">the IndexOutput the skip lists shall be written to 
            </param>
            <returns> the pointer the skip list starts
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.DefaultSkipListWriter.SetSkipData(System.Int32,System.Boolean,System.Int32)">
            <summary> Sets the values for the current skip data. </summary>
        </member>
        <member name="T:Lucene.Net.Index.CorruptIndexException">
            <summary> This exception is thrown when Lucene detects
            an inconsistency in the index.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex">
            <summary> Basic tool and API to check the health of an index and
            write a new segments file that removes reference to
            problematic segments.
            
            <p/>As this tool checks every byte in the index, on a large
            index it can take quite a long time to run.
            
            <p/><b>WARNING</b>: this tool and API is new and
            experimental and is subject to suddenly change in the
            next release.  Please make a complete backup of your
            index before using this to fix your index!
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.out_Renamed">
            <summary>Default PrintStream for all CheckIndex instances.</summary>
            <deprecated> Use {@link #setInfoStream} per instance,
            instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.#ctor(Lucene.Net.Store.Directory)">
            <summary>Create a new CheckIndex on the directory. </summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.SetInfoStream(System.IO.StreamWriter)">
            <summary>Set infoStream where messages should go.  If null, no
            messages are printed 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.Check(Lucene.Net.Store.Directory,System.Boolean)">
            <summary>Returns true if index is clean, else false. </summary>
            <deprecated> Please instantiate a CheckIndex and then use {@link #CheckIndex()} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.Check(Lucene.Net.Store.Directory,System.Boolean,System.Collections.IList)">
            <summary>Returns true if index is clean, else false.</summary>
            <deprecated> Please instantiate a CheckIndex and then use {@link #CheckIndex(List)} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.CheckIndex_Renamed_Method">
            <summary>Returns a {@link Status} instance detailing
            the state of the index.
            
            <p/>As this method checks every byte in the index, on a large
            index it can take quite a long time to run.
            
            <p/><b>WARNING</b>: make sure
            you only call this when the index is not opened by any
            writer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.CheckIndex_Renamed_Method(System.Collections.IList)">
            <summary>Returns a {@link Status} instance detailing
            the state of the index.
            
            </summary>
            <param name="onlySegments">list of specific segment names to check
            
            <p/>As this method checks every byte in the specified
            segments, on a large index it can take quite a long
            time to run.
            
            <p/><b>WARNING</b>: make sure
            you only call this when the index is not opened by any
            writer. 
            </param>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.TestFieldNorms(System.Collections.Generic.ICollection{System.String},Lucene.Net.Index.SegmentReader)">
            <summary> Test field norms.</summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.TestTermIndex(Lucene.Net.Index.SegmentInfo,Lucene.Net.Index.SegmentReader)">
            <summary> Test the term index.</summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.TestStoredFields(Lucene.Net.Index.SegmentInfo,Lucene.Net.Index.SegmentReader,System.Globalization.NumberFormatInfo)">
            <summary> Test stored fields for a segment.</summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.TestTermVectors(Lucene.Net.Index.SegmentInfo,Lucene.Net.Index.SegmentReader,System.Globalization.NumberFormatInfo)">
            <summary> Test term vectors for a segment.</summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.FixIndex(Lucene.Net.Index.CheckIndex.Status)">
            <summary>Repairs the index using previously returned result
            from {@link #checkIndex}.  Note that this does not
            remove any of the unreferenced files after it's done;
            you must separately open an {@link IndexWriter}, which
            deletes unreferenced files when it's created.
            
            <p/><b>WARNING</b>: this writes a
            new segments file into the index, effectively removing
            all documents in broken segments from the index.
            BE CAREFUL.
            
            <p/><b>WARNING</b>: Make sure you only call this when the
            index is not opened  by any writer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.CheckIndex.Main(System.String[])">
            <summary>Command-line interface to check and fix an index.
            <p/>
            Run it like this:
            <pre>
            java -ea:Lucene.Net... Lucene.Net.Index.CheckIndex pathToIndex [-fix] [-segment X] [-segment Y]
            </pre>
            <ul>
            <li><code>-fix</code>: actually write a new segments_N file, removing any problematic segments</li>
            <li><code>-segment X</code>: only check the specified
            segment(s).  This can be specified multiple times,
            to check more than one segment, eg <code>-segment _2
            -segment _a</code>.  You can't use this with the -fix
            option.</li>
            </ul>
            <p/><b>WARNING</b>: <code>-fix</code> should only be used on an emergency basis as it will cause
            documents (perhaps many) to be permanently removed from the index.  Always make
            a backup copy of your index before running this!  Do not run this tool on an index
            that is actively being written to.  You have been warned!
            <p/>                Run without -fix, this tool will open the index, report version information
            and report any exceptions it hits and what action it would take if -fix were
            specified.  With -fix, this tool will remove any segments that have issues and
            write a new segments_N file.  This means all documents contained in the affected
            segments will be removed.
            <p/>
            This tool exits with exit code 1 if the index cannot be opened or has any
            corruption, else 0.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status">
            <summary> Returned from {@link #CheckIndex()} detailing the health and status of the index.
            
            <p/><b>WARNING</b>: this API is new and experimental and is
            subject to suddenly change in the next release.
            
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.clean">
            <summary>True if no problems were found with the index. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.missingSegments">
            <summary>True if we were unable to locate and load the segments_N file. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.cantOpenSegments">
            <summary>True if we were unable to open the segments_N file. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.missingSegmentVersion">
            <summary>True if we were unable to read the version number from segments_N file. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.segmentsFileName">
            <summary>Name of latest segments_N file in the index. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.numSegments">
            <summary>Number of segments in the index. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.segmentFormat">
            <summary>String description of the version of the index. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.segmentsChecked">
            <summary>Empty unless you passed specific segments list to check as optional 3rd argument.</summary>
            <seealso cref="!:CheckIndex.CheckIndex(List)">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.toolOutOfDate">
            <summary>True if the index was created with a newer version of Lucene than the CheckIndex tool. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.segmentInfos">
            <summary>List of {@link SegmentInfoStatus} instances, detailing status of each segment. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.dir">
            <summary>Directory index is in. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.newSegments">
            <summary> SegmentInfos instance containing only segments that
            had no problems (this is used with the {@link CheckIndex#fixIndex} 
            method to repair the index. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.totLoseDocCount">
            <summary>How many documents will be lost to bad segments. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.numBadSegments">
            <summary>How many bad segments were found. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.partial">
            <summary>True if we checked only specific segments ({@link
            #CheckIndex(List)}) was called with non-null
            argument). 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.userData">
            <summary>Holds the userData of the last commit in the index </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus">
            <summary>Holds the status of each segment in the index.
            See {@link #segmentInfos}.
            
            <p/><b>WARNING</b>: this API is new and experimental and is
            subject to suddenly change in the next release.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.name">
            <summary>Name of the segment. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.docCount">
            <summary>Document count (does not take deletions into account). </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.compound">
            <summary>True if segment is compound file format. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.numFiles">
            <summary>Number of files referenced by this segment. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.sizeMB">
            <summary>Net size (MB) of the files referenced by this
            segment. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.docStoreOffset">
            <summary>Doc store offset, if this segment shares the doc
            store files (stored fields and term vectors) with
            other segments.  This is -1 if it does not share. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.docStoreSegment">
            <summary>String of the shared doc store segment, or null if
            this segment does not share the doc store files. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.docStoreCompoundFile">
            <summary>True if the shared doc store files are compound file
            format. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.hasDeletions">
            <summary>True if this segment has pending deletions. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.deletionsFileName">
            <summary>Name of the current deletions file name. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.numDeleted">
            <summary>Number of deleted documents. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.openReaderPassed">
            <summary>True if we were able to open a SegmentReader on this
            segment. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.numFields">
            <summary>Number of fields in this segment. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.hasProx">
            <summary>True if at least one of the fields in this segment
            does not omitTermFreqAndPositions.
            </summary>
            <seealso cref="!:AbstractField.setOmitTermFreqAndPositions">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.diagnostics">
            <summary>Map&lt;String, String&gt; that includes certain
            debugging details that IndexWriter records into
            each segment it creates 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.fieldNormStatus">
            <summary>Status for testing of field norms (null if field norms could not be tested). </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.termIndexStatus">
            <summary>Status for testing of indexed terms (null if indexed terms could not be tested). </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.storedFieldStatus">
            <summary>Status for testing of stored fields (null if stored fields could not be tested). </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.SegmentInfoStatus.termVectorStatus">
            <summary>Status for testing of term vectors (null if term vectors could not be tested). </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status.FieldNormStatus">
            <summary> Status from testing field norms.</summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.FieldNormStatus.totFields">
            <summary>Number of fields successfully tested </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.FieldNormStatus.error">
            <summary>Exception thrown during term index test (null on success) </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status.TermIndexStatus">
            <summary> Status from testing term index.</summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermIndexStatus.termCount">
            <summary>Total term count </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermIndexStatus.totFreq">
            <summary>Total frequency across all terms. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermIndexStatus.totPos">
            <summary>Total number of positions. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermIndexStatus.error">
            <summary>Exception thrown during term index test (null on success) </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status.StoredFieldStatus">
            <summary> Status from testing stored fields.</summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.StoredFieldStatus.docCount">
            <summary>Number of documents tested. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.StoredFieldStatus.totFields">
            <summary>Total number of stored fields tested. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.StoredFieldStatus.error">
            <summary>Exception thrown during stored fields test (null on success) </summary>
        </member>
        <member name="T:Lucene.Net.Index.CheckIndex.Status.TermVectorStatus">
            <summary> Status from testing stored fields.</summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermVectorStatus.docCount">
            <summary>Number of documents tested. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermVectorStatus.totVectors">
            <summary>Total number of term vectors tested. </summary>
        </member>
        <member name="F:Lucene.Net.Index.CheckIndex.Status.TermVectorStatus.error">
            <summary>Exception thrown during term vector test (null on success) </summary>
        </member>
        <member name="T:Lucene.Net.Index.BufferedDeletes">
            <summary>Holds buffered deletes, by docID, term or query.  We
            hold two instances of this class: one for the deletes
            prior to the last flush, the other for deletes after
            the last flush.  This is so if we need to abort
            (discard all buffered docs) we can also discard the
            buffered deletes yet keep the deletes done during
            previously flushed segments. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.Fieldable">
            <summary> Synonymous with {@link Field}.
            
            <p/><bold>WARNING</bold>: This interface may change within minor versions, despite Lucene's backward compatibility requirements.
            This means new methods may be added from version to version.  This change only affects the Fieldable API; other backwards
            compatibility promises remain intact. For example, Lucene can still
            read and write indices created within the same major version.
            <p/>
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.SetBoost(System.Single)">
            <summary>Sets the boost factor hits on this field.  This value will be
            multiplied into the score of all hits on this this field of this
            document.
            
            <p/>The boost is multiplied by {@link Lucene.Net.Documents.Document#GetBoost()} of the document
            containing this field.  If a document has multiple fields with the same
            name, all such values are multiplied together.  This product is then
            used to compute the norm factor for the field.  By
            default, in the {@link
            Lucene.Net.Search.Similarity#ComputeNorm(String,
            FieldInvertState)} method, the boost value is multiplied
            by the {@link
            Lucene.Net.Search.Similarity#LengthNorm(String,
            int)} and then rounded by {@link Lucene.Net.Search.Similarity#EncodeNorm(float)} before it is stored in the
            index.  One should attempt to ensure that this product does not overflow
            the range of that encoding.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Document.SetBoost(System.Single)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.ComputeNorm(System.String,Lucene.Net.Index.FieldInvertState)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.EncodeNorm(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetBoost">
            <summary>Returns the boost factor for hits for this field.
            
            <p/>The default value is 1.0.
            
            <p/>Note: this value is not stored directly with the document in the index.
            Documents returned from {@link Lucene.Net.Index.IndexReader#Document(int)} and
            {@link Lucene.Net.Search.Hits#Doc(int)} may thus not have the same value present as when
            this field was indexed.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Fieldable.SetBoost(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.Name">
            <summary>Returns the name of the field as an interned string.
            For example "date", "title", "body", ...
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.StringValue">
            <summary>The value of the field as a String, or null.
            <p/>
            For indexing, if isStored()==true, the stringValue() will be used as the stored field value
            unless isBinary()==true, in which case binaryValue() will be used.
            
            If isIndexed()==true and isTokenized()==false, this String value will be indexed as a single token.
            If isIndexed()==true and isTokenized()==true, then tokenStreamValue() will be used to generate indexed tokens if not null,
            else readerValue() will be used to generate indexed tokens if not null, else stringValue() will be used to generate tokens.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.ReaderValue">
            <summary>The value of the field as a Reader, which can be used at index time to generate indexed tokens.</summary>
            <seealso cref="M:Lucene.Net.Documents.Fieldable.StringValue">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.BinaryValue">
            <summary>The value of the field in Binary, or null.</summary>
            <seealso cref="M:Lucene.Net.Documents.Fieldable.StringValue">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.TokenStreamValue">
            <summary>The TokenStream for this field to be used when indexing, or null.</summary>
            <seealso cref="M:Lucene.Net.Documents.Fieldable.StringValue">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsStored">
            <summary>True if the value of the field is to be stored in the index for return
            with search hits. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsIndexed">
            <summary>True if the value of the field is to be indexed, so that it may be
            searched on. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsTokenized">
            <summary>True if the value of the field should be tokenized as text prior to
            indexing.  Un-tokenized fields are indexed as a single word and may not be
            Reader-valued. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsCompressed">
            <summary>True if the value of the field is stored and compressed within the index </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsTermVectorStored">
            <summary>True if the term or terms used to index this field are stored as a term
            vector, available from {@link Lucene.Net.Index.IndexReader#GetTermFreqVector(int,String)}.
            These methods do not provide access to the original content of the field,
            only to terms used to index it. If the original content must be
            preserved, use the <code>stored</code> attribute instead.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.GetTermFreqVector(System.Int32,System.String)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsStoreOffsetWithTermVector">
            <summary> True if terms are stored as term vector together with their offsets 
            (start and end positon in source text).
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsStorePositionWithTermVector">
            <summary> True if terms are stored as term vector together with their token positions.</summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsBinary">
            <summary>True if the value of the field is stored as binary </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetOmitNorms">
            <summary>True if norms are omitted for this indexed field </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.SetOmitNorms(System.Boolean)">
            <summary>Expert:
            
            If set, omit normalization factors associated with this indexed field.
            This effectively disables indexing boosts and length normalization for this field.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.SetOmitTf(System.Boolean)">
            <deprecated> Renamed to {@link AbstractField#setOmitTermFreqAndPositions} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetOmitTf">
            <deprecated> Renamed to {@link AbstractField#getOmitTermFreqAndPositions} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.IsLazy">
            <summary> Indicates whether a Field is Lazy or not.  The semantics of Lazy loading are such that if a Field is lazily loaded, retrieving
            it's values via {@link #StringValue()} or {@link #BinaryValue()} is only valid as long as the {@link Lucene.Net.Index.IndexReader} that
            retrieved the {@link Document} is still open.
            
            </summary>
            <returns> true if this field can be loaded lazily
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetBinaryOffset">
            <summary> Returns offset into byte[] segment that is used as value, if Field is not binary
            returned value is undefined
            </summary>
            <returns> index of the first character in byte[] segment that represents this Field value
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetBinaryLength">
            <summary> Returns length of byte[] segment that is used as value, if Field is not binary
            returned value is undefined
            </summary>
            <returns> length of byte[] segment that represents this Field value
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetBinaryValue">
            <summary> Return the raw byte[] for the binary field.  Note that
            you must also call {@link #getBinaryLength} and {@link
            #getBinaryOffset} to know which range of bytes in this
            returned array belong to the field.
            </summary>
            <returns> reference to the Field value as byte[].
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Fieldable.GetBinaryValue(System.Byte[])">
            <summary> Return the raw byte[] for the binary field.  Note that
            you must also call {@link #getBinaryLength} and {@link
            #getBinaryOffset} to know which range of bytes in this
            returned array belong to the field.<p/>
            About reuse: if you pass in the result byte[] and it is
            used, likely the underlying implementation will hold
            onto this byte[] and return it in future calls to
            {@link #BinaryValue()} or {@link #GetBinaryValue()}.
            So if you subsequently re-use the same byte[] elsewhere
            it will alter this Fieldable's value.
            </summary>
            <param name="result"> User defined buffer that will be used if
            possible.  If this is null or not large enough, a new
            buffer is allocated
            </param>
            <returns> reference to the Field value as byte[].
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Token">
            <summary>A Token is an occurrence of a term from the text of a field.  It consists of
            a term's text, the start and end offset of the term in the text of the field,
            and a type string.
            <p/>
            The start and end offsets permit applications to re-associate a token with
            its source text, e.g., to display highlighted query terms in a document
            browser, or to show matching text fragments in a <abbr title="KeyWord In Context">KWIC</abbr> display, etc.
            <p/>
            The type is a string, assigned by a lexical analyzer
            (a.k.a. tokenizer), naming the lexical or syntactic class that the token
            belongs to.  For example an end of sentence marker token might be implemented
            with type "eos".  The default token type is "word".  
            <p/>
            A Token can optionally have metadata (a.k.a. Payload) in the form of a variable
            length byte array. Use {@link TermPositions#GetPayloadLength()} and 
            {@link TermPositions#GetPayload(byte[], int)} to retrieve the payloads from the index.
            </summary>
            <summary><br/><br/>
            </summary>
            <summary><p/><b>NOTE:</b> As of 2.9, Token implements all {@link Attribute} interfaces
            that are part of core Lucene and can be found in the {@code tokenattributes} subpackage.
            Even though it is not necessary to use Token anymore, with the new TokenStream API it can
            be used as convenience class that implements all {@link Attribute}s, which is especially useful
            to easily switch from the old to the new TokenStream API.
            </summary>
            <summary><br/><br/>
            <p/><b>NOTE:</b> As of 2.3, Token stores the term text
            internally as a malleable char[] termBuffer instead of
            String termText.  The indexing code and core tokenizers
            have been changed to re-use a single Token instance, changing
            its buffer and other fields in-place as the Token is
            processed.  This provides substantially better indexing
            performance as it saves the GC cost of new'ing a Token and
            String for every term.  The APIs that accept String
            termText are still available but a warning about the
            associated performance cost has been added (below).  The
            {@link #TermText()} method has been deprecated.<p/>
            </summary>
            <summary><p/>Tokenizers and TokenFilters should try to re-use a Token instance when
            possible for best performance, by implementing the
            {@link TokenStream#IncrementToken()} API.
            Failing that, to create a new Token you should first use
            one of the constructors that starts with null text.  To load
            the token from a char[] use {@link #SetTermBuffer(char[], int, int)}.
            To load from a String use {@link #SetTermBuffer(String)} or {@link #SetTermBuffer(String, int, int)}.
            Alternatively you can get the Token's termBuffer by calling either {@link #TermBuffer()},
            if you know that your text is shorter than the capacity of the termBuffer
            or {@link #ResizeTermBuffer(int)}, if there is any possibility
            that you may need to grow the buffer. Fill in the characters of your term into this
            buffer, with {@link String#getChars(int, int, char[], int)} if loading from a string,
            or with {@link System#arraycopy(Object, int, Object, int, int)}, and finally call {@link #SetTermLength(int)} to
            set the length of the term text.  See <a target="_top" href="https://issues.apache.org/jira/browse/LUCENE-969">LUCENE-969</a>
            for details.<p/>
            <p/>Typical Token reuse patterns:
            <ul>
            <li> Copying text from a string (type is reset to {@link #DEFAULT_TYPE} if not
            specified):<br/>
            <pre>
            return reusableToken.reinit(string, startOffset, endOffset[, type]);
            </pre>
            </li>
            <li> Copying some text from a string (type is reset to {@link #DEFAULT_TYPE}
            if not specified):<br/>
            <pre>
            return reusableToken.reinit(string, 0, string.length(), startOffset, endOffset[, type]);
            </pre>
            </li>
            <li> Copying text from char[] buffer (type is reset to {@link #DEFAULT_TYPE}
            if not specified):<br/>
            <pre>
            return reusableToken.reinit(buffer, 0, buffer.length, startOffset, endOffset[, type]);
            </pre>
            </li>
            <li> Copying some text from a char[] buffer (type is reset to
            {@link #DEFAULT_TYPE} if not specified):<br/>
            <pre>
            return reusableToken.reinit(buffer, start, end - start, startOffset, endOffset[, type]);
            </pre>
            </li>
            <li> Copying from one one Token to another (type is reset to
            {@link #DEFAULT_TYPE} if not specified):<br/>
            <pre>
            return reusableToken.reinit(source.termBuffer(), 0, source.termLength(), source.startOffset(), source.endOffset()[, source.type()]);
            </pre>
            </li>
            </ul>
            A few things to note:
            <ul>
            <li>clear() initializes all of the fields to default values. This was changed in contrast to Lucene 2.4, but should affect no one.</li>
            <li>Because <code>TokenStreams</code> can be chained, one cannot assume that the <code>Token's</code> current type is correct.</li>
            <li>The startOffset and endOffset represent the start and offset in the
            source text, so be careful in adjusting them.</li>
            <li>When caching a reusable token, clone it. When injecting a cached token into a stream that can be reset, clone it again.</li>
            </ul>
            <p/>
            </summary>
            <seealso cref="T:Lucene.Net.Index.Payload">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.TermAttribute">
            <summary> The term text of a Token.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.Term">
            <summary>Returns the Token's term text.
            
            This method has a performance penalty
            because the text is stored internally in a char[].  If
            possible, use {@link #TermBuffer()} and {@link
            #TermLength()} directly instead.  If you really need a
            String, use this method, which is nothing more than
            a convenience call to <b>new String(token.termBuffer(), 0, token.termLength())</b>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.SetTermBuffer(System.Char[],System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset for
            length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.SetTermBuffer(System.String)">
            <summary>Copies the contents of buffer into the termBuffer array.</summary>
            <param name="buffer">the buffer to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.SetTermBuffer(System.String,System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset and continuing
            for length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.TermBuffer">
            <summary>Returns the internal termBuffer character array which
            you can then directly alter.  If the array is too
            small for your token, use {@link
            #ResizeTermBuffer(int)} to increase it.  After
            altering the buffer be sure to call {@link
            #setTermLength} to record the number of valid
            characters that were placed into the termBuffer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.ResizeTermBuffer(System.Int32)">
            <summary>Grows the termBuffer to at least size newSize, preserving the
            existing content. Note: If the next operation is to change
            the contents of the term buffer use
            {@link #SetTermBuffer(char[], int, int)},
            {@link #SetTermBuffer(String)}, or
            {@link #SetTermBuffer(String, int, int)}
            to optimally combine the resize with the setting of the termBuffer.
            </summary>
            <param name="newSize">minimum size of the new termBuffer
            </param>
            <returns> newly created termBuffer with length >= newSize
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.TermLength">
            <summary>Return number of valid characters (length of the term)
            in the termBuffer array. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttribute.SetTermLength(System.Int32)">
            <summary>Set number of valid characters (length of the term) in
            the termBuffer array. Use this to truncate the termBuffer
            or to synchronize with external manipulation of the termBuffer.
            Note: to grow the size of the array,
            use {@link #ResizeTermBuffer(int)} first.
            </summary>
            <param name="length">the truncated length
            </param>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttribute">
            <summary>The positionIncrement determines the position of this token
            relative to the previous Token in a TokenStream, used in phrase
            searching.
            
            <p/>The default value is one.
            
            <p/>Some common uses for this are:<ul>
            
            <li>Set it to zero to put multiple terms in the same position.  This is
            useful if, e.g., a word has multiple stems.  Searches for phrases
            including either stem will match.  In this case, all but the first stem's
            increment should be set to zero: the increment of the first instance
            should be one.  Repeating a token with an increment of zero can also be
            used to boost the scores of matches on that token.</li>
            
            <li>Set it to values greater than one to inhibit exact phrase matches.
            If, for example, one does not want phrases to match across removed stop
            words, then one could build a stop word filter that removes stop words and
            also sets the increment to the number of stop words removed before each
            non-stop word.  Then exact phrase queries will only match when the terms
            occur with no intervening stop words.</li>
            
            </ul>
            
            </summary>
            <seealso cref="T:Lucene.Net.Index.TermPositions">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttribute.SetPositionIncrement(System.Int32)">
            <summary>Set the position increment. The default value is one.
            
            </summary>
            <param name="positionIncrement">the distance from the prior term
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttribute.GetPositionIncrement">
            <summary>Returns the position increment of this Token.</summary>
            <seealso cref="!:setPositionIncrement">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.termText">
            <deprecated> We will remove this when we remove the
            deprecated APIs 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.termBuffer">
            <summary> Characters for the term text.</summary>
            <deprecated> This will be made private. Instead, use:
            {@link #TermBuffer()}, 
            {@link #SetTermBuffer(char[], int, int)},
            {@link #SetTermBuffer(String)}, or
            {@link #SetTermBuffer(String, int, int)}
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.termLength">
            <summary> Length of term text in the buffer.</summary>
            <deprecated> This will be made private. Instead, use:
            {@link #TermLength()}, or @{link setTermLength(int)}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.startOffset">
            <summary> Start in source text.</summary>
            <deprecated> This will be made private. Instead, use:
            {@link #StartOffset()}, or @{link setStartOffset(int)}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.endOffset">
            <summary> End in source text.</summary>
            <deprecated> This will be made private. Instead, use:
            {@link #EndOffset()}, or @{link setEndOffset(int)}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.type">
            <summary> The lexical type of the token.</summary>
            <deprecated> This will be made private. Instead, use:
            {@link #Type()}, or @{link setType(String)}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.payload">
            <deprecated> This will be made private. Instead, use:
            {@link #GetPayload()}, or @{link setPayload(Payload)}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Token.positionIncrement">
            <deprecated> This will be made private. Instead, use:
            {@link #GetPositionIncrement()}, or @{link setPositionIncrement(String)}.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor">
            <summary>Constructs a Token will null text. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.Int32,System.Int32)">
            <summary>Constructs a Token with null text and start &amp; end
            offsets.
            </summary>
            <param name="start">start offset in the source text
            </param>
            <param name="end">end offset in the source text 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.Int32,System.Int32,System.String)">
            <summary>Constructs a Token with null text and start &amp; end
            offsets plus the Token type.
            </summary>
            <param name="start">start offset in the source text
            </param>
            <param name="end">end offset in the source text
            </param>
            <param name="typ">the lexical type of this Token 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary> Constructs a Token with null text and start &amp; end
            offsets plus flags. NOTE: flags is EXPERIMENTAL.
            </summary>
            <param name="start">start offset in the source text
            </param>
            <param name="end">end offset in the source text
            </param>
            <param name="flags">The bits to set for this token
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.String,System.Int32,System.Int32)">
            <summary>Constructs a Token with the given term text, and start
            &amp; end offsets.  The type defaults to "word."
            <b>NOTE:</b> for better indexing speed you should
            instead use the char[] termBuffer methods to set the
            term text.
            </summary>
            <param name="text">term text
            </param>
            <param name="start">start offset
            </param>
            <param name="end">end offset
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.String,System.Int32,System.Int32,System.String)">
            <summary>Constructs a Token with the given text, start and end
            offsets, &amp; type.  <b>NOTE:</b> for better indexing
            speed you should instead use the char[] termBuffer
            methods to set the term text.
            </summary>
            <param name="text">term text
            </param>
            <param name="start">start offset
            </param>
            <param name="end">end offset
            </param>
            <param name="typ">token type
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.String,System.Int32,System.Int32,System.Int32)">
            <summary>  Constructs a Token with the given text, start and end
            offsets, &amp; type.  <b>NOTE:</b> for better indexing
            speed you should instead use the char[] termBuffer
            methods to set the term text.
            </summary>
            <param name="text">
            </param>
            <param name="start">
            </param>
            <param name="end">
            </param>
            <param name="flags">token type bits
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.#ctor(System.Char[],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>  Constructs a Token with the given term buffer (offset
            &amp; length), start and end
            offsets
            </summary>
            <param name="startTermBuffer">
            </param>
            <param name="termBufferOffset">
            </param>
            <param name="termBufferLength">
            </param>
            <param name="start">
            </param>
            <param name="end">
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetPositionIncrement(System.Int32)">
            <summary>Set the position increment.  This determines the position of this token
            relative to the previous Token in a {@link TokenStream}, used in phrase
            searching.
            
            <p/>The default value is one.
            
            <p/>Some common uses for this are:<ul>
            
            <li>Set it to zero to put multiple terms in the same position.  This is
            useful if, e.g., a word has multiple stems.  Searches for phrases
            including either stem will match.  In this case, all but the first stem's
            increment should be set to zero: the increment of the first instance
            should be one.  Repeating a token with an increment of zero can also be
            used to boost the scores of matches on that token.</li>
            
            <li>Set it to values greater than one to inhibit exact phrase matches.
            If, for example, one does not want phrases to match across removed stop
            words, then one could build a stop word filter that removes stop words and
            also sets the increment to the number of stop words removed before each
            non-stop word.  Then exact phrase queries will only match when the terms
            occur with no intervening stop words.</li>
            
            </ul>
            </summary>
            <param name="positionIncrement">the distance from the prior term
            </param>
            <seealso cref="T:Lucene.Net.Index.TermPositions">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.GetPositionIncrement">
            <summary>Returns the position increment of this Token.</summary>
            <seealso cref="!:setPositionIncrement">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetTermText(System.String)">
            <summary>Sets the Token's term text.  <b>NOTE:</b> for better
            indexing speed you should instead use the char[]
            termBuffer methods to set the term text.
            </summary>
            <deprecated> use {@link #SetTermBuffer(char[], int, int)} or
            {@link #SetTermBuffer(String)} or
            {@link #SetTermBuffer(String, int, int)}.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.TermText">
            <summary>Returns the Token's term text.
            
            </summary>
            <deprecated> This method now has a performance penalty
            because the text is stored internally in a char[].  If
            possible, use {@link #TermBuffer()} and {@link
            #TermLength()} directly instead.  If you really need a
            String, use {@link #Term()}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Term">
            <summary>Returns the Token's term text.
            
            This method has a performance penalty
            because the text is stored internally in a char[].  If
            possible, use {@link #TermBuffer()} and {@link
            #TermLength()} directly instead.  If you really need a
            String, use this method, which is nothing more than
            a convenience call to <b>new String(token.termBuffer(), 0, token.termLength())</b>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetTermBuffer(System.Char[],System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset for
            length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetTermBuffer(System.String)">
            <summary>Copies the contents of buffer into the termBuffer array.</summary>
            <param name="buffer">the buffer to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetTermBuffer(System.String,System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset and continuing
            for length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.TermBuffer">
            <summary>Returns the internal termBuffer character array which
            you can then directly alter.  If the array is too
            small for your token, use {@link
            #ResizeTermBuffer(int)} to increase it.  After
            altering the buffer be sure to call {@link
            #setTermLength} to record the number of valid
            characters that were placed into the termBuffer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.ResizeTermBuffer(System.Int32)">
            <summary>Grows the termBuffer to at least size newSize, preserving the
            existing content. Note: If the next operation is to change
            the contents of the term buffer use
            {@link #SetTermBuffer(char[], int, int)},
            {@link #SetTermBuffer(String)}, or
            {@link #SetTermBuffer(String, int, int)}
            to optimally combine the resize with the setting of the termBuffer.
            </summary>
            <param name="newSize">minimum size of the new termBuffer
            </param>
            <returns> newly created termBuffer with length >= newSize
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.GrowTermBuffer(System.Int32)">
            <summary>Allocates a buffer char[] of at least newSize, without preserving the existing content.
            its always used in places that set the content 
            </summary>
            <param name="newSize">minimum size of the buffer
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.TermLength">
            <summary>Return number of valid characters (length of the term)
            in the termBuffer array. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetTermLength(System.Int32)">
            <summary>Set number of valid characters (length of the term) in
            the termBuffer array. Use this to truncate the termBuffer
            or to synchronize with external manipulation of the termBuffer.
            Note: to grow the size of the array,
            use {@link #ResizeTermBuffer(int)} first.
            </summary>
            <param name="length">the truncated length
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.StartOffset">
            <summary>Returns this Token's starting offset, the position of the first character
            corresponding to this token in the source text.
            Note that the difference between endOffset() and startOffset() may not be
            equal to termText.length(), as the term text may have been altered by a
            stemmer or some other filter. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetStartOffset(System.Int32)">
            <summary>Set the starting offset.</summary>
            <seealso cref="M:Lucene.Net.Analysis.Token.StartOffset">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.EndOffset">
            <summary>Returns this Token's ending offset, one greater than the position of the
            last character corresponding to this token in the source text. The length
            of the token in the source text is (endOffset - startOffset). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetEndOffset(System.Int32)">
            <summary>Set the ending offset.</summary>
            <seealso cref="M:Lucene.Net.Analysis.Token.EndOffset">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetOffset(System.Int32,System.Int32)">
            <summary>Set the starting and ending offset.
            See StartOffset() and EndOffset()
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Type">
            <summary>Returns this Token's lexical type.  Defaults to "word". </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetType(System.String)">
            <summary>Set the lexical type.</summary>
            <seealso cref="M:Lucene.Net.Analysis.Token.Type">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.GetFlags">
            <summary> EXPERIMENTAL:  While we think this is here to stay, we may want to change it to be a long.
            <p/>
            
            Get the bitset for any bits that have been set.  This is completely distinct from {@link #Type()}, although they do share similar purposes.
            The flags can be used to encode information about the token for use by other {@link Lucene.Net.Analysis.TokenFilter}s.
            
            
            </summary>
            <returns> The bits
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetFlags(System.Int32)">
            <seealso cref="M:Lucene.Net.Analysis.Token.GetFlags">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.GetPayload">
            <summary> Returns this Token's payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.SetPayload(Lucene.Net.Index.Payload)">
            <summary> Sets this Token's payload.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Clear">
            <summary>Resets the term text, payload, flags, and positionIncrement,
            startOffset, endOffset and token type to default.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Clone(System.Char[],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>Makes a clone, but replaces the term buffer &amp;
            start/end offset in the process.  This is more
            efficient than doing a full clone (and then calling
            setTermBuffer) because it saves a wasted copy of the old
            termBuffer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.Char[],System.Int32,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(char[], int, int)},
            {@link #setStartOffset},
            {@link #setEndOffset},
            {@link #setType}
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.Char[],System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(char[], int, int)},
            {@link #setStartOffset},
            {@link #setEndOffset}
            {@link #setType} on Token.DEFAULT_TYPE
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.String,System.Int32,System.Int32,System.String)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(String)},
            {@link #setStartOffset},
            {@link #setEndOffset}
            {@link #setType}
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.String)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(String, int, int)},
            {@link #setStartOffset},
            {@link #setEndOffset}
            {@link #setType}
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.String,System.Int32,System.Int32)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(String)},
            {@link #setStartOffset},
            {@link #setEndOffset}
            {@link #setType} on Token.DEFAULT_TYPE
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(System.String,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>Shorthand for calling {@link #clear},
            {@link #SetTermBuffer(String, int, int)},
            {@link #setStartOffset},
            {@link #setEndOffset}
            {@link #setType} on Token.DEFAULT_TYPE
            </summary>
            <returns> this Token instance 
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(Lucene.Net.Analysis.Token)">
            <summary> Copy the prototype token's fields into this one. Note: Payloads are shared.</summary>
            <param name="prototype">
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(Lucene.Net.Analysis.Token,System.String)">
            <summary> Copy the prototype token's fields into this one, with a different term. Note: Payloads are shared.</summary>
            <param name="prototype">
            </param>
            <param name="newTerm">
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Token.Reinit(Lucene.Net.Analysis.Token,System.Char[],System.Int32,System.Int32)">
            <summary> Copy the prototype token's fields into this one, with a different term. Note: Payloads are shared.</summary>
            <param name="prototype">
            </param>
            <param name="newTermBuffer">
            </param>
            <param name="offset">
            </param>
            <param name="length">
            </param>
        </member>
        <member name="T:Lucene.Net.Analysis.PorterStemFilter">
            <summary>Transforms the token stream as per the Porter stemming algorithm.
            Note: the input to the stemming filter must already be in lower case,
            so you will need to use LowerCaseFilter or LowerCaseTokenizer farther
            down the Tokenizer chain in order for this to work properly!
            <p/>
            To use this filter with other analyzers, you'll want to write an
            Analyzer class that sets up the TokenStream chain as you want it.
            To use this with LowerCaseTokenizer, for example, you'd write an
            analyzer like this:
            <p/>
            <PRE>
            class MyAnalyzer extends Analyzer {
            public final TokenStream tokenStream(String fieldName, Reader reader) {
            return new PorterStemFilter(new LowerCaseTokenizer(reader));
            }
            }
            </PRE>
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.KeywordAnalyzer">
            <summary> "Tokenizes" the entire stream as a single token. This is useful
            for data like zip codes, ids, and some product names.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.ISOLatin1AccentFilter">
            <summary> A filter that replaces accented characters in the ISO Latin 1 character set 
            (ISO-8859-1) by their unaccented equivalent. The case will not be altered.
            <p/>
            For instance, '&#192;' will be replaced by 'a'.
            <p/>
            
            </summary>
            <deprecated> in favor of {@link ASCIIFoldingFilter} which covers a superset 
            of Latin 1. This class will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.ISOLatin1AccentFilter.Next(Lucene.Net.Analysis.Token)">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.ISOLatin1AccentFilter.Next">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.ISOLatin1AccentFilter.RemoveAccents(System.Char[],System.Int32)">
            <summary> To replace accented characters in a String by unaccented equivalents.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CharArraySet">
            <summary> A simple class that stores Strings as char[]'s in a
            hash table.  Note that this is not a general purpose
            class.  For example, it cannot remove items from the
            set, nor does it resize its hash table to be smaller,
            etc.  It is designed to be quick to test if a char[]
            is in the set without the necessity of converting it
            to a String first.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.#ctor(System.Int32,System.Boolean)">
            <summary>Create set with enough capacity to hold startSize
            terms 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.#ctor(System.Collections.ICollection,System.Boolean)">
            <summary>Create set from a Collection of char[] or String </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.#ctor(System.Char[][],System.Boolean,System.Int32)">
            <summary>Create set from entries </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.Contains(System.Char[],System.Int32,System.Int32)">
            <summary>true if the <code>len</code> chars of <code>text</code> starting at <code>off</code>
            are in the set 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.Contains(System.String)">
            <summary>true if the <code>System.String</code> is in the set </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.GetSlot(System.String)">
            <summary>Returns true if the String is in the set </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.Add(System.String)">
            <summary>Add this String into the set </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.Add(System.Char[])">
            <summary>Add this char[] directly to the set.
            If ignoreCase is true for this Set, the text array will be directly modified.
            The user should never modify this text array after calling this method.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.UnmodifiableSet(Lucene.Net.Analysis.CharArraySet)">
            <summary> Returns an unmodifiable {@link CharArraySet}. This allows to provide
            unmodifiable views of internal sets for "read-only" use.
            
            </summary>
            <param name="set">a set for which the unmodifiable set is returned.
            </param>
            <returns> an new unmodifiable {@link CharArraySet}.
            </returns>
            <throws>  NullPointerException </throws>
            <summary>           if the given set is <code>null</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.AddAll(System.Collections.ICollection)">
            <summary>Adds all of the elements in the specified collection to this collection </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.Clear">
            <summary>Removes all elements from the set </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.RemoveAll(System.Collections.ICollection)">
            <summary>Removes from this set all of its elements that are contained in the specified collection </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.RetainAll(System.Collections.ICollection)">
            <summary>Retains only the elements in this set that are contained in the specified collection </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CharArraySet.CharArraySetIterator">
            <summary>The Iterator&lt;String&gt; for this set.  Strings are constructed on the fly, so
            use <code>nextCharArray</code> for more efficient access. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CharArraySet.CharArraySetIterator.NextCharArray">
            <summary>do not modify the returned char[] </summary>
        </member>
        <member name="P:Lucene.Net.Analysis.CharArraySet.CharArraySetIterator.Current">
            <summary>Returns the next String, as a Set&lt;String&gt; would...
            use nextCharArray() for better efficiency. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CharArraySet.UnmodifiableCharArraySet">
            <summary> Efficient unmodifiable {@link CharArraySet}. This implementation does not
            delegate calls to a give {@link CharArraySet} like
            {@link Collections#UnmodifiableSet(java.util.Set)} does. Instead is passes
            the internal representation of a {@link CharArraySet} to a super
            constructor and overrides all mutators. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.Version">
            <summary> Use by certain classes to match version compatibility
            across releases of Lucene.
             <p/>
             <b>WARNING</b>: When changing the version parameter
             that you supply to components in Lucene, do not simply
             change the version at search-time, but instead also adjust
             your indexing code to match, and re-index.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_CURRENT">
            <summary>
            <p/><b>WARNING</b>: if you use this setting, and then
            upgrade to a newer release of Lucene, sizable changes
            may happen.  If precise back compatibility is important
            then you should instead explicitly specify an actual
            version.
            If you use this constant then you may need to
            <b>re-index all of your documents</b> when upgrading
            Lucene, as the way text is indexed may have changed.
            Additionally, you may need to <b>re-test your entire
            application</b> to ensure it behaves as expected, as
            some defaults may have changed and may break functionality
            in your application.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_20">
            <summary>Match settings and bugs in Lucene's 2.0 release. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_21">
            <summary>Match settings and bugs in Lucene's 2.1 release. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_22">
            <summary>Match settings and bugs in Lucene's 2.2 release. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_23">
            <summary>Match settings and bugs in Lucene's 2.3 release. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Version.LUCENE_24">
            <summary>Match settings and bugs in Lucene's 2.3 release. </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "F:Lucene.Net.Util.Version.LUCENE_29" -->
        <member name="T:Lucene.Net.Util.AverageGuessMemoryModel">
            <summary> An average, best guess, MemoryModel that should work okay on most systems.
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.MemoryModel">
            <summary> Returns primitive memory sizes for estimating RAM usage.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.MemoryModel.GetArraySize">
            <returns> size of array beyond contents
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.MemoryModel.GetClassSize">
            <returns> Class size overhead
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.MemoryModel.GetPrimitiveSize(System.Type)">
            <param name="clazz">a primitive Class - bool, byte, char, short, long, float,
            short, double, int
            </param>
            <returns> the size in bytes of given primitive Class
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.MemoryModel.GetReferenceSize">
            <returns> size of reference
            </returns>
        </member>
        <member name="T:Lucene.Net.Store.ChecksumIndexOutput">
            <summary>Writes bytes through to a primary IndexOutput, computing
            checksum.  Note that you cannot use seek().
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.ChecksumIndexOutput.PrepareCommit">
            <summary> Starts but does not complete the commit of this file (=
            writing of the final checksum at the end).  After this
            is called must call {@link #finishCommit} and the
            {@link #close} to complete the commit.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.ChecksumIndexOutput.FinishCommit">
            <summary>See {@link #prepareCommit} </summary>
        </member>
        <member name="T:Lucene.Net.Search.TermScorer">
            <summary>Expert: A <code>Scorer</code> for documents matching a <code>Term</code>.</summary>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.#ctor(Lucene.Net.Search.Weight,Lucene.Net.Index.TermDocs,Lucene.Net.Search.Similarity,System.Byte[])">
            <summary> Construct a <code>TermScorer</code>.
            
            </summary>
            <param name="weight">The weight of the <code>Term</code> in the query.
            </param>
            <param name="td">An iterator over the documents matching the <code>Term</code>.
            </param>
            <param name="similarity">The <code>Similarity</code> implementation to be used for score
            computations.
            </param>
            <param name="norms">The field norms of the document fields for the <code>Term</code>.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Score(Lucene.Net.Search.HitCollector)">
            <deprecated> use {@link #Score(Collector)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Score(Lucene.Net.Search.HitCollector,System.Int32)">
            <deprecated> use {@link #Score(Collector, int, int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Next">
            <summary> Advances to the next document matching the query. <br/>
            The iterator over the matching documents is buffered using
            {@link TermDocs#Read(int[],int[])}.
            
            </summary>
            <returns> true iff there is another document matching the query.
            </returns>
            <deprecated> use {@link #NextDoc()} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.NextDoc">
            <summary> Advances to the next document matching the query. <br/>
            The iterator over the matching documents is buffered using
            {@link TermDocs#Read(int[],int[])}.
            
            </summary>
            <returns> the document matching the query or -1 if there are no more documents.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.SkipTo(System.Int32)">
            <summary> Skips to the first match beyond the current whose document number is
            greater than or equal to a given target. <br/>
            The implementation uses {@link TermDocs#SkipTo(int)}.
            
            </summary>
            <param name="target">The target document number.
            </param>
            <returns> true iff there is such a match.
            </returns>
            <deprecated> use {@link #Advance(int)} instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Advance(System.Int32)">
            <summary> Advances to the first match beyond the current whose document number is
            greater than or equal to a given target. <br/>
            The implementation uses {@link TermDocs#SkipTo(int)}.
            
            </summary>
            <param name="target">The target document number.
            </param>
            <returns> the matching document or -1 if none exist.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.Explain(System.Int32)">
            <summary>Returns an explanation of the score for a document.
            <br/>When this method is used, the {@link #Next()} method
            and the {@link #Score(HitCollector)} method should not be used.
            </summary>
            <param name="doc">The document number for the explanation.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TermScorer.ToString">
            <summary>Returns a string representation of this <code>TermScorer</code>. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.FieldMaskingSpanQuery">
            <summary> <p/>Wrapper to allow {@link SpanQuery} objects participate in composite 
            single-field SpanQueries by 'lying' about their search field. That is, 
            the masked SpanQuery will function as normal, 
            but {@link SpanQuery#GetField()} simply hands back the value supplied 
            in this class's constructor.<p/>
            
            <p/>This can be used to support Queries like {@link SpanNearQuery} or 
            {@link SpanOrQuery} across different fields, which is not ordinarily 
            permitted.<p/>
            
            <p/>This can be useful for denormalized relational data: for example, when 
            indexing a document with conceptually many 'children': <p/>
            
            <pre>
            teacherid: 1
            studentfirstname: james
            studentsurname: jones
            
            teacherid: 2
            studenfirstname: james
            studentsurname: smith
            studentfirstname: sally
            studentsurname: jones
            </pre>
            
            <p/>a SpanNearQuery with a slop of 0 can be applied across two 
            {@link SpanTermQuery} objects as follows:
            <pre>
            SpanQuery q1  = new SpanTermQuery(new Term("studentfirstname", "james"));
            SpanQuery q2  = new SpanTermQuery(new Term("studentsurname", "jones"));
            SpanQuery q2m new FieldMaskingSpanQuery(q2, "studentfirstname");
            Query q = new SpanNearQuery(new SpanQuery[]{q1, q2m}, -1, false);
            </pre>
            to search for 'studentfirstname:james studentsurname:jones' and find 
            teacherid 1 without matching teacherid 2 (which has a 'james' in position 0 
            and 'jones' in position 1). <p/>
            
            <p/>Note: as {@link #GetField()} returns the masked field, scoring will be 
            done using the norms of the field name supplied. This may lead to unexpected
            scoring behaviour.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.FieldMaskingSpanQuery.GetTerms">
            <deprecated> use {@link #ExtractTerms(Set)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.BoostingTermQuery">
            <summary> The BoostingTermQuery is very similar to the {@link Lucene.Net.Search.Spans.SpanTermQuery} except
            that it factors in the value of the payload located at each of the positions where the
            {@link Lucene.Net.Index.Term} occurs.
            <p/>
            In order to take advantage of this, you must override {@link Lucene.Net.Search.Similarity#ScorePayload(String, byte[],int,int)}
            which returns 1 by default.
            <p/>
            Payload scores are averaged across term occurrences in the document.  
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.ScorePayload(System.String,System.Byte[],System.Int32,System.Int32)">
            
            </seealso>
            <deprecated> See {@link Lucene.Net.Search.Payloads.PayloadTermQuery}
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.MultiPhraseQuery">
            <summary> MultiPhraseQuery is a generalized version of PhraseQuery, with an added
            method {@link #Add(Term[])}.
            To use this class, to search for the phrase "Microsoft app*" first use
            add(Term) on the term "Microsoft", then find all terms that have "app" as
            prefix using IndexReader.terms(Term), and use MultiPhraseQuery.add(Term[]
            terms) to add them to the query.
            
            </summary>
            <version>  1.0
            </version>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.SetSlop(System.Int32)">
            <summary>Sets the phrase slop for this query.</summary>
            <seealso cref="M:Lucene.Net.Search.PhraseQuery.SetSlop(System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.GetSlop">
            <summary>Sets the phrase slop for this query.</summary>
            <seealso cref="M:Lucene.Net.Search.PhraseQuery.GetSlop">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.Add(Lucene.Net.Index.Term)">
            <summary>Add a single term at the next position in the phrase.</summary>
            <seealso cref="!:PhraseQuery.add(Term)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.Add(Lucene.Net.Index.Term[])">
            <summary>Add multiple terms at the next position in the phrase.  Any of the terms
            may match.
            
            </summary>
            <seealso cref="!:PhraseQuery.add(Term)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.Add(Lucene.Net.Index.Term[],System.Int32)">
            <summary> Allows to specify the relative position of terms within the phrase.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.PhraseQuery.Add(Lucene.Net.Index.Term,System.Int32)">
            </seealso>
            <param name="terms">
            </param>
            <param name="position">
            </param>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.GetTermArrays">
            <summary> Returns a List&lt;Term[]&gt; of the terms in the multiphrase.
            Do not modify the List or its contents.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.GetPositions">
            <summary> Returns the relative positions of terms in this phrase.</summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.MultiPhraseQuery.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Index.SortedTermVectorMapper">
            <summary> Store a sorted collection of {@link Lucene.Net.Index.TermVectorEntry}s.  Collects all term information
            into a single, SortedSet.
            <br/>
            NOTE: This Mapper ignores all Field information for the Document.  This means that if you are using offset/positions you will not
            know what Fields they correlate with.
            <br/>
            This is not thread-safe  
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SortedTermVectorMapper.ALL">
            <summary> Stand-in name for the field in {@link TermVectorEntry}.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SortedTermVectorMapper.#ctor(System.Collections.Generic.IComparer{System.Object})">
            <summary> </summary>
            <param name="comparator">A Comparator for sorting {@link TermVectorEntry}s
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SortedTermVectorMapper.Map(System.String,System.Int32,Lucene.Net.Index.TermVectorOffsetInfo[],System.Int32[])">
            <summary> </summary>
            <param name="term">The term to map
            </param>
            <param name="frequency">The frequency of the term
            </param>
            <param name="offsets">Offset information, may be null
            </param>
            <param name="positions">Position information, may be null
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SortedTermVectorMapper.GetTermVectorEntrySet">
            <summary> The TermVectorEntrySet.  A SortedSet of {@link TermVectorEntry} objects.  Sort is by the comparator passed into the constructor.
            <br/>
            This set will be empty until after the mapping process takes place.
            
            </summary>
            <returns> The SortedSet of {@link TermVectorEntry}.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermVector.GetField">
            <summary> </summary>
            <returns> The number of the field this vector is associated with
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.TermPositionVector">
            <summary>Extends <code>TermFreqVector</code> to provide additional information about
            positions in which each of the terms is found. A TermPositionVector not necessarily
            contains both positions and offsets, but at least one of these arrays exists.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermPositionVector.GetTermPositions(System.Int32)">
            <summary>Returns an array of positions in which the term is found.
            Terms are identified by the index at which its number appears in the
            term String array obtained from the <code>indexOf</code> method.
            May return null if positions have not been stored.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermPositionVector.GetOffsets(System.Int32)">
            <summary> Returns an array of TermVectorOffsetInfo in which the term is found.
            May return null if offsets have not been stored.
            
            </summary>
            <seealso cref="T:Lucene.Net.Analysis.Token">
            
            </seealso>
            <param name="index">The position in the array to get the offsets from
            </param>
            <returns> An array of TermVectorOffsetInfo objects or the empty list
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermPositionVector.GetOffsets(System.Int32)">
            <summary> Returns an array of TermVectorOffsetInfo in which the term is found.
            
            </summary>
            <param name="index">The position in the array to get the offsets from
            </param>
            <returns> An array of TermVectorOffsetInfo objects or the empty list
            </returns>
            <seealso cref="T:Lucene.Net.Analysis.Token">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermPositionVector.GetTermPositions(System.Int32)">
            <summary> Returns an array of positions in which the term is found.
            Terms are identified by the index at which its number appears in the
            term String array obtained from the <code>indexOf</code> method.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.SegmentInfo">
            <summary> Information about a segment such as it's name, directory, and files related
            to the segment.
            
            * <p/><b>NOTE:</b> This API is new and still experimental
            (subject to change suddenly in the next release)<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.Reset(Lucene.Net.Index.SegmentInfo)">
            <summary> Copy everything from src SegmentInfo into our instance.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.#ctor(Lucene.Net.Store.Directory,System.Int32,Lucene.Net.Store.IndexInput)">
            <summary> Construct a new SegmentInfo instance by reading a
            previously saved SegmentInfo from input.
            
            </summary>
            <param name="dir">directory to load from
            </param>
            <param name="format">format of the segments info file
            </param>
            <param name="input">input handle to read segment info from
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.SizeInBytes">
            <summary>Returns total size in bytes of all of files used by
            this segment. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.HasSeparateNorms(System.Int32)">
            <summary> Returns true if this field for this segment has saved a separate norms file (_&lt;segment&gt;_N.sX).
            
            </summary>
            <param name="fieldNumber">the field index to check
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.HasSeparateNorms">
            <summary> Returns true if any fields in this segment have separate norms.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.AdvanceNormGen(System.Int32)">
            <summary> Increment the generation count for the norms file for
            this field.
            
            </summary>
            <param name="fieldIndex">field whose norm file will be rewritten
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.GetNormFileName(System.Int32)">
            <summary> Get the file name for the norms file for this field.
            
            </summary>
            <param name="number">field index
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.SetUseCompoundFile(System.Boolean)">
            <summary> Mark whether this segment is stored as a compound file.
            
            </summary>
            <param name="isCompoundFile">true if this is a compound file;
            else, false
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.GetUseCompoundFile">
            <summary> Returns true if this segment is stored as a compound
            file; else, false.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.Write(Lucene.Net.Store.IndexOutput)">
            <summary> Save this segment's info.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.SegString(Lucene.Net.Store.Directory)">
            <summary>Used for debugging </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentInfo.Equals(System.Object)">
            <summary>We consider another SegmentInfo instance equal if it
            has the same dir and same name. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldInfos">
            <summary>Access to the Fieldable Info file that describes document fields and whether or
            not they are indexed. Each segment has a separate Fieldable Info file. Objects
            of this class are thread-safe for multiple readers, but only one thread can
            be adding documents at a time, with no other reader or writer threads
            accessing this object.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.#ctor(Lucene.Net.Store.Directory,System.String)">
            <summary> Construct a FieldInfos object using the directory and the name of the file
            IndexInput
            </summary>
            <param name="d">The directory to open the IndexInput from
            </param>
            <param name="name">The name of the file to open the IndexInput from in the Directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Clone">
            <summary> Returns a deep clone of this FieldInfos instance.</summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(Lucene.Net.Documents.Document)">
            <summary>Adds field info for a Document. </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.HasProx">
            <summary>Returns true if any fields do not omitTermFreqAndPositions </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.AddIndexed(System.Collections.ICollection,System.Boolean,System.Boolean,System.Boolean)">
            <summary> Add fields that are indexed. Whether they have termvectors has to be specified.
            
            </summary>
            <param name="names">The names of the fields
            </param>
            <param name="storeTermVectors">Whether the fields store term vectors or not
            </param>
            <param name="storePositionWithTermVector">true if positions should be stored.
            </param>
            <param name="storeOffsetWithTermVector">true if offsets should be stored
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.Collections.Generic.ICollection{System.String},System.Boolean)">
            <summary> Assumes the fields are not storing term vectors.
            
            </summary>
            <param name="names">The names of the fields
            </param>
            <param name="isIndexed">Whether the fields are indexed or not
            
            </param>
            <seealso cref="!:Add(String, boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.String,System.Boolean)">
            <summary> Calls 5 parameter add with false for all TermVector parameters.
            
            </summary>
            <param name="name">The name of the Fieldable
            </param>
            <param name="isIndexed">true if the field is indexed
            </param>
            <seealso cref="!:Add(String, boolean, boolean, boolean, boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.String,System.Boolean,System.Boolean)">
            <summary> Calls 5 parameter add with false for term vector positions and offsets.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="isIndexed"> true if the field is indexed
            </param>
            <param name="storeTermVector">true if the term vector should be stored
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>If the field is not yet known, adds it. If it is known, checks to make
            sure that the isIndexed flag is the same as was given previously for this
            field. If not - marks it as being indexed.  Same goes for the TermVector
            parameters.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="isIndexed">true if the field is indexed
            </param>
            <param name="storeTermVector">true if the term vector should be stored
            </param>
            <param name="storePositionWithTermVector">true if the term vector with positions should be stored
            </param>
            <param name="storeOffsetWithTermVector">true if the term vector with offsets should be stored
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>If the field is not yet known, adds it. If it is known, checks to make
            sure that the isIndexed flag is the same as was given previously for this
            field. If not - marks it as being indexed.  Same goes for the TermVector
            parameters.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="isIndexed">true if the field is indexed
            </param>
            <param name="storeTermVector">true if the term vector should be stored
            </param>
            <param name="storePositionWithTermVector">true if the term vector with positions should be stored
            </param>
            <param name="storeOffsetWithTermVector">true if the term vector with offsets should be stored
            </param>
            <param name="omitNorms">true if the norms for the indexed field should be omitted
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.Add(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>If the field is not yet known, adds it. If it is known, checks to make
            sure that the isIndexed flag is the same as was given previously for this
            field. If not - marks it as being indexed.  Same goes for the TermVector
            parameters.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="isIndexed">true if the field is indexed
            </param>
            <param name="storeTermVector">true if the term vector should be stored
            </param>
            <param name="storePositionWithTermVector">true if the term vector with positions should be stored
            </param>
            <param name="storeOffsetWithTermVector">true if the term vector with offsets should be stored
            </param>
            <param name="omitNorms">true if the norms for the indexed field should be omitted
            </param>
            <param name="storePayloads">true if payloads should be stored for this field
            </param>
            <param name="omitTermFreqAndPositions">true if term freqs should be omitted for this field
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.FieldName(System.Int32)">
            <summary> Return the fieldName identified by its number.
            
            </summary>
            <param name="fieldNumber">
            </param>
            <returns> the fieldName or an empty string when the field
            with the given number doesn't exist.
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.FieldInfos.FieldInfo(System.Int32)">
            <summary> Return the fieldinfo object referenced by the fieldNumber.</summary>
            <param name="fieldNumber">
            </param>
            <returns> the FieldInfo object or null when the given fieldNumber
            doesn't exist.
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.DocFieldProcessorPerField">
            <summary> Holds all per thread, per field state.</summary>
        </member>
        <member name="T:Lucene.Net.Analysis.PerFieldAnalyzerWrapper">
            <summary> This analyzer is used to facilitate scenarios where different
            fields require different analysis techniques.  Use {@link #addAnalyzer}
            to add a non-default analyzer on a field name basis.
            
            <p/>Example usage:
            
            <pre>
            PerFieldAnalyzerWrapper aWrapper =
            new PerFieldAnalyzerWrapper(new StandardAnalyzer());
            aWrapper.addAnalyzer("firstname", new KeywordAnalyzer());
            aWrapper.addAnalyzer("lastname", new KeywordAnalyzer());
            </pre>
            
            <p/>In this example, StandardAnalyzer will be used for all fields except "firstname"
            and "lastname", for which KeywordAnalyzer will be used.
            
            <p/>A PerFieldAnalyzerWrapper can be used like any other analyzer, for both indexing
            and query parsing.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PerFieldAnalyzerWrapper.#ctor(Lucene.Net.Analysis.Analyzer)">
            <summary> Constructs with default analyzer.
            
            </summary>
            <param name="defaultAnalyzer">Any fields not specifically
            defined to use a different analyzer will use the one provided here.
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.PerFieldAnalyzerWrapper.#ctor(Lucene.Net.Analysis.Analyzer,System.Collections.IDictionary)">
            <summary> Constructs with default analyzer and a map of analyzers to use for 
            specific fields.
            
            </summary>
            <param name="defaultAnalyzer">Any fields not specifically
            defined to use a different analyzer will use the one provided here.
            </param>
            <param name="fieldAnalyzers">a Map (String field name to the Analyzer) to be 
            used for those fields 
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.PerFieldAnalyzerWrapper.AddAnalyzer(System.String,Lucene.Net.Analysis.Analyzer)">
            <summary> Defines an analyzer to use for the specified field.
            
            </summary>
            <param name="fieldName">field name requiring a non-default analyzer
            </param>
            <param name="analyzer">non-default analyzer to use for field
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.PerFieldAnalyzerWrapper.GetPositionIncrementGap(System.String)">
            <summary>Return the positionIncrementGap from the analyzer assigned to fieldName </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PerFieldAnalyzerWrapper.GetOffsetGap(Lucene.Net.Documents.Fieldable)">
            <summary> Return the offsetGap from the analyzer assigned to field </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.CachingTokenFilter">
            <summary> This class can be used if the token attributes of a TokenStream
            are intended to be consumed more than once. It caches
            all token attribute states locally in a List.
            
            <p/>CachingTokenFilter implements the optional method
            {@link TokenStream#Reset()}, which repositions the
            stream to the first Token. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CachingTokenFilter.Next(Lucene.Net.Analysis.Token)">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.CachingTokenFilter.Next">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Util.SimpleStringInterner">
            <summary> Simple lockless and memory barrier free String intern cache that is guaranteed
            to return the same String instance as String.intern() does.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.StringInterner">
            <summary> Subclasses of StringInterner are required to
            return the same single String object for all equal strings.
            Depending on the implementation, this may not be
            the same object returned as String.intern().
            
            This StringInterner base class simply delegates to String.intern().
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.StringInterner.Intern(System.String)">
            <summary>Returns a single object instance for each equal string. </summary>
        </member>
        <member name="M:Lucene.Net.Util.StringInterner.Intern(System.Char[],System.Int32,System.Int32)">
            <summary>Returns a single object instance for each equal string. </summary>
        </member>
        <member name="M:Lucene.Net.Util.SimpleStringInterner.#ctor(System.Int32,System.Int32)">
            <param name="tableSize"> Size of the hash table, should be a power of two.
            </param>
            <param name="maxChainLength"> Maximum length of each bucket, after which the oldest item inserted is dropped.
            </param>
        </member>
        <member name="T:Lucene.Net.Search.TermRangeTermEnum">
            <summary> Subclass of FilteredTermEnum for enumerating all terms that match the
            specified range parameters.
            <p/>
            Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeTermEnum.#ctor(Lucene.Net.Index.IndexReader,System.String,System.String,System.String,System.Boolean,System.Boolean,System.Globalization.CompareInfo)">
            <summary> Enumerates all terms greater/equal than <code>lowerTerm</code>
            but less/equal than <code>upperTerm</code>. 
            
            If an endpoint is null, it is said to be "open". Either or both 
            endpoints may be open.  Open endpoints may not be exclusive 
            (you can't select all but the first or last term without 
            explicitly specifying the term to exclude.)
            
            </summary>
            <param name="reader">
            </param>
            <param name="field">An interned field that holds both lower and upper terms.
            </param>
            <param name="lowerTermText">The term text at the lower end of the range
            </param>
            <param name="upperTermText">The term text at the upper end of the range
            </param>
            <param name="includeLower">If true, the <code>lowerTerm</code> is included in the range.
            </param>
            <param name="includeUpper">If true, the <code>upperTerm</code> is included in the range.
            </param>
            <param name="collator">The collator to use to collate index Terms, to determine their
            membership in the range bounded by <code>lowerTerm</code> and
            <code>upperTerm</code>.
            
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Search.TermRangeFilter">
            <summary> A Filter that restricts search results to a range of values in a given
            field.
            
            <p/>This filter matches the documents looking for terms that fall into the
            supplied range according to {@link String#compareTo(String)}. It is not intended
            for numerical ranges, use {@link NumericRangeFilter} instead.
            
            <p/>If you construct a large number of range filters with different ranges but on the 
            same field, {@link FieldCacheRangeFilter} may have significantly better performance. 
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean)">
            <param name="fieldName">The field this range applies to
            </param>
            <param name="lowerTerm">The lower bound on this range
            </param>
            <param name="upperTerm">The upper bound on this range
            </param>
            <param name="includeLower">Does this range include the lower bound?
            </param>
            <param name="includeUpper">Does this range include the upper bound?
            </param>
            <throws>  IllegalArgumentException if both terms are null or if </throws>
            <summary>  lowerTerm is null and includeLower is true (similar for upperTerm
            and includeUpper)
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.#ctor(System.String,System.String,System.String,System.Boolean,System.Boolean,System.Globalization.CompareInfo)">
            <summary> <strong>WARNING:</strong> Using this constructor and supplying a non-null
            value in the <code>collator</code> parameter will cause every single 
            index Term in the Field referenced by lowerTerm and/or upperTerm to be
            examined.  Depending on the number of index Terms in this Field, the 
            operation could be very slow.
            
            </summary>
            <param name="lowerTerm">The lower bound on this range
            </param>
            <param name="upperTerm">The upper bound on this range
            </param>
            <param name="includeLower">Does this range include the lower bound?
            </param>
            <param name="includeUpper">Does this range include the upper bound?
            </param>
            <param name="collator">The collator to use when determining range inclusion; set
            to null to use Unicode code point ordering instead of collation.
            </param>
            <throws>  IllegalArgumentException if both terms are null or if </throws>
            <summary>  lowerTerm is null and includeLower is true (similar for upperTerm
            and includeUpper)
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.Less(System.String,System.String)">
            <summary> Constructs a filter for field <code>fieldName</code> matching
            less than or equal to <code>upperTerm</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.More(System.String,System.String)">
            <summary> Constructs a filter for field <code>fieldName</code> matching
            greater than or equal to <code>lowerTerm</code>.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.GetField">
            <summary>Returns the field name for this filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.GetLowerTerm">
            <summary>Returns the lower value of this range filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.GetUpperTerm">
            <summary>Returns the upper value of this range filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.IncludesLower">
            <summary>Returns <code>true</code> if the lower endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.IncludesUpper">
            <summary>Returns <code>true</code> if the upper endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.TermRangeFilter.GetCollator">
            <summary>Returns the collator used to determine range inclusion, if any. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanOrQuery">
            <summary>Matches the union of its clauses.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanOrQuery.#ctor(Lucene.Net.Search.Spans.SpanQuery[])">
            <summary>Construct a SpanOrQuery merging the provided clauses. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanOrQuery.GetClauses">
            <summary>Return the clauses whose spans are matched. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanOrQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.PhraseQuery">
            <summary>A Query that matches documents containing a particular sequence of terms.
            A PhraseQuery is built by QueryParser for input like <code>"new york"</code>.
            
            <p/>This query may be combined with other terms or queries with a {@link BooleanQuery}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.#ctor">
            <summary>Constructs an empty phrase query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.SetSlop(System.Int32)">
            <summary>Sets the number of other words permitted between words in query phrase.
            If zero, then this is an exact phrase search.  For larger values this works
            like a <code>WITHIN</code> or <code>NEAR</code> operator.
            <p/>The slop is in fact an edit-distance, where the units correspond to
            moves of terms in the query phrase out of position.  For example, to switch
            the order of two words requires two moves (the first move places the words
            atop one another), so to permit re-orderings of phrases, the slop must be
            at least two.
            <p/>More exact matches are scored higher than sloppier matches, thus search
            results are sorted by exactness.
            <p/>The slop is zero by default, requiring exact matches.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.GetSlop">
            <summary>Returns the slop.  See setSlop(). </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.Add(Lucene.Net.Index.Term)">
            <summary> Adds a term to the end of the query phrase.
            The relative position of the term is the one immediately after the last term added.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.Add(Lucene.Net.Index.Term,System.Int32)">
            <summary> Adds a term to the end of the query phrase.
            The relative position of the term within the phrase is specified explicitly.
            This allows e.g. phrases with more than one term at the same position
            or phrases with gaps (e.g. in connection with stopwords).
            
            </summary>
            <param name="term">
            </param>
            <param name="position">
            </param>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.GetTerms">
            <summary>Returns the set of terms in this phrase. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.GetPositions">
            <summary> Returns the relative positions of terms in this phrase.</summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.ExtractTerms(System.Collections.Hashtable)">
            <seealso cref="!:Lucene.Net.Search.Query.ExtractTerms(java.util.Set)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PhraseQuery.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.PayloadSpanUtil">
            <summary> Experimental class to get set of payloads for most standard Lucene queries.
            Operates like Highlighter - IndexReader should only contain doc of interest,
            best to use MemoryIndex.
            
            <p/>
            <font color="#FF0000">
            WARNING: The status of the <b>Payloads</b> feature is experimental.
            The APIs introduced here might change in the future and will not be
            supported anymore in such a case.</font>
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadSpanUtil.#ctor(Lucene.Net.Index.IndexReader)">
            <param name="reader">that contains doc with payloads to extract
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadSpanUtil.GetPayloadsForQuery(Lucene.Net.Search.Query)">
            <summary> Query should be rewritten for wild/fuzzy support.
            
            </summary>
            <param name="query">
            </param>
            <returns> payloads Collection
            </returns>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Search.Function.ValueSourceQuery">
            <summary> Expert: A Query that sets the scores of document to the
            values obtained from a {@link Lucene.Net.Search.Function.ValueSource ValueSource}.
            <p/>
            This query provides a score for <em>each and every</em> undeleted document in the index.    
            <p/>
            The value source can be based on a (cached) value of an indexed field, but it
            can also be based on an external source, e.g. values read from an external database. 
            <p/>
            Score is set as: Score(doc,query) = query.getBoost()<sup>2</sup> * valueSource(doc).  
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.#ctor(Lucene.Net.Search.Function.ValueSource)">
            <summary> Create a value source query</summary>
            <param name="valSrc">provides the values defines the function to be used for scoring
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.GetHashCode">
            <summary>Returns a hash code value for this object. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.ValueSourceQuery.ValueSourceScorer">
            <summary> A scorer that (simply) matches all documents, and scores each document with 
            the value of the value soure in effect. As an example, if the value source 
            is a (cached) field source, then value of that field in that document will 
            be used. (assuming field is indexed for this doc, with a single token.)   
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.ValueSourceScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.ValueSourceScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Function.ValueSourceQuery.ValueSourceScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.QueryParsers.QueryParserTokenManager">
            <summary>Token Manager. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserTokenManager.debugStream">
            <summary>Debug output. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.SetDebugStream(System.IO.StreamWriter)">
            <summary>Set debug output. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserTokenManager.jjstrLiteralImages">
            <summary>Token literal values. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserTokenManager.lexStateNames">
            <summary>Lexer state names. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.QueryParserTokenManager.jjnewLexState">
            <summary>Lex State array. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.#ctor(Lucene.Net.QueryParsers.CharStream)">
            <summary>Constructor. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.#ctor(Lucene.Net.QueryParsers.CharStream,System.Int32)">
            <summary>Constructor. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.ReInit(Lucene.Net.QueryParsers.CharStream)">
            <summary>Reinitialise parser. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.ReInit(Lucene.Net.QueryParsers.CharStream,System.Int32)">
            <summary>Reinitialise parser. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.SwitchTo(System.Int32)">
            <summary>Switch to specified lex state. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.QueryParserTokenManager.GetNextToken">
            <summary>Get the next Token. </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermVectorsReader">
            <version>  $Id: TermVectorsReader.java 687046 2008-08-19 13:01:11Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsReader.RawDocs(System.Int32[],System.Int32[],System.Int32,System.Int32)">
            <summary>Retrieve the length (in bytes) of the tvd and tvf
            entries for the next numDocs starting with
            startDocID.  This is used for bulk copying when
            merging segments, if the field numbers are
            congruent.  Once this returns, the tvf &amp; tvd streams
            are seeked to the startDocID. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsReader.Size">
            <summary> </summary>
            <returns> The number of documents in the reader
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsReader.Get(System.Int32,System.String)">
            <summary> Retrieve the term vector for the given document and field</summary>
            <param name="docNum">The document number to retrieve the vector for
            </param>
            <param name="field">The field within the document to retrieve
            </param>
            <returns> The TermFreqVector for the document and field or null if there is no termVector for this field.
            </returns>
            <throws>  IOException if there is an error reading the term vector files </throws>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsReader.Get(System.Int32)">
            <summary> Return all term vectors stored for this document or null if the could not be read in.
            
            </summary>
            <param name="docNum">The document number to retrieve the vector for
            </param>
            <returns> All term frequency vectors
            </returns>
            <throws>  IOException if there is an error reading the term vector files  </throws>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsReader.ReadTermVector(System.String,System.Int64,Lucene.Net.Index.TermVectorMapper)">
            <summary> </summary>
            <param name="field">The field to read in
            </param>
            <param name="tvfPointer">The pointer within the tvf file where we should start reading
            </param>
            <param name="mapper">The mapper used to map the TermVector
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="T:Lucene.Net.Index.ParallelArrayTermVectorMapper">
            <summary> Models the existing parallel array structure</summary>
        </member>
        <member name="M:Lucene.Net.Index.ParallelArrayTermVectorMapper.MaterializeVector">
            <summary> Construct the vector</summary>
            <returns> The {@link TermFreqVector} based on the mappings.
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.MultipleTermPositions">
            <summary> Allows you to iterate over the {@link TermPositions} for multiple {@link Term}s as
            a single {@link TermPositions}.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.#ctor(Lucene.Net.Index.IndexReader,Lucene.Net.Index.Term[])">
            <summary> Creates a new <code>MultipleTermPositions</code> instance.
            
            </summary>
            <exception cref="!:IOException">
            </exception>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.Seek(Lucene.Net.Index.Term)">
            <summary> Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.Seek(Lucene.Net.Index.TermEnum)">
            <summary> Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.Read(System.Int32[],System.Int32[])">
            <summary> Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.GetPayloadLength">
            <summary> Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.GetPayload(System.Byte[],System.Int32)">
            <summary> Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultipleTermPositions.IsPayloadAvailable">
            <summary> </summary>
            <returns> false
            </returns>
        </member>
        <member name="T:Lucene.Net.Index.LogByteSizeMergePolicy">
            <summary>This is a {@link LogMergePolicy} that measures size of a
            segment as the total byte size of the segment's files. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.LogMergePolicy">
            <summary><p/>This class implements a {@link MergePolicy} that tries
            to merge segments into levels of exponentially
            increasing size, where each level has fewer segments than
            the value of the merge factor. Whenever extra segments
            (beyond the merge factor upper bound) are encountered,
            all segments within the level are merged. You can get or
            set the merge factor using {@link #GetMergeFactor()} and
            {@link #SetMergeFactor(int)} respectively.<p/>
            
            <p/>This class is abstract and requires a subclass to
            define the {@link #size} method which specifies how a
            segment's size is determined.  {@link LogDocMergePolicy}
            is one subclass that measures size by document count in
            the segment.  {@link LogByteSizeMergePolicy} is another
            subclass that measures size as the total byte size of the
            file(s) for the segment.<p/>
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MergePolicy">
            <summary> <p/>Expert: a MergePolicy determines the sequence of
            primitive merge operations to be used for overall merge
            and optimize operations.<p/>
            
            <p/>Whenever the segments in an index have been altered by
            {@link IndexWriter}, either the addition of a newly
            flushed segment, addition of many segments from
            addIndexes* calls, or a previous merge that may now need
            to cascade, {@link IndexWriter} invokes {@link
            #findMerges} to give the MergePolicy a chance to pick
            merges that are now required.  This method returns a
            {@link MergeSpecification} instance describing the set of
            merges that should be done, or null if no merges are
            necessary.  When IndexWriter.optimize is called, it calls
            {@link #findMergesForOptimize} and the MergePolicy should
            then return the necessary merges.<p/>
            
            <p/>Note that the policy can return more than one merge at
            a time.  In this case, if the writer is using {@link
            SerialMergeScheduler}, the merges will be run
            sequentially but if it is using {@link
            ConcurrentMergeScheduler} they will be run concurrently.<p/>
            
            <p/>The default MergePolicy is {@link
            LogByteSizeMergePolicy}.<p/>
            
            <p/><b>NOTE:</b> This API is new and still experimental
            (subject to change suddenly in the next release)<p/>
            
            <p/><b>NOTE</b>: This class typically requires access to
            package-private APIs (e.g. <code>SegmentInfos</code>) to do its job;
            if you implement your own MergePolicy, you'll need to put
            it in package Lucene.Net.Index in order to use
            these APIs.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.FindMerges(Lucene.Net.Index.SegmentInfos)">
            <summary> Determine what set of merge operations are now necessary on the index.
            {@link IndexWriter} calls this whenever there is a change to the segments.
            This call is always synchronized on the {@link IndexWriter} instance so
            only one thread at a time will call this method.
            
            </summary>
            <param name="segmentInfos">the total set of segments in the index
            </param>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.FindMergesForOptimize(Lucene.Net.Index.SegmentInfos,System.Int32,System.Collections.Hashtable)">
            <summary> Determine what set of merge operations is necessary in order to optimize
            the index. {@link IndexWriter} calls this when its
            {@link IndexWriter#Optimize()} method is called. This call is always
            synchronized on the {@link IndexWriter} instance so only one thread at a
            time will call this method.
            
            </summary>
            <param name="segmentInfos">the total set of segments in the index
            </param>
            <param name="maxSegmentCount">requested maximum number of segments in the index (currently this
            is always 1)
            </param>
            <param name="segmentsToOptimize">contains the specific SegmentInfo instances that must be merged
            away. This may be a subset of all SegmentInfos.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.FindMergesToExpungeDeletes(Lucene.Net.Index.SegmentInfos)">
            <summary> Determine what set of merge operations is necessary in order to expunge all
            deletes from the index.
            
            </summary>
            <param name="segmentInfos">the total set of segments in the index
            </param>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.Close">
            <summary> Release all resources for the policy.</summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.UseCompoundFile(Lucene.Net.Index.SegmentInfos,Lucene.Net.Index.SegmentInfo)">
            <summary> Returns true if a newly flushed (not from merge)
            segment should use the compound file format.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.UseCompoundDocStore(Lucene.Net.Index.SegmentInfos)">
            <summary> Returns true if the doc store files should use the
            compound file format.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MergePolicy.OneMerge">
            <summary>OneMerge provides the information necessary to perform
            an individual primitive merge operation, resulting in
            a single new segment.  The merge spec includes the
            subset of segments to be merged as well as whether the
            new segment should use the compound file format. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.OneMerge.SetException(System.Exception)">
            <summary>Record that an exception occurred while executing
            this merge 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.OneMerge.GetException">
            <summary>Retrieve previous exception set by {@link
            #setException}. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.OneMerge.Abort">
            <summary>Mark this merge as aborted.  If this is called
            before the merge is committed then the merge will
            not be committed. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.OneMerge.IsAborted">
            <summary>Returns true if this merge was aborted. </summary>
        </member>
        <member name="T:Lucene.Net.Index.MergePolicy.MergeSpecification">
            <summary> A MergeSpecification instance provides the information
            necessary to perform multiple merges.  It simply
            contains a list of {@link OneMerge} instances.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.MergePolicy.MergeSpecification.merges">
            <summary> The subset of segments to be included in the primitive merge.</summary>
        </member>
        <member name="T:Lucene.Net.Index.MergePolicy.MergeException">
            <summary>Exception thrown if there are any problems while
            executing a merge. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.MergeException.#ctor(System.String)">
            <deprecated>
            Use {@link #MergePolicy.MergeException(String,Directory)} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.MergeException.#ctor(System.Exception)">
            <deprecated>
            Use {@link #MergePolicy.MergeException(Throwable,Directory)} instead 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.MergePolicy.MergeException.GetDirectory">
            <summary>Returns the {@link Directory} of the index that hit
            the exception. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.LogMergePolicy.LEVEL_LOG_SPAN">
            <summary>Defines the allowed range of log(size) for each
            level.  A level is computed by taking the max segment
            log size, minus LEVEL_LOG_SPAN, and finding all
            segments falling within that range. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.LogMergePolicy.DEFAULT_MERGE_FACTOR">
            <summary>Default merge factor, which is how many segments are
            merged at a time 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.LogMergePolicy.DEFAULT_MAX_MERGE_DOCS">
            <summary>Default maximum segment size.  A segment of this size</summary>
            <seealso cref="!:setMaxMergeDocs">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.LogMergePolicy.DEFAULT_NO_CFS_RATIO">
            <summary> Default noCFSRatio.  If a merge's size is >= 10% of
             the index, then we disable compound file for it.
             @see #setNoCFSRatio 
             </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetNoCFSRatio">
            @see #setNoCFSRatio 
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetNoCFSRatio(System.Double)">
            If a merged segment will be more than this percentage
            of the total size of the index, leave the segment as
            non-compound file even if compound file is enabled.
            Set to 1.0 to always use CFS regardless of merge
            size. 
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetMergeFactor">
            <summary><p/>Returns the number of segments that are merged at
            once and also controls the total number of segments
            allowed to accumulate in the index.<p/> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetMergeFactor(System.Int32)">
            <summary>Determines how often segment indices are merged by
            addDocument().  With smaller values, less RAM is used
            while indexing, and searches on unoptimized indices are
            faster, but indexing speed is slower.  With larger
            values, more RAM is used during indexing, and while
            searches on unoptimized indices are slower, indexing is
            faster.  Thus larger values (&gt; 10) are best for batch
            index creation, and smaller values (&lt; 10) for indices
            that are interactively maintained. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetUseCompoundFile(System.Boolean)">
            <summary>Sets whether compound file format should be used for
            newly flushed and newly merged segments. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetUseCompoundFile">
            <summary>Returns true if newly flushed and newly merge segments</summary>
            <seealso cref="M:Lucene.Net.Index.LogMergePolicy.SetUseCompoundFile(System.Boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetUseCompoundDocStore(System.Boolean)">
            <summary>Sets whether compound file format should be used for
            newly flushed and newly merged doc store
            segment files (term vectors and stored fields). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetUseCompoundDocStore">
            <summary>Returns true if newly flushed and newly merge doc
            store segment files (term vectors and stored fields)
            </summary>
            <seealso cref="M:Lucene.Net.Index.LogMergePolicy.SetUseCompoundDocStore(System.Boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetCalibrateSizeByDeletes(System.Boolean)">
            <summary>Sets whether the segment size should be calibrated by
            the number of deletes when choosing segments for merge. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetCalibrateSizeByDeletes">
            <summary>Returns true if the segment size should be calibrated 
            by the number of deletes when choosing segments for merge. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.IsOptimized(Lucene.Net.Index.SegmentInfo)">
            <summary>Returns true if this single info is optimized (has no
            pending norms or deletes, is in the same dir as the
            writer, and matches the current compound file setting 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.FindMergesForOptimize(Lucene.Net.Index.SegmentInfos,System.Int32,System.Collections.Hashtable)">
            <summary>Returns the merges necessary to optimize the index.
            This merge policy defines "optimized" to mean only one
            segment in the index, where that segment has no
            deletions pending nor separate norms, and it is in
            compound file format if the current useCompoundFile
            setting is true.  This method returns multiple merges
            (mergeFactor at a time) so the {@link MergeScheduler}
            in use may make use of concurrency. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.FindMergesToExpungeDeletes(Lucene.Net.Index.SegmentInfos)">
            <summary> Finds merges necessary to expunge all deletes from the
            index.  We simply merge adjacent segments that have
            deletes, up to mergeFactor at a time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.FindMerges(Lucene.Net.Index.SegmentInfos)">
            <summary>Checks if any merges are now necessary and returns a
            {@link MergePolicy.MergeSpecification} if so.  A merge
            is necessary when there are more than {@link
            #setMergeFactor} segments at a given level.  When
            multiple levels have too many segments, this method
            will return multiple merges, allowing the {@link
            MergeScheduler} to use concurrency. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.SetMaxMergeDocs(System.Int32)">
            <summary><p/>Determines the largest segment (measured by
            document count) that may be merged with other segments.
            Small values (e.g., less than 10,000) are best for
            interactive indexing, as this limits the length of
            pauses while indexing to a few seconds.  Larger values
            are best for batched indexing and speedier
            searches.<p/>
            
            <p/>The default value is {@link Integer#MAX_VALUE}.<p/>
            
            <p/>The default merge policy ({@link
            LogByteSizeMergePolicy}) also allows you to set this
            limit by net size (in MB) of the segment, using {@link
            LogByteSizeMergePolicy#setMaxMergeMB}.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogMergePolicy.GetMaxMergeDocs">
            <summary>Returns the largest segment (measured by document
            count) that may be merged with other segments.
            </summary>
            <seealso cref="!:setMaxMergeDocs">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.LogByteSizeMergePolicy.DEFAULT_MIN_MERGE_MB">
            <seealso cref="!:setMinMergeMB">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.LogByteSizeMergePolicy.DEFAULT_MAX_MERGE_MB">
            <summary>Default maximum segment size.  A segment of this size</summary>
            <seealso cref="!:setMaxMergeMB">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.LogByteSizeMergePolicy.SetMaxMergeMB(System.Double)">
            <summary><p/>Determines the largest segment (measured by total
            byte size of the segment's files, in MB) that may be
            merged with other segments.  Small values (e.g., less
            than 50 MB) are best for interactive indexing, as this
            limits the length of pauses while indexing to a few
            seconds.  Larger values are best for batched indexing
            and speedier searches.<p/>
            
            <p/>Note that {@link #setMaxMergeDocs} is also
            used to check whether a segment is too large for
            merging (it's either or).<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogByteSizeMergePolicy.GetMaxMergeMB">
            <summary>Returns the largest segment (meaured by total byte
            size of the segment's files, in MB) that may be merged
            with other segments.
            </summary>
            <seealso cref="!:setMaxMergeMB">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.LogByteSizeMergePolicy.SetMinMergeMB(System.Double)">
            <summary>Sets the minimum size for the lowest level segments.
            Any segments below this size are considered to be on
            the same level (even if they vary drastically in size)
            and will be merged whenever there are mergeFactor of
            them.  This effectively truncates the "long tail" of
            small segments that would otherwise be created into a
            single level.  If you set this too large, it could
            greatly increase the merging cost during indexing (if
            you flush many small segments). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogByteSizeMergePolicy.GetMinMergeMB">
            <summary>Get the minimum size for a segment to remain
            un-merged.
            </summary>
            <seealso cref="!:setMinMergeMB">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Documents.NumericField">
            <summary> <p/>This class provides a {@link Field} that enables indexing
            of numeric values for efficient range filtering and
            sorting.  Here's an example usage, adding an int value:
            <pre>
            document.add(new NumericField(name).setIntValue(value));
            </pre>
            
            For optimal performance, re-use the
            <code>NumericField</code> and {@link Document} instance for more than
            one document:
            
            <pre>
            NumericField field = new NumericField(name);
            Document document = new Document();
            document.add(field);
            
            for(all documents) {
            ...
            field.setIntValue(value)
            writer.addDocument(document);
            ...
            }
            </pre>
            
            <p/>The java native types <code>int</code>, <code>long</code>,
            <code>float</code> and <code>double</code> are
            directly supported.  However, any value that can be
            converted into these native types can also be indexed.
            For example, date/time values represented by a
            {@link java.util.Date} can be translated into a long
            value using the {@link java.util.Date#getTime} method.  If you
            don't need millisecond precision, you can quantize the
            value, either by dividing the result of
            {@link java.util.Date#getTime} or using the separate getters
            (for year, month, etc.) to construct an <code>int</code> or
            <code>long</code> value.<p/>
            
            <p/>To perform range querying or filtering against a
            <code>NumericField</code>, use {@link NumericRangeQuery} or {@link
            NumericRangeFilter}.  To sort according to a
            <code>NumericField</code>, use the normal numeric sort types, eg
            {@link SortField#INT} (note that {@link SortField#AUTO}
            will not work with these fields).  <code>NumericField</code> values
            can also be loaded directly from {@link FieldCache}.<p/>
            
            <p/>By default, a <code>NumericField</code>'s value is not stored but
            is indexed for range filtering and sorting.  You can use
            the {@link #NumericField(String,Field.Store,boolean)}
            constructor if you need to change these defaults.<p/>
            
            <p/>You may add the same field name as a <code>NumericField</code> to
            the same document more than once.  Range querying and
            filtering will be the logical OR of all values; so a range query
            will hit all documents that have at least one value in
            the range. However sort behavior is not defined.  If you need to sort,
            you should separately index a single-valued <code>NumericField</code>.<p/>
            
            <p/>A <code>NumericField</code> will consume somewhat more disk space
            in the index than an ordinary single-valued field.
            However, for a typical index that includes substantial
            textual content per document, this increase will likely
            be in the noise. <p/>
            
            <p/>Within Lucene, each numeric value is indexed as a
            <em>trie</em> structure, where each term is logically
            assigned to larger and larger pre-defined brackets (which
            are simply lower-precision representations of the value).
            The step size between each successive bracket is called the
            <code>precisionStep</code>, measured in bits.  Smaller
            <code>precisionStep</code> values result in larger number
            of brackets, which consumes more disk space in the index
            but may result in faster range search performance.  The
            default value, 4, was selected for a reasonable tradeoff
            of disk space consumption versus performance.  You can
            use the expert constructor {@link
            #NumericField(String,int,Field.Store,boolean)} if you'd
            like to change the value.  Note that you must also
            specify a congruent value when creating {@link
            NumericRangeQuery} or {@link NumericRangeFilter}.
            For low cardinality fields larger precision steps are good.
            If the cardinality is &lt; 100, it is fair
            to use {@link Integer#MAX_VALUE}, which produces one
            term per value.
            
            <p/>For more information on the internals of numeric trie
            indexing, including the <a
            href="../search/NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>
            configuration, see {@link NumericRangeQuery}. The format of
            indexed values is described in {@link NumericUtils}.
            
            <p/>If you only need to sort by numeric value, and never
            run range querying/filtering, you can index using a
            <code>precisionStep</code> of {@link Integer#MAX_VALUE}.
            This will minimize disk space consumed. <p/>
            
            <p/>More advanced users can instead use {@link
            NumericTokenStream} directly, when indexing numbers. This
            class is a wrapper around this token stream type for
            easier, more intuitive usage.<p/>
            
            <p/><b>NOTE:</b> This class is only used during
            indexing. When retrieving the stored field value from a
            {@link Document} instance after search, you will get a
            conventional {@link Fieldable} instance where the numeric
            values are returned as {@link String}s (according to
            <code>toString(value)</code> of the used data type).
            
            <p/><font color="red"><b>NOTE:</b> This API is
            experimental and might change in incompatible ways in the
            next release.</font>
            
            </summary>
            <since> 2.9
            </since>
        </member>
        <member name="T:Lucene.Net.Documents.AbstractField">
            <summary> 
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.SetBoost(System.Single)">
            <summary>Sets the boost factor hits on this field.  This value will be
            multiplied into the score of all hits on this this field of this
            document.
            
            <p/>The boost is multiplied by {@link Lucene.Net.Documents.Document#GetBoost()} of the document
            containing this field.  If a document has multiple fields with the same
            name, all such values are multiplied together.  This product is then
            used to compute the norm factor for the field.  By
            default, in the {@link
            Lucene.Net.Search.Similarity#ComputeNorm(String,
            FieldInvertState)} method, the boost value is multipled
            by the {@link
            Lucene.Net.Search.Similarity#LengthNorm(String,
            int)} and then
            rounded by {@link Lucene.Net.Search.Similarity#EncodeNorm(float)} before it is stored in the
            index.  One should attempt to ensure that this product does not overflow
            the range of that encoding.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Document.SetBoost(System.Single)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.ComputeNorm(System.String,Lucene.Net.Index.FieldInvertState)">
            </seealso>
            <seealso cref="M:Lucene.Net.Search.Similarity.EncodeNorm(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetBoost">
            <summary>Returns the boost factor for hits for this field.
            
            <p/>The default value is 1.0.
            
            <p/>Note: this value is not stored directly with the document in the index.
            Documents returned from {@link Lucene.Net.Index.IndexReader#Document(int)} and
            {@link Lucene.Net.Search.Hits#Doc(int)} may thus not have the same value present as when
            this field was indexed.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.AbstractField.SetBoost(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.Name">
            <summary>Returns the name of the field as an interned string.
            For example "date", "title", "body", ...
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsStored">
            <summary>True iff the value of the field is to be stored in the index for return
            with search hits.  It is an error for this to be true if a field is
            Reader-valued. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsIndexed">
            <summary>True iff the value of the field is to be indexed, so that it may be
            searched on. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsTokenized">
            <summary>True iff the value of the field should be tokenized as text prior to
            indexing.  Un-tokenized fields are indexed as a single word and may not be
            Reader-valued. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsCompressed">
            <summary>True if the value of the field is stored and compressed within the index </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsTermVectorStored">
            <summary>True iff the term or terms used to index this field are stored as a term
            vector, available from {@link Lucene.Net.Index.IndexReader#GetTermFreqVector(int,String)}.
            These methods do not provide access to the original content of the field,
            only to terms used to index it. If the original content must be
            preserved, use the <code>stored</code> attribute instead.
            
            </summary>
            <seealso cref="M:Lucene.Net.Index.IndexReader.GetTermFreqVector(System.Int32,System.String)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsStoreOffsetWithTermVector">
            <summary> True iff terms are stored as term vector together with their offsets 
            (start and end position in source text).
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsStorePositionWithTermVector">
            <summary> True iff terms are stored as term vector together with their token positions.</summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.IsBinary">
            <summary>True iff the value of the filed is stored as binary </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetBinaryValue">
            <summary> Return the raw byte[] for the binary field.  Note that
            you must also call {@link #getBinaryLength} and {@link
            #getBinaryOffset} to know which range of bytes in this
            returned array belong to the field.
            </summary>
            <returns> reference to the Field value as byte[].
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetBinaryLength">
            <summary> Returns length of byte[] segment that is used as value, if Field is not binary
            returned value is undefined
            </summary>
            <returns> length of byte[] segment that represents this Field value
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetBinaryOffset">
            <summary> Returns offset into byte[] segment that is used as value, if Field is not binary
            returned value is undefined
            </summary>
            <returns> index of the first character in byte[] segment that represents this Field value
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetOmitNorms">
            <summary>True if norms are omitted for this indexed field </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetOmitTf">
            <deprecated> Renamed to {@link #getOmitTermFreqAndPositions} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.GetOmitTermFreqAndPositions">
            <seealso cref="!:setOmitTermFreqAndPositions">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.SetOmitNorms(System.Boolean)">
            <summary>Expert:
            
            If set, omit normalization factors associated with this indexed field.
            This effectively disables indexing boosts and length normalization for this field.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.SetOmitTf(System.Boolean)">
            <deprecated> Renamed to {@link #setOmitTermFreqAndPositions} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.SetOmitTermFreqAndPositions(System.Boolean)">
            <summary>Expert:
            
            If set, omit term freq, positions and payloads from
            postings for this field.
            
            <p/><b>NOTE</b>: While this option reduces storage space
            required in the index, it also means any query
            requiring positional information, such as {@link
            PhraseQuery} or {@link SpanQuery} subclasses will
            silently fail to find results.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.AbstractField.ToString">
            <summary>Prints a Field for human consumption. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.#ctor(System.String)">
            <summary> Creates a field for numeric values using the default <code>precisionStep</code>
            {@link NumericUtils#PRECISION_STEP_DEFAULT} (4). The instance is not yet initialized with
            a numeric value, before indexing a document containing this field,
            set a value using the various set<em>???</em>Value() methods.
            This constructor creates an indexed, but not stored field.
            </summary>
            <param name="name">the field name
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.#ctor(System.String,Lucene.Net.Documents.Field.Store,System.Boolean)">
            <summary> Creates a field for numeric values using the default <code>precisionStep</code>
            {@link NumericUtils#PRECISION_STEP_DEFAULT} (4). The instance is not yet initialized with
            a numeric value, before indexing a document containing this field,
            set a value using the various set<em>???</em>Value() methods.
            </summary>
            <param name="name">the field name
            </param>
            <param name="store">if the field should be stored in plain text form
            (according to <code>toString(value)</code> of the used data type)
            </param>
            <param name="index">if the field should be indexed using {@link NumericTokenStream}
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.#ctor(System.String,System.Int32)">
            <summary> Creates a field for numeric values with the specified
            <code>precisionStep</code>. The instance is not yet initialized with
            a numeric value, before indexing a document containing this field,
            set a value using the various set<em>???</em>Value() methods.
            This constructor creates an indexed, but not stored field.
            </summary>
            <param name="name">the field name
            </param>
            <param name="precisionStep">the used <a href="../search/NumericRangeQuery.html#precisionStepDesc">precision step</a>
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.#ctor(System.String,System.Int32,Lucene.Net.Documents.Field.Store,System.Boolean)">
            <summary> Creates a field for numeric values with the specified
            <code>precisionStep</code>. The instance is not yet initialized with
            a numeric value, before indexing a document containing this field,
            set a value using the various set<em>???</em>Value() methods.
            </summary>
            <param name="name">the field name
            </param>
            <param name="precisionStep">the used <a href="../search/NumericRangeQuery.html#precisionStepDesc">precision step</a>
            </param>
            <param name="store">if the field should be stored in plain text form
            (according to <code>toString(value)</code> of the used data type)
            </param>
            <param name="index">if the field should be indexed using {@link NumericTokenStream}
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.TokenStreamValue">
            <summary>Returns a {@link NumericTokenStream} for indexing the numeric value. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.BinaryValue">
            <summary>Returns always <code>null</code> for numeric fields </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.GetBinaryValue(System.Byte[])">
            <summary>Returns always <code>null</code> for numeric fields </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.ReaderValue">
            <summary>Returns always <code>null</code> for numeric fields </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.StringValue">
            <summary>Returns the numeric value as a string (how it is stored, when {@link Field.Store#YES} is chosen). </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.GetNumericValue">
            <summary>Returns the current numeric value as a subclass of {@link Number}, <code>null</code> if not yet initialized. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.SetLongValue(System.Int64)">
            <summary> Initializes the field with the supplied <code>long</code> value.</summary>
            <param name="value">the numeric value
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>document.add(new NumericField(name, precisionStep).SetLongValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.SetIntValue(System.Int32)">
            <summary> Initializes the field with the supplied <code>int</code> value.</summary>
            <param name="value">the numeric value
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>document.add(new NumericField(name, precisionStep).setIntValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.SetDoubleValue(System.Double)">
            <summary> Initializes the field with the supplied <code>double</code> value.</summary>
            <param name="value">the numeric value
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>document.add(new NumericField(name, precisionStep).setDoubleValue(value))</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.NumericField.SetFloatValue(System.Single)">
            <summary> Initializes the field with the supplied <code>float</code> value.</summary>
            <param name="value">the numeric value
            </param>
            <returns> this instance, because of this you can use it the following way:
            <code>document.add(new NumericField(name, precisionStep).setFloatValue(value))</code>
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl">
            <summary> The term text of a Token.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.Term">
            <summary>Returns the Token's term text.
            
            This method has a performance penalty
            because the text is stored internally in a char[].  If
            possible, use {@link #TermBuffer()} and {@link
            #TermLength()} directly instead.  If you really need a
            String, use this method, which is nothing more than
            a convenience call to <b>new String(token.termBuffer(), 0, token.termLength())</b>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.SetTermBuffer(System.Char[],System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset for
            length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.SetTermBuffer(System.String)">
            <summary>Copies the contents of buffer into the termBuffer array.</summary>
            <param name="buffer">the buffer to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.SetTermBuffer(System.String,System.Int32,System.Int32)">
            <summary>Copies the contents of buffer, starting at offset and continuing
            for length characters, into the termBuffer array.
            </summary>
            <param name="buffer">the buffer to copy
            </param>
            <param name="offset">the index in the buffer of the first character to copy
            </param>
            <param name="length">the number of characters to copy
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.TermBuffer">
            <summary>Returns the internal termBuffer character array which
            you can then directly alter.  If the array is too
            small for your token, use {@link
            #ResizeTermBuffer(int)} to increase it.  After
            altering the buffer be sure to call {@link
            #setTermLength} to record the number of valid
            characters that were placed into the termBuffer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.ResizeTermBuffer(System.Int32)">
            <summary>Grows the termBuffer to at least size newSize, preserving the
            existing content. Note: If the next operation is to change
            the contents of the term buffer use
            {@link #SetTermBuffer(char[], int, int)},
            {@link #SetTermBuffer(String)}, or
            {@link #SetTermBuffer(String, int, int)}
            to optimally combine the resize with the setting of the termBuffer.
            </summary>
            <param name="newSize">minimum size of the new termBuffer
            </param>
            <returns> newly created termBuffer with length >= newSize
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.GrowTermBuffer(System.Int32)">
            <summary>Allocates a buffer char[] of at least newSize, without preserving the existing content.
            its always used in places that set the content 
            </summary>
            <param name="newSize">minimum size of the buffer
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.TermLength">
            <summary>Return number of valid characters (length of the term)
            in the termBuffer array. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.TermAttributeImpl.SetTermLength(System.Int32)">
            <summary>Set number of valid characters (length of the term) in
            the termBuffer array. Use this to truncate the termBuffer
            or to synchronize with external manipulation of the termBuffer.
            Note: to grow the size of the array,
            use {@link #ResizeTermBuffer(int)} first.
            </summary>
            <param name="length">the truncated length
            </param>
        </member>
        <member name="T:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttributeImpl">
            <summary>The positionIncrement determines the position of this token
            relative to the previous Token in a {@link TokenStream}, used in phrase
            searching.
            
            <p/>The default value is one.
            
            <p/>Some common uses for this are:<ul>
            
            <li>Set it to zero to put multiple terms in the same position.  This is
            useful if, e.g., a word has multiple stems.  Searches for phrases
            including either stem will match.  In this case, all but the first stem's
            increment should be set to zero: the increment of the first instance
            should be one.  Repeating a token with an increment of zero can also be
            used to boost the scores of matches on that token.</li>
            
            <li>Set it to values greater than one to inhibit exact phrase matches.
            If, for example, one does not want phrases to match across removed stop
            words, then one could build a stop word filter that removes stop words and
            also sets the increment to the number of stop words removed before each
            non-stop word.  Then exact phrase queries will only match when the terms
            occur with no intervening stop words.</li>
            
            </ul>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttributeImpl.SetPositionIncrement(System.Int32)">
            <summary>Set the position increment. The default value is one.
            
            </summary>
            <param name="positionIncrement">the distance from the prior term
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttributeImpl.GetPositionIncrement">
            <summary>Returns the position increment of this Token.</summary>
            <seealso cref="!:setPositionIncrement">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Analysis.LowerCaseFilter">
            <summary> Normalizes token text to lower case.
            
            </summary>
            <version>  $Id: LowerCaseFilter.java 797665 2009-07-24 21:45:48Z buschmi $
            </version>
        </member>
        <member name="T:Lucene.Net.Analysis.ASCIIFoldingFilter">
            <summary> This class converts alphabetic, numeric, and symbolic Unicode characters
            which are not in the first 127 ASCII characters (the "Basic Latin" Unicode
            block) into their ASCII equivalents, if one exists.
            
            Characters from the following Unicode blocks are converted; however, only
            those characters with reasonable ASCII alternatives are converted:
            
            <ul>
            <li>C1 Controls and Latin-1 Supplement: <a href="http://www.unicode.org/charts/PDF/U0080.pdf">http://www.unicode.org/charts/PDF/U0080.pdf</a></li>
            <li>Latin Extended-A: <a href="http://www.unicode.org/charts/PDF/U0100.pdf">http://www.unicode.org/charts/PDF/U0100.pdf</a></li>
            <li>Latin Extended-B: <a href="http://www.unicode.org/charts/PDF/U0180.pdf">http://www.unicode.org/charts/PDF/U0180.pdf</a></li>
            <li>Latin Extended Additional: <a href="http://www.unicode.org/charts/PDF/U1E00.pdf">http://www.unicode.org/charts/PDF/U1E00.pdf</a></li>
            <li>Latin Extended-C: <a href="http://www.unicode.org/charts/PDF/U2C60.pdf">http://www.unicode.org/charts/PDF/U2C60.pdf</a></li>
            <li>Latin Extended-D: <a href="http://www.unicode.org/charts/PDF/UA720.pdf">http://www.unicode.org/charts/PDF/UA720.pdf</a></li>
            <li>IPA Extensions: <a href="http://www.unicode.org/charts/PDF/U0250.pdf">http://www.unicode.org/charts/PDF/U0250.pdf</a></li>
            <li>Phonetic Extensions: <a href="http://www.unicode.org/charts/PDF/U1D00.pdf">http://www.unicode.org/charts/PDF/U1D00.pdf</a></li>
            <li>Phonetic Extensions Supplement: <a href="http://www.unicode.org/charts/PDF/U1D80.pdf">http://www.unicode.org/charts/PDF/U1D80.pdf</a></li>
            <li>General Punctuation: <a href="http://www.unicode.org/charts/PDF/U2000.pdf">http://www.unicode.org/charts/PDF/U2000.pdf</a></li>
            <li>Superscripts and Subscripts: <a href="http://www.unicode.org/charts/PDF/U2070.pdf">http://www.unicode.org/charts/PDF/U2070.pdf</a></li>
            <li>Enclosed Alphanumerics: <a href="http://www.unicode.org/charts/PDF/U2460.pdf">http://www.unicode.org/charts/PDF/U2460.pdf</a></li>
            <li>Dingbats: <a href="http://www.unicode.org/charts/PDF/U2700.pdf">http://www.unicode.org/charts/PDF/U2700.pdf</a></li>
            <li>Supplemental Punctuation: <a href="http://www.unicode.org/charts/PDF/U2E00.pdf">http://www.unicode.org/charts/PDF/U2E00.pdf</a></li>
            <li>Alphabetic Presentation Forms: <a href="http://www.unicode.org/charts/PDF/UFB00.pdf">http://www.unicode.org/charts/PDF/UFB00.pdf</a></li>
            <li>Halfwidth and Fullwidth Forms: <a href="http://www.unicode.org/charts/PDF/UFF00.pdf">http://www.unicode.org/charts/PDF/UFF00.pdf</a></li>
            </ul>
            
            See: <a href="http://en.wikipedia.org/wiki/Latin_characters_in_Unicode">http://en.wikipedia.org/wiki/Latin_characters_in_Unicode</a>
            
            The set of character conversions supported by this class is a superset of
            those supported by Lucene's {@link ISOLatin1AccentFilter} which strips
            accents from Latin1 characters.  For example, '&#192;' will be replaced by
            'a'.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.ASCIIFoldingFilter.FoldToASCII(System.Char[],System.Int32)">
            <summary> Converts characters above ASCII to their ASCII equivalents.  For example,
            accents are removed from accented characters.
            </summary>
            <param name="input">The string to fold
            </param>
            <param name="length">The number of characters in the input string
            </param>
        </member>
        <member name="T:Lucene.Net.Util.RamUsageEstimator">
            <summary> Estimates the size of a given Object using a given MemoryModel for primitive
            size information.
            
            Resource Usage: 
            
            Internally uses a Map to temporally hold a reference to every
            object seen. 
            
            If checkIntered, all Strings checked will be interned, but those
            that were not already interned will be released for GC when the
            estimate is complete.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.RamUsageEstimator.#ctor">
            <summary> Constructs this object with an AverageGuessMemoryModel and
            checkInterned = true.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.RamUsageEstimator.#ctor(System.Boolean)">
            <param name="checkInterned">check if Strings are interned and don't add to size
            if they are. Defaults to true but if you know the objects you are checking
            won't likely contain many interned Strings, it will be faster to turn off
            intern checking.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.RamUsageEstimator.#ctor(Lucene.Net.Util.MemoryModel)">
            <param name="memoryModel">MemoryModel to use for primitive object sizes.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.RamUsageEstimator.#ctor(Lucene.Net.Util.MemoryModel,System.Boolean)">
            <param name="memoryModel">MemoryModel to use for primitive object sizes.
            </param>
            <param name="checkInterned">check if Strings are interned and don't add to size
            if they are. Defaults to true but if you know the objects you are checking
            won't likely contain many interned Strings, it will be faster to turn off
            intern checking.
            </param>
        </member>
        <member name="M:Lucene.Net.Util.RamUsageEstimator.HumanReadableUnits(System.Int64,System.IFormatProvider)">
            <summary> Return good default units based on byte size.</summary>
        </member>
        <member name="T:Lucene.Net.Util.DocIdBitSet">
            <summary>Simple DocIdSet and DocIdSetIterator backed by a BitSet </summary>
        </member>
        <member name="M:Lucene.Net.Util.DocIdBitSet.IsCacheable">
            <summary>This DocIdSet implementation is cacheable.</summary>
        </member>
        <member name="M:Lucene.Net.Util.DocIdBitSet.GetBitSet">
            <summary> Returns the underlying BitSet. </summary>
        </member>
        <member name="M:Lucene.Net.Util.DocIdBitSet.DocIdBitSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.DocIdBitSet.DocIdBitSetIterator.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.DocIdBitSet.DocIdBitSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Store.VerifyingLockFactory">
            <summary> A {@link LockFactory} that wraps another {@link
            LockFactory} and verifies that each lock obtain/release
            is "correct" (never results in two processes holding the
            lock at the same time).  It does this by contacting an
            external server ({@link LockVerifyServer}) to assert that
            at most one process holds the lock at a time.  To use
            this, you should also run {@link LockVerifyServer} on the
            host &amp; port matching what you pass to the constructor.
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockVerifyServer">
            </seealso>
            <seealso cref="T:Lucene.Net.Store.LockStressTest">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.VerifyingLockFactory.#ctor(System.SByte,Lucene.Net.Store.LockFactory,System.String,System.Int32)">
            <param name="id">should be a unique id across all clients
            </param>
            <param name="lf">the LockFactory that we are testing
            </param>
            <param name="host">host or IP where {@link LockVerifyServer}
            is running
            </param>
            <param name="port">the port {@link LockVerifyServer} is
            listening on
            </param>
        </member>
        <member name="T:Lucene.Net.Store.RAMOutputStream">
            <summary> A memory-resident {@link IndexOutput} implementation.
            
            </summary>
            <version>  $Id: RAMOutputStream.java 691694 2008-09-03 17:34:29Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Store.RAMOutputStream.#ctor">
            <summary>Construct an empty output buffer. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMOutputStream.WriteTo(Lucene.Net.Store.IndexOutput)">
            <summary>Copy the current contents of this buffer to the named output. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMOutputStream.Reset">
            <summary>Resets this to an empty buffer. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMOutputStream.SizeInBytes">
            <summary>Returns byte usage of all buffers. </summary>
        </member>
        <member name="T:Lucene.Net.Store.NoLockFactory">
            <summary> Use this {@link LockFactory} to disable locking entirely.
            This LockFactory is used when you call {@link FSDirectory#setDisableLocks}.
            Only one instance of this lock is created.  You should call {@link
            #GetNoLockFactory()} to get the instance.
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockFactory">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.LockReleaseFailedException">
            <summary> This exception is thrown when the <code>write.lock</code>
            could not be released.
            </summary>
            <seealso cref="!:Lock.release()">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.Spans.SpanNearQuery">
            <summary>Matches spans which are near one another.  One can specify <i>slop</i>, the
            maximum number of intervening unmatched positions, as well as whether
            matches are required to be in-order. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.#ctor(Lucene.Net.Search.Spans.SpanQuery[],System.Int32,System.Boolean)">
            <summary>Construct a SpanNearQuery.  Matches spans matching a span from each
            clause, with up to <code>slop</code> total unmatched positions between
            them.  * When <code>inOrder</code> is true, the spans from each clause
            must be * ordered as in <code>clauses</code>. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.GetClauses">
            <summary>Return the clauses whose spans are matched. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.GetSlop">
            <summary>Return the maximum number of intervening unmatched positions permitted.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.IsInOrder">
            <summary>Return true if matches are required to be in-order.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.GetTerms">
            <summary>Returns a collection of all terms matched by this query.</summary>
            <deprecated> use extractTerms instead
            </deprecated>
            <seealso cref="!:ExtractTerms(Set)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Spans.SpanNearQuery.Equals(System.Object)">
            <summary>Returns true iff <code>o</code> is equal to this. </summary>
        </member>
        <member name="T:Lucene.Net.Search.NumericRangeQuery">
            <summary> <p/>A {@link Query} that matches numeric values within a
            specified range.  To use this, you must first index the
            numeric values using {@link NumericField} (expert: {@link
            NumericTokenStream}).  If your terms are instead textual,
            you should use {@link TermRangeQuery}.  {@link
            NumericRangeFilter} is the filter equivalent of this
            query.<p/>
            
            <p/>You create a new NumericRangeQuery with the static
            factory methods, eg:
            
            <pre>
            Query q = NumericRangeQuery.newFloatRange("weight",
            new Float(0.3f), new Float(0.10f),
            true, true);
            </pre>
            
            matches all documents whose float valued "weight" field
            ranges from 0.3 to 0.10, inclusive.
            
            <p/>The performance of NumericRangeQuery is much better
            than the corresponding {@link TermRangeQuery} because the
            number of terms that must be searched is usually far
            fewer, thanks to trie indexing, described below.<p/>
            
            <p/>You can optionally specify a <a
            href="#precisionStepDesc"><code>precisionStep</code></a>
            when creating this query.  This is necessary if you've
            changed this configuration from its default (4) during
            indexing.  Lower values consume more disk space but speed
            up searching.  Suitable values are between <b>1</b> and
            <b>8</b>. A good starting point to test is <b>4</b>,
            which is the default value for all <code>Numeric*</code>
            classes.  See <a href="#precisionStepDesc">below</a> for
            details.
            
            <p/>This query defaults to {@linkplain
            MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT} for
            32 bit (int/float) ranges with precisionStep &lt;8 and 64
            bit (long/double) ranges with precisionStep &lt;6.
            Otherwise it uses {@linkplain
            MultiTermQuery#CONSTANT_SCORE_FILTER_REWRITE} as the
            number of terms is likely to be high.  With precision
            steps of &lt;4, this query can be run with one of the
            BooleanQuery rewrite methods without changing
            BooleanQuery's default max clause count.
            
            <p/><font color="red"><b>NOTE:</b> This API is experimental and
            might change in incompatible ways in the next release.</font>
            
            <br/><h3>How it works</h3>
            
            <p/>See the publication about <a target="_blank" href="http://www.panfmp.org">panFMP</a>,
            where this algorithm was described (referred to as <code>TrieRangeQuery</code>):
            
            <blockquote><strong>Schindler, U, Diepenbroek, M</strong>, 2008.
            <em>Generic XML-based Framework for Metadata Portals.</em>
            Computers &amp; Geosciences 34 (12), 1947-1955.
            <a href="http://dx.doi.org/10.1016/j.cageo.2008.02.023"
            target="_blank">doi:10.1016/j.cageo.2008.02.023</a></blockquote>
            
            <p/><em>A quote from this paper:</em> Because Apache Lucene is a full-text
            search engine and not a conventional database, it cannot handle numerical ranges
            (e.g., field value is inside user defined bounds, even dates are numerical values).
            We have developed an extension to Apache Lucene that stores
            the numerical values in a special string-encoded format with variable precision
            (all numerical values like doubles, longs, floats, and ints are converted to
            lexicographic sortable string representations and stored with different precisions
            (for a more detailed description of how the values are stored,
            see {@link NumericUtils}). A range is then divided recursively into multiple intervals for searching:
            The center of the range is searched only with the lowest possible precision in the <em>trie</em>,
            while the boundaries are matched more exactly. This reduces the number of terms dramatically.<p/>
            
            <p/>For the variant that stores long values in 8 different precisions (each reduced by 8 bits) that
            uses a lowest precision of 1 byte, the index contains only a maximum of 256 distinct values in the
            lowest precision. Overall, a range could consist of a theoretical maximum of
            <code>7*255*2 + 255 = 3825</code> distinct terms (when there is a term for every distinct value of an
            8-byte-number in the index and the range covers almost all of them; a maximum of 255 distinct values is used
            because it would always be possible to reduce the full 256 values to one term with degraded precision).
            In practice, we have seen up to 300 terms in most cases (index with 500,000 metadata records
            and a uniform value distribution).<p/>
            
            <a name="precisionStepDesc"/><h3>Precision Step</h3>
            <p/>You can choose any <code>precisionStep</code> when encoding values.
            Lower step values mean more precisions and so more terms in index (and index gets larger).
            On the other hand, the maximum number of terms to match reduces, which optimized query speed.
            The formula to calculate the maximum term count is:
            <pre>
            n = [ (bitsPerValue/precisionStep - 1) * (2^precisionStep - 1 ) * 2 ] + (2^precisionStep - 1 )
            </pre>
            <p/><em>(this formula is only correct, when <code>bitsPerValue/precisionStep</code> is an integer;
            in other cases, the value must be rounded up and the last summand must contain the modulo of the division as
            precision step)</em>.
            For longs stored using a precision step of 4, <code>n = 15*15*2 + 15 = 465</code>, and for a precision
            step of 2, <code>n = 31*3*2 + 3 = 189</code>. But the faster search speed is reduced by more seeking
            in the term enum of the index. Because of this, the ideal <code>precisionStep</code> value can only
            be found out by testing. <b>Important:</b> You can index with a lower precision step value and test search speed
            using a multiple of the original step value.<p/>
            
            <p/>Good values for <code>precisionStep</code> are depending on usage and data type:
            <ul>
            <li>The default for all data types is <b>4</b>, which is used, when no <code>precisionStep</code> is given.</li>
            <li>Ideal value in most cases for <em>64 bit</em> data types <em>(long, double)</em> is <b>6</b> or <b>8</b>.</li>
            <li>Ideal value in most cases for <em>32 bit</em> data types <em>(int, float)</em> is <b>4</b>.</li>
            <li>Steps <b>&gt;64</b> for <em>long/double</em> and <b>&gt;32</b> for <em>int/float</em> produces one token
            per value in the index and querying is as slow as a conventional {@link TermRangeQuery}. But it can be used
            to produce fields, that are solely used for sorting (in this case simply use {@link Integer#MAX_VALUE} as
            <code>precisionStep</code>). Using {@link NumericField NumericFields} for sorting
            is ideal, because building the field cache is much faster than with text-only numbers.
            Sorting is also possible with range query optimized fields using one of the above <code>precisionSteps</code>.</li>
            </ul>
            
            <p/>Comparisons of the different types of RangeQueries on an index with about 500,000 docs showed
            that {@link TermRangeQuery} in boolean rewrite mode (with raised {@link BooleanQuery} clause count)
            took about 30-40 secs to complete, {@link TermRangeQuery} in constant score filter rewrite mode took 5 secs
            and executing this class took &lt;100ms to complete (on an Opteron64 machine, Java 1.5, 8 bit
            precision step). This query type was developed for a geographic portal, where the performance for
            e.g. bounding boxes or exact date/time stamps is important.<p/>
            
            </summary>
            <since> 2.9
            
            </since>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewLongRange(System.String,System.Int32,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>long</code>
            range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewLongRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>long</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewIntRange(System.String,System.Int32,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>int</code>
            range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewIntRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>int</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewDoubleRange(System.String,System.Int32,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>double</code>
            range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewDoubleRange(System.String,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>double</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewFloatRange(System.String,System.Int32,System.Single,System.Single,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>float</code>
            range using the given <a href="#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NewFloatRange(System.String,System.Single,System.Single,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeQuery</code>, that queries a <code>float</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.GetField">
            <summary>Returns the field name for this query </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.IncludesMin">
            <summary>Returns <code>true</code> if the lower endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.IncludesMax">
            <summary>Returns <code>true</code> if the upper endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.GetMin">
            <summary>Returns the lower value of this range query </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.GetMax">
            <summary>Returns the upper value of this range query </summary>
        </member>
        <member name="T:Lucene.Net.Search.NumericRangeQuery.NumericRangeTermEnum">
            <summary> Subclass of FilteredTermEnum for enumerating all terms that match the
            sub-ranges for trie range queries.
            <p/>
            WARNING: This term enumeration is not guaranteed to be always ordered by
            {@link Term#compareTo}.
            The ordering depends on how {@link NumericUtils#splitLongRange} and
            {@link NumericUtils#splitIntRange} generates the sub-ranges. For
            {@link MultiTermQuery} ordering is not relevant.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NumericRangeTermEnum.EndEnum">
            <summary>this is a dummy, it is not used by this class. </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NumericRangeTermEnum.TermCompare(Lucene.Net.Index.Term)">
            <summary> Compares if current upper bound is reached,
            this also updates the term count for statistics.
            In contrast to {@link FilteredTermEnum}, a return value
            of <code>false</code> ends iterating the current enum
            and forwards to the next sub-range.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NumericRangeTermEnum.Next">
            <summary>Increments the enumeration to the next element.  True if one exists. </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeQuery.NumericRangeTermEnum.Close">
            <summary>Closes the enumeration to further activity, freeing resources.  </summary>
        </member>
        <member name="T:Lucene.Net.Search.IndexSearcher">
            <summary>Implements search over a single IndexReader.
            
            <p/>Applications usually need only call the inherited {@link #Search(Query)}
            or {@link #Search(Query,Filter)} methods. For performance reasons it is 
            recommended to open only one IndexSearcher and use it for all of your searches.
            
            <p/>Note that you can only access Hits from an IndexSearcher as long as it is
            not yet closed, otherwise an IOException will be thrown. 
            
            <a name="thread-safety"></a><p/><b>NOTE</b>: {@link
            <code>IndexSearcher</code>} instances are completely
            thread safe, meaning multiple threads can call any of its
            methods, concurrently.  If your application requires
            external synchronization, you should <b>not</b>
            synchronize on the <code>IndexSearcher</code> instance;
            use your own (non-Lucene) objects instead.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.#ctor(System.String)">
            <summary>Creates a searcher searching the index in the named directory.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #IndexSearcher(Directory, boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.#ctor(System.String,System.Boolean)">
            <summary>Creates a searcher searching the index in the named
            directory.  You should pass readOnly=true, since it
            gives much better concurrent performance, unless you
            intend to do write operations (delete documents or
            change norms) with the underlying IndexReader.
            </summary>
            <param name="path">directory where IndexReader will be opened
            </param>
            <param name="readOnly">if true, the underlying IndexReader
            will be opened readOnly
            </param>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #IndexSearcher(Directory, boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.#ctor(Lucene.Net.Store.Directory)">
            <summary>Creates a searcher searching the index in the provided directory.</summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <deprecated> Use {@link #IndexSearcher(Directory, boolean)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.#ctor(Lucene.Net.Store.Directory,System.Boolean)">
            <summary>Creates a searcher searching the index in the named
            directory.  You should pass readOnly=true, since it
            gives much better concurrent performance, unless you
            intend to do write operations (delete documents or
            change norms) with the underlying IndexReader.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
            <param name="path">directory where IndexReader will be opened
            </param>
            <param name="readOnly">if true, the underlying IndexReader
            will be opened readOnly
            </param>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.#ctor(Lucene.Net.Index.IndexReader)">
            <summary>Creates a searcher searching the provided index. </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.GetIndexReader">
            <summary>Return the {@link IndexReader} this searches. </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.Close">
            <summary> Note that the underlying IndexReader is not closed, if
            IndexSearcher was constructed with IndexSearcher(IndexReader r).
            If the IndexReader was supplied implicitly by specifying a directory, then
            the IndexReader gets closed.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort,System.Boolean)">
            <summary> Just like {@link #Search(Weight, Filter, int, Sort)}, but you choose
            whether or not the fields in the returned {@link FieldDoc} instances
            should be set by specifying fillFields.<br/>
            
            <p/>
            NOTE: this does not compute scores by default. If you need scores, create
            a {@link TopFieldCollector} instance by calling
            {@link TopFieldCollector#create} and then pass that to
            {@link #Search(Weight, Filter, Collector)}.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.IndexSearcher.SetDefaultFieldSortScoring(System.Boolean,System.Boolean)">
            <summary> By default, no scores are computed when sorting by field (using
            {@link #Search(Query,Filter,int,Sort)}). You can change that, per
            IndexSearcher instance, by calling this method. Note that this will incur
            a CPU cost.
            
            </summary>
            <param name="doTrackScores">If true, then scores are returned for every matching document
            in {@link TopFieldDocs}.
            
            </param>
            <param name="doMaxScore">If true, then the max score for all matching docs is computed.
            </param>
        </member>
        <member name="T:Lucene.Net.Search.BooleanClause">
            <summary>A clause in a BooleanQuery. </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanClause.query">
            <summary>The query whose matching documents are combined by the boolean query.</summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanClause.#ctor(Lucene.Net.Search.Query,Lucene.Net.Search.BooleanClause.Occur)">
            <summary>Constructs a BooleanClause.</summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanClause.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.BooleanClause.GetHashCode">
            <summary>Returns a hash code value for this object.</summary>
        </member>
        <member name="T:Lucene.Net.Search.BooleanClause.Occur">
            <summary>Specifies how clauses are to occur in matching documents. </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanClause.Occur.MUST">
            <summary>Use this operator for clauses that <i>must</i> appear in the matching documents. </summary>
        </member>
        <member name="F:Lucene.Net.Search.BooleanClause.Occur.SHOULD">
            <summary>Use this operator for clauses that <i>should</i> appear in the 
            matching documents. For a BooleanQuery with no <code>MUST</code> 
            clauses one or more <code>SHOULD</code> clauses must match a document 
            for the BooleanQuery to match.
            </summary>
            <seealso cref="!:BooleanQuery.setMinimumNumberShouldMatch">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.BooleanClause.Occur.MUST_NOT">
            <summary>Use this operator for clauses that <i>must not</i> appear in the matching documents.
            Note that it is not possible to search for queries that only consist
            of a <code>MUST_NOT</code> clause. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsWriter.AddAllDocVectors(Lucene.Net.Index.TermFreqVector[])">
            <summary> Add a complete document specified by all its term vectors. If document has no
            term vectors, add value for tvx.
            
            </summary>
            <param name="vectors">
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsWriter.AddRawDocuments(Lucene.Net.Index.TermVectorsReader,System.Int32[],System.Int32[],System.Int32)">
            <summary> Do a bulk copy of numDocs documents from reader to our
            streams.  This is used to expedite merging, if the
            field numbers are congruent.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsWriter.Close">
            <summary>Close all streams. </summary>
        </member>
        <member name="T:Lucene.Net.Index.LogDocMergePolicy">
            <summary>This is a {@link LogMergePolicy} that measures size of a
            segment as the number of documents (not taking deletions
            into account). 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.LogDocMergePolicy.DEFAULT_MIN_MERGE_DOCS">
            <seealso cref="!:setMinMergeDocs">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.LogDocMergePolicy.SetMinMergeDocs(System.Int32)">
            <summary>Sets the minimum size for the lowest level segments.
            Any segments below this size are considered to be on
            the same level (even if they vary drastically in size)
            and will be merged whenever there are mergeFactor of
            them.  This effectively truncates the "long tail" of
            small segments that would otherwise be created into a
            single level.  If you set this too large, it could
            greatly increase the merging cost during indexing (if
            you flush many small segments). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.LogDocMergePolicy.GetMinMergeDocs">
            <summary>Get the minimum size for a segment to remain
            un-merged.
            </summary>
            <seealso cref="!:setMinMergeDocs">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Index.ConcurrentMergeScheduler">
            <summary>A {@link MergeScheduler} that runs each merge using a
            separate thread, up until a maximum number of threads
            ({@link #setMaxThreadCount}) at which when a merge is
            needed, the thread(s) that are updating the index will
            pause until one or more merges completes.  This is a
            simple way to use concurrency in the indexing process
            without having to create and manage application level
            threads. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.SetMaxThreadCount(System.Int32)">
            <summary>Sets the max # simultaneous threads that may be
            running.  If a merge is necessary yet we already have
            this many threads running, the incoming thread (that
            is calling add/updateDocument) will block until
            a merge thread has completed. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.GetMaxThreadCount">
            <summary>Get the max # simultaneous threads that may be</summary>
            <seealso cref="!:setMaxThreadCount">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.GetMergeThreadPriority">
            <summary>Return the priority that merge threads run at.  By
            default the priority is 1 plus the priority of (ie,
            slightly higher priority than) the first thread that
            calls merge. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.SetMergeThreadPriority(System.Int32)">
            <summary>Return the priority that merge threads run at. </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.DoMerge(Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Does the actual merge, by calling {@link IndexWriter#merge} </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.GetMergeThread(Lucene.Net.Index.IndexWriter,Lucene.Net.Index.MergePolicy.OneMerge)">
            <summary>Create and return a new MergeThread </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.HandleMergeException(System.Exception)">
            <summary>Called when an exception is hit in a background merge
            thread 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.AnyUnhandledExceptions">
            <summary>Used for testing </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.AddMyself">
            <summary>Used for testing </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.SetSuppressExceptions">
            <summary>Used for testing </summary>
        </member>
        <member name="M:Lucene.Net.Index.ConcurrentMergeScheduler.ClearSuppressExceptions">
            <summary>Used for testing </summary>
        </member>
        <member name="F:Lucene.Net.Index.ConcurrentMergeScheduler.allInstances">
            <summary>Used for testing </summary>
        </member>
        <member name="T:Lucene.Net.Documents.Document">
            <summary>Documents are the unit of indexing and search.
            
            A Document is a set of fields.  Each field has a name and a textual value.
            A field may be {@link Fieldable#IsStored() stored} with the document, in which
            case it is returned with search hits on the document.  Thus each document
            should typically contain one or more stored fields which uniquely identify
            it.
            
            <p/>Note that fields which are <i>not</i> {@link Fieldable#IsStored() stored} are
            <i>not</i> available in documents retrieved from the index, e.g. with {@link
            ScoreDoc#doc}, {@link Searcher#Doc(int)} or {@link
            IndexReader#Document(int)}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.#ctor">
            <summary>Constructs a new document with no fields. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.SetBoost(System.Single)">
            <summary>Sets a boost factor for hits on any field of this document.  This value
            will be multiplied into the score of all hits on this document.
            
            <p/>The default value is 1.0.
            
            <p/>Values are multiplied into the value of {@link Fieldable#GetBoost()} of
            each field in this document.  Thus, this method in effect sets a default
            boost for the fields of this document.
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Fieldable.SetBoost(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetBoost">
            <summary>Returns, at indexing time, the boost factor as set by {@link #SetBoost(float)}. 
            
            <p/>Note that once a document is indexed this value is no longer available
            from the index.  At search time, for retrieved documents, this method always 
            returns 1. This however does not mean that the boost value set at  indexing 
            time was ignored - it was just combined with other indexing time factors and 
            stored elsewhere, for better indexing and search performance. (For more 
            information see the "norm(t,d)" part of the scoring formula in 
            {@link Lucene.Net.Search.Similarity Similarity}.)
            
            </summary>
            <seealso cref="M:Lucene.Net.Documents.Document.SetBoost(System.Single)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Documents.Document.Add(Lucene.Net.Documents.Fieldable)">
            <summary> <p/>Adds a field to a document.  Several fields may be added with
            the same name.  In this case, if the fields are indexed, their text is
            treated as though appended for the purposes of search.<p/>
            <p/> Note that add like the removeField(s) methods only makes sense 
            prior to adding a document to an index. These methods cannot
            be used to change the content of an existing index! In order to achieve this,
            a document has to be deleted from an index and a new changed version of that
            document has to be added.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.RemoveField(System.String)">
            <summary> <p/>Removes field with the specified name from the document.
            If multiple fields exist with this name, this method removes the first field that has been added.
            If there is no field with the specified name, the document remains unchanged.<p/>
            <p/> Note that the removeField(s) methods like the add method only make sense 
            prior to adding a document to an index. These methods cannot
            be used to change the content of an existing index! In order to achieve this,
            a document has to be deleted from an index and a new changed version of that
            document has to be added.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.RemoveFields(System.String)">
            <summary> <p/>Removes all fields with the given name from the document.
            If there is no field with the specified name, the document remains unchanged.<p/>
            <p/> Note that the removeField(s) methods like the add method only make sense 
            prior to adding a document to an index. These methods cannot
            be used to change the content of an existing index! In order to achieve this,
            a document has to be deleted from an index and a new changed version of that
            document has to be added.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetField(System.String)">
            <summary>Returns a field with the given name if any exist in this document, or
            null.  If multiple fields exists with this name, this method returns the
            first value added.
            Do not use this method with lazy loaded fields.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetFieldable(System.String)">
            <summary>Returns a field with the given name if any exist in this document, or
            null.  If multiple fields exists with this name, this method returns the
            first value added.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.Get(System.String)">
            <summary>Returns the string value of the field with the given name if any exist in
            this document, or null.  If multiple fields exist with this name, this
            method returns the first value added. If only binary fields with this name
            exist, returns null.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.Fields">
            <summary>Returns an Enumeration of all the fields in a document.</summary>
            <deprecated> use {@link #GetFields()} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetFields">
            <summary>Returns a List of all the fields in a document.
            <p/>Note that fields which are <i>not</i> {@link Fieldable#IsStored() stored} are
            <i>not</i> available in documents retrieved from the
            index, e.g. {@link Searcher#Doc(int)} or {@link
            IndexReader#Document(int)}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetFields(System.String)">
            <summary> Returns an array of {@link Field}s with the given name.
            Do not use with lazy loaded fields.
            This method returns an empty array when there are no
            matching fields.  It never returns null.
            
            </summary>
            <param name="name">the name of the field
            </param>
            <returns> a <code>Field[]</code> array
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetFieldables(System.String)">
            <summary> Returns an array of {@link Fieldable}s with the given name.
            This method returns an empty array when there are no
            matching fields.  It never returns null.
            
            </summary>
            <param name="name">the name of the field
            </param>
            <returns> a <code>Fieldable[]</code> array
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetValues(System.String)">
            <summary> Returns an array of values of the field specified as the method parameter.
            This method returns an empty array when there are no
            matching fields.  It never returns null.
            </summary>
            <param name="name">the name of the field
            </param>
            <returns> a <code>String[]</code> of field values
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetBinaryValues(System.String)">
            <summary> Returns an array of byte arrays for of the fields that have the name specified
            as the method parameter.  This method returns an empty
            array when there are no matching fields.  It never
            returns null.
            
            </summary>
            <param name="name">the name of the field
            </param>
            <returns> a <code>byte[][]</code> of binary field values
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Document.GetBinaryValue(System.String)">
            <summary> Returns an array of bytes for the first (or only) field that has the name
            specified as the method parameter. This method will return <code>null</code>
            if no binary fields with the specified name are available.
            There may be non-binary fields with the same name.
            
            </summary>
            <param name="name">the name of the field.
            </param>
            <returns> a <code>byte[]</code> containing the binary field value or <code>null</code>
            </returns>
        </member>
        <member name="M:Lucene.Net.Documents.Document.ToString">
            <summary>Prints the fields of a document for human consumption. </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.PorterStemmer">
            <summary> 
            Stemmer, implementing the Porter Stemming Algorithm
            
            The Stemmer class transforms a word into its root form.  The input
            word can be provided a character at time (by calling add()), or at once
            by calling one of the various stem(something) methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Reset">
            <summary> reset() resets the stemmer so it can stem another word.  If you invoke
            the stemmer by calling add(char) and then stem(), you must call reset()
            before starting another word.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Add(System.Char)">
            <summary> Add a character to the word being stemmed.  When you are finished
            adding characters, you can call stem(void) to process the word.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.ToString">
            <summary> After a word has been stemmed, it can be retrieved by toString(),
            or a reference to the internal buffer can be retrieved by getResultBuffer
            and getResultLength (which is generally more efficient.)
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.GetResultLength">
            <summary> Returns the length of the word resulting from the stemming process.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.GetResultBuffer">
            <summary> Returns a reference to a character buffer containing the results of
            the stemming process.  You also need to consult getResultLength()
            to determine the length of the result.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Stem(System.String)">
            <summary> Stem a word provided as a String.  Returns the result as a String.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Stem(System.Char[])">
            <summary>Stem a word contained in a char[].  Returns true if the stemming process
            resulted in a word different from the input.  You can retrieve the
            result with getResultLength()/getResultBuffer() or toString().
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Stem(System.Char[],System.Int32,System.Int32)">
            <summary>Stem a word contained in a portion of a char[] array.  Returns
            true if the stemming process resulted in a word different from
            the input.  You can retrieve the result with
            getResultLength()/getResultBuffer() or toString().
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Stem(System.Char[],System.Int32)">
            <summary>Stem a word contained in a leading portion of a char[] array.
            Returns true if the stemming process resulted in a word different
            from the input.  You can retrieve the result with
            getResultLength()/getResultBuffer() or toString().
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Stem">
            <summary>Stem the word placed into the Stemmer buffer through calls to add().
            Returns true if the stemming process resulted in a word different
            from the input.  You can retrieve the result with
            getResultLength()/getResultBuffer() or toString().
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.PorterStemmer.Main(System.String[])">
            <summary>Test program for demonstrating the Stemmer.  It reads a file and
            stems each word, writing the result to standard out.
            Usage: Stemmer file-name
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.OpenBitSetIterator">
            <summary>An iterator to iterate over set bits in an OpenBitSet.
            This is faster than nextSetBit() for iterating over the complete set of bits,
            especially when the density of the bits set is high.
            
            </summary>
            <version>  $Id$
            </version>
        </member>
        <member name="F:Lucene.Net.Util.OpenBitSetIterator.arr">
            <summary>** the python code that generated bitlist
            def bits2int(val):
            arr=0
            for shift in range(8,0,-1):
            if val &amp; 0x80:
            arr = (arr &lt;&lt; 4) | shift
            val = val &lt;&lt; 1
            return arr
            def int_table():
            tbl = [ hex(bits2int(val)).strip('L') for val in range(256) ]
            return ','.join(tbl)
            ****
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetIterator.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Util.OpenBitSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Util.Constants">
            <summary> Some useful constants.
            
            
            </summary>
            <version>  $Id: Constants.java 828327 2009-10-22 06:47:40Z uschindler $
            
            </version>
        </member>
        <member name="F:Lucene.Net.Util.Constants.JAVA_VERSION">
            <summary>The value of <tt>System.getProperty("java.version")</tt>. *</summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.JAVA_1_1">
            <summary>True iff this is Java version 1.1. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.JAVA_1_2">
            <summary>True iff this is Java version 1.2. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.JAVA_1_3">
            <summary>True iff this is Java version 1.3. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.OS_NAME">
            <summary>The value of <tt>System.getProperty("os.name")</tt>. *</summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.LINUX">
            <summary>True iff running on Linux. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.WINDOWS">
            <summary>True iff running on Windows. </summary>
        </member>
        <member name="F:Lucene.Net.Util.Constants.SUN_OS">
            <summary>True iff running on SunOS. </summary>
        </member>
        <member name="T:Lucene.Net.Util.BitVector">
            <summary>Optimized implementation of a vector of bits.  This is more-or-less like
            java.util.BitSet, but also includes the following:
            <ul>
            <li>a count() method, which efficiently computes the number of one bits;</li>
            <li>optimized read from and write to disk;</li>
            <li>inlinable get() method;</li>
            <li>store and load, as bit set or d-gaps, depending on sparseness;</li> 
            </ul>
            </summary>
            <version>  $Id: BitVector.java 765649 2009-04-16 14:29:26Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.#ctor(System.Int32)">
            <summary>Constructs a vector capable of holding <code>n</code> bits. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Set(System.Int32)">
            <summary>Sets the value of <code>bit</code> to one. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.GetAndSet(System.Int32)">
            <summary>Sets the value of <code>bit</code> to true, and
            returns true if bit was already set 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Clear(System.Int32)">
            <summary>Sets the value of <code>bit</code> to zero. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Get(System.Int32)">
            <summary>Returns <code>true</code> if <code>bit</code> is one and
            <code>false</code> if it is zero. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Size">
            <summary>Returns the number of bits in this vector.  This is also one greater than
            the number of the largest valid bit number. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Count">
            <summary>Returns the total number of one bits in this vector.  This is efficiently
            computed and cached, so that, if the vector is not changed, no
            recomputation is done for repeated calls. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.GetRecomputedCount">
            <summary>
            For testing 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Write(Lucene.Net.Store.Directory,System.String)">
            <summary>Writes this vector to the file <code>name</code> in Directory
            <code>d</code>, in a format that can be read by the constructor {@link
            #BitVector(Directory, String)}.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.WriteBits(Lucene.Net.Store.IndexOutput)">
            <summary>Write as a bit set </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.WriteDgaps(Lucene.Net.Store.IndexOutput)">
            <summary>Write as a d-gaps list </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.IsSparse">
            <summary>Indicates if the bit vector is sparse and should be saved as a d-gaps list, or dense, and should be saved as a bit set. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.#ctor(Lucene.Net.Store.Directory,System.String)">
            <summary>Constructs a bit vector from the file <code>name</code> in Directory
            <code>d</code>, as written by the {@link #write} method.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.ReadBits(Lucene.Net.Store.IndexInput)">
            <summary>Read as a bit set </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.ReadDgaps(Lucene.Net.Store.IndexInput)">
            <summary>read as a d-gaps list </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitVector.Subset(System.Int32,System.Int32)">
            <summary> Retrieve a subset of this BitVector.
            
            </summary>
            <param name="start">starting index, inclusive
            </param>
            <param name="end">ending index, exclusive
            </param>
            <returns> subset
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.QueryTermVector">
            <summary> 
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.QueryTermVector.#ctor(System.String[])">
            <summary> </summary>
            <param name="queryTerms">The original list of terms from the query, can contain duplicates
            </param>
        </member>
        <member name="T:Lucene.Net.Search.ParallelMultiSearcher">
            <summary>Implements parallel search over a set of <code>Searchables</code>.
            
            <p/>Applications usually need only call the inherited {@link #Search(Query)}
            or {@link #Search(Query,Filter)} methods.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ParallelMultiSearcher.#ctor(Lucene.Net.Search.Searchable[])">
            <summary>Creates a searchable which searches <i>searchables</i>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ParallelMultiSearcher.DocFreq(Lucene.Net.Index.Term)">
            <summary> TODO: parallelize this one too</summary>
        </member>
        <member name="M:Lucene.Net.Search.ParallelMultiSearcher.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32)">
            <summary> A search implementation which spans a new thread for each
            Searchable, waits for each search to complete and merge
            the results back together.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ParallelMultiSearcher.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            <summary> A search implementation allowing sorting which spans a new thread for each
            Searchable, waits for each search to complete and merges
            the results back together.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ParallelMultiSearcher.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,Lucene.Net.Search.Collector)">
            <summary>Lower-level search API.
            
            <p/>{@link Collector#Collect(int)} is called for every matching document.
            
            <p/>Applications should only use this if they need <i>all</i> of the
            matching documents.  The high-level search API ({@link
            Searcher#Search(Query)}) is usually more efficient, as it skips
            non-high-scoring hits.
            
            </summary>
            <param name="weight">to match documents
            </param>
            <param name="filter">if non-null, a bitset used to eliminate some documents
            </param>
            <param name="collector">to receive hits
            
            TODO: parallelize this one too
            </param>
        </member>
        <member name="T:Lucene.Net.Search.MultiSearcherThread">
            <summary> A thread subclass for searching a single searchable </summary>
        </member>
        <member name="T:Lucene.Net.Search.HitIterator">
            <summary> An iterator over {@link Hits} that provides lazy fetching of each document.
            {@link Hits#Iterator()} returns an instance of this class.  Calls to {@link #next()}
            return a {@link Hit} instance.
            
            </summary>
            <deprecated> Use {@link TopScoreDocCollector} and {@link TopDocs} instead. Hits will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.HitIterator.#ctor(Lucene.Net.Search.Hits)">
            <summary> Constructed from {@link Hits#Iterator()}.</summary>
        </member>
        <member name="M:Lucene.Net.Search.HitIterator.MoveNext">
            <returns> true if current hit is less than the total number of {@link Hits}.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.HitIterator.Remove">
            <summary> Unsupported operation.
            
            </summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Search.HitIterator.Length">
            <summary> Returns the total number of hits.</summary>
        </member>
        <member name="P:Lucene.Net.Search.HitIterator.Current">
            <summary> Returns a {@link Hit} instance representing the next hit in {@link Hits}.
            
            </summary>
            <returns> Next {@link Hit}.
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.FuzzyQuery">
            <summary>Implements the fuzzy search query. The similarity measurement
            is based on the Levenshtein (edit distance) algorithm.
            
            Warning: this query is not very scalable with its default prefix
            length of 0 - in this case, *every* term will be enumerated and
            cause an edit score calculation.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.#ctor(Lucene.Net.Index.Term,System.Single,System.Int32)">
            <summary> Create a new FuzzyQuery that will match terms with a similarity 
            of at least <code>minimumSimilarity</code> to <code>term</code>.
            If a <code>prefixLength</code> &gt; 0 is specified, a common prefix
            of that length is also required.
            
            </summary>
            <param name="term">the term to search for
            </param>
            <param name="minimumSimilarity">a value between 0 and 1 to set the required similarity
            between the query term and the matching terms. For example, for a
            <code>minimumSimilarity</code> of <code>0.5</code> a term of the same length
            as the query term is considered similar to the query term if the edit distance
            between both terms is less than <code>length(term)*0.5</code>
            </param>
            <param name="prefixLength">length of common (non-fuzzy) prefix
            </param>
            <throws>  IllegalArgumentException if minimumSimilarity is &gt;= 1 or &lt; 0 </throws>
            <summary> or if prefixLength &lt; 0
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.#ctor(Lucene.Net.Index.Term,System.Single)">
            <summary> Calls {@link #FuzzyQuery(Term, float) FuzzyQuery(term, minimumSimilarity, 0)}.</summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.#ctor(Lucene.Net.Index.Term)">
            <summary> Calls {@link #FuzzyQuery(Term, float) FuzzyQuery(term, 0.5f, 0)}.</summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.GetMinSimilarity">
            <summary> Returns the minimum similarity that is required for this query to match.</summary>
            <returns> float value between 0.0 and 1.0
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.GetPrefixLength">
            <summary> Returns the non-fuzzy prefix length. This is the number of characters at the start
            of a term that must be identical (not fuzzy) to the query term if the query
            is to match that term. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FuzzyQuery.GetTerm">
            <summary> Returns the pattern term.</summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.ShortFieldSource">
            <summary> Expert: obtains short field values from the 
            {@link Lucene.Net.Search.FieldCache FieldCache}
            using <code>getShorts()</code> and makes those values 
            available as other numeric types, casting as needed.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            </summary>
            <seealso cref="T:Lucene.Net.Search.Function.FieldCacheSource"> for requirements
            on the field.
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.ShortFieldSource.#ctor(System.String)">
            <summary> Create a cached short field source with default string-to-short parser. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ShortFieldSource.#ctor(System.String,Lucene.Net.Search.ShortParser)">
            <summary> Create a cached short field source with a specific string-to-short parser. </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.CustomScoreQuery">
            <summary> Query that sets document score as a programmatic function of several (sub) scores:
            <ol>
            <li>the score of its subQuery (any query)</li>
            <li>(optional) the score of its ValueSourceQuery (or queries).
            For most simple/convenient use cases this query is likely to be a 
            {@link Lucene.Net.Search.Function.FieldScoreQuery FieldScoreQuery}</li>
            </ol>
            Subclasses can modify the computation by overriding {@link #getCustomScoreProvider}.
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.#ctor(Lucene.Net.Search.Query)">
            <summary> Create a CustomScoreQuery over input subQuery.</summary>
            <param name="subQuery">the sub query whose scored is being customed. Must not be null. 
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.#ctor(Lucene.Net.Search.Query,Lucene.Net.Search.Function.ValueSourceQuery)">
            <summary> Create a CustomScoreQuery over input subQuery and a {@link ValueSourceQuery}.</summary>
            <param name="subQuery">the sub query whose score is being customed. Must not be null.
            </param>
            <param name="valSrcQuery">a value source query whose scores are used in the custom score
            computation. For most simple/convineient use case this would be a 
            {@link Lucene.Net.Search.Function.FieldScoreQuery FieldScoreQuery}.
            This parameter is optional - it can be null or even an empty array.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.#ctor(Lucene.Net.Search.Query,Lucene.Net.Search.Function.ValueSourceQuery[])">
            <summary> Create a CustomScoreQuery over input subQuery and a {@link ValueSourceQuery}.</summary>
            <param name="subQuery">the sub query whose score is being customized. Must not be null.
            </param>
            <param name="valSrcQueries">value source queries whose scores are used in the custom score
            computation. For most simple/convenient use case these would be 
            {@link Lucene.Net.Search.Function.FieldScoreQuery FieldScoreQueries}.
            This parameter is optional - it can be null or even an empty array.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.GetHashCode">
            <summary>Returns a hash code value for this object. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.GetCustomScoreProvider(Lucene.Net.Index.IndexReader)">
            Returns a {@link CustomScoreProvider} that calculates the custom scores
            for the given {@link IndexReader}. The default implementation returns a default
            implementation as specified in the docs of {@link CustomScoreProvider}.
            @since 2.9.2
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomScore(System.Int32,System.Single,System.Single[])">
            <summary>
            Compute a custom score by the subQuery score and a number of 
            ValueSourceQuery scores.
            
            The doc is relative to the current reader, which is
            unknown to CustomScoreQuery when using per-segment search (since Lucene 2.9).
            Please override {@link #getCustomScoreProvider} and return a subclass
            of {@link CustomScoreProvider} for the given {@link IndexReader}.
            see CustomScoreProvider#customScore(int,float,float[])
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomScore(System.Int32,System.Single,System.Single)">
            <summary> Compute a custom score by the subQuery score and the ValueSourceQuery score.
            
            The doc is relative to the current reader, which is
            unknown to CustomScoreQuery when using per-segment search (since Lucene 2.9).
            Please override {@link #getCustomScoreProvider} and return a subclass
            of {@link CustomScoreProvider} for the given {@link IndexReader}.
            @see CustomScoreProvider#customScore(int,float,float)
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomExplain(System.Int32,Lucene.Net.Search.Explanation,Lucene.Net.Search.Explanation[])">
            <summary> Explain the custom score.
            
            The doc is relative to the current reader, which is
            unknown to CustomScoreQuery when using per-segment search (since Lucene 2.9).
            Please override {@link #getCustomScoreProvider} and return a subclass
            of {@link CustomScoreProvider} for the given {@link IndexReader}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomExplain(System.Int32,Lucene.Net.Search.Explanation,Lucene.Net.Search.Explanation)">
            <summary> Explain the custom score.
            The doc is relative to the current reader, which is
            unknown to CustomScoreQuery when using per-segment search (since Lucene 2.9).
            Please override {@link #getCustomScoreProvider} and return a subclass
            of {@link CustomScoreProvider} for the given {@link IndexReader}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.IsStrict">
            <summary> Checks if this is strict custom scoring.
            In strict custom scoring, the ValueSource part does not participate in weight normalization.
            This may be useful when one wants full control over how scores are modified, and does 
            not care about normalizing by the ValueSource part.
            One particular case where this is useful if for testing this query.   
            <p/>
            Note: only has effect when the ValueSource part is not null.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.SetStrict(System.Boolean)">
            <summary> Set the strict mode of this query. </summary>
            <param name="strict">The strict mode to set.
            </param>
            <seealso cref="M:Lucene.Net.Search.Function.CustomScoreQuery.IsStrict">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.Name">
            <summary> A short name of this query, used in {@link #ToString(String)}.</summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.CustomScoreQuery.CustomScorer">
            <summary> A scorer that applies a (callback) function on scores of the subQuery.</summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Function.CustomScoreQuery.CustomScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.FilterManager">
            <summary> Filter caching singleton.  It can be used 
            to save filters locally for reuse.
            This class makes it possble to cache Filters even when using RMI, as it
            keeps the cache on the seaercher side of the RMI connection.
            
            Also could be used as a persistent storage for any filter as long as the
            filter provides a proper hashCode(), as that is used as the key in the cache.
            
            The cache is periodically cleaned up from a separate thread to ensure the
            cache doesn't exceed the maximum size.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.DEFAULT_CACHE_CLEAN_SIZE">
            <summary>The default maximum number of Filters in the cache </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.DEFAULT_CACHE_SLEEP_TIME">
            <summary>The default frequency of cache clenup </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.cache">
            <summary>The cache itself </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.cacheCleanSize">
            <summary>Maximum allowed cache size </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.cleanSleepTime">
            <summary>Cache cleaning frequency </summary>
        </member>
        <member name="F:Lucene.Net.Search.FilterManager.filterCleaner">
            <summary>Cache cleaner that runs in a separate thread </summary>
        </member>
        <member name="M:Lucene.Net.Search.FilterManager.#ctor">
            <summary> Sets up the FilterManager singleton.</summary>
        </member>
        <member name="M:Lucene.Net.Search.FilterManager.SetCacheSize(System.Int32)">
            <summary> Sets the max size that cache should reach before it is cleaned up</summary>
            <param name="cacheCleanSize">maximum allowed cache size
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FilterManager.SetCleanThreadSleepTime(System.Int64)">
            <summary> Sets the cache cleaning frequency in milliseconds.</summary>
            <param name="cleanSleepTime">cleaning frequency in millioseconds
            </param>
        </member>
        <member name="M:Lucene.Net.Search.FilterManager.GetFilter(Lucene.Net.Search.Filter)">
            <summary> Returns the cached version of the filter.  Allows the caller to pass up
            a small filter but this will keep a persistent version around and allow
            the caching filter to do its job.
            
            </summary>
            <param name="filter">The input filter
            </param>
            <returns> The cached version of the filter
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.FilterManager.FilterItem">
            <summary> Holds the filter and the last time the filter was used, to make LRU-based
            cache cleaning possible.
            TODO: Clean this up when we switch to Java 1.5
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FilterManager.FilterCleaner">
            <summary> Keeps the cache from getting too big.
            If we were using Java 1.5, we could use LinkedHashMap and we would not need this thread
            to clean out the cache.
            
            The SortedSet sortedFilterItems is used only to sort the items from the cache,
            so when it's time to clean up we have the TreeSet sort the FilterItems by
            timestamp.
            
            Removes 1.5 * the numbers of items to make the cache smaller.
            For example:
            If cache clean size is 10, and the cache is at 15, we would remove (15 - 10) * 1.5 = 7.5 round up to 8.
            This way we clean the cache a bit more, and avoid having the cache cleaner having to do it frequently.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.DisjunctionMaxQuery">
            <summary> A query that generates the union of documents produced by its subqueries, and that scores each document with the maximum
            score for that document as produced by any subquery, plus a tie breaking increment for any additional matching subqueries.
            This is useful when searching for a word in multiple fields with different boost factors (so that the fields cannot be
            combined equivalently into a single search field).  We want the primary score to be the one associated with the highest boost,
            not the sum of the field scores (as BooleanQuery would give).
            If the query is "albino elephant" this ensures that "albino" matching one field and "elephant" matching
            another gets a higher score than "albino" matching both fields.
            To get this result, use both BooleanQuery and DisjunctionMaxQuery:  for each term a DisjunctionMaxQuery searches for it in
            each field, while the set of these DisjunctionMaxQuery's is combined into a BooleanQuery.
            The tie breaker capability allows results that include the same term in multiple fields to be judged better than results that
            include this term in only the best of those multiple fields, without confusing this with the better case of two different terms
            in the multiple fields.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.#ctor(System.Single)">
            <summary>Creates a new empty DisjunctionMaxQuery.  Use add() to add the subqueries.</summary>
            <param name="tieBreakerMultiplier">the score of each non-maximum disjunct for a document is multiplied by this weight
            and added into the final score.  If non-zero, the value should be small, on the order of 0.1, which says that
            10 occurrences of word in a lower-scored field that is also in a higher scored field is just as good as a unique
            word in the lower scored field (i.e., one that is not in any higher scored field.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.#ctor(System.Collections.ICollection,System.Single)">
            <summary> Creates a new DisjunctionMaxQuery</summary>
            <param name="disjuncts">a Collection&lt;Query&gt; of all the disjuncts to add
            </param>
            <param name="tieBreakerMultiplier">  the weight to give to each matching non-maximum disjunct
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Add(Lucene.Net.Search.Query)">
            <summary>Add a subquery to this disjunction</summary>
            <param name="query">the disjunct added
            </param>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Add(System.Collections.ICollection)">
            <summary>Add a collection of disjuncts to this disjunction
            via Iterable
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Iterator">
            <summary>An Iterator&lt;Query&gt; over the disjuncts </summary>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Rewrite(Lucene.Net.Index.IndexReader)">
            <summary>Optimize our representation and our subqueries representations</summary>
            <param name="reader">the IndexReader we query
            </param>
            <returns> an optimized copy of us (which may not be a copy if there is nothing to optimize) 
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Clone">
            <summary>Create a shallow copy of us -- used in rewriting if necessary</summary>
            <returns> a copy of us (but reuse, don't copy, our subqueries) 
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.ToString(System.String)">
            <summary>Prettyprint us.</summary>
            <param name="field">the field to which we are applied
            </param>
            <returns> a string that shows what we do, of the form "(disjunct1 | disjunct2 | ... | disjunctn)^boost"
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.Equals(System.Object)">
            <summary>Return true iff we represent the same query as o</summary>
            <param name="o">another object
            </param>
            <returns> true iff o is a DisjunctionMaxQuery with the same boost and the same subqueries, in the same order, as us
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.DisjunctionMaxQuery.GetHashCode">
            <summary>Compute a hash code for hashing us</summary>
            <returns> the hash code
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.DisjunctionMaxQuery.DisjunctionMaxWeight">
            <summary> Expert: the Weight for DisjunctionMaxQuery, used to
            normalize, score and explain these queries.
            
            <p/>NOTE: this API and implementation is subject to
            change suddenly in the next release.<p/>
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionMaxQuery.DisjunctionMaxWeight.similarity">
            <summary>The Similarity implementation. </summary>
        </member>
        <member name="F:Lucene.Net.Search.DisjunctionMaxQuery.DisjunctionMaxWeight.weights">
            <summary>The Weights for our subqueries, in 1-1 correspondence with disjuncts </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.MultiFieldQueryParser">
            <summary> A QueryParser which constructs queries to search multiple fields.
            
            </summary>
            <version>  $Revision: 829134 $
            </version>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.#ctor(System.String[],Lucene.Net.Analysis.Analyzer,System.Collections.IDictionary)">
            <summary> Creates a MultiFieldQueryParser. Allows passing of a map with term to
            Boost, and the boost to apply to each term.
            
            <p/>
            It will, when parse(String query) is called, construct a query like this
            (assuming the query consists of two terms and you specify the two fields
            <code>title</code> and <code>body</code>):
            <p/>
            
            <code>
            (title:term1 body:term1) (title:term2 body:term2)
            </code>
            
            <p/>
            When setDefaultOperator(AND_OPERATOR) is set, the result will be:
            <p/>
            
            <code>
            +(title:term1 body:term1) +(title:term2 body:term2)
            </code>
            
            <p/>
            When you pass a boost (title=>5 body=>10) you can get
            <p/>
            
            <code>
            +(title:term1^5.0 body:term1^10.0) +(title:term2^5.0 body:term2^10.0)
            </code>
            
            <p/>
            In other words, all the query's terms must appear, but it doesn't matter
            in what fields they appear.
            <p/>
            
            </summary>
            <deprecated> Please use
            {@link #MultiFieldQueryParser(Version, String[], Analyzer, Map)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.#ctor(Lucene.Net.Util.Version,System.String[],Lucene.Net.Analysis.Analyzer,System.Collections.IDictionary)">
            <summary> Creates a MultiFieldQueryParser. Allows passing of a map with term to
            Boost, and the boost to apply to each term.
            
            <p/>
            It will, when parse(String query) is called, construct a query like this
            (assuming the query consists of two terms and you specify the two fields
            <code>title</code> and <code>body</code>):
            <p/>
            
            <code>
            (title:term1 body:term1) (title:term2 body:term2)
            </code>
            
            <p/>
            When setDefaultOperator(AND_OPERATOR) is set, the result will be:
            <p/>
            
            <code>
            +(title:term1 body:term1) +(title:term2 body:term2)
            </code>
            
            <p/>
            When you pass a boost (title=>5 body=>10) you can get
            <p/>
            
            <code>
            +(title:term1^5.0 body:term1^10.0) +(title:term2^5.0 body:term2^10.0)
            </code>
            
            <p/>
            In other words, all the query's terms must appear, but it doesn't matter
            in what fields they appear.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.#ctor(System.String[],Lucene.Net.Analysis.Analyzer)">
            <summary> Creates a MultiFieldQueryParser.
            
            <p/>
            It will, when parse(String query) is called, construct a query like this
            (assuming the query consists of two terms and you specify the two fields
            <code>title</code> and <code>body</code>):
            <p/>
            
            <code>
            (title:term1 body:term1) (title:term2 body:term2)
            </code>
            
            <p/>
            When setDefaultOperator(AND_OPERATOR) is set, the result will be:
            <p/>
            
            <code>
            +(title:term1 body:term1) +(title:term2 body:term2)
            </code>
            
            <p/>
            In other words, all the query's terms must appear, but it doesn't matter
            in what fields they appear.
            <p/>
            
            </summary>
            <deprecated> Please use
            {@link #MultiFieldQueryParser(Version, String[], Analyzer)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.#ctor(Lucene.Net.Util.Version,System.String[],Lucene.Net.Analysis.Analyzer)">
            <summary> Creates a MultiFieldQueryParser.
            
            <p/>
            It will, when parse(String query) is called, construct a query like this
            (assuming the query consists of two terms and you specify the two fields
            <code>title</code> and <code>body</code>):
            <p/>
            
            <code>
            (title:term1 body:term1) (title:term2 body:term2)
            </code>
            
            <p/>
            When setDefaultOperator(AND_OPERATOR) is set, the result will be:
            <p/>
            
            <code>
            +(title:term1 body:term1) +(title:term2 body:term2)
            </code>
            
            <p/>
            In other words, all the query's terms must appear, but it doesn't matter
            in what fields they appear.
            <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(System.String[],System.String[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query which searches on the fields specified.
            <p/>
            If x fields are specified, this effectively constructs:
            
            <pre>
            &lt;code&gt;
            (field1:query1) (field2:query2) (field3:query3)...(fieldx:queryx)
            &lt;/code&gt;
            </pre>
            
            </summary>
            <param name="queries">Queries strings to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException </throws>
            <summary>             if query parsing fails
            </summary>
            <throws>  IllegalArgumentException </throws>
            <summary>             if the length of the queries array differs from the length of
            the fields array
            </summary>
            <deprecated> Use {@link #Parse(Version,String[],String[],Analyzer)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(Lucene.Net.Util.Version,System.String[],System.String[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query which searches on the fields specified.
            <p/>
            If x fields are specified, this effectively constructs:
            
            <pre>
            &lt;code&gt;
            (field1:query1) (field2:query2) (field3:query3)...(fieldx:queryx)
            &lt;/code&gt;
            </pre>
            
            </summary>
            <param name="matchVersion">Lucene version to match; this is passed through to
            QueryParser.
            </param>
            <param name="queries">Queries strings to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException </throws>
            <summary>             if query parsing fails
            </summary>
            <throws>  IllegalArgumentException </throws>
            <summary>             if the length of the queries array differs from the length of
            the fields array
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(System.String,System.String[],Lucene.Net.Search.BooleanClause.Occur[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query, searching on the fields specified.
            Use this if you need to specify certain fields as required,
            and others as prohibited.
            <p/><pre>
            Usage:
            <code>
            String[] fields = {"filename", "contents", "description"};
            BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
            BooleanClause.Occur.MUST,
            BooleanClause.Occur.MUST_NOT};
            MultiFieldQueryParser.parse("query", fields, flags, analyzer);
            </code>
            </pre>
            <p/>
            The code above would construct a query:
            <pre>
            <code>
            (filename:query) +(contents:query) -(description:query)
            </code>
            </pre>
            
            </summary>
            <param name="query">Query string to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="flags">Flags describing the fields
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException if query parsing fails </throws>
            <throws>  IllegalArgumentException if the length of the fields array differs </throws>
            <summary>  from the length of the flags array
            </summary>
            <deprecated> Use
            {@link #Parse(Version, String, String[], BooleanClause.Occur[], Analyzer)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(Lucene.Net.Util.Version,System.String,System.String[],Lucene.Net.Search.BooleanClause.Occur[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query, searching on the fields specified. Use this if you need
            to specify certain fields as required, and others as prohibited.
            <p/>
            
            <pre>
            Usage:
            &lt;code&gt;
            String[] fields = {&quot;filename&quot;, &quot;contents&quot;, &quot;description&quot;};
            BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
            BooleanClause.Occur.MUST,
            BooleanClause.Occur.MUST_NOT};
            MultiFieldQueryParser.parse(&quot;query&quot;, fields, flags, analyzer);
            &lt;/code&gt;
            </pre>
            <p/>
            The code above would construct a query:
            
            <pre>
            &lt;code&gt;
            (filename:query) +(contents:query) -(description:query)
            &lt;/code&gt;
            </pre>
            
            </summary>
            <param name="matchVersion">Lucene version to match; this is passed through to
            QueryParser.
            </param>
            <param name="query">Query string to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="flags">Flags describing the fields
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException </throws>
            <summary>             if query parsing fails
            </summary>
            <throws>  IllegalArgumentException </throws>
            <summary>             if the length of the fields array differs from the length of
            the flags array
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(System.String[],System.String[],Lucene.Net.Search.BooleanClause.Occur[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query, searching on the fields specified.
            Use this if you need to specify certain fields as required,
            and others as prohibited.
            <p/><pre>
            Usage:
            <code>
            String[] query = {"query1", "query2", "query3"};
            String[] fields = {"filename", "contents", "description"};
            BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
            BooleanClause.Occur.MUST,
            BooleanClause.Occur.MUST_NOT};
            MultiFieldQueryParser.parse(query, fields, flags, analyzer);
            </code>
            </pre>
            <p/>
            The code above would construct a query:
            <pre>
            <code>
            (filename:query1) +(contents:query2) -(description:query3)
            </code>
            </pre>
            
            </summary>
            <param name="queries">Queries string to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="flags">Flags describing the fields
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException if query parsing fails </throws>
            <throws>  IllegalArgumentException if the length of the queries, fields, </throws>
            <summary>  and flags array differ
            </summary>
            <deprecated> Used
            {@link #Parse(Version, String[], String[], BooleanClause.Occur[], Analyzer)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.QueryParsers.MultiFieldQueryParser.Parse(Lucene.Net.Util.Version,System.String[],System.String[],Lucene.Net.Search.BooleanClause.Occur[],Lucene.Net.Analysis.Analyzer)">
            <summary> Parses a query, searching on the fields specified. Use this if you need
            to specify certain fields as required, and others as prohibited.
            <p/>
            
            <pre>
            Usage:
            &lt;code&gt;
            String[] query = {&quot;query1&quot;, &quot;query2&quot;, &quot;query3&quot;};
            String[] fields = {&quot;filename&quot;, &quot;contents&quot;, &quot;description&quot;};
            BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
            BooleanClause.Occur.MUST,
            BooleanClause.Occur.MUST_NOT};
            MultiFieldQueryParser.parse(query, fields, flags, analyzer);
            &lt;/code&gt;
            </pre>
            <p/>
            The code above would construct a query:
            
            <pre>
            &lt;code&gt;
            (filename:query1) +(contents:query2) -(description:query3)
            &lt;/code&gt;
            </pre>
            
            </summary>
            <param name="matchVersion">Lucene version to match; this is passed through to
            QueryParser.
            </param>
            <param name="queries">Queries string to parse
            </param>
            <param name="fields">Fields to search on
            </param>
            <param name="flags">Flags describing the fields
            </param>
            <param name="analyzer">Analyzer to use
            </param>
            <throws>  ParseException </throws>
            <summary>             if query parsing fails
            </summary>
            <throws>  IllegalArgumentException </throws>
            <summary>             if the length of the queries, fields, and flags array differ
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermVectorEntry">
            <summary> Convenience class for holding TermVector information.</summary>
        </member>
        <member name="T:Lucene.Net.Index.NormsWriter">
            <summary>Writes norms.  Each thread X field accumulates the norms
            for the doc/fields it saw, then the flush method below
            merges all of these together into a single _X.nrm file.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.NormsWriter.Flush(System.Collections.IDictionary,Lucene.Net.Index.SegmentWriteState)">
            <summary>Produce _X.nrm if any document had a field with norms
            not disabled 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsTermsWriter.AddTerm(System.Char[],System.Int32)">
            <summary>Adds a new term in this field </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsTermsWriter.Finish">
            <summary>Called when we are done adding terms to this field </summary>
        </member>
        <member name="T:Lucene.Net.Documents.SetBasedFieldSelector">
            <summary> Declare what fields to load normally and what fields to load lazily
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.SetBasedFieldSelector.#ctor(System.Collections.Hashtable,System.Collections.Hashtable)">
            <summary> Pass in the Set of {@link Field} names to load and the Set of {@link Field} names to load lazily.  If both are null, the
            Document will not have any {@link Field} on it.  
            </summary>
            <param name="fieldsToLoad">A Set of {@link String} field names to load.  May be empty, but not null
            </param>
            <param name="lazyFieldsToLoad">A Set of {@link String} field names to load lazily.  May be empty, but not null  
            </param>
        </member>
        <member name="M:Lucene.Net.Documents.SetBasedFieldSelector.Accept(System.String)">
            <summary> Indicate whether to load the field with the given name or not. If the {@link Field#Name()} is not in either of the 
            initializing Sets, then {@link Lucene.Net.Documents.FieldSelectorResult#NO_LOAD} is returned.  If a Field name
            is in both <code>fieldsToLoad</code> and <code>lazyFieldsToLoad</code>, lazy has precedence.
            
            </summary>
            <param name="fieldName">The {@link Field} name to check
            </param>
            <returns> The {@link FieldSelectorResult}
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.WhitespaceTokenizer">
            <summary>A WhitespaceTokenizer is a tokenizer that divides text at whitespace.
            Adjacent sequences of non-Whitespace characters form tokens. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.WhitespaceTokenizer.#ctor(System.IO.TextReader)">
            <summary>Construct a new WhitespaceTokenizer. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.WhitespaceTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader)">
            <summary>Construct a new WhitespaceTokenizer using a given {@link AttributeSource}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.WhitespaceTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader)">
            <summary>Construct a new WhitespaceTokenizer using a given {@link Lucene.Net.Util.AttributeSource.AttributeFactory}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.WhitespaceTokenizer.IsTokenChar(System.Char)">
            <summary>Collects only characters which do not satisfy
            {@link Character#isWhitespace(char)}.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TeeSinkTokenFilter">
            <summary> This TokenFilter provides the ability to set aside attribute states
            that have already been analyzed.  This is useful in situations where multiple fields share
            many common analysis steps and then go their separate ways.
            <p/>
            It is also useful for doing things like entity extraction or proper noun analysis as
            part of the analysis workflow and saving off those tokens for use in another field.
            
            <pre>
            TeeSinkTokenFilter source1 = new TeeSinkTokenFilter(new WhitespaceTokenizer(reader1));
            TeeSinkTokenFilter.SinkTokenStream sink1 = source1.newSinkTokenStream();
            TeeSinkTokenFilter.SinkTokenStream sink2 = source1.newSinkTokenStream();
            TeeSinkTokenFilter source2 = new TeeSinkTokenFilter(new WhitespaceTokenizer(reader2));
            source2.addSinkTokenStream(sink1);
            source2.addSinkTokenStream(sink2);
            TokenStream final1 = new LowerCaseFilter(source1);
            TokenStream final2 = source2;
            TokenStream final3 = new EntityDetect(sink1);
            TokenStream final4 = new URLDetect(sink2);
            d.add(new Field("f1", final1));
            d.add(new Field("f2", final2));
            d.add(new Field("f3", final3));
            d.add(new Field("f4", final4));
            </pre>
            In this example, <code>sink1</code> and <code>sink2</code> will both get tokens from both
            <code>reader1</code> and <code>reader2</code> after whitespace tokenizer
            and now we can further wrap any of these in extra analysis, and more "sources" can be inserted if desired.
            It is important, that tees are consumed before sinks (in the above example, the field names must be
            less the sink's field names). If you are not sure, which stream is consumed first, you can simply
            add another sink and then pass all tokens to the sinks at once using {@link #consumeAllTokens}.
            This TokenFilter is exhausted after this. In the above example, change
            the example above to:
            <pre>
            ...
            TokenStream final1 = new LowerCaseFilter(source1.newSinkTokenStream());
            TokenStream final2 = source2.newSinkTokenStream();
            sink1.consumeAllTokens();
            sink2.consumeAllTokens();
            ...
            </pre>
            In this case, the fields can be added in any order, because the sources are not used anymore and all sinks are ready.
            <p/>Note, the EntityDetect and URLDetect TokenStreams are for the example and do not currently exist in Lucene.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.#ctor(Lucene.Net.Analysis.TokenStream)">
            <summary> Instantiates a new TeeSinkTokenFilter.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.NewSinkTokenStream">
            <summary> Returns a new {@link SinkTokenStream} that receives all tokens consumed by this stream.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.NewSinkTokenStream(Lucene.Net.Analysis.TeeSinkTokenFilter.SinkFilter)">
            <summary> Returns a new {@link SinkTokenStream} that receives all tokens consumed by this stream
            that pass the supplied filter.
            </summary>
            <seealso cref="T:Lucene.Net.Analysis.TeeSinkTokenFilter.SinkFilter">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.AddSinkTokenStream(Lucene.Net.Analysis.TeeSinkTokenFilter.SinkTokenStream)">
            <summary> Adds a {@link SinkTokenStream} created by another <code>TeeSinkTokenFilter</code>
            to this one. The supplied stream will also receive all consumed tokens.
            This method can be used to pass tokens from two different tees to one sink.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.ConsumeAllTokens">
            <summary> <code>TeeSinkTokenFilter</code> passes all tokens to the added sinks
            when itself is consumed. To be sure, that all tokens from the input
            stream are passed to the sinks, you can call this methods.
            This instance is exhausted after this, but all sinks are instant available.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TeeSinkTokenFilter.SinkFilter">
            <summary> A filter that decides which {@link AttributeSource} states to store in the sink.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.SinkFilter.Accept(Lucene.Net.Util.AttributeSource)">
            <summary> Returns true, iff the current state of the passed-in {@link AttributeSource} shall be stored
            in the sink. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.TeeSinkTokenFilter.SinkFilter.Reset">
            <summary> Called by {@link SinkTokenStream#Reset()}. This method does nothing by default
            and can optionally be overridden.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Standard.StandardTokenizer">
            <summary>A grammar-based tokenizer constructed with JFlex
            
            <p/> This should be a good tokenizer for most European-language documents:
            
            <ul>
            <li>Splits words at punctuation characters, removing punctuation. However, a 
            dot that's not followed by whitespace is considered part of a token.</li>
            <li>Splits words at hyphens, unless there's a number in the token, in which case
            the whole token is interpreted as a product number and is not split.</li>
            <li>Recognizes email addresses and internet hostnames as one token.</li>
            </ul>
            
            <p/>Many applications have specific tokenizer needs.  If this tokenizer does
            not suit your application, please consider copying this source code
            directory to your project and maintaining your own grammar-based tokenizer.
            
            <a name="version"/>
            <p/>
            You must specify the required {@link Version} compatibility when creating
            StandardAnalyzer:
            <ul>
            <li>As of 2.4, Tokens incorrectly identified as acronyms are corrected (see
            <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a></li>
            </ul>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizer.ACRONYM_DEP">
            <deprecated> this solves a bug where HOSTs that end with '.' are identified
            as ACRONYMs. It is deprecated and will be removed in the next
            release.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizer.scanner">
            <summary>A private instance of the JFlex-constructed scanner </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizer.TOKEN_TYPES">
            <summary>String token types that correspond to token type int constants </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizer.tokenImage">
            <deprecated> Please use {@link #TOKEN_TYPES} instead 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.Standard.StandardTokenizer.replaceInvalidAcronym">
            <summary> Specifies whether deprecated acronyms should be replaced with HOST type.
            This is false by default to support backward compatibility.
            <p/>
            See http://issues.apache.org/jira/browse/LUCENE-1068
            
            </summary>
            <deprecated> this should be removed in the next release (3.0).
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.SetMaxTokenLength(System.Int32)">
            <summary>Set the max allowed token length.  Any token longer
            than this is skipped. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.GetMaxTokenLength">
            <seealso cref="!:setMaxTokenLength">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(System.IO.TextReader)">
            <summary> Creates a new instance of the {@link StandardTokenizer}. Attaches the
            <code>input</code> to a newly created JFlex scanner.
            </summary>
            <deprecated> Use {@link #StandardTokenizer(Version, Reader)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(System.IO.TextReader,System.Boolean)">
            <summary> Creates a new instance of the {@link Lucene.Net.Analysis.Standard.StandardTokenizer}.  Attaches
            the <code>input</code> to the newly created JFlex scanner.
            
            </summary>
            <param name="input">The input reader
            </param>
            <param name="replaceInvalidAcronym">Set to true to replace mischaracterized acronyms with HOST.
            
            See http://issues.apache.org/jira/browse/LUCENE-1068
            </param>
            <deprecated> Use {@link #StandardTokenizer(Version, Reader)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(Lucene.Net.Util.Version,System.IO.TextReader)">
            <summary> Creates a new instance of the
            {@link org.apache.lucene.analysis.standard.StandardTokenizer}. Attaches
            the <code>input</code> to the newly created JFlex scanner.
            
            </summary>
            <param name="input">The input reader
            
            See http://issues.apache.org/jira/browse/LUCENE-1068
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader,System.Boolean)">
            <summary> Creates a new StandardTokenizer with a given {@link AttributeSource}. </summary>
            <deprecated> Use
            {@link #StandardTokenizer(Version, AttributeSource, Reader)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(Lucene.Net.Util.Version,Lucene.Net.Util.AttributeSource,System.IO.TextReader)">
            <summary> Creates a new StandardTokenizer with a given {@link AttributeSource}.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader,System.Boolean)">
            <summary> Creates a new StandardTokenizer with a given {@link Lucene.Net.Util.AttributeSource.AttributeFactory} </summary>
            <deprecated> Use
            {@link #StandardTokenizer(Version, org.apache.lucene.util.AttributeSource.AttributeFactory, Reader)}
            instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.#ctor(Lucene.Net.Util.Version,Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader)">
            <summary> Creates a new StandardTokenizer with a given
            {@link org.apache.lucene.util.AttributeSource.AttributeFactory}
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.Next(Lucene.Net.Analysis.Token)">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.Next">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.IsReplaceInvalidAcronym">
            <summary> Prior to https://issues.apache.org/jira/browse/LUCENE-1068, StandardTokenizer mischaracterized as acronyms tokens like www.abc.com
            when they should have been labeled as hosts instead.
            </summary>
            <returns> true if StandardTokenizer now returns these tokens as Hosts, otherwise false
            
            </returns>
            <deprecated> Remove in 3.X and make true the only valid value
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardTokenizer.SetReplaceInvalidAcronym(System.Boolean)">
            <summary> </summary>
            <param name="replaceInvalidAcronym">Set to true to replace mischaracterized acronyms as HOST.
            </param>
            <deprecated> Remove in 3.X and make true the only valid value
            
            See https://issues.apache.org/jira/browse/LUCENE-1068
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Util.UnicodeUtil">
            <summary> Class to encode java's UTF16 char[] into UTF8 byte[]
            without always allocating a new byte[] as
            String.getBytes("UTF-8") does.
            
            <p/><b>WARNING</b>: This API is a new and experimental and
            may suddenly change. <p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.UnicodeUtil.UTF16toUTF8(System.Char[],System.Int32,Lucene.Net.Util.UnicodeUtil.UTF8Result)">
            <summary>Encode characters from a char[] source, starting at
            offset and stopping when the character 0xffff is seen.
            Returns the number of bytes written to bytesOut. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.UnicodeUtil.UTF16toUTF8(System.Char[],System.Int32,System.Int32,Lucene.Net.Util.UnicodeUtil.UTF8Result)">
            <summary>Encode characters from a char[] source, starting at
            offset for length chars.  Returns the number of bytes
            written to bytesOut. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.UnicodeUtil.UTF16toUTF8(System.String,System.Int32,System.Int32,Lucene.Net.Util.UnicodeUtil.UTF8Result)">
            <summary>Encode characters from this String, starting at offset
            for length characters.  Returns the number of bytes
            written to bytesOut. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.UnicodeUtil.UTF8toUTF16(System.Byte[],System.Int32,System.Int32,Lucene.Net.Util.UnicodeUtil.UTF16Result)">
            <summary>Convert UTF8 bytes into UTF16 characters.  If offset
            is non-zero, conversion starts at that starting point
            in utf8, re-using the results from the previous call
            up until offset. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.SorterTemplate">
            <summary> Borrowed from Cglib. Allows custom swap so that two arrays can be sorted
            at the same time.
            </summary>
        </member>
        <member name="T:Lucene.Net.Util.MapOfSets`2">
            <summary> Helper class for keeping Listss of Objects associated with keys. <b>WARNING: THIS CLASS IS NOT THREAD SAFE</b></summary>
        </member>
        <member name="M:Lucene.Net.Util.MapOfSets`2.#ctor(System.Collections.Generic.IDictionary{`0,System.Collections.Generic.Dictionary{`1,`1}})">
            <param name="m">the backing store for this object
            </param>
        </member>
        <member name="M:Lucene.Net.Util.MapOfSets`2.GetMap">
            <returns> direct access to the map backing this object.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.MapOfSets`2.Put(`0,`1)">
            <summary> Adds val to the Set associated with key in the Map.  If key is not 
            already in the map, a new Set will first be created.
            </summary>
            <returns> the size of the Set associated with key once val is added to it.
            </returns>
        </member>
        <member name="M:Lucene.Net.Util.MapOfSets`2.PutAll(`0,System.Collections.Generic.Dictionary{`1,`1})">
            <summary> Adds multiple vals to the Set associated with key in the Map.  
            If key is not 
            already in the map, a new Set will first be created.
            </summary>
            <returns> the size of the Set associated with key once val is added to it.
            </returns>
        </member>
        <member name="T:Lucene.Net.Util.BitUtil">
            <summary>A variety of high efficiencly bit twiddling routines.
            
            </summary>
            <version>  $Id$
            </version>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Pop(System.Int64)">
            <summary>Returns the number of bits set in the long </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Pop_array(System.Int64[],System.Int32,System.Int32)">
            <summary> Returns the number of set bits in an array of longs. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Pop_intersect(System.Int64[],System.Int64[],System.Int32,System.Int32)">
            <summary>Returns the popcount or cardinality of the two sets after an intersection.
            Neither array is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Pop_union(System.Int64[],System.Int64[],System.Int32,System.Int32)">
            <summary>Returns the popcount or cardinality of the union of two sets.
            Neither array is modified.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Pop_andnot(System.Int64[],System.Int64[],System.Int32,System.Int32)">
            <summary>Returns the popcount or cardinality of A &amp; ~B
            Neither array is modified.
            </summary>
        </member>
        <member name="F:Lucene.Net.Util.BitUtil.ntzTable">
            <summary>table of number of trailing zeros in a byte </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Ntz(System.Int64)">
            <summary>Returns number of trailing zeros in a 64 bit long value. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Ntz(System.Int32)">
            <summary>Returns number of trailing zeros in a 32 bit int value. </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Ntz2(System.Int64)">
            <summary>returns 0 based index of first set bit
            (only works for x!=0)
            <br/> This is an alternate implementation of ntz()
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.Ntz3(System.Int64)">
            <summary>returns 0 based index of first set bit
            <br/> This is an alternate implementation of ntz()
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.IsPowerOfTwo(System.Int32)">
            <summary>returns true if v is a power of two or zero</summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.IsPowerOfTwo(System.Int64)">
            <summary>returns true if v is a power of two or zero</summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.NextHighestPowerOfTwo(System.Int32)">
            <summary>returns the next highest power of two, or the current value if it's already a power of two or zero</summary>
        </member>
        <member name="M:Lucene.Net.Util.BitUtil.NextHighestPowerOfTwo(System.Int64)">
            <summary>returns the next highest power of two, or the current value if it's already a power of two or zero</summary>
        </member>
        <member name="T:Lucene.Net.Store.RAMDirectory">
            <summary> A memory-resident {@link Directory} implementation.  Locking
            implementation is by default the {@link SingleInstanceLockFactory}
            but can be changed with {@link #setLockFactory}.
            
            </summary>
            <version>  $Id: RAMDirectory.java 781333 2009-06-03 10:38:57Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.#ctor">
            <summary>Constructs an empty {@link Directory}. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.#ctor(Lucene.Net.Store.Directory)">
            <summary> Creates a new <code>RAMDirectory</code> instance from a different
            <code>Directory</code> implementation.  This can be used to load
            a disk-based index into memory.
            <p/>
            This should be used only with indices that can fit into memory.
            <p/>
            Note that the resulting <code>RAMDirectory</code> instance is fully
            independent from the original <code>Directory</code> (it is a
            complete copy).  Any subsequent changes to the
            original <code>Directory</code> will not be visible in the
            <code>RAMDirectory</code> instance.
            
            </summary>
            <param name="dir">a <code>Directory</code> value
            </param>
            <exception cref="!:IOException">if an error occurs
            </exception>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.#ctor(System.IO.FileInfo)">
            <summary> Creates a new <code>RAMDirectory</code> instance from the {@link FSDirectory}.
            
            </summary>
            <param name="dir">a <code>File</code> specifying the index directory
            
            </param>
            <seealso cref="M:Lucene.Net.Store.RAMDirectory.#ctor(Lucene.Net.Store.Directory)">
            </seealso>
            <deprecated> Use {@link #RAMDirectory(Directory)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.#ctor(System.String)">
            <summary> Creates a new <code>RAMDirectory</code> instance from the {@link FSDirectory}.
            
            </summary>
            <param name="dir">a <code>String</code> specifying the full index directory path
            
            </param>
            <seealso cref="M:Lucene.Net.Store.RAMDirectory.#ctor(Lucene.Net.Store.Directory)">
            </seealso>
            <deprecated> Use {@link #RAMDirectory(Directory)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.FileExists(System.String)">
            <summary>Returns true iff the named file exists in this directory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.FileModified(System.String)">
            <summary>Returns the time the named file was last modified.</summary>
            <throws>  IOException if the file does not exist </throws>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.TouchFile(System.String)">
            <summary>Set the modified time of an existing file to now.</summary>
            <throws>  IOException if the file does not exist </throws>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.FileLength(System.String)">
            <summary>Returns the length in bytes of a file in the directory.</summary>
            <throws>  IOException if the file does not exist </throws>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.SizeInBytes">
            <summary>Return total size in bytes of all files in this
            directory.  This is currently quantized to
            RAMOutputStream.BUFFER_SIZE. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.DeleteFile(System.String)">
            <summary>Removes an existing file in the directory.</summary>
            <throws>  IOException if the file does not exist </throws>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.RenameFile(System.String,System.String)">
            <summary>Renames an existing file in the directory.</summary>
            <throws>  FileNotFoundException if from does not exist </throws>
            <deprecated>
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.CreateOutput(System.String)">
            <summary>Creates a new, empty file in the directory with the given name. Returns a stream writing this file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.OpenInput(System.String)">
            <summary>Returns a stream reading an existing file. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.Close">
            <summary>Closes the store to future operations, releasing associated memory. </summary>
        </member>
        <member name="M:Lucene.Net.Store.RAMDirectory.Dispose">
            <summary>
            .NET
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.NativeFSLockFactory">
            <summary> <p/>Implements {@link LockFactory} using native OS file
            locks.  Note that because this LockFactory relies on
            java.nio.* APIs for locking, any problems with those APIs
            will cause locking to fail.  Specifically, on certain NFS
            environments the java.nio.* locks will fail (the lock can
            incorrectly be double acquired) whereas {@link
            SimpleFSLockFactory} worked perfectly in those same
            environments.  For NFS based access to an index, it's
            recommended that you try {@link SimpleFSLockFactory}
            first and work around the one limitation that a lock file
            could be left when the JVM exits abnormally.<p/>
            
            <p/>The primary benefit of {@link NativeFSLockFactory} is
            that lock files will be properly removed (by the OS) if
            the JVM has an abnormal exit.<p/>
            
            <p/>Note that, unlike {@link SimpleFSLockFactory}, the existence of
            leftover lock files in the filesystem on exiting the JVM
            is fine because the OS will free the locks held against
            these files even though the files still remain.<p/>
            
            <p/>If you suspect that this or any other LockFactory is
            not working properly in your environment, you can easily
            test it by using {@link VerifyingLockFactory}, {@link
            LockVerifyServer} and {@link LockStressTest}.<p/>
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockFactory">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.NativeFSLockFactory.#ctor">
            <summary> Create a NativeFSLockFactory instance, with null (unset)
            lock directory. When you pass this factory to a {@link FSDirectory}
            subclass, the lock directory is automatically set to the
            directory itsself. Be sure to create one instance for each directory
            your create!
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.NativeFSLockFactory.#ctor(System.String)">
            <summary> Create a NativeFSLockFactory instance, storing lock
            files into the specified lockDirName:
            
            </summary>
            <param name="lockDirName">where lock files are created.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.NativeFSLockFactory.#ctor(System.IO.FileInfo)">
            <summary> Create a NativeFSLockFactory instance, storing lock
            files into the specified lockDir:
            
            </summary>
            <param name="lockDir">where lock files are created.
            </param>
        </member>
        <member name="M:Lucene.Net.Store.NativeFSLockFactory.#ctor(System.IO.DirectoryInfo)">
            <summary> Create a NativeFSLockFactory instance, storing lock
            files into the specified lockDir:
            
            </summary>
            <param name="lockDir">where lock files are created.
            </param>
        </member>
        <member name="T:Lucene.Net.Search.TopFieldDocs">
            <summary>
            Represents hits returned by {@link Searcher#search(Query,Filter,int,Sort)}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.TopFieldDocs.fields">
            <summary>The fields which were used to sort results by. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TopFieldDocs.#ctor(System.Int32,Lucene.Net.Search.ScoreDoc[],Lucene.Net.Search.SortField[],System.Single)">
            <summary>Creates one of these objects.</summary>
            <param name="totalHits"> Total number of hits for the query.
            </param>
            <param name="scoreDocs"> The top hits for the query.
            </param>
            <param name="fields">    The sort criteria used to find the top hits.
            </param>
            <param name="maxScore">  The maximum score encountered.
            </param>
        </member>
        <member name="T:Lucene.Net.Search.TimeLimitedCollector">
            <summary> <p/>
            The TimeLimitedCollector is used to timeout search requests that take longer
            than the maximum allowed search time limit. After this time is exceeded, the
            search thread is stopped by throwing a TimeExceeded Exception.
            <p/>
            
            </summary>
            <deprecated> Use {@link TimeLimitingCollector} instead, which extends the new
            {@link Collector}. This class will be removed in 3.0.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.TimeLimitedCollector.DEFAULT_RESOLUTION">
            <summary> Default timer resolution.</summary>
            <seealso cref="!:SetResolution(long)">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.TimeLimitedCollector.DEFAULT_GREEDY">
            <summary> Default for {@link #IsGreedy()}.</summary>
            <seealso cref="M:Lucene.Net.Search.TimeLimitedCollector.IsGreedy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.#ctor(Lucene.Net.Search.HitCollector,System.Int64)">
            <summary> Create a TimeLimitedCollector wrapper over another HitCollector with a specified timeout.</summary>
            <param name="hc">the wrapped HitCollector
            </param>
            <param name="timeAllowed">max time allowed for collecting hits after which {@link TimeExceededException} is thrown
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.Collect(System.Int32,System.Single)">
            <summary> Calls collect() on the decorated HitCollector.
            
            </summary>
            <throws>  TimeExceededException if the time allowed has been exceeded. </throws>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.GetResolution">
            <summary> Return the timer resolution.</summary>
            <seealso cref="!:SetResolution(long)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.SetResolution(System.UInt32)">
            <summary> Set the timer resolution.
            The default timer resolution is 20 milliseconds. 
            This means that a search required to take no longer than 
            800 milliseconds may be stopped after 780 to 820 milliseconds.
            <br/>Note that: 
            <ul>
            <li>Finer (smaller) resolution is more accurate but less efficient.</li>
            <li>Setting resolution to less than 5 milliseconds will be silently modified to 5 milliseconds.</li>
            <li>Setting resolution smaller than current resolution might take effect only after current 
            resolution. (Assume current resolution of 20 milliseconds is modified to 5 milliseconds, 
            then it can take up to 20 milliseconds for the change to have effect.</li>
            </ul>      
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.IsGreedy">
            <summary> Checks if this time limited collector is greedy in collecting the last hit.
            A non greedy collector, upon a timeout, would throw a {@link TimeExceededException} 
            without allowing the wrapped collector to collect current doc. A greedy one would 
            first allow the wrapped hit collector to collect current doc and only then 
            throw a {@link TimeExceededException}.
            </summary>
            <seealso cref="!:SetGreedy(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.SetGreedy(System.Boolean)">
            <summary> Sets whether this time limited collector is greedy.</summary>
            <param name="greedy">true to make this time limited greedy
            </param>
            <seealso cref="M:Lucene.Net.Search.TimeLimitedCollector.IsGreedy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.TimerThread.#ctor">
            <summary> TimerThread provides a pseudo-clock service to all searching
            threads, so that they can count elapsed time with less overhead
            than repeatedly calling System.currentTimeMillis.  A single
            thread should be created to be used for all searches.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.TimerThread.GetMilliseconds">
            <summary> Get the timer value in milliseconds.</summary>
        </member>
        <member name="T:Lucene.Net.Search.TimeLimitedCollector.TimeExceededException">
            <summary> Thrown when elapsed search time exceeds allowed search time. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.TimeExceededException.GetTimeAllowed">
            <summary> Returns allowed time (milliseconds).</summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.TimeExceededException.GetTimeElapsed">
            <summary> Returns elapsed time (milliseconds).</summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitedCollector.TimeExceededException.GetLastDocCollected">
            <summary> Returns last doc that was collected when the search time exceeded.  </summary>
        </member>
        <member name="T:Lucene.Net.Search.SpanQueryFilter">
            <summary> Constrains search results to only match those which also match a provided
            query. Also provides position information about where each document matches
            at the cost of extra space compared with the QueryWrapperFilter.
            There is an added cost to this above what is stored in a {@link QueryWrapperFilter}.  Namely,
            the position information for each matching document is stored.
            <p/>
            This filter does not cache.  See the {@link Lucene.Net.Search.CachingSpanFilter} for a wrapper that
            caches.
            
            
            </summary>
            <version>  $Id:$
            </version>
        </member>
        <member name="M:Lucene.Net.Search.SpanQueryFilter.#ctor(Lucene.Net.Search.Spans.SpanQuery)">
            <summary>Constructs a filter which only matches documents matching
            <code>query</code>.
            </summary>
            <param name="query">The {@link Lucene.Net.Search.Spans.SpanQuery} to use as the basis for the Filter.
            </param>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.PayloadNearQuery">
            <summary> This class is very similar to
            {@link Lucene.Net.Search.Spans.SpanNearQuery} except that it factors
            in the value of the payloads located at each of the positions where the
            {@link Lucene.Net.Search.Spans.TermSpans} occurs.
            <p/>
            In order to take advantage of this, you must override
            {@link Lucene.Net.Search.Similarity#ScorePayload(String, byte[],int,int)}
            which returns 1 by default.
            <p/>
            Payload scores are aggregated using a pluggable {@link PayloadFunction}.
            
            </summary>
            <seealso cref="M:Lucene.Net.Search.Similarity.ScorePayload(System.String,System.Byte[],System.Int32,System.Int32)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.Payloads.PayloadNearQuery.PayloadNearSpanScorer.ProcessPayloads(System.Collections.Generic.ICollection{System.Byte[]},System.Int32,System.Int32)">
            <summary> By default, uses the {@link PayloadFunction} to score the payloads, but
            can be overridden to do other things.
            
            </summary>
            <param name="payLoads">The payloads
            </param>
            <param name="start">The start position of the span being scored
            </param>
            <param name="end">The end position of the span being scored
            
            </param>
            <seealso cref="N:Lucene.Net.Search.Spans">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Search.NumericRangeFilter">
            <summary> A {@link Filter} that only accepts numeric values within
            a specified range. To use this, you must first index the
            numeric values using {@link NumericField} (expert: {@link
            NumericTokenStream}).
            
            <p/>You create a new NumericRangeFilter with the static
            factory methods, eg:
            
            <pre>
            Filter f = NumericRangeFilter.newFloatRange("weight",
            new Float(0.3f), new Float(0.10f),
            true, true);
            </pre>
            
            accepts all documents whose float valued "weight" field
            ranges from 0.3 to 0.10, inclusive.
            See {@link NumericRangeQuery} for details on how Lucene
            indexes and searches numeric valued fields.
            
            <p/><font color="red"><b>NOTE:</b> This API is experimental and
            might change in incompatible ways in the next
            release.</font>
            
            </summary>
            <since> 2.9
            
            </since>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewLongRange(System.String,System.Int32,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that filters a <code>long</code>
            range using the given <a href="NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewLongRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that queries a <code>long</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewIntRange(System.String,System.Int32,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that filters a <code>int</code>
            range using the given <a href="NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewIntRange(System.String,System.ValueType,System.ValueType,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that queries a <code>int</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewDoubleRange(System.String,System.Int32,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that filters a <code>double</code>
            range using the given <a href="NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewDoubleRange(System.String,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that queries a <code>double</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewFloatRange(System.String,System.Int32,System.Single,System.Single,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that filters a <code>float</code>
            range using the given <a href="NumericRangeQuery.html#precisionStepDesc"><code>precisionStep</code></a>.
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.NewFloatRange(System.String,System.Single,System.Single,System.Boolean,System.Boolean)">
            <summary> Factory that creates a <code>NumericRangeFilter</code>, that queries a <code>float</code>
            range using the default <code>precisionStep</code> {@link NumericUtils#PRECISION_STEP_DEFAULT} (4).
            You can have half-open ranges (which are in fact &lt;/&#8804; or &gt;/&#8805; queries)
            by setting the min or max value to <code>null</code>. By setting inclusive to false, it will
            match all documents excluding the bounds, with inclusive on, the boundaries are hits, too.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.GetField">
            <summary>Returns the field name for this filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.IncludesMin">
            <summary>Returns <code>true</code> if the lower endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.IncludesMax">
            <summary>Returns <code>true</code> if the upper endpoint is inclusive </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.GetMin">
            <summary>Returns the lower value of this range filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.NumericRangeFilter.GetMax">
            <summary>Returns the upper value of this range filter </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.MultiValueSource">
            <summary>This class wraps another ValueSource, but protects
            against accidental double RAM usage in FieldCache when
            a composite reader is passed to {@link #getValues}.
            
            <p/><b>NOTE</b>: this class adds a CPU penalty to every
            lookup, as it must resolve the incoming document to the
            right sub-reader using a binary search.<p/>
            
            </summary>
            <deprecated> This class is temporary, to ease the
            migration to segment-based searching. Please change your
            code to not pass composite readers to these APIs. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.TermVectorsTermsWriter.Fill(System.Int32)">
            <summary>Fills in no-term-vectors for all docs we haven't seen
            since the last doc that had term vectors. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.MultiReader">
            <summary>An IndexReader which reads multiple indexes, appending their content.
            
            </summary>
            <version>  $Id: MultiReader.java 782406 2009-06-07 16:31:18Z mikemccand $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.#ctor(Lucene.Net.Index.IndexReader[])">
            <summary> <p/>Construct a MultiReader aggregating the named set of (sub)readers.
            Directory locking for delete, undeleteAll, and setNorm operations is
            left to the subreaders. <p/>
            <p/>Note that all subreaders are closed if this Multireader is closed.<p/>
            </summary>
            <param name="subReaders">set of (sub)readers
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.#ctor(Lucene.Net.Index.IndexReader[],System.Boolean)">
            <summary> <p/>Construct a MultiReader aggregating the named set of (sub)readers.
            Directory locking for delete, undeleteAll, and setNorm operations is
            left to the subreaders. <p/>
            </summary>
            <param name="closeSubReaders">indicates whether the subreaders should be closed
            when this MultiReader is closed
            </param>
            <param name="subReaders">set of (sub)readers
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.Reopen">
            <summary> Tries to reopen the subreaders.
            <br/>
            If one or more subreaders could be re-opened (i. e. subReader.reopen() 
            returned a new instance != subReader), then a new MultiReader instance 
            is returned, otherwise this instance is returned.
            <p/>
            A re-opened instance might share one or more subreaders with the old 
            instance. Index modification operations result in undefined behavior
            when performed before the old instance is closed.
            (see {@link IndexReader#Reopen()}).
            <p/>
            If subreaders are shared, then the reference count of those
            readers is increased to ensure that the subreaders remain open
            until the last referring reader is closed.
            
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error  </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.Clone">
            <summary> Clones the subreaders.
            (see {@link IndexReader#clone()}).
            <br/>
            <p/>
            If subreaders are shared, then the reference count of those
            readers is increased to ensure that the subreaders remain open
            until the last referring reader is closed.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.DoReopen(System.Boolean)">
            <summary> If clone is true then we clone each of the subreaders</summary>
            <param name="doClone">
            </param>
            <returns> New IndexReader, or same one (this) if
            reopen/clone is not necessary
            </returns>
            <throws>  CorruptIndexException </throws>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.DoCommit">
            <deprecated> 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.IsCurrent">
            <summary> Checks recursively if all subreaders are up to date. </summary>
        </member>
        <member name="M:Lucene.Net.Index.MultiReader.GetVersion">
            <summary>Not implemented.</summary>
            <throws>  UnsupportedOperationException </throws>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsPositionsConsumer.AddPosition(System.Int32,System.Byte[],System.Int32,System.Int32)">
            <summary>Add a new position &amp; payload.  If payloadLength > 0
            you must read those bytes from the IndexInput. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsPositionsConsumer.Finish">
            <summary>Called when we are done adding positions &amp; payloads </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsPositionsWriter.AddPosition(System.Int32,System.Byte[],System.Int32,System.Int32)">
            <summary>Add a new position &amp; payload </summary>
        </member>
        <member name="M:Lucene.Net.Index.FormatPostingsPositionsWriter.Finish">
            <summary>Called when we are done adding positions &amp; payloads </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsWriter.AddRawDocuments(Lucene.Net.Store.IndexInput,System.Int32[],System.Int32)">
            <summary>Bulk write a contiguous series of documents.  The
            lengths array is the length (in bytes) of each raw
            document.  The stream IndexInput is the
            fieldsStream from which we should bulk-copy all
            bytes. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldsReader">
            <summary> Class responsible for access to stored document fields.
            <p/>
            It uses &lt;segment&gt;.fdt and &lt;segment&gt;.fdx; files.
            
            </summary>
            <version>  $Id: FieldsReader.java 801344 2009-08-05 18:05:06Z yonik $
            </version>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.Clone">
            <summary>Returns a cloned FieldsReader that shares open
            IndexInputs with the original one.  It is the caller's
            job not to close the original FieldsReader until all
            clones are called (eg, currently SegmentReader manages
            this logic). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.EnsureOpen">
            <throws>  AlreadyClosedException if this FieldsReader is closed </throws>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.Close">
            <summary> Closes the underlying {@link Lucene.Net.Store.IndexInput} streams, including any ones associated with a
            lazy implementation of a Field.  This means that the Fields values will not be accessible.
            
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.RawDocs(System.Int32[],System.Int32,System.Int32)">
            <summary>Returns the length in bytes of each raw document in a
            contiguous range of length numDocs starting with
            startDocID.  Returns the IndexInput (the fieldStream),
            already seeked to the starting point for startDocID.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.SkipField(System.Boolean,System.Boolean)">
            <summary> Skip the field.  We still have to read some of the information about the field, but can skip past the actual content.
            This will have the most payoff on large fields.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldsReader.LazyField">
            <summary> A Lazy implementation of Fieldable that differs loading of fields until asked for, instead of when the Document is
            loaded.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.LazyField.BinaryValue">
            <summary>The value of the field in Binary, or null.  If null, the Reader value,
            String value, or TokenStream value is used. Exactly one of stringValue(), 
            readerValue(), binaryValue(), and tokenStreamValue() must be set. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.LazyField.ReaderValue">
            <summary>The value of the field as a Reader, or null.  If null, the String value,
            binary value, or TokenStream value is used.  Exactly one of stringValue(), 
            readerValue(), binaryValue(), and tokenStreamValue() must be set. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.LazyField.TokenStreamValue">
            <summary>The value of the field as a TokenStream, or null.  If null, the Reader value,
            String value, or binary value is used. Exactly one of stringValue(), 
            readerValue(), binaryValue(), and tokenStreamValue() must be set. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldsReader.LazyField.StringValue">
            <summary>The value of the field as a String, or null.  If null, the Reader value,
            binary value, or TokenStream value is used.  Exactly one of stringValue(), 
            readerValue(), binaryValue(), and tokenStreamValue() must be set. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocInverter">
            <summary>This is a DocFieldConsumer that inverts each field,
            separately, from a Document, and accepts a
            InvertedTermsConsumer to process those terms. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.LengthFilter">
            <summary> Removes words that are too long or too short from the stream.
            
            
            </summary>
            <version>  $Id: LengthFilter.java 807201 2009-08-24 13:22:34Z markrmiller $
            </version>
        </member>
        <member name="M:Lucene.Net.Analysis.LengthFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32)">
            <summary> Build a filter that removes words that are too long or too
            short from the text.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.LengthFilter.IncrementToken">
            <summary> Returns the next input Token whose term() is the right len</summary>
        </member>
        <member name="T:Lucene.Net.Util.ToStringUtils">
            <summary> Helper methods to ease implementing {@link Object#toString()}.</summary>
        </member>
        <member name="M:Lucene.Net.Util.ToStringUtils.Boost(System.Single)">
            <summary>for printing boost only if not 1.0 </summary>
        </member>
        <member name="T:Lucene.Net.Search.Spans.TermSpans">
            <summary> Expert:
            Public for extension only
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Sort">
            <summary> Encapsulates sort criteria for returned hits.
            
            <p/>The fields used to determine sort order must be carefully chosen.
            Documents must contain a single term in such a field,
            and the value of the term should indicate the document's relative position in
            a given sort order.  The field must be indexed, but should not be tokenized,
            and does not need to be stored (unless you happen to want it back with the
            rest of your document data).  In other words:
            
            <p/><code>document.add (new Field ("byNumber", Integer.toString(x), Field.Store.NO, Field.Index.NOT_ANALYZED));</code><p/>
            
            
            <p/><h3>Valid Types of Values</h3>
            
            <p/>There are four possible kinds of term values which may be put into
            sorting fields: Integers, Longs, Floats, or Strings.  Unless
            {@link SortField SortField} objects are specified, the type of value
            in the field is determined by parsing the first term in the field.
            
            <p/>Integer term values should contain only digits and an optional
            preceding negative sign.  Values must be base 10 and in the range
            <code>Integer.MIN_VALUE</code> and <code>Integer.MAX_VALUE</code> inclusive.
            Documents which should appear first in the sort
            should have low value integers, later documents high values
            (i.e. the documents should be numbered <code>1..n</code> where
            <code>1</code> is the first and <code>n</code> the last).
            
            <p/>Long term values should contain only digits and an optional
            preceding negative sign.  Values must be base 10 and in the range
            <code>Long.MIN_VALUE</code> and <code>Long.MAX_VALUE</code> inclusive.
            Documents which should appear first in the sort
            should have low value integers, later documents high values.
            
            <p/>Float term values should conform to values accepted by
            {@link Float Float.valueOf(String)} (except that <code>NaN</code>
            and <code>Infinity</code> are not supported).
            Documents which should appear first in the sort
            should have low values, later documents high values.
            
            <p/>String term values can contain any valid String, but should
            not be tokenized.  The values are sorted according to their
            {@link Comparable natural order}.  Note that using this type
            of term value has higher memory requirements than the other
            two types.
            
            <p/><h3>Object Reuse</h3>
            
            <p/>One of these objects can be
            used multiple times and the sort order changed between usages.
            
            <p/>This class is thread safe.
            
            <p/><h3>Memory Usage</h3>
            
            <p/>Sorting uses of caches of term values maintained by the
            internal HitQueue(s).  The cache is static and contains an integer
            or float array of length <code>IndexReader.maxDoc()</code> for each field
            name for which a sort is performed.  In other words, the size of the
            cache in bytes is:
            
            <p/><code>4 * IndexReader.maxDoc() * (# of different fields actually used to sort)</code>
            
            <p/>For String fields, the cache is larger: in addition to the
            above array, the value of every term in the field is kept in memory.
            If there are many unique terms in the field, this could
            be quite large.
            
            <p/>Note that the size of the cache is not affected by how many
            fields are in the index and <i>might</i> be used to sort - only by
            the ones actually used to sort a result set.
            
            <p/>Created: Feb 12, 2004 10:53:57 AM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: Sort.java 795179 2009-07-17 18:23:30Z mikemccand $
            </version>
        </member>
        <member name="F:Lucene.Net.Search.Sort.RELEVANCE">
            <summary> Represents sorting by computed relevance. Using this sort criteria returns
            the same results as calling
            {@link Searcher#Search(Query) Searcher#search()}without a sort criteria,
            only with slightly more overhead.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.Sort.INDEXORDER">
            <summary>Represents sorting by index order. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor">
            <summary> Sorts by computed relevance. This is the same sort criteria as calling
            {@link Searcher#Search(Query) Searcher#search()}without a sort criteria,
            only with slightly more overhead.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor(System.String)">
            <summary> Sorts by the terms in <code>field</code> then by index order (document
            number). The type of value in <code>field</code> is determined
            automatically.
            
            </summary>
            <seealso cref="F:Lucene.Net.Search.SortField.AUTO">
            </seealso>
            <deprecated> Please specify the type explicitly by
            first creating a {@link SortField} and then use {@link
            #Sort(SortField)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor(System.String,System.Boolean)">
            <summary> Sorts possibly in reverse by the terms in <code>field</code> then by
            index order (document number). The type of value in <code>field</code> is
            determined automatically.
            
            </summary>
            <seealso cref="F:Lucene.Net.Search.SortField.AUTO">
            </seealso>
            <deprecated> Please specify the type explicitly by
            first creating a {@link SortField} and then use {@link
            #Sort(SortField)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor(System.String[])">
            <summary> Sorts in succession by the terms in each field. The type of value in
            <code>field</code> is determined automatically.
            
            </summary>
            <seealso cref="F:Lucene.Net.Search.SortField.AUTO">
            </seealso>
            <deprecated> Please specify the type explicitly by
            first creating {@link SortField}s and then use {@link
            #Sort(SortField[])}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor(Lucene.Net.Search.SortField)">
            <summary>Sorts by the criteria in the given SortField. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.#ctor(Lucene.Net.Search.SortField[])">
            <summary>Sorts in succession by the criteria in each SortField. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.SetSort(System.String)">
            <summary> Sets the sort to the terms in <code>field</code> then by index order
            (document number).
            </summary>
            <deprecated> Please specify the type explicitly by
            first creating a {@link SortField} and then use {@link
            #SetSort(SortField)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.SetSort(System.String,System.Boolean)">
            <summary> Sets the sort to the terms in <code>field</code> possibly in reverse,
            then by index order (document number).
            </summary>
            <deprecated> Please specify the type explicitly by
            first creating a {@link SortField} and then use {@link
            #SetSort(SortField)}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.SetSort(System.String[])">
            <summary>Sets the sort to the terms in each field in succession.</summary>
            <deprecated> Please specify the type explicitly by
            first creating {@link SortField}s and then use {@link
            #SetSort(SortField[])} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Sort.SetSort(Lucene.Net.Search.SortField)">
            <summary>Sets the sort to the given criteria. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.SetSort(Lucene.Net.Search.SortField[])">
            <summary>Sets the sort to the given criteria in succession. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.GetSort">
            <summary> Representation of the sort criteria.</summary>
            <returns> Array of SortField objects used in this sort criteria
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.Sort.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Sort.GetHashCode">
            <summary>Returns a hash code value for this object. </summary>
        </member>
        <member name="T:Lucene.Net.Search.ScoreDocComparator_Fields">
            <summary> Expert: Compares two ScoreDoc objects for sorting.
            
            <p/>Created: Feb 3, 2004 9:00:16 AM 
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: ScoreDocComparator.java 738219 2009-01-27 20:15:21Z mikemccand $
            </version>
            <deprecated> use {@link FieldComparator}
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.ScoreDocComparator_Fields.RELEVANCE">
            <summary>Special comparator for sorting hits according to computed relevance (document score). </summary>
        </member>
        <member name="F:Lucene.Net.Search.ScoreDocComparator_Fields.INDEXORDER">
            <summary>Special comparator for sorting hits according to index order (document number). </summary>
        </member>
        <member name="T:Lucene.Net.Search.PrefixQuery">
            <summary>A Query that matches documents containing terms with a specified prefix. A PrefixQuery
            is built by QueryParser for input like <code>app*</code>.
            
            <p/>This query uses the {@link
            MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}
            rewrite method. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.PrefixQuery.#ctor(Lucene.Net.Index.Term)">
            <summary>Constructs a query for terms starting with <code>prefix</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PrefixQuery.GetPrefix">
            <summary>Returns the prefix of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.PrefixQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldValueHitQueue">
            <summary> Expert: A hit queue for sorting by hits by terms in more than one field.
            Uses <code>FieldCache.DEFAULT</code> for maintaining
            internal term lookup tables.
            
            This class will not resolve SortField.AUTO types, and expects the type
            of all SortFields used for construction to already have been resolved. 
            {@link SortField#DetectFieldType(IndexReader, String)} is a utility method which
            may be used for field type detection.
            
            <b>NOTE:</b> This API is experimental and might change in
            incompatible ways in the next release.
            
            </summary>
            <since> 2.9
            </since>
            <version>  $Id:
            </version>
            <seealso cref="M:Lucene.Net.Search.Searcher.Search(Lucene.Net.Search.Query,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            </seealso>
            <seealso cref="T:Lucene.Net.Search.FieldCache">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FieldValueHitQueue.Create(Lucene.Net.Search.SortField[],System.Int32)">
            <summary> Creates a hit queue sorted by the given list of fields.
            
            <p/><b>NOTE</b>: The instances returned by this method
            pre-allocate a full array of length <code>numHits</code>.
            
            </summary>
            <param name="fields">SortField array we are sorting by in priority order (highest
            priority first); cannot be <code>null</code> or empty
            </param>
            <param name="size">The number of hits to retain. Must be greater than zero.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="F:Lucene.Net.Search.FieldValueHitQueue.fields">
            <summary>Stores the sort criteria being used. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldValueHitQueue.FillFields(Lucene.Net.Search.FieldValueHitQueue.Entry)">
            <summary> Given a queue Entry, creates a corresponding FieldDoc
            that contains the values used to sort the given document.
            These values are not the raw values out of the index, but the internal
            representation of them. This is so the given search hit can be collated by
            a MultiSearcher with other search hits.
            
            </summary>
            <param name="entry">The Entry used to create a FieldDoc
            </param>
            <returns> The newly created FieldDoc
            </returns>
            <seealso cref="M:Lucene.Net.Search.Searchable.Search(Lucene.Net.Search.Weight,Lucene.Net.Search.Filter,System.Int32,Lucene.Net.Search.Sort)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.FieldValueHitQueue.GetFields">
            <summary>Returns the SortFields being used by this hit queue. </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldValueHitQueue.OneComparatorFieldValueHitQueue">
            <summary> An implementation of {@link FieldValueHitQueue} which is optimized in case
            there is just one comparator.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldValueHitQueue.OneComparatorFieldValueHitQueue.LessThan(System.Object,System.Object)">
            <summary> Returns whether <code>a</code> is less relevant than <code>b</code>.</summary>
            <param name="a">ScoreDoc
            </param>
            <param name="b">ScoreDoc
            </param>
            <returns> <code>true</code> if document <code>a</code> should be sorted after document <code>b</code>.
            </returns>
        </member>
        <member name="T:Lucene.Net.Search.FieldValueHitQueue.MultiComparatorsFieldValueHitQueue">
            <summary> An implementation of {@link FieldValueHitQueue} which is optimized in case
            there is more than one comparator.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldComparatorSource">
            <summary> Provides a {@link FieldComparator} for custom field sorting.
            
            <b>NOTE:</b> This API is experimental and might change in
            incompatible ways in the next release.
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldComparatorSource.NewComparator(System.String,System.Int32,System.Int32,System.Boolean)">
            <summary> Creates a comparator for the field in the given index.
            
            </summary>
            <param name="fieldname">Name of the field to create comparator for.
            </param>
            <returns> FieldComparator.
            </returns>
            <throws>  IOException </throws>
            <summary>           If an error occurs reading the index.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.FieldCacheTermsFilter">
            <summary> A {@link Filter} that only accepts documents whose single
            term value in the specified field is contained in the
            provided set of allowed terms.
            
            <p/>
            
            This is the same functionality as TermsFilter (from
            contrib/queries), except this filter requires that the
            field contains only a single term for all documents.
            Because of drastically different implementations, they
            also have different performance characteristics, as
            described below.
            
            <p/>
            
            The first invocation of this filter on a given field will
            be slower, since a {@link FieldCache.StringIndex} must be
            created.  Subsequent invocations using the same field
            will re-use this cache.  However, as with all
            functionality based on {@link FieldCache}, persistent RAM
            is consumed to hold the cache, and is not freed until the
            {@link IndexReader} is closed.  In contrast, TermsFilter
            has no persistent RAM consumption.
            
            
            <p/>
            
            With each search, this filter translates the specified
            set of Terms into a private {@link OpenBitSet} keyed by
            term number per unique {@link IndexReader} (normally one
            reader per segment).  Then, during matching, the term
            number for each docID is retrieved from the cache and
            then checked for inclusion using the {@link OpenBitSet}.
            Since all testing is done using RAM resident data
            structures, performance should be very fast, most likely
            fast enough to not require further caching of the
            DocIdSet for each possible combination of terms.
            However, because docIDs are simply scanned linearly, an
            index with a great many small documents may find this
            linear scan too costly.
            
            <p/>
            
            In contrast, TermsFilter builds up an {@link OpenBitSet},
            keyed by docID, every time it's created, by enumerating
            through all matching docs using {@link TermDocs} to seek
            and scan through each term's docID list.  While there is
            no linear scan of all docIDs, besides the allocation of
            the underlying array in the {@link OpenBitSet}, this
            approach requires a number of "disk seeks" in proportion
            to the number of terms, which can be exceptionally costly
            when there are cache misses in the OS's IO cache.
            
            <p/>
            
            Generally, this filter will be slower on the first
            invocation for a given field, but subsequent invocations,
            even if you change the allowed set of Terms, should be
            faster than TermsFilter, especially as the number of
            Terms being matched increases.  If you are matching only
            a very small number of terms, and those terms in turn
            match a very small number of documents, TermsFilter may
            perform faster.
            
            <p/>
            
            Which filter is best is very application dependent.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheTermsFilter.FieldCacheTermsFilterDocIdSet.IsCacheable">
            <summary>This DocIdSet implementation is cacheable. </summary>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheTermsFilter.FieldCacheTermsFilterDocIdSet.FieldCacheTermsFilterDocIdSetIterator.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheTermsFilter.FieldCacheTermsFilterDocIdSet.FieldCacheTermsFilterDocIdSetIterator.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.FieldCacheTermsFilter.FieldCacheTermsFilterDocIdSet.FieldCacheTermsFilterDocIdSetIterator.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.DefaultSimilarity">
            <summary>Expert: Default scoring implementation. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.ComputeNorm(System.String,Lucene.Net.Index.FieldInvertState)">
            <summary>Implemented as
            <code>state.getBoost()*lengthNorm(numTerms)</code>, where
            <code>numTerms</code> is {@link FieldInvertState#GetLength()} if {@link
            #setDiscountOverlaps} is false, else it's {@link
            FieldInvertState#GetLength()} - {@link
            FieldInvertState#GetNumOverlap()}.
            
            <p/><b>WARNING</b>: This API is new and experimental, and may suddenly
            change.<p/> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.LengthNorm(System.String,System.Int32)">
            <summary>Implemented as <code>1/sqrt(numTerms)</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.QueryNorm(System.Single)">
            <summary>Implemented as <code>1/sqrt(sumOfSquaredWeights)</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.Tf(System.Single)">
            <summary>Implemented as <code>sqrt(freq)</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.SloppyFreq(System.Int32)">
            <summary>Implemented as <code>1 / (distance + 1)</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.Idf(System.Int32,System.Int32)">
            <summary>Implemented as <code>log(numDocs/(docFreq+1)) + 1</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.Coord(System.Int32,System.Int32)">
            <summary>Implemented as <code>overlap / maxOverlap</code>. </summary>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.SetDiscountOverlaps(System.Boolean)">
            <summary>Determines whether overlap tokens (Tokens with
            0 position increment) are ignored when computing
            norm.  By default this is false, meaning overlap
            tokens are counted just like non-overlap tokens.
            
            <p/><b>WARNING</b>: This API is new and experimental, and may suddenly
            change.<p/>
            
            </summary>
            <seealso cref="!:computeNorm">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.DefaultSimilarity.GetDiscountOverlaps">
            <seealso cref="!:setDiscountOverlaps">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Messages.NLS">
            <summary> MessageBundles classes extend this class, to implement a bundle.
            
            For Native Language Support (NLS), system of software internationalization.
            
            This interface is similar to the NLS class in eclipse.osgi.util.NLS class -
            initializeMessages() method resets the values of all static strings, should
            only be called by classes that extend from NLS (see TestMessages.java for
            reference) - performs validation of all message in a bundle, at class load
            time - performs per message validation at runtime - see NLSTest.java for
            usage reference
            
            MessageBundle classes may subclass this type.
            </summary>
        </member>
        <member name="M:Lucene.Net.Messages.NLS.InitializeMessages(System.String,System.Type)">
            <summary> Initialize a given class with the message bundle Keys Should be called from
            a class that extends NLS in a static block at class load time.
            
            </summary>
            <param name="bundleName">Property file with that contains the message bundle
            </param>
            <param name="clazz">where constants will reside
            </param>
        </member>
        <member name="M:Lucene.Net.Messages.NLS.Load(System.Type)">
            <param name="clazz">
            </param>
        </member>
        <member name="M:Lucene.Net.Messages.NLS.LoadfieldValue(System.Reflection.FieldInfo,System.Boolean,System.Type)">
            <param name="field">
            </param>
            <param name="isFieldAccessible">
            </param>
        </member>
        <member name="M:Lucene.Net.Messages.NLS.ValidateMessage(System.String,System.Type)">
            <param name="key">- Message Key
            </param>
        </member>
        <member name="M:Lucene.Net.Messages.NLS.IPriviligedAction.Run">
            <summary>
            Performs the priviliged action.
            </summary>
            <returns>A value that may represent the result of the action.</returns>
        </member>
        <member name="T:Lucene.Net.Index.TermInfosWriter">
            <summary>This stores a monotonically increasing set of &lt;Term, TermInfo&gt; pairs in a
            Directory.  A TermInfos can be written once, in order.  
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.TermInfosWriter.FORMAT">
            <summary>The file format version, a negative number. </summary>
        </member>
        <member name="F:Lucene.Net.Index.TermInfosWriter.indexInterval">
            <summary>Expert: The fraction of terms in the "dictionary" which should be stored
            in RAM.  Smaller values use more memory, but make searching slightly
            faster, while larger values use less memory and make searching slightly
            slower.  Searching is typically not dominated by dictionary lookup, so
            tweaking this is rarely useful.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.TermInfosWriter.skipInterval">
            <summary>Expert: The fraction of {@link TermDocs} entries stored in skip tables,
            used to accellerate {@link TermDocs#SkipTo(int)}.  Larger values result in
            smaller indexes, greater acceleration, but fewer accelerable cases, while
            smaller values result in bigger indexes, less acceleration and more
            accelerable cases. More detailed experiments would be useful here. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.TermInfosWriter.maxSkipLevels">
            <summary>Expert: The maximum number of skip levels. Smaller values result in 
            slightly smaller indexes, but slower skipping in big posting lists.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosWriter.Add(System.Int32,System.Byte[],System.Int32,Lucene.Net.Index.TermInfo)">
            <summary>Adds a new &lt;fieldNumber, termBytes&gt;, TermInfo> pair to the set.
            Term must be lexicographically greater than all previous Terms added.
            TermInfo pointers must be positive and greater than all previous.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosWriter.Close">
            <summary>Called to complete TermInfos creation. </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermInfosReader">
            <summary>This stores a monotonically increasing set of &lt;Term, TermInfo&gt; pairs in a
            Directory.  Pairs are accessed either by Term or by ordinal position the
            set.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.Size">
            <summary>Returns the number of term/value pairs in the set. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.GetIndexOffset(Lucene.Net.Index.Term)">
            <summary>Returns the offset of the greatest index entry which is less than or equal to term.</summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.Get(Lucene.Net.Index.Term)">
            <summary>Returns the TermInfo for a Term in the set, or null. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.Get(Lucene.Net.Index.Term,System.Boolean)">
            <summary>Returns the TermInfo for a Term in the set, or null. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.GetPosition(Lucene.Net.Index.Term)">
            <summary>Returns the position of a Term in the set or -1. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.Terms">
            <summary>Returns an enumeration of all the Terms and TermInfos in the set. </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermInfosReader.Terms(Lucene.Net.Index.Term)">
            <summary>Returns an enumeration of terms starting at or after the named term. </summary>
        </member>
        <member name="T:Lucene.Net.Index.TermInfosReader.ThreadResources">
            <summary> Per-thread resources managed by ThreadLocal</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.Next">
            <summary>Increments the enumeration to the next element.  True if one exists.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.ScanTo(Lucene.Net.Index.Term)">
            <summary>Optimized scan, without allocating new terms. 
            Return number of invocations to next(). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.Term">
            <summary>Returns the current Term in the enumeration.
            Initially invalid, valid after next() called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.Prev">
            <summary>Returns the previous Term enumerated. Initially null.</summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.TermInfo">
            <summary>Returns the current TermInfo in the enumeration.
            Initially invalid, valid after next() called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.TermInfo(Lucene.Net.Index.TermInfo)">
            <summary>Sets the argument to the current TermInfo in the enumeration.
            Initially invalid, valid after next() called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.DocFreq">
            <summary>Returns the docFreq from the current TermInfo in the enumeration.
            Initially invalid, valid after next() called for the first time.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentTermEnum.Close">
            <summary>Closes the enumeration to further activity, freeing resources. </summary>
        </member>
        <member name="T:Lucene.Net.Documents.NumberTools">
            <summary> Provides support for converting longs to Strings, and back again. The strings
            are structured so that lexicographic sorting order is preserved.
            
            <p/>
            That is, if l1 is less than l2 for any two longs l1 and l2, then
            NumberTools.longToString(l1) is lexicographically less than
            NumberTools.longToString(l2). (Similarly for "greater than" and "equals".)
            
            <p/>
            This class handles <b>all</b> long values (unlike
            {@link Lucene.Net.Documents.DateField}).
            
            </summary>
            <deprecated> For new indexes use {@link NumericUtils} instead, which
            provides a sortable binary representation (prefix encoded) of numeric
            values.
            To index and efficiently query numeric values use {@link NumericField}
            and {@link NumericRangeQuery}.
            This class is included for use with existing
            indices and will be removed in a future release.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.NumberTools.MIN_STRING_VALUE">
            <summary> Equivalent to longToString(Long.MIN_VALUE)</summary>
        </member>
        <member name="F:Lucene.Net.Documents.NumberTools.MAX_STRING_VALUE">
            <summary> Equivalent to longToString(Long.MAX_VALUE)</summary>
        </member>
        <member name="F:Lucene.Net.Documents.NumberTools.STR_SIZE">
            <summary> The length of (all) strings returned by {@link #longToString}</summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumberTools.LongToString(System.Int64)">
            <summary> Converts a long to a String suitable for indexing.</summary>
        </member>
        <member name="M:Lucene.Net.Documents.NumberTools.StringToLong(System.String)">
            <summary> Converts a String that was returned by {@link #longToString} back to a
            long.
            
            </summary>
            <throws>  IllegalArgumentException </throws>
            <summary>             if the input is null
            </summary>
            <throws>  NumberFormatException </throws>
            <summary>             if the input does not parse (it was not a String returned by
            longToString()).
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.FieldSelectorResult">
            <summary>  Provides information about what should be done with this Field 
            
            
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.LOAD">
            <summary> Load this {@link Field} every time the {@link Document} is loaded, reading in the data as it is encountered.
            {@link Document#GetField(String)} and {@link Document#GetFieldable(String)} should not return null.
            <p/>
            {@link Document#Add(Fieldable)} should be called by the Reader.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.LAZY_LOAD">
            <summary> Lazily load this {@link Field}.  This means the {@link Field} is valid, but it may not actually contain its data until
            invoked.  {@link Document#GetField(String)} SHOULD NOT BE USED.  {@link Document#GetFieldable(String)} is safe to use and should
            return a valid instance of a {@link Fieldable}.
            <p/>
            {@link Document#Add(Fieldable)} should be called by the Reader.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.NO_LOAD">
            <summary> Do not load the {@link Field}.  {@link Document#GetField(String)} and {@link Document#GetFieldable(String)} should return null.
            {@link Document#Add(Fieldable)} is not called.
            <p/>
            {@link Document#Add(Fieldable)} should not be called by the Reader.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.LOAD_AND_BREAK">
            <summary> Load this field as in the {@link #LOAD} case, but immediately return from {@link Field} loading for the {@link Document}.  Thus, the
            Document may not have its complete set of Fields.  {@link Document#GetField(String)} and {@link Document#GetFieldable(String)} should
            both be valid for this {@link Field}
            <p/>
            {@link Document#Add(Fieldable)} should be called by the Reader.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.LOAD_FOR_MERGE">
            <summary> Behaves much like {@link #LOAD} but does not uncompress any compressed data.  This is used for internal purposes.
            {@link Document#GetField(String)} and {@link Document#GetFieldable(String)} should not return null.
            <p/>
            {@link Document#Add(Fieldable)} should be called by
            the Reader.
            </summary>
            <deprecated> This is an internal option only, and is
            no longer needed now that {@link CompressionTools}
            is used for field compression.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.SIZE">
            <summary>Expert:  Load the size of this {@link Field} rather than its value.
            Size is measured as number of bytes required to store the field == bytes for a binary or any compressed value, and 2*chars for a String value.
            The size is stored as a binary value, represented as an int in a byte[], with the higher order byte first in [0]
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.FieldSelectorResult.SIZE_AND_BREAK">
            <summary>Expert: Like {@link #SIZE} but immediately break from the field loading loop, i.e., stop loading further fields, after the size is loaded </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.KeywordTokenizer">
            <summary> Emits the entire input as a single token.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.KeywordTokenizer.Next(Lucene.Net.Analysis.Token)">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.KeywordTokenizer.Next">
            <deprecated> Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Analysis.CharacterCache">
            <summary> Replacement for Java 1.5 Character.valueOf()</summary>
            <deprecated> Move to Character.valueOf() in 3.0
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.CharacterCache.ValueOf(System.Char)">
            <summary> Returns a Character instance representing the given char value
            
            </summary>
            <param name="c">a char value
            </param>
            <returns> a Character representation of the given char value.
            </returns>
        </member>
        <member name="T:Lucene.Net.Store.MMapDirectory">
            <summary>File-based {@link Directory} implementation that uses
            mmap for reading, and {@link
            SimpleFSDirectory.SimpleFSIndexOutput} for writing.
            
            <p/><b>NOTE</b>: memory mapping uses up a portion of the
            virtual memory address space in your process equal to the
            size of the file being mapped.  Before using this class,
            be sure your have plenty of virtual address space, e.g. by
            using a 64 bit JRE, or a 32 bit JRE with indexes that are
            guaranteed to fit within the address space.
            On 32 bit platforms also consult {@link #setMaxChunkSize}
            if you have problems with mmap failing because of fragmented
            address space. If you get an OutOfMemoryException, it is recommened
            to reduce the chunk size, until it works.
            
            <p/>Due to <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4724038">
            this bug</a> in Sun's JRE, MMapDirectory's {@link IndexInput#close}
            is unable to close the underlying OS file handle.  Only when GC
            finally collects the underlying objects, which could be quite
            some time later, will the file handle be closed.
            
            <p/>This will consume additional transient disk usage: on Windows,
            attempts to delete or overwrite the files will result in an
            exception; on other platforms, which typically have a &quot;delete on
            last close&quot; semantics, while such operations will succeed, the bytes
            are still consuming space on disk.  For many applications this
            limitation is not a problem (e.g. if you have plenty of disk space,
            and you don't rely on overwriting files on Windows) but it's still
            an important limitation to be aware of.
            
            <p/>This class supplies the workaround mentioned in the bug report
            (disabled by default, see {@link #setUseUnmap}), which may fail on
            non-Sun JVMs. It forcefully unmaps the buffer on close by using
            an undocumented internal cleanup functionality.
            {@link #UNMAP_SUPPORTED} is <code>true</code>, if the workaround
            can be enabled (with no guarantees).
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.#ctor(System.IO.FileInfo,Lucene.Net.Store.LockFactory)">
            <summary>Create a new MMapDirectory for the named location.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <param name="lockFactory">the lock factory to use, or null for the default.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.#ctor(System.IO.DirectoryInfo,Lucene.Net.Store.LockFactory)">
            <summary>Create a new MMapDirectory for the named location.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <param name="lockFactory">the lock factory to use, or null for the default.
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.#ctor(System.IO.FileInfo)">
            <summary>Create a new MMapDirectory for the named location and the default lock factory.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.#ctor(System.IO.DirectoryInfo)">
            <summary>Create a new MMapDirectory for the named location and the default lock factory.
            
            </summary>
            <param name="path">the path of the directory
            </param>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.#ctor">
            <deprecated> 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Store.MMapDirectory.UNMAP_SUPPORTED">
            <summary> <code>true</code>, if this platform supports unmapping mmaped files.</summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.SetUseUnmap(System.Boolean)">
            <summary> This method enables the workaround for unmapping the buffers
            from address space after closing {@link IndexInput}, that is
            mentioned in the bug report. This hack may fail on non-Sun JVMs.
            It forcefully unmaps the buffer on close by using
            an undocumented internal cleanup functionality.
            <p/><b>NOTE:</b> Enabling this is completely unsupported
            by Java and may lead to JVM crashs if <code>IndexInput</code>
            is closed while another thread is still accessing it (SIGSEGV).
            </summary>
            <throws>  IllegalArgumentException if {@link #UNMAP_SUPPORTED} </throws>
            <summary> is <code>false</code> and the workaround cannot be enabled.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.GetUseUnmap">
            <summary> Returns <code>true</code>, if the unmap workaround is enabled.</summary>
            <seealso cref="!:setUseUnmap">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.CleanMapping(System.IO.MemoryStream)">
            <summary> Try to unmap the buffer, this method silently fails if no support
            for that in the JVM. On Windows, this leads to the fact,
            that mmapped files cannot be modified or deleted.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.SetMaxChunkSize(System.Int32)">
            <summary> Sets the maximum chunk size (default is {@link Integer#MAX_VALUE} for
            64 bit JVMs and 256 MiBytes for 32 bit JVMs) used for memory mapping.
            Especially on 32 bit platform, the address space can be very fragmented,
            so large index files cannot be mapped.
            Using a lower chunk size makes the directory implementation a little
            bit slower (as the correct chunk must be resolved on each seek)
            but the chance is higher that mmap does not fail. On 64 bit
            Java platforms, this parameter should always be {@link Integer#MAX_VALUE},
            as the adress space is big enough.
            </summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.GetMaxChunkSize">
            <summary> Returns the current mmap chunk size.</summary>
            <seealso cref="!:setMaxChunkSize">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.OpenInput(System.String,System.Int32)">
            <summary>Creates an IndexInput for the file with the given name. </summary>
        </member>
        <member name="M:Lucene.Net.Store.MMapDirectory.CreateOutput(System.String)">
            <summary>Creates an IndexOutput for the file with the given name. </summary>
        </member>
        <member name="T:Lucene.Net.Search.QueryFilter">
            <summary>Constrains search results to only match those which also match a provided
            query.  Results are cached, so that searches after the first on the same
            index using this filter are much faster.
            
            </summary>
            <version>  $Id: QueryFilter.java 528298 2007-04-13 00:59:28Z hossman $
            </version>
            <deprecated> use a CachingWrapperFilter with QueryWrapperFilter
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.QueryFilter.#ctor(Lucene.Net.Search.Query)">
            <summary>Constructs a filter which only matches documents matching
            <code>query</code>.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.PrefixTermEnum">
            <summary> Subclass of FilteredTermEnum for enumerating all terms that match the
            specified prefix filter term.
            <p/>
            Term enumerations are always ordered by Term.compareTo().  Each term in
            the enumeration is greater than all that precede it.
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Payloads.MinPayloadFunction">
            <summary> Calculates the minimum payload seen
            
            
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Hits">
            <summary> A ranked list of documents, used to hold search results.
            <p/>
            <b>Caution:</b> Iterate only over the hits needed. Iterating over all hits is
            generally not desirable and may be the source of performance issues. If you
            need to iterate over many or all hits, consider using the search method that
            takes a {@link HitCollector}.
            <p/>
            <p/>
            <b>Note:</b> Deleting matching documents concurrently with traversing the
            hits, might, when deleting hits that were not yet retrieved, decrease
            {@link #Length()}. In such case,
            {@link java.util.ConcurrentModificationException
            ConcurrentModificationException} is thrown when accessing hit <code>n</code>
            &gt; current_{@link #Length()} (but <code>n</code> &lt; {@link #Length()}
            _at_start).
            
            </summary>
            <deprecated> see {@link Searcher#Search(Query, int)},
            {@link Searcher#Search(Query, Filter, int)} and
            {@link Searcher#Search(Query, Filter, int, Sort)}:<br/>
            
            <pre>
            TopDocs topDocs = searcher.Search(query, numHits);
            ScoreDoc[] hits = topDocs.scoreDocs;
            for (int i = 0; i &lt; hits.Length; i++) {
            int docId = hits[i].doc;
            Document d = searcher.Doc(docId);
            // do something with current hit
            ...
            </pre>
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.Hits.GetMoreDocs(System.Int32)">
            <summary> Tries to add new documents to hitDocs.
            Ensures that the hit numbered <code>min</code> has been retrieved.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Hits.Length">
            <summary>Returns the total number of hits available in this set. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Hits.Doc(System.Int32)">
            <summary>Returns the stored fields of the n<sup>th</sup> document in this set.
            <p/>Documents are cached, so that repeated requests for the same element may
            return the same Document object.
            </summary>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Search.Hits.Score(System.Int32)">
            <summary>Returns the score for the n<sup>th</sup> document in this set. </summary>
        </member>
        <member name="M:Lucene.Net.Search.Hits.Id(System.Int32)">
            <summary>Returns the id for the n<sup>th</sup> document in this set.
            Note that ids may change when the index changes, so you cannot
            rely on the id to be stable.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Hits.Iterator">
            <summary> Returns a {@link HitIterator} to navigate the Hits.  Each item returned
            from {@link Iterator#next()} is a {@link Hit}.
            <p/>
            <b>Caution:</b> Iterate only over the hits needed.  Iterating over all
            hits is generally not desirable and may be the source of
            performance issues. If you need to iterate over many or all hits, consider
            using a search method that takes a {@link HitCollector}.
            <p/>
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.ConstantScoreQuery">
            <summary> A query that wraps a filter and simply returns a constant score equal to the
            query boost for every document in the filter.
            
            
            </summary>
            <version>  $Id: ConstantScoreQuery.java 807180 2009-08-24 12:26:43Z markrmiller $
            </version>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.GetFilter">
            <summary>Returns the encapsulated filter </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.ToString(System.String)">
            <summary>Prints a user-readable version of this query. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.GetHashCode">
            <summary>Returns a hash code value for this object. </summary>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.ConstantScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.ConstantScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ConstantScoreQuery.ConstantScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Index.Payload">
            <summary>  A Payload is metadata that can be stored together with each occurrence 
            of a term. This metadata is stored inline in the posting list of the
            specific term.  
            <p/>
            To store payloads in the index a {@link TokenStream} has to be used that
            produces payload data.
            <p/>
            Use {@link TermPositions#GetPayloadLength()} and {@link TermPositions#GetPayload(byte[], int)}
            to retrieve the payloads from the index.<br/>
            
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.Payload.data">
            <summary>the byte array containing the payload data </summary>
        </member>
        <member name="F:Lucene.Net.Index.Payload.offset">
            <summary>the offset within the byte array </summary>
        </member>
        <member name="F:Lucene.Net.Index.Payload.length">
            <summary>the length of the payload data </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.#ctor">
            <summary>Creates an empty payload and does not allocate a byte array. </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.#ctor(System.Byte[])">
            <summary> Creates a new payload with the the given array as data.
            A reference to the passed-in array is held, i. e. no 
            copy is made.
            
            </summary>
            <param name="data">the data of this payload
            </param>
        </member>
        <member name="M:Lucene.Net.Index.Payload.#ctor(System.Byte[],System.Int32,System.Int32)">
            <summary> Creates a new payload with the the given array as data. 
            A reference to the passed-in array is held, i. e. no 
            copy is made.
            
            </summary>
            <param name="data">the data of this payload
            </param>
            <param name="offset">the offset in the data byte array
            </param>
            <param name="length">the length of the data
            </param>
        </member>
        <member name="M:Lucene.Net.Index.Payload.SetData(System.Byte[])">
            <summary> Sets this payloads data. 
            A reference to the passed-in array is held, i. e. no 
            copy is made.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.SetData(System.Byte[],System.Int32,System.Int32)">
            <summary> Sets this payloads data. 
            A reference to the passed-in array is held, i. e. no 
            copy is made.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.GetData">
            <summary> Returns a reference to the underlying byte array
            that holds this payloads data.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.GetOffset">
            <summary> Returns the offset in the underlying byte array </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.Length">
            <summary> Returns the length of the payload data. </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.ByteAt(System.Int32)">
            <summary> Returns the byte at the given index.</summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.ToByteArray">
            <summary> Allocates a new byte array, copies the payload data into it and returns it. </summary>
        </member>
        <member name="M:Lucene.Net.Index.Payload.CopyTo(System.Byte[],System.Int32)">
            <summary> Copies the payload data to a byte array.
            
            </summary>
            <param name="target">the target byte array
            </param>
            <param name="targetOffset">the offset in the target byte array
            </param>
        </member>
        <member name="M:Lucene.Net.Index.Payload.Clone">
            <summary> Clones this payload by creating a copy of the underlying
            byte array.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.FieldReaderException">
            <summary> 
            
            
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldReaderException.#ctor">
            <summary> Constructs a new runtime exception with <code>null</code> as its
            detail message.  The cause is not initialized, and may subsequently be
            initialized by a call to {@link #innerException}.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.FieldReaderException.#ctor(System.Exception)">
            <summary> Constructs a new runtime exception with the specified cause and a
            detail message of <tt>(cause==null &#63; null : cause.toString())</tt>
            (which typically contains the class and detail message of
            <tt>cause</tt>).  
            <p/>
            This constructor is useful for runtime exceptions
            that are little more than wrappers for other throwables.
            
            </summary>
            <param name="cause">the cause (which is saved for later retrieval by the
            {@link #InnerException()} method).  (A <tt>null</tt> value is
            permitted, and indicates that the cause is nonexistent or
            unknown.)
            </param>
            <since> 1.4
            </since>
        </member>
        <member name="M:Lucene.Net.Index.FieldReaderException.#ctor(System.String)">
            <summary> Constructs a new runtime exception with the specified detail message.
            The cause is not initialized, and may subsequently be initialized by a
            call to {@link #innerException}.
            
            </summary>
            <param name="message">the detail message. The detail message is saved for
            later retrieval by the {@link #getMessage()} method.
            </param>
        </member>
        <member name="M:Lucene.Net.Index.FieldReaderException.#ctor(System.String,System.Exception)">
            <summary> Constructs a new runtime exception with the specified detail message and
            cause.  <p/>Note that the detail message associated with
            <code>cause</code> is <i>not</i> automatically incorporated in
            this runtime exception's detail message.
            
            </summary>
            <param name="message">the detail message (which is saved for later retrieval
            by the {@link #getMessage()} method).
            </param>
            <param name="cause">  the cause (which is saved for later retrieval by the
            {@link #InnerException()} method).  (A <tt>null</tt> value is
            permitted, and indicates that the cause is nonexistent or
            unknown.)
            </param>
            <since> 1.4
            </since>
        </member>
        <member name="T:Lucene.Net.Index.DocFieldProcessor">
            <summary> This is a DocConsumer that gathers all fields under the
            same name, and calls per-field consumers to process field
            by field.  This class doesn't doesn't do any "real" work
            of its own: it just forwards the fields to a
            DocFieldConsumer.
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.Field">
            <summary>A field is a section of a Document.  Each field has two parts, a name and a
            value.  Values may be free text, provided as a String or as a Reader, or they
            may be atomic keywords, which are not further processed.  Such keywords may
            be used to represent dates, urls, etc.  Fields are optionally stored in the
            index, so that they may be returned with hits on the document.
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.StringValue">
            <summary>The value of the field as a String, or null.  If null, the Reader value or
            binary value is used.  Exactly one of stringValue(),
            readerValue(), and getBinaryValue() must be set. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.ReaderValue">
            <summary>The value of the field as a Reader, or null.  If null, the String value or
            binary value is used.  Exactly one of stringValue(),
            readerValue(), and getBinaryValue() must be set. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.BinaryValue">
            <summary>The value of the field in Binary, or null.  If null, the Reader value,
            or String value is used. Exactly one of stringValue(),
            readerValue(), and getBinaryValue() must be set.
            </summary>
            <deprecated> This method must allocate a new byte[] if
            the {@link AbstractField#GetBinaryOffset()} is non-zero
            or {@link AbstractField#GetBinaryLength()} is not the
            full length of the byte[]. Please use {@link
            AbstractField#GetBinaryValue()} instead, which simply
            returns the byte[].
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.Field.TokenStreamValue">
            <summary>The TokesStream for this field to be used when indexing, or null.  If null, the Reader value
            or String value is analyzed to produce the indexed tokens. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetValue(System.String)">
            <summary><p/>Expert: change the value of this field.  This can
            be used during indexing to re-use a single Field
            instance to improve indexing speed by avoiding GC cost
            of new'ing and reclaiming Field instances.  Typically
            a single {@link Document} instance is re-used as
            well.  This helps most on small documents.<p/>
            
            <p/>Each Field instance should only be used once
            within a single {@link Document} instance.  See <a
            href="http://wiki.apache.org/lucene-java/ImproveIndexingSpeed">ImproveIndexingSpeed</a>
            for details.<p/> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetValue(System.IO.TextReader)">
            <summary>Expert: change the value of this field.  See <a href="#setValue(java.lang.String)">setValue(String)</a>. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetValue(System.Byte[])">
            <summary>Expert: change the value of this field.  See <a href="#setValue(java.lang.String)">setValue(String)</a>. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetValue(System.Byte[],System.Int32,System.Int32)">
            <summary>Expert: change the value of this field.  See <a href="#setValue(java.lang.String)">setValue(String)</a>. </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetValue(Lucene.Net.Analysis.TokenStream)">
            <summary>Expert: change the value of this field.  See <a href="#setValue(java.lang.String)">setValue(String)</a>.</summary>
            <deprecated> use {@link #setTokenStream} 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Documents.Field.SetTokenStream(Lucene.Net.Analysis.TokenStream)">
            <summary>Expert: sets the token stream to be used for indexing and causes isIndexed() and isTokenized() to return true.
            May be combined with stored values from stringValue() or binaryValue() 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.String,Lucene.Net.Documents.Field.Store,Lucene.Net.Documents.Field.Index)">
            <summary> Create a field by specifying its name, value and how it will
            be saved in the index. Term vectors will not be stored in the index.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="value">The string to process
            </param>
            <param name="store">Whether <code>value</code> should be stored in the index
            </param>
            <param name="index">Whether the field should be indexed, and if so, if it should
            be tokenized before indexing 
            </param>
            <throws>  NullPointerException if name or value is <code>null</code> </throws>
            <throws>  IllegalArgumentException if the field is neither stored nor indexed  </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.String,Lucene.Net.Documents.Field.Store,Lucene.Net.Documents.Field.Index,Lucene.Net.Documents.Field.TermVector)">
            <summary> Create a field by specifying its name, value and how it will
            be saved in the index.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="value">The string to process
            </param>
            <param name="store">Whether <code>value</code> should be stored in the index
            </param>
            <param name="index">Whether the field should be indexed, and if so, if it should
            be tokenized before indexing 
            </param>
            <param name="termVector">Whether term vector should be stored
            </param>
            <throws>  NullPointerException if name or value is <code>null</code> </throws>
            <throws>  IllegalArgumentException in any of the following situations: </throws>
            <summary> <ul> 
            <li>the field is neither stored nor indexed</li> 
            <li>the field is not indexed but termVector is <code>TermVector.YES</code></li>
            </ul> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.Boolean,System.String,Lucene.Net.Documents.Field.Store,Lucene.Net.Documents.Field.Index,Lucene.Net.Documents.Field.TermVector)">
            <summary> Create a field by specifying its name, value and how it will
            be saved in the index.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="internName">Whether to .intern() name or not
            </param>
            <param name="value">The string to process
            </param>
            <param name="store">Whether <code>value</code> should be stored in the index
            </param>
            <param name="index">Whether the field should be indexed, and if so, if it should
            be tokenized before indexing 
            </param>
            <param name="termVector">Whether term vector should be stored
            </param>
            <throws>  NullPointerException if name or value is <code>null</code> </throws>
            <throws>  IllegalArgumentException in any of the following situations: </throws>
            <summary> <ul> 
            <li>the field is neither stored nor indexed</li> 
            <li>the field is not indexed but termVector is <code>TermVector.YES</code></li>
            </ul> 
            </summary>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.IO.TextReader)">
            <summary> Create a tokenized and indexed field that is not stored. Term vectors will
            not be stored.  The Reader is read only when the Document is added to the index,
            i.e. you may not close the Reader until {@link IndexWriter#AddDocument(Document)}
            has been called.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="reader">The reader with the content
            </param>
            <throws>  NullPointerException if name or reader is <code>null</code> </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.IO.TextReader,Lucene.Net.Documents.Field.TermVector)">
            <summary> Create a tokenized and indexed field that is not stored, optionally with 
            storing term vectors.  The Reader is read only when the Document is added to the index,
            i.e. you may not close the Reader until {@link IndexWriter#AddDocument(Document)}
            has been called.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="reader">The reader with the content
            </param>
            <param name="termVector">Whether term vector should be stored
            </param>
            <throws>  NullPointerException if name or reader is <code>null</code> </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,Lucene.Net.Analysis.TokenStream)">
            <summary> Create a tokenized and indexed field that is not stored. Term vectors will
            not be stored. This is useful for pre-analyzed fields.
            The TokenStream is read only when the Document is added to the index,
            i.e. you may not close the TokenStream until {@link IndexWriter#AddDocument(Document)}
            has been called.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="tokenStream">The TokenStream with the content
            </param>
            <throws>  NullPointerException if name or tokenStream is <code>null</code> </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,Lucene.Net.Analysis.TokenStream,Lucene.Net.Documents.Field.TermVector)">
            <summary> Create a tokenized and indexed field that is not stored, optionally with 
            storing term vectors.  This is useful for pre-analyzed fields.
            The TokenStream is read only when the Document is added to the index,
            i.e. you may not close the TokenStream until {@link IndexWriter#AddDocument(Document)}
            has been called.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="tokenStream">The TokenStream with the content
            </param>
            <param name="termVector">Whether term vector should be stored
            </param>
            <throws>  NullPointerException if name or tokenStream is <code>null</code> </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.Byte[],Lucene.Net.Documents.Field.Store)">
            <summary> Create a stored field with binary value. Optionally the value may be compressed.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="value">The binary value
            </param>
            <param name="store">How <code>value</code> should be stored (compressed or not)
            </param>
            <throws>  IllegalArgumentException if store is <code>Store.NO</code>  </throws>
        </member>
        <member name="M:Lucene.Net.Documents.Field.#ctor(System.String,System.Byte[],System.Int32,System.Int32,Lucene.Net.Documents.Field.Store)">
            <summary> Create a stored field with binary value. Optionally the value may be compressed.
            
            </summary>
            <param name="name">The name of the field
            </param>
            <param name="value">The binary value
            </param>
            <param name="offset">Starting offset in value where this Field's bytes are
            </param>
            <param name="length">Number of bytes to use for this Field, starting at offset
            </param>
            <param name="store">How <code>value</code> should be stored (compressed or not)
            </param>
            <throws>  IllegalArgumentException if store is <code>Store.NO</code>  </throws>
        </member>
        <member name="T:Lucene.Net.Documents.Field.Store">
            <summary>Specifies whether and how a field should be stored. </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Store.COMPRESS">
            <summary>Store the original field value in the index in a compressed form. This is
            useful for long documents and for binary valued fields.
            </summary>
            <deprecated> Please use {@link CompressionTools} instead.
            For string fields that were previously indexed and stored using compression,
            the new way to achieve this is: First add the field indexed-only (no store)
            and additionally using the same field name as a binary, stored field
            with {@link CompressionTools#compressString}.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Store.YES">
            <summary>Store the original field value in the index. This is useful for short texts
            like a document's title which should be displayed with the results. The
            value is stored in its original form, i.e. no analyzer is used before it is
            stored.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Store.NO">
            <summary>Do not store the field value in the index. </summary>
        </member>
        <member name="T:Lucene.Net.Documents.Field.Index">
            <summary>Specifies whether and how a field should be indexed. </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.NO">
            <summary>Do not index the field value. This field can thus not be searched,
            but one can still access its contents provided it is
            {@link Field.Store stored}. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.ANALYZED">
            <summary>Index the tokens produced by running the field's
            value through an Analyzer.  This is useful for
            common text. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.TOKENIZED">
            <deprecated> this has been renamed to {@link #ANALYZED} 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.NOT_ANALYZED">
            <summary>Index the field's value without using an Analyzer, so it can be searched.
            As no analyzer is used the value will be stored as a single term. This is
            useful for unique Ids like product numbers.
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.UN_TOKENIZED">
            <deprecated> This has been renamed to {@link #NOT_ANALYZED} 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.NOT_ANALYZED_NO_NORMS">
            <summary>Expert: Index the field's value without an Analyzer,
            and also disable the storing of norms.  Note that you
            can also separately enable/disable norms by calling
            {@link Field#setOmitNorms}.  No norms means that
            index-time field and document boosting and field
            length normalization are disabled.  The benefit is
            less memory usage as norms take up one byte of RAM
            per indexed field for every document in the index,
            during searching.  Note that once you index a given
            field <i>with</i> norms enabled, disabling norms will
            have no effect.  In other words, for this to have the
            above described effect on a field, all instances of
            that field must be indexed with NOT_ANALYZED_NO_NORMS
            from the beginning. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.NO_NORMS">
            <deprecated> This has been renamed to
            {@link #NOT_ANALYZED_NO_NORMS} 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Documents.Field.Index.ANALYZED_NO_NORMS">
            <summary>Expert: Index the tokens produced by running the
            field's value through an Analyzer, and also
            separately disable the storing of norms.  See
            {@link #NOT_ANALYZED_NO_NORMS} for what norms are
            and why you may want to disable them. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Documents.Field.TermVector">
            <summary>Specifies whether and how a field should have term vectors. </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.TermVector.NO">
            <summary>Do not store term vectors. </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.TermVector.YES">
            <summary>Store the term vectors of each document. A term vector is a list
            of the document's terms and their number of occurrences in that document. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Documents.Field.TermVector.WITH_POSITIONS">
            <summary> Store the term vector + token position information
            
            </summary>
            <seealso cref="F:Lucene.Net.Documents.Field.TermVector.YES">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Documents.Field.TermVector.WITH_OFFSETS">
            <summary> Store the term vector + Token offset information
            
            </summary>
            <seealso cref="F:Lucene.Net.Documents.Field.TermVector.YES">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Documents.Field.TermVector.WITH_POSITIONS_OFFSETS">
            <summary> Store the term vector + Token position and offset information
            
            </summary>
            <seealso cref="F:Lucene.Net.Documents.Field.TermVector.YES">
            </seealso>
            <seealso cref="F:Lucene.Net.Documents.Field.TermVector.WITH_POSITIONS">
            </seealso>
            <seealso cref="F:Lucene.Net.Documents.Field.TermVector.WITH_OFFSETS">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Analysis.WhitespaceAnalyzer">
            <summary>An Analyzer that uses {@link WhitespaceTokenizer}. </summary>
        </member>
        <member name="T:Lucene.Net.Util.IndexableBinaryStringTools">
            <summary> Provides support for converting byte sequences to Strings and back again.
            The resulting Strings preserve the original byte sequences' sort order.
            
            The Strings are constructed using a Base 8000h encoding of the original
            binary data - each char of an encoded String represents a 15-bit chunk
            from the byte sequence.  Base 8000h was chosen because it allows for all
            lower 15 bits of char to be used without restriction; the surrogate range 
            [U+D8000-U+DFFF] does not represent valid chars, and would require
            complicated handling to avoid them and allow use of char's high bit.
            
            Although unset bits are used as padding in the final char, the original
            byte sequence could contain trailing bytes with no set bits (null bytes):
            padding is indistinguishable from valid information.  To overcome this
            problem, a char is appended, indicating the number of encoded bytes in the
            final content char.
            
            This class's operations are defined over CharBuffers and ByteBuffers, to
            allow for wrapped arrays to be reused, reducing memory allocation costs for
            repeated operations.  Note that this class calls array() and arrayOffset()
            on the CharBuffers and ByteBuffers it uses, so only wrapped arrays may be
            used.  This class interprets the arrayOffset() and limit() values returned by
            its input buffers as beginning and end+1 positions on the wrapped array,
            resprectively; similarly, on the output buffer, arrayOffset() is the first
            position written to, and limit() is set to one past the final output array
            position.
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.GetEncodedLength(System.Collections.Generic.List{System.Byte})">
            <summary> Returns the number of chars required to encode the given byte sequence.
            
            </summary>
            <param name="original">The byte sequence to be encoded.  Must be backed by an array.
            </param>
            <returns> The number of chars required to encode the given byte sequence
            </returns>
            <throws>  IllegalArgumentException If the given ByteBuffer is not backed by an array </throws>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.GetDecodedLength(System.Collections.Generic.List{System.Char})">
            <summary> Returns the number of bytes required to decode the given char sequence.
            
            </summary>
            <param name="encoded">The char sequence to be encoded.  Must be backed by an array.
            </param>
            <returns> The number of bytes required to decode the given char sequence
            </returns>
            <throws>  IllegalArgumentException If the given CharBuffer is not backed by an array </throws>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.Encode(System.Collections.Generic.List{System.Byte},System.Collections.Generic.List{System.Char})">
            <summary> Encodes the input byte sequence into the output char sequence.  Before
            calling this method, ensure that the output CharBuffer has sufficient
            capacity by calling {@link #GetEncodedLength(java.nio.ByteBuffer)}.
            
            </summary>
            <param name="input">The byte sequence to encode
            </param>
            <param name="output">Where the char sequence encoding result will go.  The limit
            is set to one past the position of the final char.
            </param>
            <throws>  IllegalArgumentException If either the input or the output buffer </throws>
            <summary>  is not backed by an array
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.Decode(System.Collections.Generic.List{System.Char},System.Collections.Generic.List{System.Byte})">
            <summary> Decodes the input char sequence into the output byte sequence.  Before
            calling this method, ensure that the output ByteBuffer has sufficient
            capacity by calling {@link #GetDecodedLength(java.nio.CharBuffer)}.
            
            </summary>
            <param name="input">The char sequence to decode
            </param>
            <param name="output">Where the byte sequence decoding result will go.  The limit
            is set to one past the position of the final char.
            </param>
            <throws>  IllegalArgumentException If either the input or the output buffer </throws>
            <summary>  is not backed by an array
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.Decode(System.Collections.Generic.List{System.Char})">
            <summary> Decodes the given char sequence, which must have been encoded by
            {@link #Encode(java.nio.ByteBuffer)} or 
            {@link #Encode(java.nio.ByteBuffer, java.nio.CharBuffer)}.
            
            </summary>
            <param name="input">The char sequence to decode
            </param>
            <returns> A byte sequence containing the decoding result.  The limit
            is set to one past the position of the final char.
            </returns>
            <throws>  IllegalArgumentException If the input buffer is not backed by an </throws>
            <summary>  array
            </summary>
        </member>
        <member name="M:Lucene.Net.Util.IndexableBinaryStringTools.Encode(System.Collections.Generic.List{System.Byte})">
            <summary> Encodes the input byte sequence.
            
            </summary>
            <param name="input">The byte sequence to encode
            </param>
            <returns> A char sequence containing the encoding result.  The limit is set
            to one past the position of the final char.
            </returns>
            <throws>  IllegalArgumentException If the input buffer is not backed by an </throws>
            <summary>  array
            </summary>
        </member>
        <member name="T:Lucene.Net.Store.LockObtainFailedException">
            <summary> This exception is thrown when the <code>write.lock</code>
            could not be acquired.  This
            happens when a writer tries to open an index
            that another writer already has open.
            </summary>
            <seealso cref="!:Lock.obtain(long)">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.AlreadyClosedException">
            <summary> This exception is thrown when there is an attempt to
            access something that has already been closed.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.TimeLimitingCollector">
            <summary> The {@link TimeLimitingCollector} is used to timeout search requests that
            take longer than the maximum allowed search time limit. After this time is
            exceeded, the search thread is stopped by throwing a
            {@link TimeExceededException}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.TimeLimitingCollector.DEFAULT_RESOLUTION">
            <summary> Default timer resolution.</summary>
            <seealso cref="!:SetResolution(long)">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.TimeLimitingCollector.DEFAULT_GREEDY">
            <summary> Default for {@link #IsGreedy()}.</summary>
            <seealso cref="M:Lucene.Net.Search.TimeLimitingCollector.IsGreedy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.#ctor(Lucene.Net.Search.Collector,System.Int64)">
            <summary> Create a TimeLimitedCollector wrapper over another {@link Collector} with a specified timeout.</summary>
            <param name="collector">the wrapped {@link Collector}
            </param>
            <param name="timeAllowed">max time allowed for collecting hits after which {@link TimeExceededException} is thrown
            </param>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.GetResolution">
            <summary> Return the timer resolution.</summary>
            <seealso cref="!:SetResolution(long)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.SetResolution(System.UInt32)">
            <summary> Set the timer resolution.
            The default timer resolution is 20 milliseconds. 
            This means that a search required to take no longer than 
            800 milliseconds may be stopped after 780 to 820 milliseconds.
            <br/>Note that: 
            <ul>
            <li>Finer (smaller) resolution is more accurate but less efficient.</li>
            <li>Setting resolution to less than 5 milliseconds will be silently modified to 5 milliseconds.</li>
            <li>Setting resolution smaller than current resolution might take effect only after current 
            resolution. (Assume current resolution of 20 milliseconds is modified to 5 milliseconds, 
            then it can take up to 20 milliseconds for the change to have effect.</li>
            </ul>      
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.IsGreedy">
            <summary> Checks if this time limited collector is greedy in collecting the last hit.
            A non greedy collector, upon a timeout, would throw a {@link TimeExceededException} 
            without allowing the wrapped collector to collect current doc. A greedy one would 
            first allow the wrapped hit collector to collect current doc and only then 
            throw a {@link TimeExceededException}.
            </summary>
            <seealso cref="!:SetGreedy(boolean)">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.SetGreedy(System.Boolean)">
            <summary> Sets whether this time limited collector is greedy.</summary>
            <param name="greedy">true to make this time limited greedy
            </param>
            <seealso cref="M:Lucene.Net.Search.TimeLimitingCollector.IsGreedy">
            </seealso>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.Collect(System.Int32)">
            <summary> Calls {@link Collector#Collect(int)} on the decorated {@link Collector}
            unless the allowed time has passed, in which case it throws an exception.
            
            </summary>
            <throws>  TimeExceededException </throws>
            <summary>           if the time allowed has exceeded.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.TimerThread.#ctor">
            <summary> TimerThread provides a pseudo-clock service to all searching
            threads, so that they can count elapsed time with less overhead
            than repeatedly calling System.currentTimeMillis.  A single
            thread should be created to be used for all searches.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.TimerThread.GetMilliseconds">
            <summary> Get the timer value in milliseconds.</summary>
        </member>
        <member name="T:Lucene.Net.Search.TimeLimitingCollector.TimeExceededException">
            <summary>Thrown when elapsed search time exceeds allowed search time. </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.TimeExceededException.GetTimeAllowed">
            <summary>Returns allowed time (milliseconds). </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.TimeExceededException.GetTimeElapsed">
            <summary>Returns elapsed time (milliseconds). </summary>
        </member>
        <member name="M:Lucene.Net.Search.TimeLimitingCollector.TimeExceededException.GetLastDocCollected">
            <summary>Returns last doc(absolute doc id) that was collected when the search time exceeded. </summary>
        </member>
        <member name="T:Lucene.Net.Search.SortField">
            <summary> Stores information about how to sort documents by terms in an individual
            field.  Fields must be indexed in order to sort by them.
            
            <p/>Created: Feb 11, 2004 1:25:29 PM
            
            </summary>
            <since>   lucene 1.4
            </since>
            <version>  $Id: SortField.java 801344 2009-08-05 18:05:06Z yonik $
            </version>
            <seealso cref="T:Lucene.Net.Search.Sort">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Search.SortField.SCORE">
            <summary>Sort by document score (relevancy).  Sort values are Float and higher
            values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.DOC">
            <summary>Sort by document number (index order).  Sort values are Integer and lower
            values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.AUTO">
            <summary>Guess type of sort based on field contents.  A regular expression is used
            to look at the first term indexed for the field and determine if it
            represents an integer number, a floating point number, or just arbitrary
            string characters.
            </summary>
            <deprecated> Please specify the exact type, instead.
            Especially, guessing does <b>not</b> work with the new
            {@link NumericField} type.
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.SortField.STRING">
            <summary>Sort using term values as Strings.  Sort values are String and lower
            values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.INT">
            <summary>Sort using term values as encoded Integers.  Sort values are Integer and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.FLOAT">
            <summary>Sort using term values as encoded Floats.  Sort values are Float and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.LONG">
            <summary>Sort using term values as encoded Longs.  Sort values are Long and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.DOUBLE">
            <summary>Sort using term values as encoded Doubles.  Sort values are Double and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.SHORT">
            <summary>Sort using term values as encoded Shorts.  Sort values are Short and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.CUSTOM">
            <summary>Sort using a custom Comparator.  Sort values are any Comparable and
            sorting is done according to natural order. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.BYTE">
            <summary>Sort using term values as encoded Bytes.  Sort values are Byte and
            lower values are at the front. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.STRING_VAL">
            <summary>Sort using term values as Strings, but comparing by
            value (using String.compareTo) for all comparisons.
            This is typically slower than {@link #STRING}, which
            uses ordinals to do the sorting. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.FIELD_SCORE">
            <summary>Represents sorting by document score (relevancy). </summary>
        </member>
        <member name="F:Lucene.Net.Search.SortField.FIELD_DOC">
            <summary>Represents sorting by document number (index order). </summary>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String)">
            <summary>Creates a sort by terms in the given field where the type of term value
            is determined dynamically ({@link #AUTO AUTO}).
            </summary>
            <param name="field">Name of field to sort by, cannot be
            <code>null</code>.
            </param>
            <deprecated> Please specify the exact type instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, by terms in the given field where
            the type of term value is determined dynamically ({@link #AUTO AUTO}).
            </summary>
            <param name="field">Name of field to sort by, cannot be <code>null</code>.
            </param>
            <param name="reverse">True if natural order should be reversed.
            </param>
            <deprecated> Please specify the exact type instead.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,System.Int32)">
            <summary>Creates a sort by terms in the given field with the type of term
            values explicitly given.
            </summary>
            <param name="field"> Name of field to sort by.  Can be <code>null</code> if
            <code>type</code> is SCORE or DOC.
            </param>
            <param name="type">  Type of values in the terms.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,System.Int32,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, by terms in the given field with the
            type of term values explicitly given.
            </summary>
            <param name="field"> Name of field to sort by.  Can be <code>null</code> if
            <code>type</code> is SCORE or DOC.
            </param>
            <param name="type">  Type of values in the terms.
            </param>
            <param name="reverse">True if natural order should be reversed.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.Parser)">
            <summary>Creates a sort by terms in the given field, parsed
            to numeric values using a custom {@link FieldCache.Parser}.
            </summary>
            <param name="field"> Name of field to sort by.  Must not be null.
            </param>
            <param name="parser">Instance of a {@link FieldCache.Parser},
            which must subclass one of the existing numeric
            parsers from {@link FieldCache}. Sort type is inferred
            by testing which numeric parser the parser subclasses.
            </param>
            <throws>  IllegalArgumentException if the parser fails to </throws>
            <summary>  subclass an existing numeric parser, or field is null
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.Parser,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, by terms in the given field, parsed
            to numeric values using a custom {@link FieldCache.Parser}.
            </summary>
            <param name="field"> Name of field to sort by.  Must not be null.
            </param>
            <param name="parser">Instance of a {@link FieldCache.Parser},
            which must subclass one of the existing numeric
            parsers from {@link FieldCache}. Sort type is inferred
            by testing which numeric parser the parser subclasses.
            </param>
            <param name="reverse">True if natural order should be reversed.
            </param>
            <throws>  IllegalArgumentException if the parser fails to </throws>
            <summary>  subclass an existing numeric parser, or field is null
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,System.Globalization.CultureInfo)">
            <summary>Creates a sort by terms in the given field sorted
            according to the given locale.
            </summary>
            <param name="field"> Name of field to sort by, cannot be <code>null</code>.
            </param>
            <param name="locale">Locale of values in the field.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,System.Globalization.CultureInfo,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, by terms in the given field sorted
            according to the given locale.
            </summary>
            <param name="field"> Name of field to sort by, cannot be <code>null</code>.
            </param>
            <param name="locale">Locale of values in the field.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.SortComparatorSource)">
            <summary>Creates a sort with a custom comparison function.</summary>
            <param name="field">Name of field to sort by; cannot be <code>null</code>.
            </param>
            <param name="comparator">Returns a comparator for sorting hits.
            </param>
            <deprecated> use SortField (String field, FieldComparatorSource comparator)
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.FieldComparatorSource)">
            <summary>Creates a sort with a custom comparison function.</summary>
            <param name="field">Name of field to sort by; cannot be <code>null</code>.
            </param>
            <param name="comparator">Returns a comparator for sorting hits.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.SortComparatorSource,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, with a custom comparison function.</summary>
            <param name="field">Name of field to sort by; cannot be <code>null</code>.
            </param>
            <param name="comparator">Returns a comparator for sorting hits.
            </param>
            <param name="reverse">True if natural order should be reversed.
            </param>
            <deprecated> use SortField (String field, FieldComparatorSource comparator, boolean reverse)
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.#ctor(System.String,Lucene.Net.Search.FieldComparatorSource,System.Boolean)">
            <summary>Creates a sort, possibly in reverse, with a custom comparison function.</summary>
            <param name="field">Name of field to sort by; cannot be <code>null</code>.
            </param>
            <param name="comparator">Returns a comparator for sorting hits.
            </param>
            <param name="reverse">True if natural order should be reversed.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetField">
            <summary>Returns the name of the field.  Could return <code>null</code>
            if the sort is by SCORE or DOC.
            </summary>
            <returns> Name of field, possibly <code>null</code>.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetType">
            <summary>Returns the type of contents in the field.</summary>
            <returns> One of the constants SCORE, DOC, AUTO, STRING, INT or FLOAT.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetLocale">
            <summary>Returns the Locale by which term values are interpreted.
            May return <code>null</code> if no Locale was specified.
            </summary>
            <returns> Locale, or <code>null</code>.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetParser">
            <summary>Returns the instance of a {@link FieldCache} parser that fits to the given sort type.
            May return <code>null</code> if no parser was specified. Sorting is using the default parser then.
            </summary>
            <returns> An instance of a {@link FieldCache} parser, or <code>null</code>.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetReverse">
            <summary>Returns whether the sort should be reversed.</summary>
            <returns>  True if natural order should be reversed.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetFactory">
            <deprecated> use {@link #GetComparatorSource()}
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.SetUseLegacySearch(System.Boolean)">
            <summary> Use legacy IndexSearch implementation: search with a DirectoryReader rather
            than passing a single hit collector to multiple SegmentReaders.
            
            </summary>
            <param name="legacy">true for legacy behavior
            </param>
            <deprecated> will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetUseLegacySearch">
            <returns> if true, IndexSearch will use legacy sorting search implementation.
            eg. multiple Priority Queues.
            </returns>
            <deprecated> will be removed in Lucene 3.0.
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.SortField.Equals(System.Object)">
            <summary>Returns true if <code>o</code> is equal to this.  If a
            {@link SortComparatorSource} (deprecated) or {@link
            FieldCache.Parser} was provided, it must properly
            implement equals (unless a singleton is always used). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetHashCode">
            <summary>Returns true if <code>o</code> is equal to this.  If a
            {@link SortComparatorSource} (deprecated) or {@link
            FieldCache.Parser} was provided, it must properly
            implement hashCode (unless a singleton is always
            used). 
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.SortField.GetComparator(System.Int32,System.Int32)">
            <summary>Returns the {@link FieldComparator} to use for
            sorting.
            
            <b>NOTE:</b> This API is experimental and might change in
            incompatible ways in the next release.
            
            </summary>
            <param name="numHits">number of top hits the queue will store
            </param>
            <param name="sortPos">position of this SortField within {@link
            Sort}.  The comparator is primary if sortPos==0,
            secondary if sortPos==1, etc.  Some comparators can
            optimize themselves when they are the primary sort.
            </param>
            <returns> {@link FieldComparator} to use when sorting
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.SortField.DetectFieldType(Lucene.Net.Index.IndexReader,System.String)">
            <summary> Attempts to detect the given field type for an IndexReader.</summary>
            <deprecated>
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.ReqOptSumScorer">
            <summary>A Scorer for queries with a required part and an optional part.
            Delays skipTo() on the optional part until a score() is needed.
            <br/>
            This <code>Scorer</code> implements {@link Scorer#SkipTo(int)}.
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.ReqOptSumScorer.reqScorer">
            <summary>The scorers passed from the constructor.
            These are set to null as soon as their next() or skipTo() returns false.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.#ctor(Lucene.Net.Search.Scorer,Lucene.Net.Search.Scorer)">
            <summary>Construct a <code>ReqOptScorer</code>.</summary>
            <param name="reqScorer">The required scorer. This must match.
            </param>
            <param name="optScorer">The optional scorer. This is used for scoring only.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.Score">
            <summary>Returns the score of the current document matching the query.
            Initially invalid, until {@link #Next()} is called the first time.
            </summary>
            <returns> The score of the required scorer, eventually increased by the score
            of the optional scorer when it also matches the current document.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ReqOptSumScorer.Explain(System.Int32)">
            <summary>Explain the score of a document.
            TODO: Also show the total score.
            See BooleanScorer.explain() on how to do this.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.Function.FieldScoreQuery">
            <summary> A query that scores each document as the value of the numeric input field.
            <p/> 
            The query matches all documents, and scores each document according to the numeric 
            value of that field. 
            <p/>
            It is assumed, and expected, that:
            <ul>
            <li>The field used here is indexed, and has exactly 
            one token in every scored document.</li> 
            <li>Best if this field is un_tokenized.</li>
            <li>That token is parsable to the selected type.</li>
            </ul>
            <p/>  
            Combining this query in a FunctionQuery allows much freedom in affecting document scores.
            Note, that with this freedom comes responsibility: it is more than likely that the
            default Lucene scoring is superior in quality to scoring modified as explained here.
            However, in some cases, and certainly for research experiments, this capability may turn useful.
            <p/>
            When contructing this query, select the appropriate type. That type should match the data stored in the
            field. So in fact the "right" type should be selected before indexing. Type selection
            has effect on the RAM usage: 
            <ul>
            <li>{@link Type#BYTE} consumes 1 * maxDocs bytes.</li>
            <li>{@link Type#SHORT} consumes 2 * maxDocs bytes.</li>
            <li>{@link Type#INT} consumes 4 * maxDocs bytes.</li>
            <li>{@link Type#FLOAT} consumes 8 * maxDocs bytes.</li>
            </ul>
            <p/>
            <b>Caching:</b>
            Values for the numeric field are loaded once and cached in memory for further use with the same IndexReader. 
            To take advantage of this, it is extremely important to reuse index-readers or index-searchers, 
            otherwise, for instance if for each query a new index reader is opened, large penalties would be 
            paid for loading the field values into memory over and over again!
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.FieldScoreQuery.#ctor(System.String,Lucene.Net.Search.Function.FieldScoreQuery.Type)">
            <summary> Create a FieldScoreQuery - a query that scores each document as the value of the numeric input field.
            <p/>
            The <code>type</code> param tells how to parse the field string values into a numeric score value.
            </summary>
            <param name="field">the numeric field to be used.
            </param>
            <param name="type">the type of the field: either
            {@link Type#BYTE}, {@link Type#SHORT}, {@link Type#INT}, or {@link Type#FLOAT}. 
            </param>
        </member>
        <member name="T:Lucene.Net.Search.Function.FieldScoreQuery.Type">
            <summary> Type of score field, indicating how field values are interpreted/parsed.  
            <p/>
            The type selected at search search time should match the data stored in the field. 
            Different types have different RAM requirements: 
            <ul>
            <li>{@link #BYTE} consumes 1 * maxDocs bytes.</li>
            <li>{@link #SHORT} consumes 2 * maxDocs bytes.</li>
            <li>{@link #INT} consumes 4 * maxDocs bytes.</li>
            <li>{@link #FLOAT} consumes 8 * maxDocs bytes.</li>
            </ul>
            </summary>
        </member>
        <member name="F:Lucene.Net.Search.Function.FieldScoreQuery.Type.BYTE">
            <summary>field values are interpreted as numeric byte values. </summary>
        </member>
        <member name="F:Lucene.Net.Search.Function.FieldScoreQuery.Type.SHORT">
            <summary>field values are interpreted as numeric short values. </summary>
        </member>
        <member name="F:Lucene.Net.Search.Function.FieldScoreQuery.Type.INT">
            <summary>field values are interpreted as numeric int values. </summary>
        </member>
        <member name="F:Lucene.Net.Search.Function.FieldScoreQuery.Type.FLOAT">
            <summary>field values are interpreted as numeric float values. </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.Token">
            <summary> Describes the input token stream.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.kind">
            <summary> An integer that describes the kind of this token.  This numbering
            system is determined by JavaCCParser, and a table of these numbers is
            stored in the file ...Constants.java.
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.beginLine">
            <summary>The line number of the first character of this Token. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.beginColumn">
            <summary>The column number of the first character of this Token. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.endLine">
            <summary>The line number of the last character of this Token. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.endColumn">
            <summary>The column number of the last character of this Token. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.image">
            <summary> The string image of the token.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.next">
            <summary> A reference to the next regular (non-special) token from the input
            stream.  If this is the last token from the input stream, or if the
            token manager has not read tokens beyond this one, this field is
            set to null.  This is true only if this token is also a regular
            token.  Otherwise, see below for a description of the contents of
            this field.
            </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.Token.specialToken">
            <summary> This field is used to access special tokens that occur prior to this
            token, but after the immediately preceding regular (non-special) token.
            If there are no such special tokens, this field is set to null.
            When there are more than one such special token, this field refers
            to the last of these special tokens, which in turn refers to the next
            previous special token through its specialToken field, and so on
            until the first special token (whose specialToken field is null).
            The next fields of special tokens refer to other special tokens that
            immediately follow it (without an intervening regular token).  If there
            is no such token, this field is null.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.GetValue">
            <summary> An optional attribute value of the Token.
            Tokens which are not used as syntactic sugar will often contain
            meaningful values that will be used later on by the compiler or
            interpreter. This attribute value is often different from the image.
            Any subclass of Token that actually wants to return a non-null value can
            override this method as appropriate.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.#ctor">
            <summary> No-argument constructor</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.#ctor(System.Int32)">
            <summary> Constructs a new token for the specified Image.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.#ctor(System.Int32,System.String)">
            <summary> Constructs a new token for the specified Image and Kind.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.ToString">
            <summary> Returns the image.</summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.Token.NewToken(System.Int32,System.String)">
            <summary> Returns a new Token object, by default. However, if you want, you
            can create and return subclass objects based on the value of ofKind.
            Simply add the cases to the switch for all those special cases.
            For example, if you have a subclass of Token called IDToken that
            you want to create if ofKind is ID, simply add something like :
            
            case MyParserConstants.ID : return new IDToken(ofKind, image);
            
            to the following switch statement. Then you can cast matchedToken
            variable to the appropriate type and use sit in your lexical actions.
            </summary>
        </member>
        <member name="T:Lucene.Net.QueryParsers.FastCharStream">
            <summary>An efficient implementation of JavaCC's CharStream interface.  <p/>Note that
            this does not do line-number counting, but instead keeps track of the
            character position of the token in the input, as required by Lucene's {@link
            Lucene.Net.Analysis.Token} API. 
            
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.FastCharStream.#ctor(System.IO.TextReader)">
            <summary>Constructs from a Reader. </summary>
        </member>
        <member name="T:Lucene.Net.Index.StaleReaderException">
            <summary> This exception is thrown when an {@link IndexReader}
            tries to make changes to the index (via {@link
            IndexReader#deleteDocument}, {@link
            IndexReader#undeleteAll} or {@link IndexReader#setNorm})
            but changes have already been committed to the index
            since this reader was instantiated.  When this happens
            you must open a new reader on the current index to make
            the changes.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.IndexFileNames">
            <summary> Useful constants representing filenames and extensions used by lucene
            
            </summary>
            <version>  $rcs = ' $Id: Exp $ ' ;
            </version>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.SEGMENTS">
            <summary>Name of the index segment file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.SEGMENTS_GEN">
            <summary>Name of the generation reference file name </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.DELETABLE">
            <summary>Name of the index deletable file (only used in
            pre-lockless indices) 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.NORMS_EXTENSION">
            <summary>Extension of norms file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.FREQ_EXTENSION">
            <summary>Extension of freq postings file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.PROX_EXTENSION">
            <summary>Extension of prox postings file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.TERMS_EXTENSION">
            <summary>Extension of terms file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.TERMS_INDEX_EXTENSION">
            <summary>Extension of terms index file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.FIELDS_INDEX_EXTENSION">
            <summary>Extension of stored fields index file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.FIELDS_EXTENSION">
            <summary>Extension of stored fields file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.VECTORS_FIELDS_EXTENSION">
            <summary>Extension of vectors fields file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.VECTORS_DOCUMENTS_EXTENSION">
            <summary>Extension of vectors documents file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.VECTORS_INDEX_EXTENSION">
            <summary>Extension of vectors index file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.COMPOUND_FILE_EXTENSION">
            <summary>Extension of compound file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.COMPOUND_FILE_STORE_EXTENSION">
            <summary>Extension of compound file for doc store files</summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.DELETES_EXTENSION">
            <summary>Extension of deletes </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.FIELD_INFOS_EXTENSION">
            <summary>Extension of field infos </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.PLAIN_NORMS_EXTENSION">
            <summary>Extension of plain norms </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.SEPARATE_NORMS_EXTENSION">
            <summary>Extension of separate norms </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.GEN_EXTENSION">
            <summary>Extension of gen file </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.INDEX_EXTENSIONS">
            <summary> This array contains all filename extensions used by
            Lucene's index files, with two exceptions, namely the
            extension made up from <code>.f</code> + a number and
            from <code>.s</code> + a number.  Also note that
            Lucene's <code>segments_N</code> files do not have any
            filename extension.
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.INDEX_EXTENSIONS_IN_COMPOUND_FILE">
            <summary>File extensions that are added to a compound file
            (same as above, minus "del", "gen", "cfs"). 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.COMPOUND_EXTENSIONS">
            <summary>File extensions of old-style index files </summary>
        </member>
        <member name="F:Lucene.Net.Index.IndexFileNames.VECTOR_EXTENSIONS">
            <summary>File extensions for term vector support </summary>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileNames.FileNameFromGeneration(System.String,System.String,System.Int64)">
            <summary> Computes the full file name from base, extension and
            generation.  If the generation is -1, the file name is
            null.  If it's 0, the file name is 
            If it's > 0, the file name is 
            
            </summary>
            <param name="base">-- main part of the file name
            </param>
            <param name="extension">-- extension of the filename (including .)
            </param>
            <param name="gen">-- generation
            </param>
        </member>
        <member name="M:Lucene.Net.Index.IndexFileNames.IsDocStoreFile(System.String)">
            <summary> Returns true if the provided filename is one of the doc
            store files (ends with an extension in
            STORE_INDEX_EXTENSIONS).
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.StopAnalyzer">
            <summary> Filters {@link LetterTokenizer} with {@link LowerCaseFilter} and
            {@link StopFilter}.
            
            <a name="version"/>
            <p/>
            You must specify the required {@link Version} compatibility when creating
            StopAnalyzer:
            <ul>
            <li>As of 2.9, position increments are preserved</li>
            </ul>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.StopAnalyzer.ENGLISH_STOP_WORDS">
            <summary>An array containing some common English words that are not usually useful
            for searching. 
            </summary>
            <deprecated> Use {@link #ENGLISH_STOP_WORDS_SET} instead 
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Analysis.StopAnalyzer.ENGLISH_STOP_WORDS_SET">
            <summary>An unmodifiable set containing some common English words that are not usually useful
            for searching.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor">
            <summary>Builds an analyzer which removes words in
            ENGLISH_STOP_WORDS.
            </summary>
            <deprecated> Use {@link #StopAnalyzer(Version)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(Lucene.Net.Util.Version)">
            <summary> Builds an analyzer which removes words in ENGLISH_STOP_WORDS.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.Boolean)">
            <summary>Builds an analyzer which removes words in
            ENGLISH_STOP_WORDS.
            </summary>
            <param name="enablePositionIncrements">
            See {@link StopFilter#SetEnablePositionIncrements}
            </param>
            <deprecated> Use {@link #StopAnalyzer(Version)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>Builds an analyzer with the stop words from the given set.</summary>
            <deprecated> Use {@link #StopAnalyzer(Version, Set)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(Lucene.Net.Util.Version,System.Collections.Hashtable)">
            <summary>Builds an analyzer with the stop words from the given set.</summary>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.Collections.Hashtable,System.Boolean)">
            <summary>Builds an analyzer with the stop words from the given set.</summary>
            <param name="stopWords">Set of stop words
            </param>
            <param name="enablePositionIncrements">
            See {@link StopFilter#SetEnablePositionIncrements}
            </param>
            <deprecated> Use {@link #StopAnalyzer(Version, Set)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.String[])">
            <summary>Builds an analyzer which removes words in the provided array.</summary>
            <deprecated> Use {@link #StopAnalyzer(Set, boolean)} instead 
            </deprecated>
            <deprecated> Use {@link #StopAnalyzer(Version, Set)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.String[],System.Boolean)">
            <summary>Builds an analyzer which removes words in the provided array.</summary>
            <param name="stopWords">Array of stop words
            </param>
            <param name="enablePositionIncrements">
            See {@link StopFilter#SetEnablePositionIncrements}
            </param>
            <deprecated> Use {@link #StopAnalyzer(Version, Set)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>Builds an analyzer with the stop words from the given file.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(File)">
            </seealso>
            <deprecated> Use {@link #StopAnalyzer(Version, File)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.IO.FileInfo,System.Boolean)">
            <summary>Builds an analyzer with the stop words from the given file.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(File)">
            </seealso>
            <param name="stopwordsFile">File to load stop words from
            </param>
            <param name="enablePositionIncrements">
            See {@link StopFilter#SetEnablePositionIncrements}
            </param>
            <deprecated> Use {@link #StopAnalyzer(Version, File)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(Lucene.Net.Util.Version,System.IO.FileInfo)">
            <summary> Builds an analyzer with the stop words from the given file.
            
            </summary>
            <seealso cref="!:WordlistLoader.getWordSet(File)">
            </seealso>
            <param name="matchVersion">See <a href="#version">above</a>
            </param>
            <param name="stopwordsFile">File to load stop words from
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.IO.TextReader)">
            <summary>Builds an analyzer with the stop words from the given reader.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(Reader)">
            </seealso>
            <deprecated> Use {@link #StopAnalyzer(Version, Reader)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(System.IO.TextReader,System.Boolean)">
            <summary>Builds an analyzer with the stop words from the given reader.</summary>
            <seealso cref="!:WordlistLoader.GetWordSet(Reader)">
            </seealso>
            <param name="stopwords">Reader to load stop words from
            </param>
            <param name="enablePositionIncrements">
            See {@link StopFilter#SetEnablePositionIncrements}
            </param>
            <deprecated> Use {@link #StopAnalyzer(Version, Reader)} instead
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.#ctor(Lucene.Net.Util.Version,System.IO.TextReader)">
            <summary>Builds an analyzer with the stop words from the given reader. </summary>
            <seealso cref="!:WordlistLoader.GetWordSet(Reader)">
            </seealso>
            <param name="matchVersion">See <a href="#Version">above</a>
            </param>
            <param name="stopwords">Reader to load stop words from
            </param>
        </member>
        <member name="M:Lucene.Net.Analysis.StopAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>Filters LowerCaseTokenizer with StopFilter. </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.StopAnalyzer.SavedStreams">
            <summary>Filters LowerCaseTokenizer with StopFilter. </summary>
        </member>
        <member name="T:Lucene.Net.Store.SingleInstanceLockFactory">
            <summary> Implements {@link LockFactory} for a single in-process instance,
            meaning all locking will take place through this one instance.
            Only use this {@link LockFactory} when you are certain all
            IndexReaders and IndexWriters for a given index are running
            against a single shared in-process Directory instance.  This is
            currently the default locking for RAMDirectory.
            
            </summary>
            <seealso cref="T:Lucene.Net.Store.LockFactory">
            </seealso>
        </member>
        <member name="T:Lucene.Net.Store.NoSuchDirectoryException">
            <summary> This exception is thrown when you try to list a
            non-existent directory.
            </summary>
        </member>
        <member name="T:Lucene.Net.Search.ReqExclScorer">
            <summary>A Scorer for queries with a required subscorer
            and an excluding (prohibited) sub DocIdSetIterator.
            <br/>
            This <code>Scorer</code> implements {@link Scorer#SkipTo(int)},
            and it uses the skipTo() on the given scorers.
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.#ctor(Lucene.Net.Search.Scorer,Lucene.Net.Search.DocIdSetIterator)">
            <summary>Construct a <code>ReqExclScorer</code>.</summary>
            <param name="reqScorer">The scorer that must match, except where
            </param>
            <param name="exclDisi">indicates exclusion.
            </param>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.Next">
            <deprecated> use {@link #NextDoc()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.ToNonExcluded">
            <summary>Advance to non excluded doc.
            <br/>On entry:
            <ul>
            <li>reqScorer != null, </li>
            <li>exclScorer != null, </li>
            <li>reqScorer was advanced once via next() or skipTo() 
            and reqScorer.doc() may still be excluded.</li>
            </ul>
            Advances reqScorer a non excluded required doc, if any.
            </summary>
            <returns> true iff there is a non excluded required doc.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.Doc">
            <deprecated> use {@link #DocID()} instead. 
            </deprecated>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.Score">
            <summary>Returns the score of the current document matching the query.
            Initially invalid, until {@link #Next()} is called the first time.
            </summary>
            <returns> The score of the required scorer.
            </returns>
        </member>
        <member name="M:Lucene.Net.Search.ReqExclScorer.SkipTo(System.Int32)">
            <deprecated> use {@link #Advance(int)} instead. 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.Function.ReverseOrdFieldSource">
            <summary> Expert: obtains the ordinal of the field value from the default Lucene 
            {@link Lucene.Net.Search.FieldCache FieldCache} using getStringIndex()
            and reverses the order.
            <p/>
            The native lucene index order is used to assign an ordinal value for each field value.
            <p/>
            Field values (terms) are lexicographically ordered by unicode value, and numbered starting at 1.
            <br/>
            Example of reverse ordinal (rord):
            <br/>If there were only three field values: "apple","banana","pear"
            <br/>then rord("apple")=3, rord("banana")=2, ord("pear")=1
            <p/>
            WARNING: 
            rord() depends on the position in an index and can thus change 
            when other documents are inserted or deleted,
            or if a MultiSearcher is used. 
            
            <p/><font color="#FF0000">
            WARNING: The status of the <b>Search.Function</b> package is experimental. 
            The APIs introduced here might change in the future and will not be 
            supported anymore in such a case.</font>
            
            <p/><b>NOTE</b>: with the switch in 2.9 to segment-based
            searching, if {@link #getValues} is invoked with a
            composite (multi-segment) reader, this can easily cause
            double RAM usage for the values in the FieldCache.  It's
            best to switch your application to pass only atomic
            (single segment) readers to this API.  Alternatively, for
            a short-term fix, you could wrap your ValueSource using
            {@link MultiValueSource}, which costs more CPU per lookup
            but will not consume double the FieldCache RAM.<p/>
            </summary>
        </member>
        <member name="M:Lucene.Net.Search.Function.ReverseOrdFieldSource.#ctor(System.String)">
            <summary> Contructor for a certain field.</summary>
            <param name="field">field whose values reverse order is used.  
            </param>
        </member>
        <member name="T:Lucene.Net.Search.ExtendedFieldCache_old.ExtendedFieldCache_Fields">
            <summary> This interface is obsolete, use {@link FieldCache} instead.
            
            </summary>
            <deprecated> Use {@link FieldCache}, this will be removed in Lucene 3.0
            
            </deprecated>
        </member>
        <member name="F:Lucene.Net.Search.ExtendedFieldCache_old.ExtendedFieldCache_Fields.EXT_DEFAULT">
            <deprecated> Use {@link FieldCache#DEFAULT}; this will be removed in Lucene 3.0 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.ExtendedFieldCache_old.LongParser">
            <deprecated> Use {@link FieldCache.LongParser}, this will be removed in Lucene 3.0 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Search.ExtendedFieldCache_old.DoubleParser">
            <deprecated> Use {@link FieldCache.DoubleParser}, this will be removed in Lucene 3.0 
            </deprecated>
        </member>
        <member name="T:Lucene.Net.QueryParsers.TokenMgrError">
            <summary>Token Manager Error. </summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.TokenMgrError.LEXICAL_ERROR">
            <summary> Lexical error occurred.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.TokenMgrError.STATIC_LEXER_ERROR">
            <summary> An attempt was made to create a second instance of a static token manager.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.TokenMgrError.INVALID_LEXICAL_STATE">
            <summary> Tried to change to an invalid lexical state.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.TokenMgrError.LOOP_DETECTED">
            <summary> Detected (and bailed out of) an infinite loop in the token manager.</summary>
        </member>
        <member name="F:Lucene.Net.QueryParsers.TokenMgrError.errorCode">
            <summary> Indicates the reason why the exception is thrown. It will have
            one of the above 4 values.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.TokenMgrError.addEscapes(System.String)">
            <summary> Replaces unprintable characters by their escaped (or unicode escaped)
            equivalents in the given string
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.TokenMgrError.LexicalError(System.Boolean,System.Int32,System.Int32,System.Int32,System.String,System.Char)">
            <summary> Returns a detailed message for the Error when it is thrown by the
            token manager to indicate a lexical error.
            Parameters :
            EOFSeen     : indicates if EOF caused the lexical error
            curLexState : lexical state in which this error occurred
            errorLine   : line number when the error occurred
            errorColumn : column number when the error occurred
            errorAfter  : prefix that was seen before this error occurred
            curchar     : the offending character
            Note: You can customize the lexical error message by modifying this method.
            </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.TokenMgrError.#ctor">
            <summary>No arg constructor. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.TokenMgrError.#ctor(System.String,System.Int32)">
            <summary>Constructor with message and reason. </summary>
        </member>
        <member name="M:Lucene.Net.QueryParsers.TokenMgrError.#ctor(System.Boolean,System.Int32,System.Int32,System.Int32,System.String,System.Char,System.Int32)">
            <summary>Full Constructor. </summary>
        </member>
        <member name="P:Lucene.Net.QueryParsers.TokenMgrError.Message">
            <summary> You can also modify the body of this method to customize your error messages.
            For example, cases like LOOP_DETECTED and INVALID_LEXICAL_STATE are not
            of end-users concern, so you can return something like :
            
            "Internal Error : Please file a bug report .... "
            
            from this method for such cases in the release version of your parser.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.TermBuffer.SetPreUTF8Strings">
            <summary>Call this if the IndexInput passed to {@link #read}
            stores terms in the "modified UTF8" (pre LUCENE-510)
            format. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.SegmentMerger">
            <summary> The SegmentMerger class combines two or more Segments, represented by an IndexReader ({@link #add},
            into a single Segment.  After adding the appropriate readers, call the merge method to combine the 
            segments.
            <p/> 
            If the compoundFile flag is set, then the segments will be merged into a compound file.
            
            
            </summary>
            <seealso cref="!:merge">
            </seealso>
            <seealso cref="!:add">
            </seealso>
        </member>
        <member name="F:Lucene.Net.Index.SegmentMerger.MAX_RAW_MERGE_DOCS">
            <summary>Maximum number of contiguous documents to bulk-copy
            when merging stored fields 
            </summary>
        </member>
        <member name="F:Lucene.Net.Index.SegmentMerger.NORMS_HEADER">
            <summary>norms header placeholder </summary>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.#ctor(Lucene.Net.Store.Directory,System.String)">
            <summary>This ctor used only by test code.
            
            </summary>
            <param name="dir">The Directory to merge the other segments into
            </param>
            <param name="name">The name of the new segment
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.Add(Lucene.Net.Index.IndexReader)">
            <summary> Add an IndexReader to the collection of readers that are to be merged</summary>
            <param name="reader">
            </param>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.SegmentReader(System.Int32)">
            <summary> </summary>
            <param name="i">The index of the reader to return
            </param>
            <returns> The ith reader to be merged
            </returns>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.Merge">
            <summary> Merges the readers specified by the {@link #add} method into the directory passed to the constructor</summary>
            <returns> The number of documents that were merged
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.Merge(System.Boolean)">
            <summary> Merges the readers specified by the {@link #add} method
            into the directory passed to the constructor.
            </summary>
            <param name="mergeDocStores">if false, we will not merge the
            stored fields nor vectors files
            </param>
            <returns> The number of documents that were merged
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.CloseReaders">
            <summary> close all IndexReaders that have been added.
            Should not be called before merge().
            </summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.MergeFields">
            <summary> </summary>
            <returns> The number of documents in all of the readers
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.MergeVectors">
            <summary> Merge the TermVectors from each of the segments into the new one.</summary>
            <throws>  IOException </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.AppendPostings(Lucene.Net.Index.FormatPostingsTermsConsumer,Lucene.Net.Index.SegmentMergeInfo[],System.Int32)">
            <summary>Process postings from multiple segments all positioned on the
            same term. Writes out merged entries into freqOutput and
            the proxOutput streams.
            
            </summary>
            <param name="smis">array of segments
            </param>
            <param name="n">number of cells in the array actually occupied
            </param>
            <returns> number of documents across all segments where this term was found
            </returns>
            <throws>  CorruptIndexException if the index is corrupt </throws>
            <throws>  IOException if there is a low-level IO error </throws>
        </member>
        <member name="M:Lucene.Net.Index.SegmentMerger.CheckAbort.Work(System.Double)">
            <summary> Records the fact that roughly units amount of work
            have been done since this method was last called.
            When adding time-consuming code into SegmentMerger,
            you should test different values for units to ensure
            that the time in between calls to merge.checkAborted
            is up to ~ 1 second.
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.DocInverterPerThread">
            <summary>This is a DocFieldConsumer that inverts each field,
            separately, from a Document, and accepts a
            InvertedTermsConsumer to process those terms. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Index.ByteSliceWriter">
            <summary> Class to write byte streams into slices of shared
            byte[].  This is used by DocumentsWriter to hold the
            posting list for many terms in RAM.
            </summary>
        </member>
        <member name="M:Lucene.Net.Index.ByteSliceWriter.Init(System.Int32)">
            <summary> Set up the writer to write at address.</summary>
        </member>
        <member name="M:Lucene.Net.Index.ByteSliceWriter.WriteByte(System.Byte)">
            <summary>Write byte into byte slice stream </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.TokenWrapper">
            <summary> This class wraps a Token and supplies a single attribute instance
            where the delegate token can be replaced.
            </summary>
            <deprecated> Will be removed, when old TokenStream API is removed.
            </deprecated>
        </member>
        <member name="T:Lucene.Net.Analysis.Standard.StandardFilter">
            <summary>Normalizes tokens extracted with {@link StandardTokenizer}. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardFilter.#ctor(Lucene.Net.Analysis.TokenStream)">
            <summary>Construct filtering <i>in</i>. </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Standard.StandardFilter.IncrementToken">
            <summary>Returns the next token in the stream, or null at EOS.
            <p/>Removes <tt>'s</tt> from the end of words.
            <p/>Removes dots from acronyms.
            </summary>
        </member>
    </members>
</doc>
